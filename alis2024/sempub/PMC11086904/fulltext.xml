<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.3" xml:lang="en" article-type="research-article"><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-journalpublishing1.dtd?><?SourceDTD.Version 39.96?><?ConverterInfo.XSLTName jats2jats3.xsl?><?ConverterInfo.Version 1?><?subarticle pone.0302333.r001?><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS One</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-title-group><journal-title>PLOS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmcid">11086904</article-id><article-id pub-id-type="publisher-id">PONE-D-23-38302</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0302333</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Molecular Biology</subject><subj-group><subject>Molecular Biology Techniques</subject><subj-group><subject>Cloning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Molecular Biology Techniques</subject><subj-group><subject>Cloning</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Software Engineering</subject><subj-group><subject>Source Code</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Software Engineering</subject><subj-group><subject>Source Code</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Linguistics</subject><subj-group><subject>Grammar</subject><subj-group><subject>Syntax</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied Mathematics</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Simulation and Modeling</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Linguistics</subject><subj-group><subject>Semantics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Artificial Intelligence</subject><subj-group><subject>Machine Learning</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Data Management</subject><subj-group><subject>Data Visualization</subject><subj-group><subject>Infographics</subject><subj-group><subject>Graphs</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Software Engineering</subject><subj-group><subject>Computer Software</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Software Engineering</subject><subj-group><subject>Computer Software</subject></subj-group></subj-group></subj-group></article-categories><title-group><article-title>A novel code representation for detecting Java code clones using high-level and abstract compiled code representations</article-title><alt-title alt-title-type="running-head">A Novel Code representation for detecting Java semantic clones</alt-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" equal-contrib="yes"><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-7872-1877</contrib-id><name><surname>Quradaa</surname><given-names>Fahmi H.</given-names></name><role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role><role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role><role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing &#x02013; original draft</role><xref rid="aff001" ref-type="aff">
<sup>1</sup>
</xref><xref rid="aff002" ref-type="aff">
<sup>2</sup>
</xref><xref rid="cor001" ref-type="corresp">*</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Shahzad</surname><given-names>Sara</given-names></name><role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role><role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role><xref rid="aff001" ref-type="aff">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2732-1352</contrib-id><name><surname>Saeed</surname><given-names>Rashad</given-names></name><role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role><role content-type="http://credit.niso.org/contributor-roles/software/">Software</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff001" ref-type="aff">
<sup>1</sup>
</xref><xref rid="aff002" ref-type="aff">
<sup>2</sup>
</xref></contrib><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0443-6819</contrib-id><name><surname>Sufyan</surname><given-names>Mubarak M.</given-names></name><role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role><role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing &#x02013; review &#x00026; editing</role><xref rid="aff001" ref-type="aff">
<sup>1</sup>
</xref><xref rid="aff003" ref-type="aff">
<sup>3</sup>
</xref></contrib></contrib-group><aff id="aff001">
<label>1</label>
<addr-line>Department of Computer Science, University of Peshawar, Peshawar, Pakistan</addr-line>
</aff><aff id="aff002">
<label>2</label>
<addr-line>Department of Computer Science, Aden Community College, Aden, Yemen</addr-line>
</aff><aff id="aff003">
<label>3</label>
<addr-line>Department of Networks and Cyber Security, AlJanad University Of Science and Technology, Taiz, Yemen</addr-line>
</aff><contrib-group><contrib contrib-type="editor"><name><surname>Yun</surname><given-names>Unil</given-names></name><role>Editor</role><xref rid="edit1" ref-type="aff"/></contrib></contrib-group><aff id="edit1">
<addr-line>Sejong University, KOREA, REPUBLIC OF</addr-line>
</aff><author-notes><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><corresp id="cor001">* E-mail: <email>Qurada@uop.edu.pk</email></corresp></author-notes><pub-date pub-type="collection"><year>2024</year></pub-date><pub-date pub-type="epub"><day>10</day><month>5</month><year>2024</year></pub-date><volume>19</volume><issue>5</issue><elocation-id>e0302333</elocation-id><history><date date-type="received"><day>5</day><month>12</month><year>2023</year></date><date date-type="accepted"><day>2</day><month>4</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; 2024 Quradaa et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Quradaa et al</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="pone.0302333.pdf"/><abstract><p>In software development, it&#x02019;s common to reuse existing source code by copying and pasting, resulting in the proliferation of numerous code clones&#x02014;similar or identical code fragments&#x02014;that detrimentally affect software quality and maintainability. Although several techniques for code clone detection exist, many encounter challenges in effectively identifying semantic clones due to their inability to extract syntax and semantics information. Fewer techniques leverage low-level source code representations like bytecode or assembly for clone detection. This work introduces a novel code representation for identifying syntactic and semantic clones in Java source code. It integrates high-level features extracted from the Abstract Syntax Tree with low-level features derived from intermediate representations generated by static analysis tools, like the Soot framework. Leveraging this combined representation, fifteen machine-learning models are trained to effectively detect code clones. Evaluation on a large dataset demonstrates the models&#x02019; efficacy in accurately identifying semantic clones. Among these classifiers, ensemble classifiers, such as the LightGBM classifier, exhibit exceptional accuracy. Linearly combining features enhances the effectiveness of the models compared to multiplication and distance combination techniques. The experimental findings indicate that the proposed method can outperform the current clone detection techniques in detecting semantic clones.</p></abstract><funding-group><funding-statement>The author(s) received no specific funding for this work.</funding-statement></funding-group><counts><fig-count count="18"/><table-count count="6"/><page-count count="31"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>The dataset utilized in the present study can be accessed at the following link: <ext-link xlink:href="https://github.com/clonebench/BigCloneBench?tab=readme-ov-file" ext-link-type="uri">https://github.com/clonebench/BigCloneBench?tab=readme-ov-file</ext-link> and support file <xref rid="pone.0302333.s004" ref-type="supplementary-material">S4</xref>.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>The dataset utilized in the present study can be accessed at the following link: <ext-link xlink:href="https://github.com/clonebench/BigCloneBench?tab=readme-ov-file" ext-link-type="uri">https://github.com/clonebench/BigCloneBench?tab=readme-ov-file</ext-link> and support file <xref rid="pone.0302333.s004" ref-type="supplementary-material">S4</xref>.</p></notes></front><body><sec sec-type="intro" id="sec001"><title>1 Introduction</title><p>Reusing existing source code via copy and pasting, instead of rewriting a similar code from scratch, is a common practice in software development. This practice is favored for its convenience and its capacity to significantly reduce the time and effort required for software development [<xref rid="pone.0302333.ref001" ref-type="bibr">1</xref>]. However, this practice often leads to the emergence of similar or identical code fragments within the software system, typically termed code clones [<xref rid="pone.0302333.ref002" ref-type="bibr">2</xref>]. Previous research indicates that approximately 7% to 23% of the source code within a typical software system can be identified as cloned code [<xref rid="pone.0302333.ref003" ref-type="bibr">3</xref>, <xref rid="pone.0302333.ref004" ref-type="bibr">4</xref>].</p><p>Researchers categorize code clones into four types [<xref rid="pone.0302333.ref005" ref-type="bibr">5</xref>, <xref rid="pone.0302333.ref006" ref-type="bibr">6</xref>]. Types I, II, and III focus on textual similarities, while Type IV emphasizes functional or semantic resemblances. Type I clones are nearly identical, differing only in minor aspects like comments and formatting. Type II clones are syntactically identical with minor variations in identifiers and literals. Type III clones are syntactically equivalent with additional modifications. Type IV clones exhibit substantial dissimilarities in both text and syntax. Within spectrum of Type III and IV clones lies the &#x0201c;Twilight zone&#x0201d; [<xref rid="pone.0302333.ref007" ref-type="bibr">7</xref>], wherein clones are further classified based on syntactic similarity percentages as follows: Very Strongly Type-III (VST3) (90% to less than 100%), Strongly Type-III (ST3) (70% to less than 90%), Moderately Type-III (MT3) (50% to less than 70%), and Weakly Type-III/Type-IV (WT3/4) (less than 50%).</p><p>While code clones can accelerate the software development process, they have an inherent adverse impact on software quality, particularly concerning the maintainability and comprehensibility of source code [<xref rid="pone.0302333.ref008" ref-type="bibr">8</xref>]. Code clones can engender the propagation of bugs, irregularities in updates, inflated codebases, and contribute to the erosion of software architecture [<xref rid="pone.0302333.ref009" ref-type="bibr">9</xref>]. Consequently, many approaches for detecting code clones have been proposed in the literature. Generally, these existing techniques fall into six primary categories: text-based, token-based, syntax-based, semantic-based, metrics-based, and hybrid clone detection techniques [<xref rid="pone.0302333.ref005" ref-type="bibr">5</xref>, <xref rid="pone.0302333.ref010" ref-type="bibr">10</xref>&#x02013;<xref rid="pone.0302333.ref012" ref-type="bibr">12</xref>].</p><p>In the clone detection technique, the choice of source code representation serves as a critical factor that not only defines the upper limit for information extraction but also influences the model design which ultimately affects the final performance [<xref rid="pone.0302333.ref013" ref-type="bibr">13</xref>]. While many existing techniques primarily emphasize high-level representations of source code, they often neglect the corresponding low-level intermediate representations, like bytecode, assembly or other intermediary forms. Interestingly, source code fragments exhibiting syntactical differences but performing similar functions can produce comparable low-level intermediate representations. This suggests that intermediate representations (IRs) may uncover potential semantic clones, which are typically challenging to identify when relying only on high-level source code representations [<xref rid="pone.0302333.ref014" ref-type="bibr">14</xref>]. Therefore, the choice of code representation plays a crucial role in enhancing the efficiency of code clone detection techniques, especially in the identification of semantic clones [<xref rid="pone.0302333.ref015" ref-type="bibr">15</xref>]. Effective code representation should, therefore, facilitate the extraction of comprehensive syntactic and semantic features, ultimately improving the detection of both syntactic and semantic clones. Hence, there exists a pressing need for a more efficient method of representing code fragments to enable the extraction of comprehensive syntactic and semantic features.</p><p>In this work, a novel code representation is proposed to enhance the detection of semantic clones in Java source code. This approach utilizes machine learning techniques to more effectively identify similarities between clones. It integrates syntactic features extracted from the high-level representation of source code, the abstract syntax tree (AST), with semantic features derived from low-level abstract compiled-code representations. The process begins with preprocessing and compiling the target source code. Subsequently, syntactic features are extracted from the normalized source code, which has been transformed into an AST. Semantic features are then derived from the compiled file using various low-level representations generated by static code analysis tools. In this work, we focus on two specific IRs, namely Baf and Jimple, from the Soot framework, which provides four IRs for Java source code. The extracted syntactic and semantic features are combined to form a comprehensive representation of the source code. This integrated representation serves as the basis for training different machine learning classifiers, which will be used to detect code clones.</p><p>The contributions of this work are summarized as follows:</p><list list-type="bullet"><list-item><p>New integrated code representation: This work introduces a novel integrated code representation that combines high-level and low-level abstract compiled code representations for Java source code. To our knowledge, this is the first attempt to utilize features from both Baf and Jimple IRs to represent the syntactic and semantic features of Java source code fragments.</p></list-item><list-item><p>Generalized machine learning model: This work proposes a generalized machine learning model designed for the identification of syntactic and semantic clones in Java source code, utilizing the proposed code representation.</p></list-item><list-item><p>Extensive experiments were performed using the dataset from BigCloneBench [<xref rid="pone.0302333.ref016" ref-type="bibr">16</xref>], a benchmark dataset containing well-labeled clone pairs. The objective was to assess the effectiveness of the proposed technique and compare it with state-of-the-art clone detection techniques in terms of recall and F1 score.</p></list-item></list><p>The study is structured as follows: Section 2 provides an outline of the background. Related research is presented in Section 3, while Section 4 discusses the research methodology. Section 5 presents our experimental results on a real-world dataset, followed by a discussion of the results in Section 6. Section 7 addresses potential threats to validity. Finally, Section 8 concludes the article and delineates avenues for future work.</p></sec><sec id="sec002"><title>2 Background</title><p>Code clone detection methodologies typically encompass three fundamental phases: (1) Pre-processing of code, which involves removing extraneous elements such as header files and comments; (2) Transformation of source code into an intermediary representation (such as AST, sequence of tokens, or Program Dependency Graphs (PDG)); and (3) Comparison of code similarity, wherein the similarity between code fragments is calculated, facilitating the detection of code clones if this similarity surpasses a predetermined threshold. This section introduces the foundational concepts underlying the techniques used in this work.</p><sec id="sec003"><title>2.1 Abstract Syntax Tree (AST)</title><p>An AST is a tree-like representation of source code, defining its abstract syntactic structure [<xref rid="pone.0302333.ref017" ref-type="bibr">17</xref>]. Unlike conventional textual source code, ASTs offer an abstraction that omits finer details such as punctuation and delimiters. Within an AST, nodes align with programming constructs or symbols present in the source code. Researchers leverage this tree structure to precisely identify programming constructs, including assignment statements, declaration statements, and various operations. This capability facilitates tasks like optimization, analysis, and code modification. For a visual representation, <xref rid="pone.0302333.g001" ref-type="fig">Fig 1</xref> shows the syntactic structure of the f() function in the form of an AST.</p><fig position="float" id="pone.0302333.g001"><object-id pub-id-type="doi">10.1371/journal.pone.0302333.g001</object-id><label>Fig 1</label><caption><title>Example of AST extracted from f() function.</title></caption><graphic xlink:href="pone.0302333.g001" position="float"/></fig><p>After generating a tree representation for code fragments, researchers have several options. They can choose to detect similarities between corresponding ASTs or their sub-trees. Alternatively, they can convert them into a sequence of tokens, denoted as [token-1, token-2, &#x02026;, token-n], or represent the frequency of each programming construct in the AST (tokens) by traversing the AST. The comparison of ASTs from two code fragments yields a distance value that quantifies their similarity [<xref rid="pone.0302333.ref018" ref-type="bibr">18</xref>].</p><p>In this study, JavaParser tool [<xref rid="pone.0302333.ref019" ref-type="bibr">19</xref>] was used to generate and process ASTs of code fragments. JavaParser [<xref rid="pone.0302333.ref020" ref-type="bibr">20</xref>] is a Java library designed to facilitate the parsing, manipulation, and analysis of Java source code. By representing code as ASTs, developers can interact with Java code programmatically, gaining insight into its syntax and structure. JavaParser streamlines tasks such as parsing Java source code, navigating its structure, and programmatically modifying it. This library finds widespread use in software development tools, static code analysis tools, and frameworks that necessitate the analysis or manipulation of Java code.</p></sec><sec id="sec004"><title>2.2 Soot framework</title><p>The Soot framework [<xref rid="pone.0302333.ref021" ref-type="bibr">21</xref>] is an open-source program designed for the optimization, analysis, transformation, and visualization of Java and Android applications. One of its core strengths lies in its capacity to convert programs into different IRs. Each of these IRs offers distinct levels of abstraction, providing multiple advantages for source code analysis. Soot offers four IRs for the analysis and transformation of Java code: Baf, Jimple, Shimple, and Grimp. However, this work primarily focuses on the Baf and Jimple IRs. Further details are available in [<xref rid="pone.0302333.ref022" ref-type="bibr">22</xref>].</p><sec id="sec005"><title>2.2.1 Baf intermediate representation</title><p>Baf is a stack-based bytecode representation, similar to Java bytecode but simplified. It abstracts the constant pool and consolidates type-dependent variations of instructions into single instructions. For instance, in <xref rid="pone.0302333.g002" ref-type="fig">Fig 2</xref>, two functions perform equivalent operations: one function adds two integers, while the other adds two floating-point numbers. To identify the similarity between these two functions at the low-level representation, a compiler, such as Javac, is employed to process both functions and retrieve the corresponding bytecode instructions using a Javap for subsequent comparison.</p><fig position="float" id="pone.0302333.g002"><object-id pub-id-type="doi">10.1371/journal.pone.0302333.g002</object-id><label>Fig 2</label><caption><title>Two functions for summation using integer and float data types.</title></caption><graphic xlink:href="pone.0302333.g002" position="float"/></fig><p>As illustrated in <xref rid="pone.0302333.g003" ref-type="fig">Fig 3</xref>, it is apparent that the bytecode instructions for each of the two functions display a significant dissimilarity. This divergence arises from the inherent diversity of Java bytecode instructions, each designed to operate with specific data types, such as iadd and fadd. Consequently, the task of identifying similarities between code fragments at the low-level representation becomes notably challenging. In fact, Java bytecode encompasses an extensive set of over 250 distinct instructions [<xref rid="pone.0302333.ref023" ref-type="bibr">23</xref>]. The Baf IR contains approximately 60 instructions designed to represent code fragments in an abstract bytecode format. As illustrated in <xref rid="pone.0302333.g004" ref-type="fig">Fig 4</xref>, it is evident that a significant level of resemblance can be observed among the Baf IR instructions employed in the two functions presented in <xref rid="pone.0302333.g004" ref-type="fig">Fig 4</xref>.</p><fig position="float" id="pone.0302333.g003"><object-id pub-id-type="doi">10.1371/journal.pone.0302333.g003</object-id><label>Fig 3</label><caption><title>Two functions for summation using integer and float data types.</title></caption><graphic xlink:href="pone.0302333.g003" position="float"/></fig><fig position="float" id="pone.0302333.g004"><object-id pub-id-type="doi">10.1371/journal.pone.0302333.g004</object-id><label>Fig 4</label><caption><title>Baf IR for the <italic toggle="yes">Integer</italic>_<italic toggle="yes">Sum</italic>() and <italic toggle="yes">Float</italic>_<italic toggle="yes">Sum</italic>() functions.</title></caption><graphic xlink:href="pone.0302333.g004" position="float"/></fig><p>Consequently, using the capability of Baf IR to represent bytecode abstractly will improve the effectiveness of code clone detection techniques in detecting more difficult clones like semantic clones.</p></sec><sec id="sec006"><title>2.2.2 Jimple intermediate representation</title><p>In the Soot framework, the primary intermediate representation is called Jimple. Jimple serves as a typed 3-address code, containing only 15 statements to represent the source code [<xref rid="pone.0302333.ref024" ref-type="bibr">24</xref>, <xref rid="pone.0302333.ref025" ref-type="bibr">25</xref>]. It acts as an intermediary layer situated above the stack-based Java bytecode, effectively replacing it. Within the Soot framework, Jimple is employed for generating optimized IR, a process that involves the elimination of dead code, unused local variables, and common sub-expressions. Furthermore, during the transformation to Jimple, expressions are linearized to ensure that statements reference, at most, three local variables or constants. To illustrate this process, refer to <xref rid="pone.0302333.g005" ref-type="fig">Fig 5</xref>, which presents a code fragment containing dead code and unused variables, along with its corresponding optimized Jimple IR. As demonstrated in the Jimple IR, the dead code and unused variables have been successfully eliminated.</p><fig position="float" id="pone.0302333.g005"><object-id pub-id-type="doi">10.1371/journal.pone.0302333.g005</object-id><label>Fig 5</label><caption><title>Code fragment <italic toggle="yes">validate</italic>() and its optimized Jimple IR.</title></caption><graphic xlink:href="pone.0302333.g005" position="float"/></fig><p>Furthermore, in Jimple IR, various programming constructs, including do-while, for, and while loops are mapped to equivalent Jimple statements, such as if and goto statements, as shown in <xref rid="pone.0302333.g006" ref-type="fig">Fig 6</xref>. These optimizations lead to a substantial reduction in the number of operations needed for an efficient representation of Java bytecode, thereby enhancing the similarity between code fragments.</p><fig position="float" id="pone.0302333.g006"><object-id pub-id-type="doi">10.1371/journal.pone.0302333.g006</object-id><label>Fig 6</label><caption><title>Code fragments with different loop statements and their Jimple IR.</title></caption><graphic xlink:href="pone.0302333.g006" position="float"/></fig><p>Utilizing optimized Jimple IR for code fragments offers substantial advantages by eliminating extraneous elements while retaining the fundamental operations that convey the semantic meaning of the code fragment. This representation diminishes the effectiveness of obfuscation techniques, such as those that alter the syntactic structure while preserving the original code&#x02019;s semantics and functionality (e.g., metamorphism and polymorphism [<xref rid="pone.0302333.ref026" ref-type="bibr">26</xref>]). Furthermore, it facilitates the detection of duplicated or camouflaged code fragments by research tools.</p></sec><sec id="sec007"><title>2.2.3 Jimple Program Dependency Graph (PDG)</title><p>A PDG is a labeled, directed graph used to depict control and data dependencies among elements within a program. In the PDG, nodes represent assignment statements and control predicates, while edges signify control and data dependencies, as well as program component execution order. Data dependencies capture relevant data flow and control dependencies represent essential control flow relationships. PDGs are valuable across various software engineering and reengineering tasks. To obtain structural insights from source code, analysis can be performed on the source code itself, binary code, or any intermediate representation (e.g., Java bytecode, Jimple IR, LLVM bitcode). This work focuses specifically on block PDG created from the Jimple intermediate representation using the Soot framework.</p><p>
<xref rid="pone.0302333.g007" ref-type="fig">Fig 7</xref> depicts a code example alongside its corresponding Jimple IR and their block PDG. In this block PDG, each rectangle represents a basic block, within which multiple intermediate instructions may exist. Both data dependencies and control dependencies can be extracted for each basic block. For instance, in basic block 1, a conditional branch dictates the execution flow between basic blocks 2 and 6.</p><fig position="float" id="pone.0302333.g007"><object-id pub-id-type="doi">10.1371/journal.pone.0302333.g007</object-id><label>Fig 7</label><caption><title>Jimple block program dependence graph example.</title></caption><graphic xlink:href="pone.0302333.g007" position="float"/></fig></sec></sec></sec><sec id="sec008"><title>3 Related work</title><p>Over the past decade, many approaches for detecting code clones have been proposed. However, the majority rely on high-level source code representations, with only a limited number using low-level source code representations.</p><p>It&#x02019;s widely recognized that the text-based, token-based, syntax-based (AST), semantic-based (PDG), and metrics-based clone detection techniques all rely on high-level source code representations as their foundation. Cordy and Roy [<xref rid="pone.0302333.ref027" ref-type="bibr">27</xref>] introduced NiCad, a text-based tool that effectively detects Type-III clones. This is achieved by normalizing source code using specific transformation rules and employing the longest common subsequence matching algorithm to identify similarities and reach a final decision. SourcererCC [<xref rid="pone.0302333.ref028" ref-type="bibr">28</xref>], introduced by Saini et al., is a token-based technique that generates tokens from source code. It employs optimized token indexing and filtering heuristics to detect code clones, both within the same project and different across projects. Tiancheng et al. [<xref rid="pone.0302333.ref029" ref-type="bibr">29</xref>] introduced an innovative technique aimed at simplifying the complex structure of the AST. This approach accelerates the process of detecting and locating code clone fragments. Furthermore, Kamalpriya and Singh [<xref rid="pone.0302333.ref030" ref-type="bibr">30</xref>] introduced a detection approach that employs the ASM technique to improve PDG-based code clone detection. Their method derives a novel similarity relationship from the findings obtained through existing PDG-based techniques. The ASM technique is employed to generate these new approximate clone relationships. Hua et al. [<xref rid="pone.0302333.ref031" ref-type="bibr">31</xref>] introduced a deep-learning-based code clone detection approach called FCCA. This method employs a hybrid code representation, including sequences of tokens, abstract syntax trees (AST), and control flow graphs (CFG), alongside an attention mechanism to accurately identify complex functional code clones in real-world codebases. In a similar vein, Fang et al. [<xref rid="pone.0302333.ref013" ref-type="bibr">13</xref>] proposed a novel approach to functional code clone detection. Their method introduces a joint code representation comprising AST and CFG and adopts fusion embedding techniques and supervised deep learning to achieve superior performance in clone detection. Basit and Jarzabek [<xref rid="pone.0302333.ref032" ref-type="bibr">32</xref>] and Ali et al. [<xref rid="pone.0302333.ref033" ref-type="bibr">33</xref>] presented code clone detection as a data mining problem and used data mining techniques to detect code clones at various levels. Heba and El-Hafeez [<xref rid="pone.0302333.ref034" ref-type="bibr">34</xref>, <xref rid="pone.0302333.ref035" ref-type="bibr">35</xref>] applied association analysis in data mining to tackle redundancy and select relevant features for text classification, a methodology that could be extended to code clone detection.</p><p>However, certain approaches concentrate on utilizing low-level source code representations, such as bytecode or assembly instructions or other intermediate representations, as the basis for clone detection. Andre et al. [<xref rid="pone.0302333.ref036" ref-type="bibr">36</xref>] used paths from the dominator tree within the control flow graph of Java bytecode to represent code fragments. Salim et al. [<xref rid="pone.0302333.ref024" ref-type="bibr">24</xref>] suggested a clone detection approach by converting Java source code into Jimple IR using the Soot framework. Then they used text-based detection techniques to locate clones at this abstraction level. Roy et al. [<xref rid="pone.0302333.ref037" ref-type="bibr">37</xref>] introduced SeByt, a model for detecting bytecode clones. They segmented the bytecode into three dimensions, comprising instructions, method calls, and types, and performed semantic searches on the bytecode ontology to match the bytecode content. Caldeira et al. [<xref rid="pone.0302333.ref038" ref-type="bibr">38</xref>] enhanced clone detection by combining the simplicity of the text-based techniques with the abstractions granted by intermediate representations. They converted the C source code into an intermediate representation using the LLVM virtual assembly language. After that, they executed NiCad on the generated IR. Yu et al. [<xref rid="pone.0302333.ref039" ref-type="bibr">39</xref>] used the Smith-Waterman algorithm to align sequences of Java bytecode in order to identify clones in Java code.</p><p>Oleksii et al. [<xref rid="pone.0302333.ref040" ref-type="bibr">40</xref>] have demonstrated that code clone detection techniques yield significantly different results when applied to the same source code with different code representation levels, namely high-level and low-level code representations. Consequently, different techniques have emerged to enhance clone detection efficiency by integrating code representations from different levels. Sheneamer et al. [<xref rid="pone.0302333.ref041" ref-type="bibr">41</xref>] introduced a new framework for detecting semantic code clones and code obfuscation. They enhanced the detection using a hybrid code representation derived from bytecode dependency graph (BDG), AST, and PDG features. White et al. [<xref rid="pone.0302333.ref008" ref-type="bibr">8</xref>] propose a technique that uses recurrent neural networks to learn source code representation by integrating features extracted from the CFG, sequence of identifier tokens, and sequence of bytecode instructions. Moreover, Tufano et. al. [<xref rid="pone.0302333.ref042" ref-type="bibr">42</xref>] uses four diverse code representations (i.e., sequence of identifier tokens, AST, bytecode, and CFG) to assess the similarity between pairs of code.</p><p>The proposed work aligns with the concept of integrating the syntax representation of the AST and the semantics representation of the compiled code and program dependency graph. <xref rid="pone.0302333.t001" ref-type="table">Table 1</xref> illustrates the code representation techniques employed in the literature.</p><table-wrap position="float" id="pone.0302333.t001"><object-id pub-id-type="doi">10.1371/journal.pone.0302333.t001</object-id><label>Table 1</label><caption><title>Code representation techniques used in the literature.</title></caption><alternatives><graphic xlink:href="pone.0302333.t001" id="pone.0302333.t001g" position="float"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="2" colspan="1">Technique</th><th align="center" rowspan="2" colspan="1">Type</th><th align="center" colspan="6" rowspan="1">Code Representation</th></tr><tr><th align="center" rowspan="1" colspan="1">Text</th><th align="center" rowspan="1" colspan="1">Token</th><th align="center" rowspan="1" colspan="1">Tree</th><th align="center" rowspan="1" colspan="1">Graph</th><th align="center" rowspan="1" colspan="1">Bytecode</th><th align="center" rowspan="1" colspan="1">IR</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Roy and Cordy</td><td align="center" rowspan="1" colspan="1">H</td><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">SourcererCC</td><td align="center" rowspan="1" colspan="1">H</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">Tiancheng et al</td><td align="center" rowspan="1" colspan="1">H</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">Kamalpriya and Singh</td><td align="center" rowspan="1" colspan="1">H</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">Hua et al.</td><td align="center" rowspan="1" colspan="1">H</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">Fang et al.</td><td align="center" rowspan="1" colspan="1">H</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">Basit and Jarzabek</td><td align="center" rowspan="1" colspan="1">H</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">Ali et al.</td><td align="center" rowspan="1" colspan="1">H</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">Andre et al.</td><td align="center" rowspan="1" colspan="1">H</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">Salim et al.</td><td align="center" rowspan="1" colspan="1">L</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1">&#x02713;</td></tr><tr><td align="left" rowspan="1" colspan="1">Roy et al.</td><td align="center" rowspan="1" colspan="1">L</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">Caldeira et al.</td><td align="center" rowspan="1" colspan="1">L</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1">&#x02713;</td></tr><tr><td align="left" rowspan="1" colspan="1">Yu et al.</td><td align="center" rowspan="1" colspan="1">L</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">White et al.</td><td align="center" rowspan="1" colspan="1">L</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">Sheneamer et al.</td><td align="center" rowspan="1" colspan="1">H/L</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1"/></tr><tr><td align="left" rowspan="1" colspan="1">Tufano et. al.</td><td align="center" rowspan="1" colspan="1">H/L</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1"/></tr></tbody></table></alternatives><table-wrap-foot><fn id="t001fn001"><p>L : indicates the low level representation; H : indicates the High-level representation; IR : indicates the intermediate representation</p></fn></table-wrap-foot></table-wrap></sec><sec id="sec009"><title>4 The proposed methodology</title><p>An ideal code representation should comprehensively preserve code features. This section describes the methodology used for the comprehensive representation and extraction of both syntactic and semantic features from source code to detect syntactic and semantic clones. The methodology encompasses three stage: pre-processing, feature extraction, and machine learning (ML) training. <xref rid="pone.0302333.g008" ref-type="fig">Fig 8</xref> provides a more detailed overview of this methodology.</p><fig position="float" id="pone.0302333.g008"><object-id pub-id-type="doi">10.1371/journal.pone.0302333.g008</object-id><label>Fig 8</label><caption><title>The proposed work&#x02019;s architecture workflow.</title></caption><graphic xlink:href="pone.0302333.g008" position="float"/></fig><sec id="sec010"><title>4.1 Stage 1: Pre-processing stage</title><p>In the proposed methodology, as part of the preprocessing stage, all files within the source code corpus undergo normalization and compilation utilizing a compilation tool such as the Stubber tool [<xref rid="pone.0302333.ref043" ref-type="bibr">43</xref>, <xref rid="pone.0302333.ref044" ref-type="bibr">44</xref>]. This stage involves several normalization operations, including the removal of unnecessary white spaces, the exclusion of comments, the substitution of variable names and function names with generic placeholders to mitigate disparities in naming conventions, and the substitution of numeric literals, string literals, and other constants with placeholders to generalize specific values. After normalizing and compiling files in this stage, they proceed to the subsequent processing steps.</p></sec><sec id="sec011"><title>4.2 Stage 2: Features extraction stage</title><p>The subsequent stage, known as the features extraction stage, comprises two sub-stages, as shown in <xref rid="pone.0302333.g008" ref-type="fig">Fig 8</xref>. The first sub-stage entails extracting syntactic features, while the second focuses on extracting semantic features. This process initiates with the reception of normalized Java source code and its associated compiled JAR file. Subsequently, it extracts code fragments (methods) from these files and analyzes their corresponding syntactic and semantic features, as illustrated in <xref rid="pone.0302333.g009" ref-type="fig">Fig 9</xref> and further explained in the subsequent subsections.</p><fig position="float" id="pone.0302333.g009"><object-id pub-id-type="doi">10.1371/journal.pone.0302333.g009</object-id><label>Fig 9</label><caption><title>The process of extracting syntactic and semantic features.</title></caption><graphic xlink:href="pone.0302333.g009" position="float"/></fig><sec id="sec012"><title>4.2.1 Extraction of syntactic features (High-level features)</title><p>To capture the abstract syntactic structure of the source code, the normalized Java source file is processed in this sub-stage. It is first converted into an AST using the JavaParser [<xref rid="pone.0302333.ref020" ref-type="bibr">20</xref>] tool to extract all methods in the file. Subsequently, each method is converted into an AST using the same tool, and the AST is traversed to extract method syntactic features. The algorithm for syntactic feature extraction, denoted as Algorithm 1, describes the procedure for extracting syntactic features.</p><p><bold>Algorithm 1</bold>: Extract syntactic features</p><p specific-use="line">&#x02003;<bold>Input</bold>: SF: Java source file</p><p specific-use="line">&#x02003;<bold>Output</bold>: ASTFeaturesMap: a Map for AST features</p><p specific-use="line"><bold>1</bold>
<italic toggle="yes">ASTFeaturesMap</italic> &#x02190; &#x02205;; <italic toggle="yes">MethodList</italic> &#x02190; &#x02205;;</p><p specific-use="line">&#x02003;// Convert Java source file into AST</p><p specific-use="line"><bold>2</bold>
<italic toggle="yes">Cu</italic> &#x02190; <italic toggle="yes">StaticJavaParser</italic>.<italic toggle="yes">parse</italic>(<italic toggle="yes">SF</italic>);</p><p specific-use="line">&#x02003;// Retrieve the list of methods in the AST</p><p specific-use="line"><bold>3</bold>
<italic toggle="yes">MethodList</italic> &#x02190; <italic toggle="yes">travserse</italic>(<italic toggle="yes">Cu</italic>);</p><p specific-use="line">&#x02003;// Method-level AST features extraction</p><p specific-use="line"><bold>4</bold>
<bold>foreach</bold>
<underline>m in MethodList</underline>
<bold>do</bold></p><p specific-use="line">&#x02003;&#x02003;// Retrieve method body</p><p specific-use="line"><bold>5</bold> &#x02003; <italic toggle="yes">Methodbody</italic> &#x02190; <italic toggle="yes">RetriveMethodBody</italic>(<italic toggle="yes">m</italic>, <italic toggle="yes">cu</italic>);</p><p specific-use="line"><bold>6</bold> &#x02003; <italic toggle="yes">IdentSeq</italic> &#x02190; &#x02205;;</p><p specific-use="line">&#x02003;&#x02003;// Convert method into AST</p><p specific-use="line"><bold>7</bold> &#x02003; <italic toggle="yes">MAST</italic> &#x02190; <italic toggle="yes">StaticJavaParser</italic>.<italic toggle="yes">parse</italic>(<italic toggle="yes">Methodbody</italic>);</p><p specific-use="line">&#x02003;&#x02003;// Traverse method AST in pre-order manner</p><p specific-use="line"><bold>8</bold> &#x02003; <italic toggle="yes">IdentSeq</italic> &#x02190; <italic toggle="yes">travserse</italic>(<italic toggle="yes">MAST</italic>);</p><p specific-use="line">&#x02003;&#x02003;// Put method&#x02019;s extracted features in Map</p><p specific-use="line"><bold>9</bold> &#x02003; <italic toggle="yes">ASTFeaturesMap</italic>.<italic toggle="yes">put</italic>(<italic toggle="yes">m</italic>, <italic toggle="yes">IdentSeq</italic>);</p><p specific-use="line"><bold>10</bold>
<bold>end foreach</bold></p><p specific-use="line"><bold>11</bold>
<bold>return</bold>
<italic toggle="yes">ASTFeaturesMap</italic>;</p><p>This procedure consists of six distinct steps, which are detailed below.</p><list list-type="order"><list-item><p>Transform the normalized Java source file into an AST using the JavaParser tool [<xref rid="pone.0302333.ref020" ref-type="bibr">20</xref>] (Algorithm 1: Line 2).</p></list-item><list-item><p>Retrieve a list of methods contained within the AST (Algorithm 1: Line 3).</p></list-item><list-item><p>For each method in the method list, the method&#x02019;s body is extracted (Algorithm 1: Line 5).</p></list-item><list-item><p>Transform the method body into an AST using the JavaParser tool (Algorithm 1: Line 7).</p></list-item><list-item><p>Iterate through each non-terminal node in the AST of the method in a preorder manner and extract a sequence of programming constructs nodes [token1, token2,&#x02026;, tokenn] (node identifiers). (Algorithm 1: Line 8).</p></list-item><list-item><p>Store the extracted sequence of AST nodes&#x02019; identifiers in a map, along with its corresponding method name. (Algorithm 1: Line 9).</p></list-item><list-item><p>Repeat steps 3 to 6 until all the methods have been scanned.</p></list-item></list><p>The primary output of the syntactic feature extraction algorithm is a map that contains method names paired with their corresponding sequence of tokens (AST nodes&#x02019; identifiers). A list of non-terminal nodes investigated in this work is presented in <xref rid="pone.0302333.t002" ref-type="table">Table 2</xref>. For further details, please refer to the <xref rid="pone.0302333.s001" ref-type="supplementary-material">S1 File</xref>.</p><table-wrap position="float" id="pone.0302333.t002"><object-id pub-id-type="doi">10.1371/journal.pone.0302333.t002</object-id><label>Table 2</label><caption><title>Selected AST non-terminal nodes.</title></caption><alternatives><graphic xlink:href="pone.0302333.t002" id="pone.0302333.t002g" position="float"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">ID</th><th align="left" rowspan="1" colspan="1">Node</th><th align="left" rowspan="1" colspan="1">Description</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">1</td><td align="left" rowspan="1" colspan="1">BlockStmt</td><td align="left" rowspan="1" colspan="1">Basic block in the method.</td></tr><tr><td align="left" rowspan="1" colspan="1">2</td><td align="left" rowspan="1" colspan="1">ArrayCreations</td><td align="left" rowspan="1" colspan="1">Arrays declaration in the method.</td></tr><tr><td align="left" rowspan="1" colspan="1">3</td><td align="left" rowspan="1" colspan="1">ObjectCreationExpr</td><td align="left" rowspan="1" colspan="1">Objects created in the method.</td></tr><tr><td align="left" rowspan="1" colspan="1">4</td><td align="left" rowspan="1" colspan="1">ExpressionStmt</td><td align="left" rowspan="1" colspan="1">Expression statements in the method.</td></tr><tr><td align="left" rowspan="1" colspan="1">5</td><td align="left" rowspan="1" colspan="1">MethodCallExpr</td><td align="left" rowspan="1" colspan="1">Methods invoked in the method.</td></tr><tr><td align="left" rowspan="1" colspan="1">6</td><td align="left" rowspan="1" colspan="1">FieldAccessExpr</td><td align="left" rowspan="1" colspan="1">Field access in the method. (i.e., Person.name)</td></tr><tr><td align="left" rowspan="1" colspan="1">7</td><td align="left" rowspan="1" colspan="1">PrimitiveType</td><td align="left" rowspan="1" colspan="1">Primitive types in the method.</td></tr><tr><td align="left" rowspan="1" colspan="1">8</td><td align="left" rowspan="1" colspan="1">VariableDeclarationExpr</td><td align="left" rowspan="1" colspan="1">Variables declared in the method.</td></tr><tr><td align="left" rowspan="1" colspan="1">9</td><td align="left" rowspan="1" colspan="1">WhileStmt</td><td align="left" rowspan="1" colspan="1">While statements in the method.</td></tr><tr><td align="left" rowspan="1" colspan="1">10</td><td align="left" rowspan="1" colspan="1">ReturnStmt</td><td align="left" rowspan="1" colspan="1">Return statements in the method.</td></tr></tbody></table></alternatives></table-wrap></sec><sec id="sec013"><title>4.2.2 Extraction of semantic features (Abstract compiled-code features)</title><p>Higher abstraction enhances a feature representation&#x02019;s capacity to measure source code semantics or meaning. This occurs because greater abstraction allows capturing a broader range of semantic code information [<xref rid="pone.0302333.ref045" ref-type="bibr">45</xref>]. Unlike syntactic features, semantic features represent source code at a higher level of abstraction, capturing logic flows and program execution sequences. To extract the semantics or meaning of a code fragment, the initial step involves parsing it into syntactic or structural components. For each component, its corresponding meaning is determined, and subsequently, the code fragment&#x02019;s overall meaning is constructed by combining these components following relevant rules [<xref rid="pone.0302333.ref041" ref-type="bibr">41</xref>].</p><p>In this work, the capabilities of the Soot framework to transform Java programs into different abstract IRs are leveraged to obtain semantic features from the source code. Specifically, two IRs, namely Baf and Jimple, are employed in this research. Furthermore, additional semantic information is extracted by abstractly representing the data and control dependencies within the Jimple IR through the construction of a block PDG. The procedure for extracting Baf IR features is outlined in Algorithm 2.</p><p><bold>Algorithm 2</bold>: Extract Baf Features</p><p specific-use="line">&#x02003;<bold>Input</bold>: JClassfile,MethodList: compiled Java file (.classfile) and List of methods in the target file</p><p specific-use="line">&#x02003;<bold>Output</bold>: BafFeatureMap: Method names and its Baf features</p><p specific-use="line"><bold>1</bold>
<italic toggle="yes">BafFeatureMap</italic> &#x02190; &#x02205;;</p><p specific-use="line"><bold>2</bold>
<italic toggle="yes">ML</italic> &#x02190; &#x02205;;</p><p specific-use="line">&#x02003;// Retrieve methods list from .classfile</p><p specific-use="line"><bold>3</bold>
<italic toggle="yes">ML</italic> &#x02190; <italic toggle="yes">Soot</italic>.<italic toggle="yes">Classfile</italic>.<italic toggle="yes">getMethods</italic>(<italic toggle="yes">JClassfile</italic>);</p><p specific-use="line">&#x02003;// Method-level Baf features extraction</p><p specific-use="line"><bold>4</bold>
<bold>foreach</bold>
<underline><italic toggle="yes">m</italic> in <italic toggle="yes">ML</italic></underline>
<bold>do</bold></p><p specific-use="line"><bold>5</bold> &#x02003;<bold>if</bold>
<underline>(<italic toggle="yes">MethodList</italic>.<italic toggle="yes">contains</italic>(<italic toggle="yes">m</italic>.<italic toggle="yes">getName</italic>()))</underline>
<bold>then</bold></p><p specific-use="line">&#x02003;&#x02003;&#x02003;// Retrieve method body in Baf IR</p><p specific-use="line"><bold>6</bold> &#x02003;&#x02003; <italic toggle="yes">Bafbody</italic> &#x02190; <italic toggle="yes">Soot</italic>.<italic toggle="yes">getBafBody</italic>(<italic toggle="yes">m</italic>);</p><p specific-use="line"><bold>7</bold> &#x02003; &#x02003;<italic toggle="yes">LBafSeq</italic> &#x02190; &#x02205;;</p><p specific-use="line">&#x02003;&#x02003;&#x02003;// Iterate through Baf units and extract sequence of instructions</p><p specific-use="line"><bold>8</bold> &#x02003;&#x02003; <bold>foreach</bold>
<underline><italic toggle="yes">Unit</italic> in <italic toggle="yes">Bafbody</italic>.<italic toggle="yes">getUnits</italic>()</underline>
<bold>do</bold></p><p specific-use="line"><bold>9</bold> &#x02003;&#x02003; &#x02003;<italic toggle="yes">LBafSeq</italic>.<italic toggle="yes">put</italic>(Unit.toString());</p><p specific-use="line"><bold>10</bold> &#x02003; &#x02003;<bold>end foreach</bold></p><p specific-use="line">&#x02003; &#x02003;&#x02003; // Put method&#x02019;s Baf extracted features in Map</p><p specific-use="line"><bold>11</bold> &#x02003; &#x02003;<italic toggle="yes">BafFeatureMap</italic>.<italic toggle="yes">put</italic>(m.getName(), LBafSeq);</p><p specific-use="line"><bold>12</bold> &#x02003;<bold>end if</bold></p><p specific-use="line">
<bold>13 end foreach</bold>
</p><p specific-use="line"><bold>14</bold>
<bold>return</bold>
<italic toggle="yes">BafFeatureMap</italic>;</p><p>This algorithm initiates by receiving two parameters: the .classfile and a list of target methods. It then proceeds through the following steps:</p><list list-type="order"><list-item><p>Retrieve a list of methods contained within the .classfile using the Soot framework (Algorithm 2: Line 3).</p></list-item><list-item><p>For each method in the method list, the Soot framework generates the optimized Baf IR of the method (Algorithm 2: Line 6).</p></list-item><list-item><p>Iterate through all instructions in the Baf body to extract Baf instructions, forming a sequence of Baf instructions (Algorithm 2: Lines 8 to 10).</p></list-item><list-item><p>Store the extracted sequence of Baf instructions in a map, along with its corresponding method name. (Algorithm 2: Line 11).</p></list-item><list-item><p>Repeat steps 4 to 13 until all the methods have been scanned.</p></list-item></list><p>The main result of this procedure is a map that pairs method names with their respective sequence of Baf instructions. A list of Baf instructions examined in this work is provided in <xref rid="pone.0302333.t003" ref-type="table">Table 3</xref>. For more details, please refer to the <xref rid="pone.0302333.s001" ref-type="supplementary-material">S1 File</xref>.</p><table-wrap position="float" id="pone.0302333.t003"><object-id pub-id-type="doi">10.1371/journal.pone.0302333.t003</object-id><label>Table 3</label><caption><title>Selected Baf instructions.</title></caption><alternatives><graphic xlink:href="pone.0302333.t003" id="pone.0302333.t003g" position="float"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">ID</th><th align="left" rowspan="1" colspan="1">Instruction</th><th align="left" rowspan="1" colspan="1">Description</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">1</td><td align="left" rowspan="1" colspan="1">Load</td><td align="left" rowspan="1" colspan="1">Load variable from local variable.</td></tr><tr><td align="left" rowspan="1" colspan="1">2</td><td align="left" rowspan="1" colspan="1">Store</td><td align="left" rowspan="1" colspan="1">Store variable into local variable.</td></tr><tr><td align="left" rowspan="1" colspan="1">3</td><td align="left" rowspan="1" colspan="1">Inc</td><td align="left" rowspan="1" colspan="1">Increment local variable by constant.</td></tr><tr><td align="left" rowspan="1" colspan="1">4</td><td align="left" rowspan="1" colspan="1">fieldget</td><td align="left" rowspan="1" colspan="1">Fetch field from object.</td></tr><tr><td align="left" rowspan="1" colspan="1">5</td><td align="left" rowspan="1" colspan="1">New</td><td align="left" rowspan="1" colspan="1">Create new object.</td></tr><tr><td align="left" rowspan="1" colspan="1">6</td><td align="left" rowspan="1" colspan="1">Ifne</td><td align="left" rowspan="1" colspan="1">Jump if value1 &#x02260; <italic toggle="yes">value 2</italic></td></tr><tr><td align="left" rowspan="1" colspan="1">7</td><td align="left" rowspan="1" colspan="1">Ifcmpeq</td><td align="left" rowspan="1" colspan="1">Branch if and only if Value1 = value 2.</td></tr><tr><td align="left" rowspan="1" colspan="1">8</td><td align="left" rowspan="1" colspan="1">sub</td><td align="left" rowspan="1" colspan="1">Subtract two varaible.</td></tr><tr><td align="left" rowspan="1" colspan="1">9</td><td align="left" rowspan="1" colspan="1">Add</td><td align="left" rowspan="1" colspan="1">Add two variables.</td></tr><tr><td align="left" rowspan="1" colspan="1">10</td><td align="left" rowspan="1" colspan="1">Checkcast</td><td align="left" rowspan="1" colspan="1">Check whether object is of given type.</td></tr></tbody></table></alternatives></table-wrap><p>Additionally, the Jimple and Block PDG feature extraction algorithm (Algorithm 3), delineates the process of extracting semantic features from the Jimple IR and its corresponding block program dependency graph. The Jimple and Block PDG feature extraction algorithm begins by receiving two parameters: the .classfile and a list of target methods. Then, it proceeds through the following steps:</p><list list-type="order"><list-item><p>Retrieve a list of methods contained within the .classfile using the Soot framework (Algorithm 3: Line 3).</p></list-item><list-item><p>For each method in the method list, the Soot framework generates the optimized Jimple IR of the method (Algorithm 3: Line 8).</p></list-item><list-item><p>Iterate through all statement units in the Jimple body to extract a sequence of Jimple statements and form a map containing the frequency of each Jimple statement (Algorithm 3: Lines 10 to 13).</p></list-item><list-item><p>Create a block program dependency graph (BPDG) for Jimple IR (Algorithm 3: Line 16).</p></list-item><list-item><p>Retrieve block control flow graph (BCFG) features for the Jimple BPDG (Algorithm 3: Line 17).</p></list-item><list-item><p>Retrieve BPDG features for the Jimple BPDG (Algorithm 3: Line 18).</p></list-item><list-item><p>Store the extracted features from Jimple, Jimple BPDG, and BCFG in a map, along with their corresponding method name. (Algorithm 3: Lines 17 to 21).</p></list-item><list-item><p>Repeat steps 4 to 22 until all the methods have been scanned.</p></list-item></list><p><bold>Algorithm 3</bold>: Extract Abstract Jimple and PDG Features</p><p specific-use="line">&#x02003;<bold>Input</bold>: JClassfile, MethodList: // .classfile and List of methods in the target file</p><p specific-use="line">&#x02003;<bold>Output</bold>: JimpleFeatureMap: // method names and its Jimple features</p><p specific-use="line"><bold>1</bold>
<italic toggle="yes">JimpleFeatureMap</italic> &#x02190; &#x02205;;</p><p specific-use="line"><bold>2</bold>
<italic toggle="yes">MList</italic> &#x02190; &#x02205;;</p><p specific-use="line">&#x02003;// Retrieve methods list from .classfile</p><p specific-use="line"><bold>3</bold>
<italic toggle="yes">MList</italic> &#x02190; <italic toggle="yes">Soot</italic>.<italic toggle="yes">Classfile</italic>.<italic toggle="yes">getMethods</italic>(<italic toggle="yes">JClassfile</italic>);</p><p specific-use="line">&#x02003;// Method-level Jimple features extraction</p><p specific-use="line"><bold>4</bold>
<bold>foreach</bold>
<underline><italic toggle="yes">m</italic> in <italic toggle="yes">MList</italic></underline>
<bold>do</bold></p><p specific-use="line"><bold>5</bold> &#x02003;<bold>if</bold>
<underline>(<italic toggle="yes">MethodList</italic>.<italic toggle="yes">contains</italic>(<italic toggle="yes">m</italic>.<italic toggle="yes">getName</italic>()))</underline>
<bold>then</bold></p><p specific-use="line"><bold>6</bold> &#x02003;&#x02003;<italic toggle="yes">FturLst</italic> &#x02190; {<italic toggle="yes">JimpleFeatures</italic>};</p><p specific-use="line"><bold>7</bold> &#x02003;&#x02003;<italic toggle="yes">JimpleLstMap</italic> &#x02190; &#x02205;;</p><p specific-use="line">&#x02003; &#x02003; // Retrieve method body in Jimple IR</p><p specific-use="line"><bold>8</bold> &#x02003;&#x02003;<italic toggle="yes">Jimplebody</italic> &#x02190; (<italic toggle="yes">JimpleBody</italic>)<italic toggle="yes">m</italic>.<italic toggle="yes">retrieveActiveBody</italic>();</p><p specific-use="line">&#x02003; &#x02003; // Iterate through Jimple units and extract the frequency of each statements and statement sequence</p><p specific-use="line"><bold>9</bold> &#x02003;&#x02003;<italic toggle="yes">JimpleSeqStmt</italic> &#x02190; &#x02205;;</p><p specific-use="line"><bold>10</bold>&#x02003;&#x02003;<bold>foreach</bold>
<underline><italic toggle="yes">u</italic> in <italic toggle="yes">Jimplebody</italic>.<italic toggle="yes">getUnits</italic>()</underline>
<bold>do</bold></p><p specific-use="line"><bold>11</bold> &#x02003;&#x02003;&#x02003;<italic toggle="yes">FturLst</italic>.<italic toggle="yes">put</italic>(<italic toggle="yes">FturLst</italic>.<italic toggle="yes">getKey</italic>(<italic toggle="yes">u</italic>), <italic toggle="yes">FturLst</italic>.<italic toggle="yes">getValue</italic>(<italic toggle="yes">u</italic>) + 1);</p><p specific-use="line"><bold>12</bold> &#x02003;&#x02003;&#x02003;<italic toggle="yes">JimpleSeqStmt</italic> &#x02190; <italic toggle="yes">JimpleSeqStmt</italic> + <italic toggle="yes">u</italic>;</p><p specific-use="line"><bold>13</bold> &#x02003;&#x02003;<bold>end foreach</bold></p><p specific-use="line">&#x02003;&#x02003; &#x02003;// Use Soot to create Block PDG for Jimple IR</p><p specific-use="line"><bold>14</bold> &#x02003;&#x02003;<italic toggle="yes">JBlockGraph</italic> &#x02190; <italic toggle="yes">Soot</italic>.<italic toggle="yes">EnhancedBlockGraph</italic>(Jimplebody);</p><p specific-use="line">&#x02003;&#x02003; &#x02003;// Retrieve Block CFG features for Jimple block graph</p><p specific-use="line"><bold>15</bold> &#x02003;&#x02003;<italic toggle="yes">BCFGfeatures</italic> &#x02190; <italic toggle="yes">getBCFGFeatures</italic>(<italic toggle="yes">JBlockGraph</italic>);</p><p specific-use="line">&#x02003;&#x02003; &#x02003;// Retrieve Block PDG features for Jimple block graph</p><p specific-use="line"><bold>16</bold> &#x02003;&#x02003;<italic toggle="yes">BPDGfeatures</italic> &#x02190; <italic toggle="yes">getPDGFeatures</italic>(<italic toggle="yes">JBlockGraph</italic>);</p><p specific-use="line">&#x02003;&#x02003; &#x02003;// Add extracted features into map features</p><p specific-use="line"><bold>17</bold> &#x02003;&#x02003;<italic toggle="yes">JimpleLstMap</italic>.<italic toggle="yes">put</italic>(<italic toggle="yes">JimpleFreq</italic>, <italic toggle="yes">FturLst</italic>);</p><p specific-use="line"><bold>18</bold> &#x02003;&#x02003;<italic toggle="yes">JimpleLstMap</italic>.<italic toggle="yes">put</italic>(<italic toggle="yes">JimpleSeqStmt</italic>, <italic toggle="yes">JimpleSeqStmt</italic>);</p><p specific-use="line"><bold>19</bold> &#x02003;&#x02003;<italic toggle="yes">JimpleLstMap</italic>.<italic toggle="yes">put</italic>(<italic toggle="yes">bcfg</italic>, <italic toggle="yes">BPDGfeatures</italic>);</p><p specific-use="line"><bold>20</bold> &#x02003;&#x02003;<italic toggle="yes">JimpleLstMap</italic>.<italic toggle="yes">put</italic>(<italic toggle="yes">bpdg</italic>, <italic toggle="yes">BPDGfeatures</italic>);</p><p specific-use="line">&#x02003;&#x02003; &#x02003;// Add extracted features in map feature into the general Map</p><p specific-use="line"><bold>21</bold> &#x02003;&#x02003;<italic toggle="yes">JimpleFeatureMap</italic>.<italic toggle="yes">put</italic>(<italic toggle="yes">m</italic>.<italic toggle="yes">getname</italic>(), <italic toggle="yes">JimpleLstMap</italic>);</p><p specific-use="line"><bold>22</bold> &#x02003;<bold>end if</bold></p><p specific-use="line"><bold>23</bold>
<bold>end foreach</bold></p><p specific-use="line"><bold>24</bold>
<bold>return</bold>
<italic toggle="yes">JimpleFeatureMap</italic>;</p><p>The main output of the Jimple and Block PDG feature extraction algorithm is a map that associates method names with their respective maps, which contain information about Jimple statement frequency, the sequence of Jimple statements, and Jimple Block PDG features. <xref rid="pone.0302333.t004" ref-type="table">Table 4</xref> presents a list of the Jimple and block PDG features. For more detailed information, please consult the <xref rid="pone.0302333.s001" ref-type="supplementary-material">S1 File</xref>.</p><table-wrap position="float" id="pone.0302333.t004"><object-id pub-id-type="doi">10.1371/journal.pone.0302333.t004</object-id><label>Table 4</label><caption><title>Selected Jimple and Block PDG features.</title></caption><alternatives><graphic xlink:href="pone.0302333.t004" id="pone.0302333.t004g" position="float"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">ID</th><th align="left" rowspan="1" colspan="1">Statement</th><th align="left" rowspan="1" colspan="1">Description</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">1</td><td align="left" rowspan="1" colspan="1">IfStmt</td><td align="left" rowspan="1" colspan="1">Represent conditional jump.</td></tr><tr><td align="left" rowspan="1" colspan="1">2</td><td align="left" rowspan="1" colspan="1">GotoStmt</td><td align="left" rowspan="1" colspan="1">Represent unconditional jump.</td></tr><tr><td align="left" rowspan="1" colspan="1">3</td><td align="left" rowspan="1" colspan="1">InvokeStmt</td><td align="left" rowspan="1" colspan="1">invokeStmt represents an invoke without an assignment to a local.</td></tr><tr><td align="left" rowspan="1" colspan="1">4</td><td align="left" rowspan="1" colspan="1">AssignStmt</td><td align="left" rowspan="1" colspan="1">Assigning a value to a local, or an immediate static field.</td></tr><tr><td align="left" rowspan="1" colspan="1">5</td><td align="left" rowspan="1" colspan="1">ThrowStmt</td><td align="left" rowspan="1" colspan="1">Represents the explicit throwing of an exception.</td></tr><tr><td align="left" rowspan="1" colspan="1">6</td><td align="left" colspan="2" rowspan="1">Number of PDG region</td></tr><tr><td align="left" rowspan="1" colspan="1">7</td><td align="left" colspan="2" rowspan="1">Number of strong regions in PDG</td></tr><tr><td align="left" rowspan="1" colspan="1">8</td><td align="left" colspan="2" rowspan="1">Number of weak regions in PDG</td></tr><tr><td align="left" rowspan="1" colspan="1">9</td><td align="left" colspan="2" rowspan="1">Number of dependency Edges in PDG</td></tr><tr><td align="left" rowspan="1" colspan="1">10</td><td align="left" colspan="2" rowspan="1">Number of control flow edges in PDG</td></tr><tr><td align="left" rowspan="1" colspan="1">11</td><td align="left" colspan="2" rowspan="1">Number of dependency-back edges in PDG</td></tr><tr><td align="left" rowspan="1" colspan="1">12</td><td align="left" colspan="2" rowspan="1">Number of dependency edges between Region node and Region node in PDG</td></tr></tbody></table></alternatives></table-wrap><p>After extracting syntactic features from the source code using Algorithm 1 and obtaining semantic features through Algorithms 2 and 3 for each method within the target Java source code, the extracted features for each method are subsequently combined and then stored within a database. The combined feature extraction algorithm (Algorithm 4), consists of the following sequential steps:</p><list list-type="order"><list-item><p>Receive two inputs: the target Java source code file and its corresponding .classfile.</p></list-item><list-item><p>Invoke the syntactic feature extraction algorithm (Algorithm 1 and supply the target Java file as input to retrieve a map containing all the methods in the target file, along with their corresponding sequence of AST nodes identifiers, (Algorithm 4 Line 4).</p></list-item><list-item><p>Invoke the extracting Baf IR features algorithm (Algorithm 2 with two parameters: the .classfile of the target Java file and the list of methods contained therein. This step generates a map containing all methods in the compiled file and their corresponding sequence of Baf instructions (Algorithm 4: Line 7).</p></list-item><list-item><p>Invoke the Jimple and BPDG feature extraction algorithm (Algorithm 3 and pass two parameters: the .classfile of the target Java file and the list of methods within that file. This operation produces a map containing all the methods in the compiled file, along with their corresponding sequence of Jimple statements, the frequency of each Jimple statement, and BPDG features (Algorithm 4: Line 9).</p></list-item><list-item><p>For each method in the method list, obtain the sequence of AST nodes&#x02019; identifiers, sequence of Baf instructions, sequence of Jimple statements, frequency of each Jimple statement, and Jimple BPDG features. Combine these elements into a single sequence or vector and store it in the features data storage. (Algorithm 4: Lines 10 to 13).</p></list-item></list><p><bold>Algorithm 4</bold>: Combined Extracted Features</p><p specific-use="line">&#x02003;<bold>Input</bold>: JClassf, SF; // Java source file and .classfile</p><p specific-use="line">&#x02003;<bold>Output</bold>: DataStorage Features;</p><p specific-use="line"><bold>1</bold>
<italic toggle="yes">combinedF</italic> &#x02190; &#x02205;; // Combined features Map</p><p specific-use="line"><bold>2</bold>
<italic toggle="yes">MList</italic> &#x02190; &#x02205;; // Method List</p><p specific-use="line"><bold>3</bold> // Invoke Algorithm 1: To extract AST features</p><p specific-use="line"><bold>4</bold>
<italic toggle="yes">ASTFMap</italic> &#x02190; <italic toggle="yes">ExtractSyntacticFeatures</italic>(<italic toggle="yes">SF</italic>);</p><p specific-use="line"><bold>5</bold>
<italic toggle="yes">MethodList</italic> &#x02190; <italic toggle="yes">ExtractSyntacticFeatures</italic>(<italic toggle="yes">SF</italic>).<italic toggle="yes">MethodList</italic>;</p><p specific-use="line"><bold>6</bold>
<italic toggle="yes">BafFMap</italic> &#x02190; &#x02205;;</p><p specific-use="line">// Invoke Algorithm 2: To extract Baf IR features</p><p specific-use="line"><bold>7</bold>
<italic toggle="yes">BafFMap</italic> &#x02190; <italic toggle="yes">ExtractBafFeatures</italic>(<italic toggle="yes">Jclassf</italic>, <italic toggle="yes">MList</italic>);</p><p specific-use="line"><bold>8</bold>
<italic toggle="yes">JimpleFMap</italic> &#x02190; &#x02205;;</p><p specific-use="line">// Invoke Algorithm 3: To extract Jimple IR features and Jimple BPDG features</p><p specific-use="line"><bold>9</bold>
<italic toggle="yes">JimpleFMap</italic> &#x02190; <italic toggle="yes">ExtractJimplePDGFeatures</italic>(<italic toggle="yes">Jclassf</italic>, <italic toggle="yes">MList</italic>);</p><p specific-use="line"><bold>10</bold>
<bold>foreach</bold>
<underline><italic toggle="yes">m</italic> in <italic toggle="yes">MList</italic></underline>
<bold>do</bold></p><p specific-use="line">&#x02003; &#x02003; // Combine the extracted features for each method and store it in DataStorge</p><p specific-use="line"><bold>11</bold> &#x02003; <italic toggle="yes">combinedF</italic> &#x02190; <italic toggle="yes">ASTFMap.get</italic>(<italic toggle="yes">m</italic>) + &#x0201c;,&#x0201d; + <italic toggle="yes">BafFMap.get</italic>(<italic toggle="yes">m</italic>) + &#x0201c;,&#x0201d; + <italic toggle="yes">JimpleFMap.get</italic>(<italic toggle="yes">m</italic>);</p><p specific-use="line"><bold>12</bold> &#x02003; <italic toggle="yes">InsertFeatureIntoDataBase</italic>(<italic toggle="yes">m</italic>, combinedF);</p><p specific-use="line"><bold>13</bold>
<bold>end foreach</bold></p><p>After applying all of these steps on the entire corpus and extracting features, which are then stored in the data storage, this work involves creating pairs of instances from the extracted features. If two original instances are represented by feature vectors <italic toggle="yes">X</italic> = (<italic toggle="yes">x</italic><sub>1</sub>, <italic toggle="yes">x</italic><sub>2</sub>, &#x02026;, <italic toggle="yes">x</italic><sub><italic toggle="yes">n</italic></sub>) and <italic toggle="yes">Y</italic> = (<italic toggle="yes">y</italic><sub>1</sub>, <italic toggle="yes">y</italic><sub>2</sub>, &#x02026;, <italic toggle="yes">y</italic><sub><italic toggle="yes">n</italic></sub>), a pair instance <italic toggle="yes">Z</italic> = (<italic toggle="yes">X</italic>, <italic toggle="yes">Y</italic>) is represented as a vector using one of the following combination techniques:</p><list list-type="bullet"><list-item><p>Linear Combination.
<disp-formula id="pone.0302333.e001"><alternatives><graphic xlink:href="pone.0302333.e001.jpg" id="pone.0302333.e001g" position="anchor"/><mml:math id="M1" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>Z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives>
<label>(1)</label></disp-formula></p></list-item><list-item><p>Distance Combination
<disp-formula id="pone.0302333.e002"><alternatives><graphic xlink:href="pone.0302333.e002.jpg" id="pone.0302333.e002g" position="anchor"/><mml:math id="M2" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>Z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>|</mml:mo><mml:mo>,</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>|</mml:mo><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives>
<label>(2)</label></disp-formula></p></list-item><list-item><p>Multiplicative Combination.
<disp-formula id="pone.0302333.e003"><alternatives><graphic xlink:href="pone.0302333.e003.jpg" id="pone.0302333.e003g" position="anchor"/><mml:math id="M3" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>Z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives>
<label>(3)</label></disp-formula></p></list-item></list></sec></sec><sec id="sec014"><title>4.3 Stage 3: Machine learning stage</title><p>In machine learning, classifiers categorize data points into specific classes using various techniques such as linear and non-linear models, probabilistic and non-probabilistic methodologies, decision trees, and more. In this phase, fifteen classification algorithms are selected, including ensemble and individual techniques, to evaluate their effectiveness in detecting semantic clones using the proposed features. The following subsection describes the classifiers used:</p><sec id="sec015"><title>4.3.1 Ensemble classifiers</title><p>Ensemble classifiers integrate base classifiers to improve prediction performance by reducing the misclassification rate of a weak classifier through the aggregating of multiple classifiers [<xref rid="pone.0302333.ref046" ref-type="bibr">46</xref>]. The key strategies employed in ensemble classifiers include bootstrap aggregation (bagging) [<xref rid="pone.0302333.ref047" ref-type="bibr">47</xref>] and boosting [<xref rid="pone.0302333.ref048" ref-type="bibr">48</xref>].</p><list list-type="bullet"><list-item><p><bold>Boosting Classifiers:</bold> CatBoost [<xref rid="pone.0302333.ref049" ref-type="bibr">49</xref>] employs gradient boosting on decision trees, with strategies to prevent overfitting. XgBoost [<xref rid="pone.0302333.ref050" ref-type="bibr">50</xref>], an extreme gradient boosting implementation, corrects errors from preceding models for final predictions. LightGBM [<xref rid="pone.0302333.ref051" ref-type="bibr">51</xref>] follows the gradient-boosting decision tree (GBDT) method for data modelling, consolidating weak learners into a robust model. LogitBoost [<xref rid="pone.0302333.ref052" ref-type="bibr">52</xref>] progressively enhances base learners&#x02019; performance by addressing misclassified instances [<xref rid="pone.0302333.ref053" ref-type="bibr">53</xref>].</p></list-item><list-item><p><bold>Boosting Classifiers:</bold> Random Committees [<xref rid="pone.0302333.ref054" ref-type="bibr">54</xref>] combine predictions from individually trained models. In contrast, the Random forest [<xref rid="pone.0302333.ref055" ref-type="bibr">55</xref>] aggregates multiple decision trees, each created by sampling from the input vector. Rotation Forest [<xref rid="pone.0302333.ref047" ref-type="bibr">47</xref>] builds on the Random Forest concept but trains decision trees independently on a rotated feature space. Bagging [<xref rid="pone.0302333.ref056" ref-type="bibr">56</xref>] constructs multiple independent classifiers from training instances and aggregates their predictions. However, the Random Subspace technique [<xref rid="pone.0302333.ref057" ref-type="bibr">57</xref>] involves training models on diverse random feature subsets.</p></list-item></list></sec><sec id="sec016"><title>4.3.2 Individual classifiers</title><p>J48 [<xref rid="pone.0302333.ref058" ref-type="bibr">58</xref>], a Java implementation of C4.5 algorithm, normalize bias using the gain ratio in decision tree classification. Naive Bayes [<xref rid="pone.0302333.ref059" ref-type="bibr">59</xref>] applies Bayes&#x02019; theorem, assuming feature independence. Linear Discriminant Analysis (LDA) [<xref rid="pone.0302333.ref060" ref-type="bibr">60</xref>] is widely used for dimensionality reduction and classification. SVMs [<xref rid="pone.0302333.ref061" ref-type="bibr">61</xref>, <xref rid="pone.0302333.ref062" ref-type="bibr">62</xref>] optimize decision boundaries to maximize margin between classes. Logistic Regression [<xref rid="pone.0302333.ref063" ref-type="bibr">63</xref>] constructs statistical models describing relationships between dependent and independent variables. FeedForward Neural Network (FFNN) [<xref rid="pone.0302333.ref064" ref-type="bibr">64</xref>] processes data linearly through hidden layers.</p></sec></sec></sec><sec id="sec017"><title>5 Experimental evaluation</title><p>In this section, the dataset used in this work is discussed, and various experiments are conducted to evaluate the effectiveness of the proposed code representation in detecting code clones. These experiments carried out using a workstation equipped with a 2.2 GHz Intel Core i7 CPU, 32GB of (DDR3L 1333/1600 memory), and a 1-Terabyte Solid State Drive.</p><sec id="sec018"><title>5.1 Dataset</title><p>Experiments in this study were carried out on a real-world dataset: BigCloneBench, a popular benchmark for assessing Java code clone detection systems, introduced by Svajlenko et al. [<xref rid="pone.0302333.ref016" ref-type="bibr">16</xref>]. It contains 55,499 Java source files from 24,557 distinct open-source projects, collected through the mining process of IJaDataset-2.0 [<xref rid="pone.0302333.ref065" ref-type="bibr">65</xref>]. Domain experts meticulously labeled this dataset, distinguishing between clones and non-clones based on specific functionalities, without relying on clone detection tools. The current version of this benchmark includes over 8.5 million labelled true clone pairs and more than 260,000 labelled false clone pairs across 43 functionalities, categorized into Type-I, Type-II, Type-III, and Type-IV [<xref rid="pone.0302333.ref016" ref-type="bibr">16</xref>]. Clones falling between Type-III and Type-IV are classified based on their syntactic similarity into four classes: VST3, ST3, MT3, and WT34 clones [<xref rid="pone.0302333.ref066" ref-type="bibr">66</xref>].</p><p>Since the proposed approach uses High-level and low-level abstract compiled code representations, the conducted experiments exclusively used the compiled version of BigCloneBench [<xref rid="pone.0302333.ref044" ref-type="bibr">44</xref>]. It&#x02019;s important to note that this compiled version shows slight discrepancies in clone counts compared to the figures outlined in the original BigCloneBench paper [<xref rid="pone.0302333.ref016" ref-type="bibr">16</xref>]. This discrepancy can be attributed to the Stubbler [<xref rid="pone.0302333.ref043" ref-type="bibr">43</xref>] tool&#x02019;s capability to compile only approximately 95% of all Java files within the BigCloneBench dataset, preserving 92.5% of all clones in the dataset.</p><p>From the compiled BigCloneBench benchmark, 27 functionalities were selected to construct the dataset. Java files and their associated JAR files for these functionalities were processed using the proposed methodology, generating syntactic features (AST) and semantic features (Baf and Jimple IRs, Jimple PDG). A total of 41,865 Java files were processed, containing 515,654 functions, resulting in 5,968,621 function-level clone pairs and 147,390 non-clone pairs. All clone types meeting or exceeding size criteria (6 lines or 50 tokens) were considered, aligning with benchmarking standards [<xref rid="pone.0302333.ref066" ref-type="bibr">66</xref>, <xref rid="pone.0302333.ref067" ref-type="bibr">67</xref>]. Dataset details are provided in <xref rid="pone.0302333.t005" ref-type="table">Table 5</xref>. For further details, please refer to the <xref rid="pone.0302333.s002" ref-type="supplementary-material">S2 File</xref>.</p><table-wrap position="float" id="pone.0302333.t005"><object-id pub-id-type="doi">10.1371/journal.pone.0302333.t005</object-id><label>Table 5</label><caption><title>Details of dataset information.</title></caption><alternatives><graphic xlink:href="pone.0302333.t005" id="pone.0302333.t005g" position="float"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Clone Type</th><th align="left" rowspan="1" colspan="1">Pair Sample</th><th align="left" rowspan="1" colspan="1">Percentage</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Type-I&#x00026;II</td><td align="left" rowspan="1" colspan="1">23,860</td><td align="char" char="." rowspan="1" colspan="1">0.4%</td></tr><tr><td align="left" rowspan="1" colspan="1">VST3</td><td align="left" rowspan="1" colspan="1">3835</td><td align="char" char="." rowspan="1" colspan="1">0.064%</td></tr><tr><td align="left" rowspan="1" colspan="1">ST3</td><td align="left" rowspan="1" colspan="1">11866</td><td align="char" char="." rowspan="1" colspan="1">0.199%</td></tr><tr><td align="left" rowspan="1" colspan="1">MT3</td><td align="left" rowspan="1" colspan="1">62654</td><td align="char" char="." rowspan="1" colspan="1">1.05%</td></tr><tr><td align="left" rowspan="1" colspan="1">WT3/4</td><td align="left" rowspan="1" colspan="1">5866406</td><td align="char" char="." rowspan="1" colspan="1">98.287%</td></tr><tr><td align="left" rowspan="1" colspan="1">Total</td><td align="left" rowspan="1" colspan="1">5968621</td><td align="left" rowspan="1" colspan="1"/></tr></tbody></table></alternatives></table-wrap></sec><sec id="sec019"><title>5.2 Evaluation</title><p>The effectiveness of the proposed code representation in identifying code clones, particularly semantic clones, is evaluated through a series of experiments. Various combinations of feature fusion techniques and different feature types and sizes are explored to demonstrate their effectiveness in achieving exceptional detection accuracy. Furthermore, the proposed technique is compared with widely used approaches for clone detection. Due to space constraints, only the best-performing classifiers from most experiments are reported in this section. For additional results, readers are encouraged to refer to the <xref rid="pone.0302333.s004" ref-type="supplementary-material">S4 File</xref>.</p><sec id="sec020"><title>5.2.1 Evaluation of the performance of various classifiers</title><p>In this experiment, an evaluation was conducted on the performance of three feature concatenation techniques and classifiers. A total of 60,000 pair samples were randomly selected for both Type-I &#x00026; II, VST3, ST3, MT3, WT3/4 clones, and false positives from the compiled BigCloneBench dataset as outlined in section 5.1. To address the issue of imbalanced data, the standard Synthetic Minority Over-sampling Technique (SMOTE [<xref rid="pone.0302333.ref068" ref-type="bibr">68</xref>]) was used to balance the samples for VST3 clone pairs. The training and testing of all candidate classifiers were performed using 10-fold Stratified cross-validation, ensuring consistent class ratios within each fold. <xref rid="pone.0302333.g010" ref-type="fig">Fig 10</xref> depicts a performance comparison in accuracy among all fifteen classifiers utilizing multiplicative, distance, and linear combination approaches on the selected dataset.</p><fig position="float" id="pone.0302333.g010"><object-id pub-id-type="doi">10.1371/journal.pone.0302333.g010</object-id><label>Fig 10</label><caption><title>Performance comparison of fifteen classifiers utilizing various feature combinations on the BigCloneBench dataset.</title></caption><graphic xlink:href="pone.0302333.g010" position="float"/></fig><p>The experimental findings highlight the effectiveness of ensemble techniques, which include bagging and boosting methods such as Rotation Forest, Random Forest, Bagging, Random Committee, XGBoost, LightGBM, and CatBoost. These techniques consistently outperform most standalone classifiers, except for the Feed Forward Neural Network (FFNN). This superiority arises from ensemble methods&#x02019; ability to combine multiple models, strategically leveraging diverse classifiers&#x02019; strengths to compensate for individual weaknesses [<xref rid="pone.0302333.ref069" ref-type="bibr">69</xref>]. Additionally, ensembles exhibit enhanced robustness to outliers and noisy data, effectively alleviating model bias and variance [<xref rid="pone.0302333.ref070" ref-type="bibr">70</xref>].</p><p>Significantly, Random Forest, Rotation Forest, LightGBM, and Xgboost classifiers demonstrate outstanding accuracy among other ensemble classifiers achieving (95.71%, 91.67%, 94.49%), (96.27%, 92.17%, 95.17%), (96.75%, 93.09%, 95.62%), and (96.73%, 93.76%, 95.8%) in linear, multiplicative, and distance combination respectively. It is noteworthy that the FFNN demonstrates competitive performance with ensemble techniques, achieving (92.22%, 87.8%, and 91.23%) accuracy in linear, multiplicative and distance combinations, demonstrating proficiency in handling complex data relationships and acquiring hierarchical representations [<xref rid="pone.0302333.ref071" ref-type="bibr">71</xref>].</p><p>Observations across all classifiers indicate that a linear combination consistently yields superior results compared to distance and multiplicative combinations. The effectiveness of Linear combination lies in its ability to preserve the original feature values without alteration, a characteristic not shared by the other two combination methods [<xref rid="pone.0302333.ref072" ref-type="bibr">72</xref>]. The use of multiplicative and distance combinations may potentially hinder classifier performance, as these methods might find certain combinations unsuitable for effective utilization.</p></sec><sec id="sec021"><title>5.2.2 Evaluation of the performance with different dataset sizes and feature types</title><p>Multiple experiments were conducted to evaluate the effectiveness of combining AST, BAF, and Jimple PDG features using three combination methods: Linear, distance, and multiplicative. The datasets employed in these experiments were subsets of BigCloneBench, as specified in section 5.1, comprising 10,000, 20,000, 30,000 and 40,000 paired samples representing both code clones and false positives. Figs <xref rid="pone.0302333.g011" ref-type="fig">11</xref>&#x02013;<xref rid="pone.0302333.g013" ref-type="fig">13</xref> display the results generated by the highest-performing classifiers in these experiments. Among these top-performing classifiers are two derived from bagging techniques (Rotation Forest and Random Forest), two from boosting techniques (LightGBM and XgBoost), and one individual classifier (Feedforward Neural Network&#x02014;FFNN).</p><fig position="float" id="pone.0302333.g011"><object-id pub-id-type="doi">10.1371/journal.pone.0302333.g011</object-id><label>Fig 11</label><caption><title>Performance of top 5 classifiers with linearly combined features on four BigCloneBench datasets.</title></caption><graphic xlink:href="pone.0302333.g011" position="float"/></fig><fig position="float" id="pone.0302333.g012"><object-id pub-id-type="doi">10.1371/journal.pone.0302333.g012</object-id><label>Fig 12</label><caption><title>Performance of top 5 classifiers with multiplicative combined features on four BigCloneBench datasets.</title></caption><graphic xlink:href="pone.0302333.g012" position="float"/></fig><fig position="float" id="pone.0302333.g013"><object-id pub-id-type="doi">10.1371/journal.pone.0302333.g013</object-id><label>Fig 13</label><caption><title>Performance of top 5 classifiers with distance combined features on four BigCloneBench datasets.</title></caption><graphic xlink:href="pone.0302333.g013" position="float"/></fig><p>The integration of AST, BAF, and Jimple PDG features collectively resulted in a significant enhancement in the performance of classifiers for clone detection. In the Linear combination experiments, the average performance disparity between using AST alone and incorporating the combined features was 3.6%. In contrast, the multiplicative combined technique exhibited an average difference of 7.4%, while the distance combined technique showed a difference of 5.4%. Interestingly, it was observed that the classifiers consistently performed well regardless of the dataset size. Additionally, it is noteworthy that a linear combination consistently produced superior results compared with the distance and multiplicative combination methods across all dataset sizes. This finding is consistent with the outcomes of the first experiment results.</p></sec><sec id="sec022"><title>5.2.3 Evaluation of the performance with different feature sizes</title><p>To underscore the importance of the proposed features in enhancing performance in code clone detection and to ensure that this improvement is not coincidental, an experiment was conducted involving varying numbers of features, combined by three combination approaches (linear, multiplicative, distance). An Equal number of features was selected from each type (AST, BAF, and Jimple PDG). The dataset utilized in this experiment was obtained from BigCloneBench, specified in section 5.1, comprising 40,000 paired samples representing different types of code clones and false positives.</p><p>Figs <xref rid="pone.0302333.g014" ref-type="fig">14</xref>&#x02013;<xref rid="pone.0302333.g016" ref-type="fig">16</xref> present the outcomes produced by top-performing classifiers, namely Rotation Forest, Random Forest, LightGBM, and XgBoost.</p><fig position="float" id="pone.0302333.g014"><object-id pub-id-type="doi">10.1371/journal.pone.0302333.g014</object-id><label>Fig 14</label><caption><title>Performance of XgBoost, LightGBM, Random Forest, and Rotation Forest classifiers with different feature sizes using distance combination approach on the BigCloneBench dataset.</title></caption><graphic xlink:href="pone.0302333.g014" position="float"/></fig><fig position="float" id="pone.0302333.g015"><object-id pub-id-type="doi">10.1371/journal.pone.0302333.g015</object-id><label>Fig 15</label><caption><title>Performance of XgBoost, LightGBM, Random Forest, and Rotation Forest classifiers with different feature sizes using multiplicative combination approach on the BigCloneBench dataset.</title></caption><graphic xlink:href="pone.0302333.g015" position="float"/></fig><fig position="float" id="pone.0302333.g016"><object-id pub-id-type="doi">10.1371/journal.pone.0302333.g016</object-id><label>Fig 16</label><caption><title>Performance of XgBoost, LightGBM, Random Forest, and Rotation Forest classifiers with different feature sizes using linear combination approach on the BigCloneBench dataset.</title></caption><graphic xlink:href="pone.0302333.g016" position="float"/></fig><p>The ascending learning curve depicted in these figures unequivocally demonstrates that the detection performance improves with the increasing number of features. This observation substantiates the critical role of the proposed features in achieving high-performance detection results.</p></sec><sec id="sec023"><title>5.2.4 Evaluation of the performance in semantic clone detection</title><p>To evaluate the effectiveness of the proposed code representation in detecting semantic clones, particularly those categorized as VST3, ST3, MT3, and WT3/4), five clone detection models were built. Each model employed a distinct classifier. Specifically, the utilized classifiers were Random Forest, Rotation Forest, LightBMG, XgBoost, and FFNN classifiers.</p><p>Five experiments were conducted using a dataset containing 20,000 paired samples. Within each clone category (VST3, ST3, MT3, and WT3/4), there were 5000 pairs of samples, randomly selected from a larger dataset sourced from BigCloneBench. These paired samples were amalgamated using three different approaches: linear, multiplicative, and distance. The models underwent training and testing using a 10-fold Stratified cross-validation approach. <xref rid="pone.0302333.t006" ref-type="table">Table 6</xref> presents the precision, recall, and F1-score for the outcomes of the models in these experiments that utilized paired samples combined using the linear combination approach.</p><table-wrap position="float" id="pone.0302333.t006"><object-id pub-id-type="doi">10.1371/journal.pone.0302333.t006</object-id><label>Table 6</label><caption><title>Results of detected semantic clones using the proposed technique.</title></caption><alternatives><graphic xlink:href="pone.0302333.t006" id="pone.0302333.t006g" position="float"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Classifier</th><th align="center" rowspan="1" colspan="1">Clone Type</th><th align="center" rowspan="1" colspan="1">Precision</th><th align="center" rowspan="1" colspan="1">Recall</th><th align="center" rowspan="1" colspan="1">F1-score</th></tr></thead><tbody><tr><td align="left" rowspan="4" colspan="1">Random Forest</td><td align="center" rowspan="1" colspan="1">VST3</td><td align="center" rowspan="1" colspan="1">91%</td><td align="center" rowspan="1" colspan="1">90%</td><td align="center" rowspan="1" colspan="1">90%</td></tr><tr><td align="center" rowspan="1" colspan="1">ST3</td><td align="center" rowspan="1" colspan="1">84%</td><td align="center" rowspan="1" colspan="1">78%</td><td align="center" rowspan="1" colspan="1">81%</td></tr><tr><td align="center" rowspan="1" colspan="1">MT3</td><td align="center" rowspan="1" colspan="1">90%</td><td align="center" rowspan="1" colspan="1">90%</td><td align="center" rowspan="1" colspan="1">90%</td></tr><tr><td align="center" rowspan="1" colspan="1">WT3/4</td><td align="center" rowspan="1" colspan="1">79%</td><td align="center" rowspan="1" colspan="1">85%</td><td align="center" rowspan="1" colspan="1">82%</td></tr><tr><td align="left" rowspan="4" colspan="1">Rotation Forest</td><td align="center" rowspan="1" colspan="1">VST3</td><td align="center" rowspan="1" colspan="1">91%</td><td align="center" rowspan="1" colspan="1">91%</td><td align="center" rowspan="1" colspan="1">91%</td></tr><tr><td align="center" rowspan="1" colspan="1">ST3</td><td align="center" rowspan="1" colspan="1">85%</td><td align="center" rowspan="1" colspan="1">79%</td><td align="center" rowspan="1" colspan="1">82%</td></tr><tr><td align="center" rowspan="1" colspan="1">MT3</td><td align="center" rowspan="1" colspan="1">91%</td><td align="center" rowspan="1" colspan="1">91%</td><td align="center" rowspan="1" colspan="1">91%</td></tr><tr><td align="center" rowspan="1" colspan="1">WT3/4</td><td align="center" rowspan="1" colspan="1">78.8%</td><td align="center" rowspan="1" colspan="1">85%</td><td align="center" rowspan="1" colspan="1">82%</td></tr><tr><td align="left" rowspan="4" colspan="1">XgBoost</td><td align="center" rowspan="1" colspan="1">VST3</td><td align="center" rowspan="1" colspan="1">90.6%</td><td align="center" rowspan="1" colspan="1">92%</td><td align="center" rowspan="1" colspan="1">91%</td></tr><tr><td align="center" rowspan="1" colspan="1">ST3</td><td align="center" rowspan="1" colspan="1">83%</td><td align="center" rowspan="1" colspan="1">80%</td><td align="center" rowspan="1" colspan="1">82%</td></tr><tr><td align="center" rowspan="1" colspan="1">MT3</td><td align="center" rowspan="1" colspan="1">95%</td><td align="center" rowspan="1" colspan="1">91%</td><td align="center" rowspan="1" colspan="1">93%</td></tr><tr><td align="center" rowspan="1" colspan="1">WT3/4</td><td align="center" rowspan="1" colspan="1">81%</td><td align="center" rowspan="1" colspan="1">86%</td><td align="center" rowspan="1" colspan="1">83%</td></tr><tr><td align="left" rowspan="4" colspan="1">LightBGM</td><td align="center" rowspan="1" colspan="1">VST3</td><td align="center" rowspan="1" colspan="1">97.9%</td><td align="center" rowspan="1" colspan="1">96.2%</td><td align="center" rowspan="1" colspan="1">97.04%</td></tr><tr><td align="center" rowspan="1" colspan="1">ST3</td><td align="center" rowspan="1" colspan="1">97.018%</td><td align="center" rowspan="1" colspan="1">96.8%</td><td align="center" rowspan="1" colspan="1">96.9%</td></tr><tr><td align="center" rowspan="1" colspan="1">MT3</td><td align="center" rowspan="1" colspan="1">96.5%</td><td align="center" rowspan="1" colspan="1">96.3%</td><td align="center" rowspan="1" colspan="1">96.4%</td></tr><tr><td align="center" rowspan="1" colspan="1">WT3/4</td><td align="center" rowspan="1" colspan="1">95%</td><td align="center" rowspan="1" colspan="1">89.7%</td><td align="center" rowspan="1" colspan="1">92.3%</td></tr><tr><td align="left" rowspan="4" colspan="1">FFNN</td><td align="center" rowspan="1" colspan="1">VST3</td><td align="center" rowspan="1" colspan="1">88%</td><td align="center" rowspan="1" colspan="1">89%</td><td align="center" rowspan="1" colspan="1">89%</td></tr><tr><td align="center" rowspan="1" colspan="1">ST3</td><td align="center" rowspan="1" colspan="1">75%</td><td align="center" rowspan="1" colspan="1">70%</td><td align="center" rowspan="1" colspan="1">72%</td></tr><tr><td align="center" rowspan="1" colspan="1">MT3</td><td align="center" rowspan="1" colspan="1">93%</td><td align="center" rowspan="1" colspan="1">87%</td><td align="center" rowspan="1" colspan="1">90%</td></tr><tr><td align="center" rowspan="1" colspan="1">WT3/4</td><td align="center" rowspan="1" colspan="1">71%</td><td align="center" rowspan="1" colspan="1">80%</td><td align="center" rowspan="1" colspan="1">75%</td></tr></tbody></table></alternatives></table-wrap><p>
<xref rid="pone.0302333.t006" ref-type="table">Table 6</xref> reveals that models built with Random Forest, Rotation Forest, and XgBoost classifiers perform well in detecting semantic clones. However, the model constructed using the LightGBM classifier achieves the highest scores across all metrics, including F1-score, precision, and recall, for detecting semantic clones (VST3 F1-score: 97.04%, ST3 F1-score: 96.9%, MT3 F1-score: 96.4%, and WT3/4 F1-score: 92.3%).</p><p>Generally, employing our code representation yields commendable results in the identification of semantic clones. This outcome primarily stems from the effectiveness of the proposed code representation. This integration enables the capture of more comprehensive semantic features, thereby enhancing the classifiers&#x02019; efficiency in identifying a broader range of Type-III and Type-IV clones.</p></sec><sec id="sec024"><title>5.2.5 Performance comparison of different clone detection techniques</title><p>To validate the effectiveness of the proposed technique, a comparative analysis was conducted against selected clone detection techniques that utilized the BigCloneBench dataset. Performance evaluation was assessed using recall and F1-score, widely accepted metrics for classification evaluation. The analysis extends beyond overall detection performance; it delves into intricacies across different semantic clone types, specifically VST3, ST3, MT3, and WT3/4. The selected baselines include:</p><list list-type="bullet"><list-item><p><bold>Traditional Techniques</bold> encompass a variety of clone detection methods, including Deckard [<xref rid="pone.0302333.ref018" ref-type="bibr">18</xref>], a widely used syntactical-based detector that generates representative vectors for each AST through predefined rules. In contrast, SourcererCC [<xref rid="pone.0302333.ref028" ref-type="bibr">28</xref>] operates as a lexical-based clone detector. Additionally, CCFinder [<xref rid="pone.0302333.ref073" ref-type="bibr">73</xref>] is a popular multilingual token-based clone detector employing a suffix-tree matching algorithm. Nicad [<xref rid="pone.0302333.ref027" ref-type="bibr">27</xref>] employs a straightforward text-based approach for clone detection. iClones [<xref rid="pone.0302333.ref074" ref-type="bibr">74</xref>] uses a hybrid token and tree approach. It creates an AST from the source code, converts it to tokens, and then detects clones using a suffix tree algorithm.</p></list-item><list-item><p><bold>Machine learning and deep learning techniques</bold> are exemplified by CCLearner [<xref rid="pone.0302333.ref075" ref-type="bibr">75</xref>], the first token-based detector employing deep learning. CDLH [<xref rid="pone.0302333.ref076" ref-type="bibr">76</xref>] represents a clone detection approach based on deep learning, utilizing ASTs to represent code features. Oreo [<xref rid="pone.0302333.ref007" ref-type="bibr">7</xref>] is a code clone detector that integrates software metrics, information retrieval, and machine learning. ASTNN [<xref rid="pone.0302333.ref077" ref-type="bibr">77</xref>] employs an AST-based neural network that represents source code with smaller statement trees derived from segmented ASTs, capturing both lexical and syntactical knowledge. Finally, Sheneamer et al. [<xref rid="pone.0302333.ref078" ref-type="bibr">78</xref>] employ multiple machine learning classifiers to detect code clones, using features extracted from ASTs and PDGs. DLC [<xref rid="pone.0302333.ref076" ref-type="bibr">76</xref>] uses a recursive neural network approach to detect code similarity, utilizing the Euclidean distance as a metric.</p></list-item></list><p>Figs <xref rid="pone.0302333.g017" ref-type="fig">17</xref> and <xref rid="pone.0302333.g018" ref-type="fig">18</xref> present a comprehensive comparison of recall and F1 scores for each semantic clone between the proposed technique and the other selected techniques. The results for NiCad, SourcererCC, iClones, CCFinder, CCLearner, Dekard, Dlc, CDLH, Oreo, ASTNN, and Sheneamer et al. align with those reported in [<xref rid="pone.0302333.ref007" ref-type="bibr">7</xref>, <xref rid="pone.0302333.ref028" ref-type="bibr">28</xref>, <xref rid="pone.0302333.ref031" ref-type="bibr">31</xref>, <xref rid="pone.0302333.ref045" ref-type="bibr">45</xref>, <xref rid="pone.0302333.ref075" ref-type="bibr">75</xref>&#x02013;<xref rid="pone.0302333.ref078" ref-type="bibr">78</xref>].</p><fig position="float" id="pone.0302333.g017"><object-id pub-id-type="doi">10.1371/journal.pone.0302333.g017</object-id><label>Fig 17</label><caption><title>Recall values when comparing the proposed method against selected methods with respected to different clone types.</title></caption><graphic xlink:href="pone.0302333.g017" position="float"/></fig><fig position="float" id="pone.0302333.g018"><object-id pub-id-type="doi">10.1371/journal.pone.0302333.g018</object-id><label>Fig 18</label><caption><title>F1-Score values when comparing the proposed method against selected methods with respected to different clone types.</title></caption><graphic xlink:href="pone.0302333.g018" position="float"/></fig><p>The results reveal low recall scores for NiCad, SorcerereCC, iClones, CCFinder, CCLearner, Dekard, and Oreo in identifying MT3 and WT3/4 clones, with scores of (0.8%,0%), (5%,0%), (0%,0%), (1%,0%), (28%,1%), (12%,1%), and (30%,0.7%) respectively. Additionally, NiCad, SourcererCC, CCFinder, Dekard, and DLC techniques exhibit low F1 scores for detecting MT-3 and WT3/4 clones, with scores of (2%,0%), (9.5%,0), (2%,0%), (21.3%,2%), and (3%,0%) respectively. Notably, F1 scores for CCLearner and Oreo are not reported and recall scores for DLC and CDLH are not reported. This indicates that these techniques may struggle to represent source code effectively, hindering their ability to capture comprehensive semantic features. Consequently, their performance (in terms of recall and F1 score) in detecting semantic clones, especially MT3 and WT3/4, is compromised.</p><p>In contrast, the proposed technique, employing the LightBGM classifier with a linear combination approach, outperforms NiCad, SourcererCC, CCFinder, CCLearner, iClones, Dekard, and Oreo in detecting the more complex clone types MT3 and WT3/4. It achieves higher recall and F1 scores, with values of (96.3%, 89.7%) and (96.4%, 92.3%) respectively. Furthermore, the proposed technique, utilizing the LightBGM classifier outperformed CDLH, ASTNN, and Sheneamer et al. [<xref rid="pone.0302333.ref078" ref-type="bibr">78</xref>] in detecting VST3, ST3, and MT3 clones in terms of F1-score.</p><p>The results shown in Figs <xref rid="pone.0302333.g017" ref-type="fig">17</xref> and <xref rid="pone.0302333.g018" ref-type="fig">18</xref> clearly demonstrate the effectiveness of the proposed code representation methodology in capturing comprehensive semantic features, thereby enhancing the identification of semantic clones.</p></sec></sec></sec><sec sec-type="conclusions" id="sec025"><title>6 Discussion</title><p>It is well-established that a higher level of abstraction in source code allows capturing a broader range of semantic code information [<xref rid="pone.0302333.ref045" ref-type="bibr">45</xref>]. This work is distinguished by its utilization of abstract features inherent in both high and low-level code representations [<xref rid="pone.0302333.ref008" ref-type="bibr">8</xref>, <xref rid="pone.0302333.ref041" ref-type="bibr">41</xref>, <xref rid="pone.0302333.ref042" ref-type="bibr">42</xref>]. Prior studies have concentrated on integrating these representations to identify Type-IV clones, emphasizing feature extraction from non-abstract representations. However, their approaches pose challenges due to the excessive details in non-abstract representations. What marks this study as distinctive is its utilization of the capabilities of static code analysis tools to convert programs into different abstract IRs, each offering distinct levels of abstraction and advantages for source code analysis, provides substantial advantages by eliminating extraneous elements while retaining the fundamental operations that convey the semantic meaning of the code fragment. These IRs diminish the effectiveness of obfuscation techniques, such as those that alter the syntactic structure while preserving the original code&#x02019;s semantics and functionality (e.g., metamorphism and polymorphism [<xref rid="pone.0302333.ref026" ref-type="bibr">26</xref>]).</p><p>This section summarizes the key findings and results obtained from the experiments and explores the following perspectives:</p><list list-type="bullet"><list-item><p><bold>How well does the proposed approach perform in detecting different types of code clones?</bold> Based on the results obtained from the experiments, it can be concluded that the proposed method shows promising performance in detecting code clones (syntactic and semantic). Ensemble classifiers, such as Random Forest, Rotation Forest, LightGBM, and Xgboost, achieved consistently high accuracy rates across different combinations, ranging from 95.65% to 96.75%, more details in <xref rid="pone.0302333.g010" ref-type="fig">Fig 10</xref>. Furthermore, the FeedForward Neural Network (FFNN) also demonstrated competitive performance, indicating its effectiveness in handling complex data relationships. These findings suggest that the proposed method, along with the selected classifiers, has the potential to effectively identify code clones in software.</p></list-item><list-item><p><bold>What is the impact of integrating different features on the effectiveness of the proposed method in detecting code clones?</bold> From the conducted experiments, it is evident that integrating different types of features, namely AST, BAF, and Jimple PDG, yields better results in detecting clones. Figs <xref rid="pone.0302333.g011" ref-type="fig">11</xref>&#x02013;<xref rid="pone.0302333.g013" ref-type="fig">13</xref> illustrate the outcomes obtained by the highest-performing classifiers in these experiments, reaffirming the effectiveness of feature integration. Across various dataset sizes and combination techniques (linear, multiplicative, and distance), the classifiers consistently performed well. Particularly noteworthy is the observation that the linear combination method consistently outperformed the distance and multiplicative methods across all dataset sizes, with average performance disparities ranging from 3.6% to 7.4%. These findings emphasize the significance of feature integration in enhancing clone detection accuracy.</p></list-item><list-item><p><bold>How does changing the number of features affect the effectiveness of the proposed approach in detecting code clones?</bold> This study extends the previous research point by confirming the effectiveness of the proposed method in identifying code clones using varying numbers of features for each type. The results presented in Figs <xref rid="pone.0302333.g014" ref-type="fig">14</xref>&#x02013;<xref rid="pone.0302333.g016" ref-type="fig">16</xref>, obtained from top-performing classifiers, including Rotation Forest, Random Forest, LightGBM, and XgBoost, clearly show an upward trend in detection performance as the number of features increases. This trend underscores the importance of the proposed features in achieving superior detection results, indicating that the observed improvements are not merely coincidental but rather driven by the inclusion of these features.</p><p>Based on the findings of this experiment, there is an opportunity to advance this research by investigating features of all types that contain more comprehensive semantic information and have made significant contributions to the semantic representation of code fragments. The techniques proposed by Heba and El-Hafeez [<xref rid="pone.0302333.ref034" ref-type="bibr">34</xref>, <xref rid="pone.0302333.ref035" ref-type="bibr">35</xref>], which introduce novel techniques for selecting the most effective features, can be applied to identify the most important features that semantically encapsulate source code and reduce the overall number of features used.</p></list-item><list-item><p><bold>How effective is the proposed method in detecting semantic clones?</bold> The analysis of the effectiveness of the proposed code representation in detecting semantic clones, particularly those classified as VST3, ST3, MT3, and WT3/4, involved building five clone detection models. Results from <xref rid="pone.0302333.t006" ref-type="table">Table 6</xref> indicate that models utilizing Random Forest, Rotation Forest, and XGBoost classifiers show promising performance in identifying semantic clones. However, the model constructed using the LightGBM classifier outperforms others across all metrics, including F1-score, precision, and recall, for detecting semantic clones (VST3 F1-score: 97.04%, ST3 F1-score: 96.9%, MT3 F1-score: 96.4%, and WT3/4 F1-score: 92.3%). Overall, the employment of the proposed code representation yields commendable results in identifying semantic clones. This success can be primarily attributed to the effectiveness of the proposed code representation, which integrates source code features (AST) with features derived from abstract compiled IRs. This integration enables the capture of more comprehensive semantic features, thereby enhancing the efficiency of classifiers in identifying a broader range of Type-III and Type-IV clones.</p></list-item><list-item><p><bold>How does the performance of the proposed technique in semantic clone detection compare to state-of-the-art approaches?</bold> The analysis conducted in Section 5.2.5 demonstrates that the proposed approach for detecting syntactic and semantic clones outperforms several state-of-the-art clone detection techniques. Utilizing the LightBGM classifier with a linear combination approach, the proposed technique outperforms NiCad, SourcererCC, iClones, CCFinder, CCLearner, Dekard, DLC, CDLH, and Oreo in detecting complex clone types MT-3 and WT3/4, achieving higher recall and F1 scores. Specifically, it achieves recall and F1 scores of 96.3% and 96.4%, respectively, for MT3 clones, and 89.7% and 92.3%, respectively, for WT3/4 clones. Overall, the results clearly demonstrate the effectiveness of the proposed code representation in capturing more comprehensive semantics features, thereby improving the identification of semantic clones.</p></list-item></list></sec><sec id="sec026"><title>7 Threats to validity and limitations</title><p>There are four primary threats to the validity of the proposed approach.</p><p>Firstly, the effectiveness of the proposed approach is only demonstrated using the BigCloneBench dataset. However, it&#x02019;s important to note that BigCloneBench contains code fragments extracted from real-world Java repositories sourced from the IJaDataset 2.0. Moreover, BigCloneBench is widely recognized as a benchmark for evaluating code clone detection methods, thereby addressing this potential limitation.</p><p>Secondly, by focusing exclusively on method-level clones, there is a risk of overlooking overlapping clones or clones within Java classes. Nevertheless, it&#x02019;s worth noting that the majority of clones in Java code fragments occur at the method level [<xref rid="pone.0302333.ref078" ref-type="bibr">78</xref>].</p><p>The third threat arises from relying on previously published results from various baseline studies. This reliance was necessary due to unclear experiment settings in some baselines, like DLC and CDLH. However, depending directly on reported data from existing papers makes it difficult for us to conduct a more detailed qualitative comparison, including counting and analyzing each clone fragment between the proposed technique and others.</p><p>Finally, this study exclusively focuses on the Java programming language, chosen for its enduring prominence in the software development domain. Java language consistently ranks among the top five programming languages in the TIOBE index [<xref rid="pone.0302333.ref079" ref-type="bibr">79</xref>], indicating its continued relevance and widespread use. Moreover, Java&#x02019;s popularity has experienced a significant boost due to its critical role in Android application development.</p></sec><sec sec-type="conclusions" id="sec027"><title>8 Conclusion</title><p>This work presents a novel technique for detecting syntactic and semantic clones in Java source code, leveraging a unique code representation that integrates high-level source code features with low-level abstract compiled code features. High-level features are extracted from the AST of the source code, while the low-level features are derived from IRs&#x02014;Baf, Jimple, and Jimple block PDG- generated by the Soot framework. Fifteen classifiers were trained and evaluated using this proposed code representation. Extensive experiments were conducted on the comprehensive real-world dataset, BigCloneBench, demonstrating the effectiveness of the approach in identifying semantic clones. The ensemble classifiers, including Random Forest, Rotation Forest, LightGBM, and XGBoost, achieved high accuracy rates across different classifiers, ranging from 95.65% to 96.75%. Moreover, the LightGBM classifier trained on the proposed technique, outperformed other baseline techniques, achieving higher recall and F1 scores of 96.3% and 96.4%, respectively, for MT3 clones, and 89.7% and 92.3%, respectively, for WT3/4 clones.</p><p>In future research, we plan to explore different deep learning architectures, including Recurrent Neural Networks (RNNs), Graph Convolutional Neural Networks (GCNNs), and Convolutional Neural Networks (CNNs), for semantic clone detection using this proposed code representation. Additionally, we will be considering extending this technique to detect semantic clones in programming languages beyond Java, with an assessment of its applicability across diverse codebases. Furthermore, we aim to investigate the effectiveness of the technique in detecting clones across various programming languages to expand its scope and impact on code clone detection. Moreover, scalability and other perspectives, such as performance optimization, were not investigated in this study. However, these areas offer promising opportunities for further investigation.</p></sec><sec id="sec028" sec-type="supplementary-material"><title>Supporting information</title><supplementary-material id="pone.0302333.s001" position="float" content-type="local-data"><label>S1 File</label><caption><title>List of features used in this study.</title><p>(PDF)</p></caption><media xlink:href="pone.0302333.s001.pdf"/></supplementary-material><supplementary-material id="pone.0302333.s002" position="float" content-type="local-data"><label>S2 File</label><caption><title>Descriptive analysis of all clones types in BigCloneBench.</title><p>(PDF)</p></caption><media xlink:href="pone.0302333.s002.pdf"/></supplementary-material><supplementary-material id="pone.0302333.s003" position="float" content-type="local-data"><label>S3 File</label><caption><title>Supplementary experiment results.</title><p>(PDF)</p></caption><media xlink:href="pone.0302333.s003.pdf"/></supplementary-material><supplementary-material id="pone.0302333.s004" position="float" content-type="local-data"><label>S4 File</label><caption><title>Constructed datasets.</title><p>(RAR)</p></caption><media xlink:href="pone.0302333.s004.rar"/></supplementary-material></sec></body><back><ack><p>The authors express their gratitude for the support of University of Peshawar in proposing this work.</p></ack><ref-list><title>References</title><ref id="pone.0302333.ref001"><label>1</label><mixed-citation publication-type="journal">
<name><surname>Saini</surname><given-names>N</given-names></name>, <name><surname>Singh</surname><given-names>S</given-names></name>, <name><surname>Suman</surname></name>. <article-title>Code clones: Detection and management</article-title>. <source>Procedia Computer Science</source>. <year>2018</year>;<volume>132</volume>:<fpage>718</fpage>&#x02013;<lpage>727</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.procs.2018.05.080</pub-id></mixed-citation></ref><ref id="pone.0302333.ref002"><label>2</label><mixed-citation publication-type="other">Gharehyazie M, Ray B, Filkov V. Some from here, Some from there: Cross-project code reuse in GitHub. In: 2017 IEEE/ACM 14th International Conference on Mining Software Repositories (MSR); 2017. p. 291&#x02013;301.</mixed-citation></ref><ref id="pone.0302333.ref003"><label>3</label><mixed-citation publication-type="journal">
<name><surname>Baker</surname><given-names>BS</given-names></name>. <article-title>Parameterized pattern matching: Algorithms and applications</article-title>. <source>Journal of Computer and System Sciences</source>. <year>1996</year>;<volume>52</volume>(<issue>1</issue>):<fpage>28</fpage>&#x02013;<lpage>42</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1006/jcss.1996.0003</pub-id></mixed-citation></ref><ref id="pone.0302333.ref004"><label>4</label><mixed-citation publication-type="other">Koschke R, Bazrafshan S. Software-clone Rates in open-source programs written in C or C++. In: 2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER). vol. 3; 2016. p. 1&#x02013;7.</mixed-citation></ref><ref id="pone.0302333.ref005"><label>5</label><mixed-citation publication-type="journal">
<name><surname>Rattan</surname><given-names>D</given-names></name>, <name><surname>Bhatia</surname><given-names>R</given-names></name>, <name><surname>Singh</surname><given-names>M</given-names></name>. <article-title>Software clone detection: A systematic review</article-title>. <source>Information and Software Technology</source>. <year>2013</year>;<volume>55</volume>(<issue>7</issue>):<fpage>1165</fpage>&#x02013;<lpage>1199</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.infsof.2013.01.008</pub-id></mixed-citation></ref><ref id="pone.0302333.ref006"><label>6</label><mixed-citation publication-type="other">Yu H, Lam W, Chen L, Li G, Xie T, Wang Q. Neural detection of semantic code clones via tree-based convolution. In: 2019 IEEE/ACM 27th International Conference on Program Comprehension (ICPC); 2019. p. 70&#x02013;80.</mixed-citation></ref><ref id="pone.0302333.ref007"><label>7</label><mixed-citation publication-type="book">
<name><surname>Saini</surname><given-names>V</given-names></name>, <name><surname>Farmahinifarahani</surname><given-names>F</given-names></name>, <name><surname>Lu</surname><given-names>Y</given-names></name>, <name><surname>Baldi</surname><given-names>P</given-names></name>, <name><surname>Lopes</surname><given-names>CV</given-names></name>. <part-title>Oreo: Detection of Clones in the Twilight Zone</part-title>. <source>ESEC/FSE 2018</source>. <publisher-loc>New York, NY, USA</publisher-loc>: <publisher-name>Association for Computing Machinery</publisher-name>; <year>2018</year>. p. <fpage>354</fpage>&#x02013;<lpage>365</lpage>. Available from: <pub-id pub-id-type="doi">10.1145/3236024.3236026</pub-id>.</mixed-citation></ref><ref id="pone.0302333.ref008"><label>8</label><mixed-citation publication-type="book">
<name><surname>White</surname><given-names>M</given-names></name>, <name><surname>Tufano</surname><given-names>M</given-names></name>, <name><surname>Vendome</surname><given-names>C</given-names></name>, <name><surname>Poshyvanyk</surname><given-names>D</given-names></name>. <part-title>Deep learning code fragments for code clone detection</part-title>. <source>ASE&#x02019;16</source>. <publisher-loc>New York, NY, USA</publisher-loc>: <publisher-name>Association for Computing Machinery</publisher-name>; <year>2016</year>. p. <fpage>87</fpage>&#x02013;<lpage>98</lpage>. Available from: <pub-id pub-id-type="doi">10.1145/2970276.2970326</pub-id>.</mixed-citation></ref><ref id="pone.0302333.ref009"><label>9</label><mixed-citation publication-type="book">
<name><surname>Saca</surname><given-names>MA</given-names></name>. <part-title>Refactoring improving the design of existing code</part-title>. In: <source>2017 IEEE 37th Central America and Panama Convention (CONCAPAN XXXVII)</source>; <year>2017</year>. p. <fpage>1</fpage>&#x02013;<lpage>3</lpage>.</mixed-citation></ref><ref id="pone.0302333.ref010"><label>10</label><mixed-citation publication-type="journal">
<name><surname>Roy</surname><given-names>CK</given-names></name>, <name><surname>Cordy</surname><given-names>JR</given-names></name>. <article-title>A survey on software clone detection research</article-title>. <source>Queen&#x02019;s School of computing TR</source>. <year>2007</year>;<volume>541</volume>(<issue>115</issue>):<fpage>64</fpage>&#x02013;<lpage>68</lpage>.</mixed-citation></ref><ref id="pone.0302333.ref011"><label>11</label><mixed-citation publication-type="journal">
<name><surname>Ain</surname><given-names>QU</given-names></name>, <name><surname>Butt</surname><given-names>WH</given-names></name>, <name><surname>Anwar</surname><given-names>MW</given-names></name>, <name><surname>Azam</surname><given-names>F</given-names></name>, <name><surname>Maqbool</surname><given-names>B</given-names></name>. <article-title>A systematic review on code clone detection</article-title>. <source>IEEE Access</source>. <year>2019</year>;<volume>7</volume>:<fpage>86121</fpage>&#x02013;<lpage>86144</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/ACCESS.2019.2918202</pub-id></mixed-citation></ref><ref id="pone.0302333.ref012"><label>12</label><mixed-citation publication-type="journal">
<name><surname>Quradaa</surname><given-names>FH</given-names></name>, <name><surname>Shahzad</surname><given-names>S</given-names></name>, <name><surname>Almoqbily</surname><given-names>RS</given-names></name>. <article-title>A systematic literature review on the applications of recurrent neural networks in code clone research</article-title>. <source>PLOS ONE</source>. <year>2024</year>;<volume>19</volume>(<issue>2</issue>):<fpage>1</fpage>&#x02013;<lpage>40</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0296858</pub-id>
<?supplied-pmid 38306372?><pub-id pub-id-type="pmid">38306372</pub-id>
</mixed-citation></ref><ref id="pone.0302333.ref013"><label>13</label><mixed-citation publication-type="other">Fang C, Liu Z, Shi Y, Huang J, Shi Q. Functional code clone detection with syntax and semantics fusion learning. In: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis. ISSTA 2020. New York, NY, USA: Association for Computing Machinery; 2020. p. 516&#x02013;527. Available from: <pub-id pub-id-type="doi">10.1145/3395363.3397362</pub-id>.</mixed-citation></ref><ref id="pone.0302333.ref014"><label>14</label><mixed-citation publication-type="other">Schneider JG, Lee SU. An experimental comparison of clone detection techniques using Java bytecode. In: 2022 29th Asia-Pacific Software Engineering Conference (APSEC); 2022. p. 139&#x02013;148.</mixed-citation></ref><ref id="pone.0302333.ref015"><label>15</label><mixed-citation publication-type="journal">
<name><surname>Alomari</surname><given-names>HW</given-names></name>, <name><surname>Stephan</surname><given-names>M</given-names></name>. <article-title>Clone detection through srcClone: A program slicing based approach</article-title>. <source>Journal of Systems and Software</source>. <year>2022</year>;<volume>184</volume>:<fpage>111115</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jss.2021.111115</pub-id></mixed-citation></ref><ref id="pone.0302333.ref016"><label>16</label><mixed-citation publication-type="other">Svajlenko J, Roy CK. Evaluating clone detection tools with BigCloneBench. In: 2015 IEEE International Conference on Software Maintenance and Evolution (ICSME); 2015. p. 131&#x02013;140.</mixed-citation></ref><ref id="pone.0302333.ref017"><label>17</label><mixed-citation publication-type="other">Baxter ID, Yahin A, Moura L, Sant&#x02019;Anna M, Bier L. Clone detection using abstract syntax trees. In: Proceedings. International Conference on Software Maintenance (Cat. No. 98CB36272); 1998. p. 368&#x02013;377.</mixed-citation></ref><ref id="pone.0302333.ref018"><label>18</label><mixed-citation publication-type="other">Jiang L, Misherghi G, Su Z, Glondu S. DECKARD: Scalable and accurate tree-based detection of code clones. In: 29th International Conference on Software Engineering (ICSE&#x02019;07); 2007. p. 96&#x02013;105.</mixed-citation></ref><ref id="pone.0302333.ref019"><label>19</label><mixed-citation publication-type="other">[online];. Available from: <ext-link xlink:href="https://github.com/javaparser/javaparser-visited" ext-link-type="uri">https://github.com/javaparser/javaparser-visited</ext-link>.</mixed-citation></ref><ref id="pone.0302333.ref020"><label>20</label><mixed-citation publication-type="journal">
<name><surname>Smith</surname><given-names>N</given-names></name>, <name><surname>Van Bruggen</surname><given-names>D</given-names></name>, <name><surname>Tomassetti</surname><given-names>F</given-names></name>. <article-title>Javaparser: visited</article-title>. <source>Leanpub, oct de</source>. <year>2017</year>;<volume>10</volume>:<fpage>29</fpage>&#x02013;<lpage>40</lpage>.</mixed-citation></ref><ref id="pone.0302333.ref021"><label>21</label><mixed-citation publication-type="other">[online];. Available from: <ext-link xlink:href="https://soot-oss.github.io/soot/" ext-link-type="uri">https://soot-oss.github.io/soot/</ext-link>.</mixed-citation></ref><ref id="pone.0302333.ref022"><label>22</label><mixed-citation publication-type="other">Vall&#x000e9;e-Rai R, Co P, Gagnon E, Hendren L, Lam P, Sundaresan V. Soot: A Java bytecode optimization framework. In: CASCON First Decade High Impact Papers. CASCON&#x02019;10. USA: IBM Corp.; 2010. p. 214&#x02013;224. Available from: <pub-id pub-id-type="doi">10.1145/1925805.1925818</pub-id>.</mixed-citation></ref><ref id="pone.0302333.ref023"><label>23</label><mixed-citation publication-type="book">
<name><surname>Lindholm</surname><given-names>T</given-names></name>, <name><surname>Yellin</surname><given-names>F</given-names></name>, <name><surname>Bracha</surname><given-names>G</given-names></name>, <name><surname>Buckley</surname><given-names>A</given-names></name>. <source>The Java virtual machine specification</source>. <publisher-name>Addison-wesley</publisher-name>; <year>2013</year>.</mixed-citation></ref><ref id="pone.0302333.ref024"><label>24</label><mixed-citation publication-type="other">Selim GMK, Foo KC, Zou Y. Enhancing source-based clone detection using intermediate representation. In: 2010 17th Working Conference on Reverse Engineering; 2010. p. 227&#x02013;236.</mixed-citation></ref><ref id="pone.0302333.ref025"><label>25</label><mixed-citation publication-type="book">
<name><surname>Dann</surname><given-names>A</given-names></name>, <name><surname>Hermann</surname><given-names>B</given-names></name>, <name><surname>Bodden</surname><given-names>E</given-names></name>. <part-title>SootDiff: Bytecode Comparison across Different Java Compilers</part-title>. <source>SOAP 2019</source>. <publisher-loc>New York, NY, USA</publisher-loc>: <publisher-name>Association for Computing Machinery</publisher-name>; <year>2019</year>. p. <fpage>14</fpage>&#x02013;<lpage>19</lpage>. Available from: <pub-id pub-id-type="doi">10.1145/3315568.3329966</pub-id>.</mixed-citation></ref><ref id="pone.0302333.ref026"><label>26</label><mixed-citation publication-type="other">Christodorescu M, Jha S, Seshia SA, Song D, Bryant RE. Semantics-aware malware detection. In: 2005 IEEE Symposium on Security and Privacy (S P&#x02019;05); 2005. p. 32&#x02013;46.</mixed-citation></ref><ref id="pone.0302333.ref027"><label>27</label><mixed-citation publication-type="other">Cordy JR, Roy CK. The NiCad Clone Detector. In: 2011 IEEE 19th International Conference on Program Comprehension; 2011. p. 219&#x02013;220.</mixed-citation></ref><ref id="pone.0302333.ref028"><label>28</label><mixed-citation publication-type="other">Sajnani H, Saini V, Svajlenko J, Roy CK, Lopes CV. SourcererCC: Scaling code clone detection to Big-Code. In: Proceedings of the 38th International Conference on Software Engineering. ICSE&#x02019;16. New York, NY, USA: Association for Computing Machinery; 2016. p. 1157&#x02013;1168. Available from: <pub-id pub-id-type="doi">10.1145/2884781.2884877</pub-id>.</mixed-citation></ref><ref id="pone.0302333.ref029"><label>29</label><mixed-citation publication-type="other">Hu T, Xu Z, Fang Y, Wu Y, Yuan B, Zou D, et al. Fine-grained code clone detection with block-based splitting of abstract syntax tree. In: Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis. ISSTA 2023. New York, NY, USA: Association for Computing Machinery; 2023. p. 89&#x02013;100. Available from: <pub-id pub-id-type="doi">10.1145/3597926.3598040</pub-id>.</mixed-citation></ref><ref id="pone.0302333.ref030"><label>30</label><mixed-citation publication-type="book">
<name><surname>Kamalpriya</surname><given-names>CM</given-names></name>, <name><surname>Singh</surname><given-names>P</given-names></name>. <part-title>Enhancing program dependency graph based clone detection using approximate subgraph matching</part-title>. In: <source>2017 IEEE 11th International Workshop on Software Clones (IWSC)</source>; <year>2017</year>. p. <fpage>1</fpage>&#x02013;<lpage>7</lpage>.</mixed-citation></ref><ref id="pone.0302333.ref031"><label>31</label><mixed-citation publication-type="journal">
<name><surname>Hua</surname><given-names>W</given-names></name>, <name><surname>Sui</surname><given-names>Y</given-names></name>, <name><surname>Wan</surname><given-names>Y</given-names></name>, <name><surname>Liu</surname><given-names>G</given-names></name>, <name><surname>Xu</surname><given-names>G</given-names></name>. <article-title>FCCA: Hybrid Code Representation for Functional Clone Detection Using Attention Networks</article-title>. <source>IEEE Transactions on Reliability</source>. <year>2021</year>;<volume>70</volume>(<issue>1</issue>):<fpage>304</fpage>&#x02013;<lpage>318</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TR.2020.3001918</pub-id></mixed-citation></ref><ref id="pone.0302333.ref032"><label>32</label><mixed-citation publication-type="journal">
<name><surname>Basit</surname><given-names>HA</given-names></name>, <name><surname>Jarzabek</surname><given-names>S</given-names></name>. <article-title>A Data Mining Approach for Detecting Higher-Level Clones in Software</article-title>. <source>IEEE Transactions on Software Engineering</source>. <year>2009</year>;<volume>35</volume>(<issue>4</issue>):<fpage>497</fpage>&#x02013;<lpage>514</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TSE.2009.16</pub-id></mixed-citation></ref><ref id="pone.0302333.ref033"><label>33</label><mixed-citation publication-type="journal">
<name><surname>El-Matarawy</surname><given-names>A</given-names></name>, <name><surname>El-Ramly</surname><given-names>M</given-names></name>, <name><surname>Bahgat</surname><given-names>R</given-names></name>. <article-title>Code Clone Detection using Sequential Pattern Mining</article-title>. <source>International Journal of Computer Applications</source>. <year>2015</year>;<volume>127</volume>(<issue>2</issue>):<fpage>10</fpage>&#x02013;<lpage>18</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.5120/ijca2015906324</pub-id></mixed-citation></ref><ref id="pone.0302333.ref034"><label>34</label><mixed-citation publication-type="journal">
<name><surname>Mamdouh Farghaly</surname><given-names>H</given-names></name>, <name><surname>Abd El-Hafeez</surname><given-names>T</given-names></name>. <article-title>A high-quality feature selection method based on frequent and correlated items for text classification</article-title>. <source>Soft Computing</source>. <year>2023</year>; p. <fpage>1</fpage>&#x02013;<lpage>16</lpage>.</mixed-citation></ref><ref id="pone.0302333.ref035"><label>35</label><mixed-citation publication-type="journal">
<name><surname>Mamdouh Farghaly</surname><given-names>H</given-names></name>, <name><surname>Abd El-Hafeez</surname><given-names>T</given-names></name>. <article-title>A new feature selection method based on frequent and associated itemsets for text classification</article-title>. <source>Concurrency and Computation: Practice and Experience</source>. <year>2022</year>;<volume>34</volume>(<issue>25</issue>):<fpage>e7258</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/cpe.7258</pub-id></mixed-citation></ref><ref id="pone.0302333.ref036"><label>36</label><mixed-citation publication-type="other">Sch&#x000e4;fer A, Amme W, Heinze TS. Detection of similar functions through the use of dominator information. In: 2020 IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion (ACSOS-C); 2020. p. 206&#x02013;211.</mixed-citation></ref><ref id="pone.0302333.ref037"><label>37</label><mixed-citation publication-type="journal">
<name><surname>Keivanloo</surname><given-names>I</given-names></name>, <name><surname>Roy</surname><given-names>CK</given-names></name>, <name><surname>Rilling</surname><given-names>J</given-names></name>. <article-title>SeByte: Scalable clone and similarity search for bytecode</article-title>. <source>Science of Computer Programming</source>. <year>2014</year>;<volume>95</volume>:<fpage>426</fpage>&#x02013;<lpage>444</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.scico.2013.10.006</pub-id></mixed-citation></ref><ref id="pone.0302333.ref038"><label>38</label><mixed-citation publication-type="book">
<name><surname>Caldeira</surname><given-names>PM</given-names></name>, <name><surname>Sakamoto</surname><given-names>K</given-names></name>, <name><surname>Washizaki</surname><given-names>H</given-names></name>, <name><surname>Fukazawa</surname><given-names>Y</given-names></name>, <name><surname>Shimada</surname><given-names>T</given-names></name>. <part-title>Improving syntactical clone detection methods through the use of an intermediate representation</part-title>. In: <source>2020 IEEE 14th International Workshop on Software Clones (IWSC)</source>; <year>2020</year>. p. <fpage>8</fpage>&#x02013;<lpage>14</lpage>.</mixed-citation></ref><ref id="pone.0302333.ref039"><label>39</label><mixed-citation publication-type="journal">
<name><surname>Yu</surname><given-names>D</given-names></name>, <name><surname>Yang</surname><given-names>J</given-names></name>, <name><surname>Chen</surname><given-names>X</given-names></name>, <name><surname>Chen</surname><given-names>J</given-names></name>. <article-title>Detecting Java code clones based on bytecode sequence alignment</article-title>. <source>IEEE Access</source>. <year>2019</year>;<volume>7</volume>:<fpage>22421</fpage>&#x02013;<lpage>22433</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/ACCESS.2019.2898411</pub-id></mixed-citation></ref><ref id="pone.0302333.ref040"><label>40</label><mixed-citation publication-type="other">Kononenko O, Zhang C, Godfrey MW. Compiling clones: What happens? In: 2014 IEEE International Conference on Software Maintenance and Evolution; 2014. p. 481&#x02013;485.</mixed-citation></ref><ref id="pone.0302333.ref041"><label>41</label><mixed-citation publication-type="journal">
<name><surname>Sheneamer</surname><given-names>A</given-names></name>, <name><surname>Roy</surname><given-names>S</given-names></name>, <name><surname>Kalita</surname><given-names>J</given-names></name>. <article-title>A detection framework for semantic code clones and obfuscated code</article-title>. <source>Expert Systems with Applications</source>. <year>2018</year>;<volume>97</volume>:<fpage>405</fpage>&#x02013;<lpage>420</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.eswa.2017.12.040</pub-id></mixed-citation></ref><ref id="pone.0302333.ref042"><label>42</label><mixed-citation publication-type="other">Tufano M, Watson C, Bavota G, Di Penta M, White M, Poshyvanyk D. Deep learning similarities from different representations of source code. In: Proceedings of the 15th International Conference on Mining Software Repositories. MSR&#x02019;18. New York, NY, USA: Association for Computing Machinery; 2018. p. 542&#x02013;553. Available from: <pub-id pub-id-type="doi">10.1145/3196398.3196431</pub-id>.</mixed-citation></ref><ref id="pone.0302333.ref043"><label>43</label><mixed-citation publication-type="book">
<name><surname>Sch&#x000e4;fer</surname><given-names>A</given-names></name>, <name><surname>Amme</surname><given-names>W</given-names></name>, <name><surname>Heinze</surname><given-names>TS</given-names></name>. <part-title>Stubber: Compiling source code into bytecode without dependencies for Java code clone detection</part-title>. In: <source>2021 IEEE 15th International Workshop on Software Clones (IWSC)</source>; <year>2021</year>. p. <fpage>29</fpage>&#x02013;<lpage>35</lpage>.</mixed-citation></ref><ref id="pone.0302333.ref044"><label>44</label><mixed-citation publication-type="other">[online];. Available from: <ext-link xlink:href="https://github.com/andre-schaefer-94/Stubber" ext-link-type="uri">https://github.com/andre-schaefer-94/Stubber</ext-link>.</mixed-citation></ref><ref id="pone.0302333.ref045"><label>45</label><mixed-citation publication-type="other">Zhao G, Huang J. DeepSim: Deep learning code functional similarity. In: Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. ESEC/FSE 2018. New York, NY, USA: Association for Computing Machinery; 2018. p. 141&#x02013;151. Available from: <pub-id pub-id-type="doi">10.1145/3236024.3236068</pub-id>.</mixed-citation></ref><ref id="pone.0302333.ref046"><label>46</label><mixed-citation publication-type="journal">
<name><surname>Rokach</surname><given-names>L</given-names></name>. <article-title>Ensemble-based classifiers</article-title>. <source>Artificial Intelligence Review</source>. <year>2010</year>;<volume>33</volume>(<issue>1-2</issue>):<fpage>1</fpage>&#x02013;<lpage>39</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s10462-009-9124-7</pub-id></mixed-citation></ref><ref id="pone.0302333.ref047"><label>47</label><mixed-citation publication-type="journal">
<name><surname>Rodriguez</surname><given-names>JJ</given-names></name>, <name><surname>Kuncheva</surname><given-names>LI</given-names></name>, <name><surname>Alonso</surname><given-names>CJ</given-names></name>. <article-title>Rotation forest: A new classifier ensemble method</article-title>. <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>. <year>2006</year>;<volume>28</volume>(<issue>10</issue>):<fpage>1619</fpage>&#x02013;<lpage>1630</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TPAMI.2006.211</pub-id>
<?supplied-pmid 16986543?><pub-id pub-id-type="pmid">16986543</pub-id>
</mixed-citation></ref><ref id="pone.0302333.ref048"><label>48</label><mixed-citation publication-type="other">K&#x000e9;gl B, Busa-Fekete R. Boosting products of base classifiers. In: Proceedings of the 26th Annual International Conference on Machine Learning. ICML&#x02019;09. New York, NY, USA: Association for Computing Machinery; 2009. p. 497&#x02013;504. Available from: <pub-id pub-id-type="doi">10.1145/1553374.1553439</pub-id>.</mixed-citation></ref><ref id="pone.0302333.ref049"><label>49</label><mixed-citation publication-type="book">
<name><surname>Prokhorenkova</surname><given-names>L</given-names></name>, <name><surname>Gusev</surname><given-names>G</given-names></name>, <name><surname>Vorobev</surname><given-names>A</given-names></name>, <name><surname>Dorogush</surname><given-names>AV</given-names></name>, <name><surname>Gulin</surname><given-names>A</given-names></name>. <part-title>CatBoost: unbiased boosting with categorical features</part-title>. In: <name><surname>Bengio</surname><given-names>S</given-names></name>, <name><surname>Wallach</surname><given-names>H</given-names></name>, <name><surname>Larochelle</surname><given-names>H</given-names></name>, <name><surname>Grauman</surname><given-names>K</given-names></name>, <name><surname>Cesa-Bianchi</surname><given-names>N</given-names></name>, <name><surname>Garnett</surname><given-names>R</given-names></name>, editors. <source>Advances in Neural Information Processing Systems</source>. vol. <volume>31</volume>. <publisher-name>Curran Associates, Inc</publisher-name>.; <year>2018</year>. Available from: <ext-link xlink:href="https://proceedings.neurips.cc/paper_files/paper/2018/file/14491b756b3a51daac41c24863285549-Paper.pdf" ext-link-type="uri">https://proceedings.neurips.cc/paper_files/paper/2018/file/14491b756b3a51daac41c24863285549-Paper.pdf</ext-link>.</mixed-citation></ref><ref id="pone.0302333.ref050"><label>50</label><mixed-citation publication-type="other">Chen T, Guestrin C. XGBoost: A scalable tree boosting system. In: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. KDD&#x02019;16. New York, NY, USA: Association for Computing Machinery; 2016. p. 785&#x02013;794. Available from: <pub-id pub-id-type="doi">10.1145/2939672.2939785</pub-id>.</mixed-citation></ref><ref id="pone.0302333.ref051"><label>51</label><mixed-citation publication-type="book">
<name><surname>Ke</surname><given-names>G</given-names></name>, <name><surname>Meng</surname><given-names>Q</given-names></name>, <name><surname>Finley</surname><given-names>T</given-names></name>, <name><surname>Wang</surname><given-names>T</given-names></name>, <name><surname>Chen</surname><given-names>W</given-names></name>, <name><surname>Ma</surname><given-names>W</given-names></name>, <etal>et al</etal>. <part-title>LightGBM: A Highly Efficient Gradient Boosting Decision Tree</part-title>. In: <name><surname>Guyon</surname><given-names>I</given-names></name>, <name><surname>Luxburg</surname><given-names>UV</given-names></name>, <name><surname>Bengio</surname><given-names>S</given-names></name>, <name><surname>Wallach</surname><given-names>H</given-names></name>, <name><surname>Fergus</surname><given-names>R</given-names></name>, <name><surname>Vishwanathan</surname><given-names>S</given-names></name>, <etal>et al</etal>., editors. <source>Advances in Neural Information Processing Systems</source>. vol. <volume>30</volume>. <publisher-name>Curran Associates, Inc</publisher-name>.; <year>2017</year>. Available from: <ext-link xlink:href="https://proceedings.neurips.cc/paper_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf" ext-link-type="uri">https://proceedings.neurips.cc/paper_files/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf</ext-link>.</mixed-citation></ref><ref id="pone.0302333.ref052"><label>52</label><mixed-citation publication-type="journal">
<name><surname>Friedman</surname><given-names>J</given-names></name>, <name><surname>Hastie</surname><given-names>T</given-names></name>, <name><surname>Tibshirani</surname><given-names>R</given-names></name>. <article-title>Additive logistic regression: A statistical view of boosting (With discussion and a rejoinder by the authors)</article-title>. <source>The Annals of Statistics</source>. <year>2000</year>;<volume>28</volume>(<issue>2</issue>):<fpage>337</fpage>&#x02013;<lpage>407</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1214/aos/1016218222</pub-id></mixed-citation></ref><ref id="pone.0302333.ref053"><label>53</label><mixed-citation publication-type="journal">
<name><surname>Sun</surname><given-names>P</given-names></name>, <name><surname>Reid</surname><given-names>MD</given-names></name>, <name><surname>Zhou</surname><given-names>J</given-names></name>. <article-title>An improved multiclass LogitBoost using adaptive-one-vs-one</article-title>. <source>Mach Learn</source>. <year>2014</year>;<volume>97</volume>(<issue>3</issue>):<fpage>295</fpage>&#x02013;<lpage>326</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s10994-014-5434-3</pub-id></mixed-citation></ref><ref id="pone.0302333.ref054"><label>54</label><mixed-citation publication-type="other">Rokach L. Pattern Classification Using Ensemble Methods. WORLD SCIENTIFIC; 2009. Available from: <ext-link xlink:href="https://www.worldscientific.com/doi/abs/10.1142/7238" ext-link-type="uri">https://www.worldscientific.com/doi/abs/10.1142/7238</ext-link>.</mixed-citation></ref><ref id="pone.0302333.ref055"><label>55</label><mixed-citation publication-type="journal">
<name><surname>&#x000d6;z&#x000e7;ift</surname><given-names>A</given-names></name>. <article-title>Random forests ensemble classifier trained with data resampling strategy to improve cardiac arrhythmia diagnosis</article-title>. <source>Computers in Biology and Medicine</source>. <year>2011</year>;<volume>41</volume>(<issue>5</issue>):<fpage>265</fpage>&#x02013;<lpage>271</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.compbiomed.2011.03.001</pub-id>
<?supplied-pmid 21419401?><pub-id pub-id-type="pmid">21419401</pub-id>
</mixed-citation></ref><ref id="pone.0302333.ref056"><label>56</label><mixed-citation publication-type="journal">
<name><surname>Breiman</surname><given-names>L</given-names></name>. <article-title>Bagging predictors</article-title>. <source>Machine learning</source>. <year>1996</year>;<volume>24</volume>:<fpage>123</fpage>&#x02013;<lpage>140</lpage>.</mixed-citation></ref><ref id="pone.0302333.ref057"><label>57</label><mixed-citation publication-type="journal">
<name><surname>Ho</surname><given-names>TK</given-names></name>. <article-title>The random subspace method for constructing decision forests</article-title>. <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>. <year>1998</year>;<volume>20</volume>(<issue>8</issue>):<fpage>832</fpage>&#x02013;<lpage>844</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/34.709601</pub-id></mixed-citation></ref><ref id="pone.0302333.ref058"><label>58</label><mixed-citation publication-type="other">Quinlan JR. C 4.5: Programs for machine learning; 1993.</mixed-citation></ref><ref id="pone.0302333.ref059"><label>59</label><mixed-citation publication-type="other">John GH, Langley P. Estimating Continuous Distributions in Bayesian Classifiers. arXiv e-prints. 2013; p. arXiv:1302.4964.</mixed-citation></ref><ref id="pone.0302333.ref060"><label>60</label><mixed-citation publication-type="book">
<name><surname>Xanthopoulos</surname><given-names>P</given-names></name>, <name><surname>Pardalos</surname><given-names>PM</given-names></name>, <name><surname>Trafalis</surname><given-names>TB</given-names></name>. In: <source>Linear Discriminant Analysis</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer New York</publisher-name>; <year>2013</year>. p. <fpage>27</fpage>&#x02013;<lpage>33</lpage>. Available from: <pub-id pub-id-type="doi">10.1007/978-1-4419-9878-1_4</pub-id>.</mixed-citation></ref><ref id="pone.0302333.ref061"><label>61</label><mixed-citation publication-type="book">
<name><surname>Pisner</surname><given-names>DA</given-names></name>, <name><surname>Schnyer</surname><given-names>DM</given-names></name>. <part-title>Chapter 6&#x02014;Support vector machine</part-title>. In: <name><surname>Mechelli</surname><given-names>A</given-names></name>, <name><surname>Vieira</surname><given-names>S</given-names></name>, editors. <source>Machine Learning</source>. <publisher-name>Academic Press</publisher-name>; <year>2020</year>. p. <fpage>101</fpage>&#x02013;<lpage>121</lpage>. Available from: <ext-link xlink:href="https://www.sciencedirect.com/science/article/pii/B9780128157398000067" ext-link-type="uri">https://www.sciencedirect.com/science/article/pii/B9780128157398000067</ext-link>.</mixed-citation></ref><ref id="pone.0302333.ref062"><label>62</label><mixed-citation publication-type="journal">
<name><surname>Farghaly</surname><given-names>HM</given-names></name>, <name><surname>Ali</surname><given-names>AA</given-names></name>, <name><surname>Abd El-Hafeez</surname><given-names>T</given-names></name>. <article-title>Building an Effective and Accurate Associative Classifier Based on Support Vector Machine</article-title>. <source>SYLWAN</source>. <year>2020</year>;<volume>164</volume>(<issue>3</issue>).</mixed-citation></ref><ref id="pone.0302333.ref063"><label>63</label><mixed-citation publication-type="book">
<name><surname>Nick</surname><given-names>TG</given-names></name>, <name><surname>Campbell</surname><given-names>KM</given-names></name>. In: <name><surname>Ambrosius</surname><given-names>WT</given-names></name>, editor. <source>Logistic Regression</source>. <publisher-loc>Totowa, NJ</publisher-loc>: <publisher-name>Humana Press</publisher-name>; <year>2007</year>. p. <fpage>273</fpage>&#x02013;<lpage>301</lpage>. Available from: <pub-id pub-id-type="doi">10.1007/978-1-59745-530-5_14</pub-id>.</mixed-citation></ref><ref id="pone.0302333.ref064"><label>64</label><mixed-citation publication-type="journal">
<name><surname>Svozil</surname><given-names>D</given-names></name>, <name><surname>Kvasnicka</surname><given-names>V</given-names></name>, <name><surname>Pospichal</surname><given-names>J</given-names></name>. <article-title>Introduction to multi-layer feed-forward neural networks</article-title>. <source>Chemometrics and Intelligent Laboratory Systems</source>. <year>1997</year>;<volume>39</volume>(<issue>1</issue>):<fpage>43</fpage>&#x02013;<lpage>62</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/S0169-7439(97)00061-0</pub-id></mixed-citation></ref><ref id="pone.0302333.ref065"><label>65</label><mixed-citation publication-type="other">[online];. Available from: <ext-link xlink:href="https://github.com/clonebench/BigCloneBench?tab=readme-ov-file" ext-link-type="uri">https://github.com/clonebench/BigCloneBench?tab=readme-ov-file</ext-link>.</mixed-citation></ref><ref id="pone.0302333.ref066"><label>66</label><mixed-citation publication-type="other">Saini V, Sajnani H, Kim J, Lopes C. SourcererCC and SourcererCC-I: tools to detect clones in batch mode and during software development. In: Proceedings of the 38th International Conference on Software Engineering Companion. ICSE&#x02019;16. New York, NY, USA: Association for Computing Machinery; 2016. p. 597&#x02013;600. Available from: <pub-id pub-id-type="doi">10.1145/2889160.2889165</pub-id>.</mixed-citation></ref><ref id="pone.0302333.ref067"><label>67</label><mixed-citation publication-type="journal">
<name><surname>Roy</surname><given-names>CK</given-names></name>, <name><surname>Cordy</surname><given-names>JR</given-names></name>, <name><surname>Koschke</surname><given-names>R</given-names></name>. <article-title>Comparison and evaluation of code clone detection techniques and tools: A qualitative approach</article-title>. <source>Science of Computer Programming</source>. <year>2009</year>;<volume>74</volume>(<issue>7</issue>):<fpage>470</fpage>&#x02013;<lpage>495</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.scico.2009.02.007</pub-id></mixed-citation></ref><ref id="pone.0302333.ref068"><label>68</label><mixed-citation publication-type="other">[online];. Available from: <ext-link xlink:href="https://imbalanced-learn.org/stable/over_sampling.html" ext-link-type="uri">https://imbalanced-learn.org/stable/over_sampling.html</ext-link>.</mixed-citation></ref><ref id="pone.0302333.ref069"><label>69</label><mixed-citation publication-type="journal">
<name><surname>Lessmann</surname><given-names>S</given-names></name>, <name><surname>Baesens</surname><given-names>B</given-names></name>, <name><surname>Seow</surname><given-names>HV</given-names></name>, <name><surname>Thomas</surname><given-names>LC</given-names></name>. <article-title>Benchmarking state-of-the-art classification algorithms for credit scoring: An update of research</article-title>. <source>European Journal of Operational Research</source>. <year>2015</year>;<volume>247</volume>(<issue>1</issue>):<fpage>124</fpage>&#x02013;<lpage>136</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.ejor.2015.05.030</pub-id></mixed-citation></ref><ref id="pone.0302333.ref070"><label>70</label><mixed-citation publication-type="journal">
<name><surname>Tsai</surname><given-names>CF</given-names></name>, <name><surname>Hsiao</surname><given-names>YC</given-names></name>. <article-title>Combining multiple feature selection methods for stock prediction: Union, intersection, and multi-intersection approaches</article-title>. <source>Decision Support Systems</source>. <year>2010</year>;<volume>50</volume>(<issue>1</issue>):<fpage>258</fpage>&#x02013;<lpage>269</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.dss.2010.08.028</pub-id></mixed-citation></ref><ref id="pone.0302333.ref071"><label>71</label><mixed-citation publication-type="journal">
<name><surname>Heaton</surname><given-names>J</given-names></name>. <article-title>Ian Goodfellow, Yoshua Bengio, and Aaron Courville: Deep learning</article-title>. <source>Genetic Programming and Evolvable Machines</source>. <year>2018</year>;<volume>19</volume>(<issue>1&#x02013;2</issue>):<fpage>305</fpage>&#x02013;<lpage>307</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s10710-017-9314-z</pub-id></mixed-citation></ref><ref id="pone.0302333.ref072"><label>72</label><mixed-citation publication-type="other">Gehler P, Nowozin S. On feature combination for multiclass object classification. In: 2009 IEEE 12th International Conference on Computer Vision; 2009. p. 221&#x02013;228.</mixed-citation></ref><ref id="pone.0302333.ref073"><label>73</label><mixed-citation publication-type="journal">
<name><surname>Kamiya</surname><given-names>T</given-names></name>, <name><surname>Kusumoto</surname><given-names>S</given-names></name>, <name><surname>Inoue</surname><given-names>K</given-names></name>. <article-title>CCFinder: a multilinguistic token-based code clone detection system for large scale source code</article-title>. <source>IEEE Transactions on Software Engineering</source>. <year>2002</year>;<volume>28</volume>(<issue>7</issue>):<fpage>654</fpage>&#x02013;<lpage>670</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TSE.2002.1019480</pub-id></mixed-citation></ref><ref id="pone.0302333.ref074"><label>74</label><mixed-citation publication-type="other">G&#x000f6;de N, Koschke R. Incremental Clone Detection. In: 2009 13th European Conference on Software Maintenance and Reengineering; 2009. p. 219&#x02013;228.</mixed-citation></ref><ref id="pone.0302333.ref075"><label>75</label><mixed-citation publication-type="other">Li L, Feng H, Zhuang W, Meng N, Ryder B. CCLearner: A Deep Learning-Based Clone Detection Approach. In: 2017 IEEE International Conference on Software Maintenance and Evolution (ICSME); 2017. p. 249&#x02013;260.</mixed-citation></ref><ref id="pone.0302333.ref076"><label>76</label><mixed-citation publication-type="other">Wei HH, Li M. Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code. In: Proceedings of the 26th International Joint Conference on Artificial Intelligence. IJCAI&#x02019;17. AAAI Press; 2017. p. 3034&#x02013;3040.</mixed-citation></ref><ref id="pone.0302333.ref077"><label>77</label><mixed-citation publication-type="other">Zhang J, Wang X, Zhang H, Sun H, Wang K, Liu X. A Novel Neural Source Code Representation Based on Abstract Syntax Tree. In: 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE); 2019. p. 783&#x02013;794.</mixed-citation></ref><ref id="pone.0302333.ref078"><label>78</label><mixed-citation publication-type="journal">
<name><surname>Sheneamer</surname><given-names>A</given-names></name>, <name><surname>Roy</surname><given-names>S</given-names></name>, <name><surname>Kalita</surname><given-names>J</given-names></name>. <article-title>An Effective Semantic Code Clone Detection Framework Using Pairwise Feature Fusion</article-title>. <source>IEEE Access</source>. <year>2021</year>;<volume>9</volume>:<fpage>84828</fpage>&#x02013;<lpage>84844</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/ACCESS.2021.3079156</pub-id></mixed-citation></ref><ref id="pone.0302333.ref079"><label>79</label><mixed-citation publication-type="other">TIOBE index; 2023. Available from: <ext-link xlink:href="https://www.techrepublic.com/article/tiobe-index-language-rankings/" ext-link-type="uri">https://www.techrepublic.com/article/tiobe-index-language-rankings/</ext-link>.</mixed-citation></ref></ref-list></back><sub-article article-type="aggregated-review-documents" id="pone.0302333.r001" specific-use="decision-letter"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0302333.r001</article-id><title-group><article-title>Decision Letter 0</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Yun</surname><given-names>Unil</given-names></name><role>Academic Editor</role></contrib></contrib-group><permissions><copyright-statement>&#x000a9; 2024 Unil Yun</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Unil Yun</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0302333" id="rel-obj001" related-article-type="reviewed-article"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>0</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="letter-date">23 Feb 2024</named-content>
</p><p><!-- <div> -->PONE-D-23-38302<!-- </div> --><!-- <div> -->A novel code representation for detecting Java source code clones<!-- </div> --><!-- <div> -->PLOS ONE</p><p>Dear Dr. Quradaa,</p><p>Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we feel that it has merit but does not fully meet PLOS ONE&#x02019;s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.</p><p>Please submit your revised manuscript by Apr 08 2024 11:59PM. If you will need more time than this to complete your revisions, please reply to this message or contact the journal office at&#x000a0;<email>plosone@plos.org</email>. When you're ready to submit your revision, log on to <ext-link xlink:href="https://www.editorialmanager.com/pone/" ext-link-type="uri">https://www.editorialmanager.com/pone/</ext-link> and select the 'Submissions Needing Revision' folder to locate your manuscript file.</p><p>Please include the following items when submitting your revised manuscript:<!-- </div> --><list list-type="bullet"><list-item><p>A rebuttal letter that responds to each point raised by the academic editor and reviewer(s). You should upload this letter as a separate file labeled 'Response to Reviewers'.</p></list-item><list-item><p>A marked-up copy of your manuscript that highlights changes made to the original version. You should upload this as a separate file labeled 'Revised Manuscript with Track Changes'.</p></list-item><list-item><p>An unmarked version of your revised paper without tracked changes. You should upload this as a separate file labeled 'Manuscript'.</p></list-item></list></p><p>If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter. Guidelines for resubmitting your figure files are available below the reviewer comments at the end of this letter.</p><p>If applicable, we recommend that you deposit your laboratory protocols in protocols.io to enhance the reproducibility of your results. Protocols.io assigns your protocol its own identifier (DOI) so that it can be cited independently in the future. For instructions see: <ext-link xlink:href="https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols" ext-link-type="uri">https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols</ext-link>. Additionally, PLOS ONE offers an option for publishing peer-reviewed Lab Protocol articles, which describe protocols hosted on protocols.io. Read more information on sharing protocols at <ext-link xlink:href="https://plos.org/protocols?utm_medium=editorial-email&#x00026;utm_source=authorletters&#x00026;utm_campaign=protocols" ext-link-type="uri">https://plos.org/protocols?utm_medium=editorial-email&#x00026;utm_source=authorletters&#x00026;utm_campaign=protocols</ext-link>.</p><p>We look forward to receiving your revised manuscript.</p><p>Kind regards,</p><p>Academic Editor</p><p>PLOS ONE</p><p>Journal Requirements:</p><p>When submitting your revision, we need you to address these additional requirements.</p><p>1. Please ensure that your manuscript meets PLOS ONE's style requirements, including those for file naming. The PLOS ONE style templates can be found at&#x000a0;</p><p><ext-link xlink:href="https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf</ext-link> and&#x000a0;</p><p>
<ext-link xlink:href="https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf</ext-link>
</p><p>2. Please note that PLOS ONE has specific guidelines on code sharing for submissions in which author-generated code underpins the findings in the manuscript. In these cases, all author-generated code must be made available without restrictions upon publication of the work. Please review our guidelines at <ext-link xlink:href="https://journals.plos.org/plosone/s/materials-and-software-sharing#loc-sharing-code" ext-link-type="uri">https://journals.plos.org/plosone/s/materials-and-software-sharing#loc-sharing-code</ext-link> and ensure that your code is shared in a way that follows best practice and facilitates reproducibility and reuse.</p><p>3. Please provide a complete Data Availability Statement in the submission form, ensuring you include all necessary access information or a reason for why you are unable to make your data freely accessible. If your research concerns only data provided within your submission, please write "All data are in the manuscript and/or supporting information files" as your Data Availability Statement.</p><p>
<bold>Additional Editor Comments:</bold>
</p><p>Although this manuscript has a few of merits, the reviewers gave serious issues and it needs significant revision.</p><p>[Note: HTML markup is below. Please do not edit.]</p><p>Reviewers' comments:</p><p>Reviewer's Responses to Questions</p><p>
<!-- <font color="black"> -->
<bold>Comments to the Author</bold>
</p><p>1. Is the manuscript technically sound, and do the data support the conclusions?</p><p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. <!-- </font> --></p><p>Reviewer #1:&#x000a0;Partly</p><p>Reviewer #2:&#x000a0;No</p><p>Reviewer #3:&#x000a0;Partly</p><p>**********</p><p><!-- <font color="black"> -->2. Has the statistical analysis been performed appropriately and rigorously? <!-- </font> --></p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #2:&#x000a0;No</p><p>Reviewer #3:&#x000a0;N/A</p><p>**********</p><p><!-- <font color="black"> -->3. Have the authors made all data underlying the findings in their manuscript fully available?</p><p>The <ext-link xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data&#x02014;e.g. participant privacy or use of data from a third party&#x02014;those must be specified.<!-- </font> --></p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #2:&#x000a0;No</p><p>Reviewer #3:&#x000a0;No</p><p>**********</p><p><!-- <font color="black"> -->4. Is the manuscript presented in an intelligible fashion and written in standard English?</p><p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.<!-- </font> --></p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #2:&#x000a0;Yes</p><p>Reviewer #3:&#x000a0;No</p><p>**********</p><p><!-- <font color="black"> -->5. Review Comments to the Author</p><p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)<!-- </font> --></p><p>Reviewer #1:&#x000a0;Some potential drawbacks of the proposed machine learning approach for code clone detection using high and low level source code representations:</p><p>1. Increased complexity: Combining multiple code representations adds complexity over single-representation techniques.</p><p>2. Scalability issues: Deriving and analyzing multiple representations could hamper analysis of very large codebases.</p><p>3. Sensitivity to changes: Small code modifications may invalidate code representations, requiring re-analysis.</p><p>4. Variability across languages: Representations and extracted features may not generalize well across different programming languages.</p><p>5. Infrastructure requirements: Extraction and processing of representations requires language-specific toolchains/infrastructure.</p><p>6. Evaluation limitations: Approach tested on limited datasets, more rigorous validation on real-world projects needed.</p><p>7. False positives risks: Semantic abstraction could wrongly link syntactically different code snippets.</p><p>8. Configuration challenges: Proper configuration of machine learning models requires hyperparameter tuning expertise.</p><p>9. Explainability challenges: Identifying why certain code is flagged as clones from multiple blended representations is difficult.</p><p>10. Intellectual property risks: Extracting and sharing representations and models could inadvertently leak proprietary code.</p><p>11. Describe dataset features in more details and its total size and size of (train/test) as a table.</p><p>12. Flowchart and algorithm steps need to be inserted.</p><p>13. Time spent need to be measured in the experimental results.</p><p>14. Limitation Section need to be inserted.</p><p>15. All metrics need to be calculated such as Accuracy, Precision, Recall, F1 score, and ROC AUC score in the experimental results as tables.</p><p>16. Address the accuracy/improvement percentages in the abstract and in the conclusion sections, as well as the significance of these results.</p><p>17. The architecture of the proposed model must be provided</p><p>18. The authors need to make a clear proofread to avoid grammatical mistakes and typo errors.</p><p>19. The authors need to add recent articles in related work and update them.</p><p>20. Add future work in last section (conclusion) (if any)</p><p>21. To improve the Related Work and Introduction sections authors are recommended to review this highly related research work paper:</p><p>a) A high-quality feature selection method based on frequent and correlated items for text classification</p><p>b) A new feature selection method based on frequent and associated itemsets for text classification</p><p>c) Building an Effective and Accurate Associative Classifier Based on Support Vector Machine</p><p>d) An ASP .NET Web Applications Data Flow Testing Approach</p><p>e) An Approach to Slicing Object-Oriented Programs</p><p>Reviewer #2:&#x000a0;The paper attempts to report work on using AST to detect Java clones. As the motivation of the work is not clearly defined, the methodology presented is not sound and proven. There is no data, experiment or lemma/theorem to support the proposal. Therefore, the paper is recommended for rejection.</p><p>Reviewer #3:&#x000a0;Dear Authors.</p><p>Thanks for submitting this work. The paper reviews code representation for detecting Java source code clones. The topic looks promising; however, a few issues are available in this manuscript.</p><p>Detailed feedback:</p><p>Title: it is recommended to rephrase the title to show the approach of clone detection, for example using bytecode or assembly.</p><p>Abstract: lines from 16 onwards might be too detailed for the abstract. it is recommended to remove them. The issue could be maintainability, reusability and even ethical consideration.</p><p>Introduction</p><p>it is recommended to provide either a table or a tree structure showing subtypes.</p><p>The role or type of machine learning used in this study is not clear. This also should reflect the abstract to include the idea of machine learning.</p><p>94-100 seems to be repeated. Many parts in the introduction are repeated.</p><p>define the acronyms on first use.</p><p>the background should come before related works.</p><p>Methodology</p><p>instead of saying, "will be normalized and compiled using a compilation tool like the Stub", authors should specify what they use and why.</p><p>Step 3 is not detailed at all, and it is suggested to be removed.</p><p>there are no results of this study, so no generalization can be made.</p><p>no limitations or dataset description.</p><p>It is highly recommended to have a section for used datasets and tools.</p><p>Discussion</p><p>is shallow, focus on research questions and the objectives, please.</p><p>conclusion</p><p>it looks like a summary, please revise</p><p>implications, limitations, and threats are crucial sections.</p><p>Minor issues</p><p>line 28- However, this approach ==&#x0003e;However, in this approach</p><p>, l section numbering and figures are not inserted in their place.</p><p>all figures are blur.</p><p>**********</p><p><!-- <font color="black"> -->6. PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p><p>If you choose &#x0201c;no&#x0201d;, your identity will remain anonymous but your review may still be made public.</p><p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.<!-- </font> --></p><p>Reviewer #1:&#x000a0;<bold>Yes:&#x000a0;</bold>Tarek Abd El-Hafeez</p><p>Reviewer #2:&#x000a0;No</p><p>Reviewer #3:&#x000a0;No</p><p>**********</p><p>[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files.]</p><p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool,&#x000a0;<ext-link xlink:href="https://pacev2.apexcovantage.com/" ext-link-type="uri">https://pacev2.apexcovantage.com/</ext-link>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email PLOS at&#x000a0;<email>figures@plos.org</email>. Please note that Supporting Information files do not need this step.</p></body></sub-article><sub-article article-type="author-comment" id="pone.0302333.r002"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0302333.r002</article-id><title-group><article-title>Author response to Decision Letter 0</article-title></title-group><related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0302333" id="rel-obj002" related-article-type="editor-report"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>1</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="author-response-date">23 Mar 2024</named-content>
</p><p>I would like to express my sincere gratitude to the Editor and the reviewers. Your valuable feedback and insights are greatly appreciated, and we are committed to addressing all your comments and suggestions to enhance the quality and impact of our work.</p><p>1. Editor's Journal comments and responses</p><p>&#x02022; Comment 1: [Please ensure that your manuscript meets PLOS ONE's style requirements, including those for file naming.]</p><p>Response : We would like to inform you that we have adhered to PLOS ONE's style requirements as outlined in the PLOS ONE style templates.</p><p>&#x02022; Comment 2: [Please note that PLOS ONE has specific guidelines on code sharing for submissions in which author-generated code underpins the findings in the manuscript. In these cases, all author-generated code must be made available without restrictions upon publication of the work.]</p><p>Response : Thank you for your concerns regarding the PLOS ONE guidelines on code sharing requirement. We assure you that we are fully committed to transparency and are willing to provide any details about the source code to reviewers upon request.</p><p>&#x02022; Comment 3: [Please provide a complete Data Availability Statement in the submission form, ensuring you include all necessary access information or a reason for why you are unable to make your data freely accessible. If your research concerns only data provided within your submission, please write "All data are in the manuscript and/or supporting information files" as your Data Availability Statement.]</p><p>Response : In reference to the Data Availability statement, all data are presently enclosed within our paper. Furthermore, a supporting information files has been included, encompassing all results we obtained and the datasets that we used in the experiments. Consequently, I respectfully request a modification of the Data Availability statement to state, " The dataset utilized in the present study can be accessed at the following link: <ext-link xlink:href="https://github.com/clonebench/BigCloneBench?tab=readme-ov-file" ext-link-type="uri">https://github.com/clonebench/BigCloneBench?tab=readme-ov-file</ext-link> and support file S4"</p><p>2. Comments from Reviewer 1 and Responses</p><p>&#x02022; Comment 1: [Increased complexity: Combining multiple code representations adds complexity over single-representation techniques.]</p><p>Response : We appreciate the insightful suggestion from the reviewer regarding the increased complexity associated with combining multiple code representations. While it's true that integrating multiple representations may introduce additional complexity, it is essential to weigh this against the benefits gained in terms of enhanced accuracy and robustness in clone detection. </p><p>When considering the complexities involved in code clone detection, it is crucial to note that researchers commonly categorize code clones into four types: Type-I, Type-II, Type-III, and Type-IV. The first three rely on textual similarities, whereas Type-IV focuses more on functional or semantic resemblances, posing challenges for detection based solely on textual similarities. </p><p>Traditionally, techniques have concentrated on detecting Types I-III clones, employing single code representations like sequences of tokens, trees, graphs, or software metrics. While successful for these types, they often struggle with Type-IV clones due to lexical differences but similar functionality. To overcome this challenge, hybrid code representation has emerged as a promising approach, integrating multiple techniques such as text, tokens, AST, PDG, and metrics. This comprehensive approach enhances clone detection accuracy by capturing semantic similarities that are difficult to detect using a single representation [1-3]. </p><p>Ultimately, the trade-off between complexity and benefits should be carefully considered. We believe that the advantages gained in terms of improved clone detection and classification, while reducing false positives, outweigh the increased complexity introduced by combining multiple code representations.</p><p>&#x02022; Comment 2: [Scalability issues: Deriving and analyzing multiple representations could hamper analysis of very large codebases.]</p><p>Response : We appreciate the insightful recommendation from the reviewer. It would indeed be interesting to explore scalability issues associated with deriving and analyzing multiple code representations. However, our main objective in this work is to propose a new code representation clones and evaluate its effectiveness in detecting both syntactic and semantic clones. While scalability analysis was not within the scope of this work, this approach aligns with the methodology applied in other studies in this domain [2] [4-7].</p><p>Nonetheless, we acknowledge that this comment has highlighted an opportunity for future and more extensive research in this direction. We have incorporated a recommendation to explore this opportunity in the revised manuscript. Please refer to page 32 of the revised manuscript, lines 741&#x02013;743.</p><p>&#x02022; Comment 3: [Sensitivity to changes: Small code modifications may invalidate code representations, requiring re-analysis.]</p><p>Response : We are grateful for the reviewer's insightful suggestion, and we acknowledge the importance of sensitivity to changes. In response to this valuable comment, we want to clarify how we made the proposed technique robust for source code changes.</p><p>Firstly, in the preprocessing stage several normalization operations have been applied, including the removal of unnecessary white spaces, the exclusion of comments, and the substitution of variable names and function names with generic placeholders to mitigate disparities in naming conventions. Numeric literals, string literals, and other constants have with placeholders to generalize specific values. For detailed information, please refer to the revised manuscript, specifically on page 11, lines 266&#x02013;273.</p><p>Secondly, the Soot Framework, a static analysis tool, has been used to optimize and represent Java source code by carrying out transformations such as eliminating repetitious code, dead code elimination, unused local variables elimination, and common sub-expression elimination. This significantly reduced the number of operations required to represent the java source code. The soot framework provides four intermediate representations (IRs). Each of the IRs has different levels of abstraction that provide several benefits when analyzing and transforming java code. Further details can be found on pages 5-8, lines 126-194.</p><p>&#x02022; Comment 4: [Variability across languages: Representations and extracted features may not generalize well across different programming languages.]</p><p>Response : Thank you for raising the concern about the variability across languages in the generalization of representations and extracted features. While it's true that representations and features may not generalize well across different programming languages, it's important to note that our proposed code representation is specifically designed and optimized for detecting clones in Java code.</p><p>We acknowledge that variability across languages can pose challenges in generalization, and we have focused our efforts on developing a representation that is tailored to the characteristics of Java code. By leveraging domain-specific knowledge and utilizing techniques that are specific to Java programming, we aim to maximize the effectiveness of our representation in detecting clones within the Java ecosystem.</p><p>While our representation may not directly generalize to other programming languages, we believe that the principles and methodologies employed in its development can serve as valuable insights for researchers working on clone detection in other languages. Additionally, future research could explore the adaptation of our techniques to other languages, taking into account their unique characteristics and requirements.</p><p>We have acknowledged this limitation in the threats to validity and limitations section and future work part in the conclusion. Please refer to page 31 of the revised manuscript, lines 715&#x02013;719 and pages 31 and 32, lines 739-741.</p><p>&#x02022; Comment 5: [Infrastructure requirements: Extraction and processing of representations requires language-specific tool chains/infrastructure.]</p><p>Response : Thank you for bringing up the concern regarding infrastructure requirements for the extraction and processing of representations, which necessitate language-specific toolchains and infrastructure.</p><p>In our work, we have developed a novel code representation specifically tailored for detecting clones in Java code. To address these infrastructure requirements, we carefully selected and utilized language-specific toolchains and infrastructure. For example, we used the Soot framework [8] for static analysis and code transformation in Java, the JavaParser [9] tool to build AST and traverse its nodes, and the Stubber [10] tool for compiling Java source code into Bytecode without dependencies. The roles of each tool are specified in the methodology section of the revised manuscript, which can be found on pages 10-20 and in the background section on pages 4-8. </p><p>&#x02022; Comment 6: [Evaluation limitations: Approach tested on limited datasets, more rigorous validation on real-world projects needed.]</p><p>Response: We appreciate the reviewer for pointing this out. In this work, we used the BigCloneBench [11] dataset (a real-world dataset), which is a widely used benchmark for assessing Java code clone detection systems. It contains 55,499 Java source files from 24,557 distinct open-source projects, collected through the mining process of IJaDataset-2.0. The current version of this benchmark includes over 8.5 million labelled true clone pairs and more than 260,000 labelled false clone pairs across 43 functionalities, categorized into Type-I, Type-II, Type-III, and Type-IV. State&#x02013;of&#x02013;the&#x02013;art techniques [2, 5, 6, 12] in the field of code clone detection have used this dataset. For more details please refer to the revised manuscript on pages 20-21, lines 433- 460.</p><p>&#x02022; Comment 7: [False positives risks: Semantic abstraction could wrongly link syntactically different code snippets.]</p><p>Response: We appreciate the insightful suggestion from the reviewer regarding the risk of false positive. As we know, representing source code in a more abstract manner may lead to extracting more comprehensive semantic features, thereby improving the effectiveness of clone detection techniques in identifying semantic clones. However, the main issue associated with abstract representation is the potential increase in false positive. To mitigate this issue, we employed both high-level source code and abstract low-level compiled code representations in our work. This approach allowed us to leverage the benefits of abstract representation while considering the specific details of the source code. For more details, please refer to the methodology section of the revised manuscript, available on pages 10-20. </p><p>&#x02022; Comment 8: [Configuration challenges: Proper configuration of machine learning models requires hyperparameter tuning expertise.]</p><p>Response: Thank you for your interesting comment. In our study, we opted to use the default settings for machine learning models, as specified in the techniques documentation. While hyperparameter tuning can indeed enhance model performance, we chose to adhere to the default settings to maintain consistency and align with established practices outlined in the documentation. By using default settings, we aimed to ensure transparency and reproducibility in our methodology. We acknowledge that further exploration of hyperparameter tuning could be beneficial and may be considered in future research.</p><p>&#x02022; Comment 9: [Explainability challenges: Identifying why certain code is flagged as clones from multiple blended representations is difficult.]</p><p>Response: We appreciate the reviewer's insightful comment regarding the challenges of explainability when using multiple blended representations for clone detection. In our work, we recognize the importance of explainability in clone detection and have taken steps to address this challenge. Firstly, we have thoroughly documented our methodology for deriving and analyzing multiple representations. This documentation includes detailed explanations of each representation technique used and how they contribute to clone detection.</p><p>Furthermore, we have conducted two experiments to investigate and illustrate how each representation contributes to the identification of code clones. In the first experiment, we evaluated the performance of the proposed techniques with different dataset sizes and feature types (AST, Baf, JimplePDG, and AST+Baf+JimplePDG). Please refer to page 23, lines 504-524, in the revised manuscript for more details. To further investigate the importance of the proposed features (code representation) in enhancing performance in code clone detection and to ensure that this improvement is not coincidental, another experiment was conducted involving varying numbers of features, combined by three combination approaches (linear, multiplicative, distance). An equal number of features was selected from each type (AST, BAF, and Jimple PDG). Please refer to page 24,lines 525-538, for more details.</p><p>&#x02022; Comment 10: [Intellectual property risks: Extracting and sharing representations and models could inadvertently leak proprietary code.]</p><p>Response: We appreciate the reviewer for highlighting the concern regarding intellectual property risks associated with extracting and sharing representations and models, which could potentially lead to the inadvertent leakage of proprietary code.</p><p>To address this concern, we have implemented several precautions in our work. Firstly, we have ensured that all code representations and models used in our study are derived from publicly available and open-source datasets, such as BigCloneBench, which contains labeled clone pairs from various open-source projects. Additionally, both the Soot, Stubber, and the JavaParser tool are freely available for use under the terms of the GNU Lesser General Public License (LGPL) version 2.1 and Eclipse Public License 2.0. Furthermore, we have meticulously anonymized and sanitized any code snippets used in our analysis to remove any proprietary or sensitive information. Overall, we are committed to upholding the highest standards of ethical conduct and data privacy in our research endeavors.</p><p>&#x02022; Comment 11: [Describe dataset features in more details and its total size and size of (train/test) as a table]</p><p>Response: Thank you for your valuable feedback. We appreciate your suggestion to provide more detailed information about the dataset features and its total size, as well as the size of the train and test sets, in a table format.</p><p>In response to your suggestion, we have included a support file, labeled as S1, which contains detailed information about different types of feature used in this work. </p><p>Regarding the dataset and its size, you can refer to Table 5 in the revised manuscript on page 21, which provides an overview of the constructed dataset. For more detailed information, please refer to support file labeled S2, which contains comprehensive details about both the BigCloneBench dataset and the constructed dataset.</p><p>As for the size of the training and test sets, we specified the dataset size used in each experiment, please refer to the evaluation section in the revised manuscript on pages 21-27. Additionally, we utilized 10-fold Stratified cross-validation for training and testing our models. This approach ensures robustness and reliability in our models evaluation process by systematically dividing the dataset into training and testing subsets while maintaining the distribution of classes.</p><p>We believe that these enhancements offer a more comprehensive understanding of the dataset used in our work and its characteristics.</p><p>&#x02022; Comment 12: [Flowchart and algorithm steps need to be inserted]</p><p>Response: We greatly appreciate your recommendation to include flowcharts to illustrate the architecture and algorithms used in our methodology.</p><p>We are pleased to inform you that we have incorporated a detailed architecture diagram in the revised manuscript, located in Figure 8 on page 11. This diagram provides a comprehensive overview of our methodology.</p><p>Additionally, in response to your suggestion, we have introduced a new figure (Figure 9) on page 11 to illustrate the process of ext</p><supplementary-material id="pone.0302333.s005" position="float" content-type="local-data"><label>Attachment</label><caption><p>Submitted filename: <named-content content-type="submitted-filename">Response to Reviewers.docx</named-content></p></caption><media xlink:href="pone.0302333.s005.docx"/></supplementary-material></body></sub-article><sub-article article-type="aggregated-review-documents" id="pone.0302333.r003" specific-use="decision-letter"><front-stub><article-id pub-id-type="doi">10.1371/journal.pone.0302333.r003</article-id><title-group><article-title>Decision Letter 1</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Yun</surname><given-names>Unil</given-names></name><role>Academic Editor</role></contrib></contrib-group><permissions><copyright-statement>&#x000a9; 2024 Unil Yun</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Unil Yun</copyright-holder><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article ext-link-type="doi" xlink:href="10.1371/journal.pone.0302333" id="rel-obj003" related-article-type="reviewed-article"/><custom-meta-group><custom-meta><meta-name>Submission Version</meta-name><meta-value>1</meta-value></custom-meta></custom-meta-group></front-stub><body><p>
<named-content content-type="letter-date">2 Apr 2024</named-content>
</p><p>A novel code representation for detecting Java code clones using high-level and abstract compiled code representations</p><p>PONE-D-23-38302R1</p><p>Dear Dr. Quradaa,</p><p>We&#x02019;re pleased to inform you that your manuscript has been judged scientifically suitable for publication and will be formally accepted for publication once it meets all outstanding technical requirements.</p><p>Within one week, you&#x02019;ll receive an e-mail detailing the required amendments. When these have been addressed, you&#x02019;ll receive a formal acceptance letter and your manuscript will be scheduled for publication.</p><p>An invoice will be generated when your article is formally accepted. Please note, if your institution has a publishing partnership with PLOS and your article meets the relevant criteria, all or part of your publication costs will be covered. Please make sure your user information is up-to-date by logging into Editorial Manager at <ext-link xlink:href="https://www.editorialmanager.com/pone/" ext-link-type="uri">Editorial Manager&#x000ae;</ext-link>&#x000a0;and clicking the &#x02018;Update My Information' link at the top of the page. If you have any questions relating to publication charges, please contact our Author Billing department directly at <email>authorbilling@plos.org</email>.</p><p>If your institution or institutions have a press office, please notify them about your upcoming paper to help maximize its impact. If they&#x02019;ll be preparing press materials, please inform our press team as soon as possible -- no later than 48 hours after receiving the formal acceptance. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact <email>onepress@plos.org</email>.</p><p>Kind regards,</p><p>Unil Yun, Ph.D.</p><p>Academic Editor</p><p>PLOS ONE</p><p>Additional Editor Comments (optional):</p><p>Authors revised carefully this manuscript and it is acceptable now.</p><p>Reviewers' comments:</p><p>Reviewer's Responses to Questions</p><p>
<!-- <font color="black"> -->
<bold>Comments to the Author</bold>
</p><p>1. If the authors have adequately addressed your comments raised in a previous round of review and you feel that this manuscript is now acceptable for publication, you may indicate that here to bypass the &#x0201c;Comments to the Author&#x0201d; section, enter your conflict of interest statement in the &#x0201c;Confidential to Editor&#x0201d; section, and submit your "Accept" recommendation.<!-- </font> --></p><p>Reviewer #1:&#x000a0;All comments have been addressed</p><p>Reviewer #3:&#x000a0;All comments have been addressed</p><p>**********</p><p><!-- <font color="black"> -->2. Is the manuscript technically sound, and do the data support the conclusions?</p><p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. <!-- </font> --></p><p>Reviewer #1:&#x000a0;Partly</p><p>Reviewer #3:&#x000a0;Yes</p><p>**********</p><p><!-- <font color="black"> -->3. Has the statistical analysis been performed appropriately and rigorously? <!-- </font> --></p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #3:&#x000a0;N/A</p><p>**********</p><p><!-- <font color="black"> -->4. Have the authors made all data underlying the findings in their manuscript fully available?</p><p>The <ext-link xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data&#x02014;e.g. participant privacy or use of data from a third party&#x02014;those must be specified.<!-- </font> --></p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #3:&#x000a0;Yes</p><p>**********</p><p><!-- <font color="black"> -->5. Is the manuscript presented in an intelligible fashion and written in standard English?</p><p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.<!-- </font> --></p><p>Reviewer #1:&#x000a0;Yes</p><p>Reviewer #3:&#x000a0;Yes</p><p>**********</p><p><!-- <font color="black"> -->6. Review Comments to the Author</p><p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)<!-- </font> --></p><p>Reviewer #1:&#x000a0;All of the comments and feedback provided have been thoroughly addressed and incorporated into the final version of the document. Given the comprehensive consideration of all suggestions, I highly recommend proceeding with accepting the document for publishing.</p><p>Reviewer #3:&#x000a0;Thank you for addressing all comments.</p><p>Please pay attention to figures as some of them are still blurry.</p><p>and kindly ensure all arguments are completely included within the manuscript were applicable.</p><p>**********</p><p><!-- <font color="black"> -->7. PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p><p>If you choose &#x0201c;no&#x0201d;, your identity will remain anonymous but your review may still be made public.</p><p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.<!-- </font> --></p><p>Reviewer #1:&#x000a0;<bold>Yes:&#x000a0;</bold>Tarek Abd El-Hafeez</p><p>Reviewer #3:&#x000a0;No</p><p>**********</p></body></sub-article></article>