<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd"> 
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 1?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sci Rep</journal-id><journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id><journal-title-group><journal-title>Scientific Reports</journal-title></journal-title-group><issn pub-type="epub">2045-2322</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmcid">10957894</article-id><article-id pub-id-type="publisher-id">56897</article-id><article-id pub-id-type="doi">10.1038/s41598-024-56897-3</article-id><article-categories><subj-group subj-group-type="heading"><subject>Registered Report</subject></subj-group></article-categories><title-group><article-title>The neural basis of naturalistic semantic and social cognition</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6383-6361</contrib-id><name><surname>Thye</surname><given-names>Melissa</given-names></name><address><email>m.thye@ed.ac.uk</email></address><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3248-3225</contrib-id><name><surname>Hoffman</surname><given-names>Paul</given-names></name><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5472-0220</contrib-id><name><surname>Mirman</surname><given-names>Daniel</given-names></name><xref ref-type="aff" rid="Aff1"/></contrib><aff id="Aff1"><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01nrxwf90</institution-id><institution-id institution-id-type="GRID">grid.4305.2</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 7988</institution-id><institution>Department of Psychology, </institution><institution>University of Edinburgh, </institution></institution-wrap>Edinburgh, EH8 9JZ UK </aff></contrib-group><pub-date pub-type="epub"><day>21</day><month>3</month><year>2024</year></pub-date><pub-date pub-type="pmc-release"><day>21</day><month>3</month><year>2024</year></pub-date><pub-date pub-type="collection"><year>2024</year></pub-date><volume>14</volume><elocation-id>6796</elocation-id><history><date date-type="received"><day>24</day><month>1</month><year>2022</year></date><date date-type="accepted"><day>11</day><month>3</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2024</copyright-statement><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><sec><title>Abstract</title><p id="Par1">Decoding social environments and engaging meaningfully with other people are critical aspects of human cognition. Multiple cognitive systems, including social and semantic cognition, work alongside each other to support these processes. This study investigated shared processing between social and semantic systems using neuroimaging data collected during movie-viewing, which captures the multimodal environment in which social knowledge is exchanged. Semantic and social content from movie events (event-level) and movie transcripts (word-level) were used in parametric modulation analyses to test (1) the degree to which semantic and social information is processed within each respective network and (2) engagement of the same cross-network regions or the same domain-general hub located within the semantic network during semantic and social processing. Semantic word and event-level content engaged the same fronto-temporo-parietal network and a portion of the semantic hub in the anterior temporal lobe (ATL). Social word and event-level content engaged the supplementary motor area and right angular gyrus within the social network, but only social words engaged the domain-general semantic hub in left ATL. There was evidence of shared processing between the social and semantic systems in the dorsolateral portion of right ATL which was engaged by word and event-level semantic and social content. Overlap between the semantic and social word and event results was highly variable within and across participants, with the most consistent loci of overlap occurring in left inferior frontal, bilateral precentral and supramarginal gyri for social and semantic words and in bilateral superior temporal gyrus extending from ATL posteriorly into supramarginal gyri for social and semantic events. These results indicate a complex pattern of shared and distinct regions for social and semantic cognition during naturalistic processing.</p></sec><sec><title>Protocol registration</title><p id="Par35">The stage 1 protocol for this Registered Report was accepted in principle on October 11, 2022. The protocol, as accepted by the journal, can be found at: 10.17605/OSF.IO/ACWQY.</p></sec></abstract><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>Language</kwd><kwd>Social behaviour</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Springer Nature Limited 2024</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par2">Social knowledge is a fundamental aspect of human cognition: it informs our moment-by-moment understanding of our social world, and it directly motivates human behaviour<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. Through our understanding of social concepts and behaviours we are able to effectively and accurately communicate complex, abstract ideas and participate in meaningful interpersonal interactions. Many of these processes are, at least partially, supported by the social cognition system, which is broadly engaged in integrating and updating information about the actions, beliefs, motives, and mental states of ourselves and the people in our environment. Much of the research on social knowledge has focused on characterizing how individuals engage the social cognition system to process information about their own and others&#x02019; actions and perspectives<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>. Decoding and reciprocating interactional dynamics leverages a whole host of other cognitive systems, ranging from perceptual and attentional systems to higher-order language and executive systems<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>. Shifting from a strict domain specificity approach and adopting models from other domains of cognition may result in greater insights in social neuroscience<sup><xref ref-type="bibr" rid="CR4">4</xref>,<xref ref-type="bibr" rid="CR5">5</xref></sup>. One key contributor is semantic cognition, which allows us to know and communicate about both the linguistic and non-linguistic physical and emotional properties of the objects, people, and events we experience, and gives meaning to the language we use<sup><xref ref-type="bibr" rid="CR6">6</xref>&#x02013;<xref ref-type="bibr" rid="CR9">9</xref></sup>. The breadth and complexity of social knowledge requires mutual or interacting support from both social and semantic cognition, and the present study examines the degree to which social cognitive processing leverages the neural architecture of the semantic system.</p><p id="Par3">A rich history of research on pragmatics shows that social cognition plays an important role in communication, where context and non-linguistic features convey critical information that is not present in the lexical units or syntactic structures themselves. This pragmatic content allows comprehension of the intended meaning beyond the surface linguistic content<sup><xref ref-type="bibr" rid="CR10">10</xref>,<xref ref-type="bibr" rid="CR11">11</xref></sup> and requires the social cognitive process of mentalizing about the perspectives of the other agents in the environment<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>. Retrieval of the relevant social knowledge&#x02014;from the names and behaviours of the people we encounter to the concepts used to label those behaviours&#x02014;may rely on semantic memory, which is an acquired conceptual store of linguistic and non-linguistic information about the multimodal world around us, informed by interactions with new objects, events, experiences, and people<sup><xref ref-type="bibr" rid="CR7">7</xref>,<xref ref-type="bibr" rid="CR8">8</xref>,<xref ref-type="bibr" rid="CR13">13</xref></sup>. Although pragmatics is predominately concerned with how communicative intent is inferred in the presence or absence of linguistic input which is separate from the goals of the present study, the research in this domain emphasizes the importance of the social cognition system in communication, a role which is also facilitated by semantic memory.</p><p id="Par4">One clear point of intersection between semantic and social cognition is the representation and processing of social concepts. What makes these concepts &#x02018;social&#x02019; is their use in ascribing meaning to human behaviour, intentions, desires, feelings, and interactions<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>. This type of social knowledge is often (although not universally<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>) described as intangible or abstract, not grounded in sensory or perceptual representations<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>. Current neurocomputational theories posit that abstract semantic representations arise through statistical regularities in the contexts in which they occur, especially natural language contexts. Concepts such as <italic>jealousy</italic> and <italic>ambition</italic> co-occur with concrete concepts in specific contexts, and knowledge about our own and others&#x02019; emotions, intentions, and beliefs is encoded along with the environment in which they occurred, thus giving rise to abstract social concepts<sup><xref ref-type="bibr" rid="CR17">17</xref>&#x02013;<xref ref-type="bibr" rid="CR19">19</xref></sup>. Social concepts, like other types of semantic knowledge<sup><xref ref-type="bibr" rid="CR14">14</xref>,<xref ref-type="bibr" rid="CR20">20</xref></sup>, are acquired through interactions in social environments in which individuals display or communicate about the behaviours associated with these concepts. As a result, these concepts are predominately not understood through sensory systems, and are instead directly informed by and grounded in emotion<sup><xref ref-type="bibr" rid="CR21">21</xref></sup>, introspection<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>, and social experiences<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>. The roles of semantic and social cognition in acquiring social knowledge are thus inseparable.</p><p id="Par5">In addition to shared conceptual knowledge, the semantic and social systems are supported by an overlapping network of brain regions (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>)<sup><xref ref-type="bibr" rid="CR3">3</xref>,<xref ref-type="bibr" rid="CR7">7</xref>,<xref ref-type="bibr" rid="CR23">23</xref></sup>. This overlap predominately occurs in the anterior temporal lobes (ATL) and the left inferior parietal lobule, regions which are consistently reported in semantic processing<sup><xref ref-type="bibr" rid="CR24">24</xref>,<xref ref-type="bibr" rid="CR25">25</xref></sup>, including representing and retrieving social knowledge<sup><xref ref-type="bibr" rid="CR14">14</xref>,<xref ref-type="bibr" rid="CR26">26</xref>,<xref ref-type="bibr" rid="CR27">27</xref></sup>, and in mentalizing tasks<sup><xref ref-type="bibr" rid="CR28">28</xref>,<xref ref-type="bibr" rid="CR29">29</xref></sup>. Engagement of the same regions for semantic and social processing has motivated a theoretical account, the <italic>graded semantic hub hypothesis</italic>, which argues that social cognition requires semantic memory and the neural architecture of the semantic cognition and semantic control systems<sup><xref ref-type="bibr" rid="CR7">7</xref>,<xref ref-type="bibr" rid="CR20">20</xref>,<xref ref-type="bibr" rid="CR30">30</xref></sup>. The same ventrolateral portion of left ATL is engaged by theory of mind processing and non-verbal semantic processing<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>, and a recent meta-analysis found that both cognitive systems rely on a shared cognitive control network<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>, which provides empirical support for this account. In addition, the ATL may be ideally positioned to serve as a hub for processing both semantic and social information given the structural connections of the uncinate fasciculus projecting from ATL to emotion processing areas in amygdala and orbitofrontal cortex<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>. Notwithstanding this evidence of overlap, there is also extensive evidence that the networks that support language processing and theory of mind processing are separable<sup><xref ref-type="bibr" rid="CR32">32</xref>,<xref ref-type="bibr" rid="CR33">33</xref></sup>. Compelling evidence of this dissociation comes from lesion studies in which individuals with extensive left hemisphere damage or aphasia have preserved theory of mind processing or ability to comprehend communicative intent<sup><xref ref-type="bibr" rid="CR34">34</xref>,<xref ref-type="bibr" rid="CR35">35</xref></sup>. This dissociation is not observed in patients with semantic dementia, which is characterized by bilateral ATL damage, who display impairments in both semantic and social processing<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>. This suggests that the location of the damage (i.e., whether the damage occurs in a shared ATL processing hub) may determine whether only one or both systems are affected. There is thus ample evidence that language and social processing can be dissociated, but a focus on separability ignores potential insights about interactive processing<sup><xref ref-type="bibr" rid="CR37">37</xref>,<xref ref-type="bibr" rid="CR38">38</xref></sup> and cannot answer whether the regions engaged by both systems are responding to both types of content (i.e., semantic and social processing) or serving as domain-general hubs that support both processes. In this view, specialization, and therefore dissociation, does occur for semantic and social processing which separately recruit more specialized regions outside of these hubs.<fig id="Fig1"><label>Figure 1</label><caption><p>Social, semantic, and semantic control brain networks. A schematic showing the critical regions within the social network (blue), semantic network (green), and semantic control network (red) is shown in the top panel. The overlap between the regions within each network is indicated by circles with mixed colours, and the relative extent of overlap is shown by the amount of colour associated with a given network in each circle (either approximately equally shared&#x02014;indicated with &#x000bd;&#x02013;&#x000bd; shading&#x02014;or predominately reported for one system with a smaller subset of the region reported for the other system&#x02014;indicated with &#x000be;&#x02013;&#x000bc; shading). The statistical maps derived from coordinate-based activation likelihood estimation (ALE) analyses of social cognition<sup><xref ref-type="bibr" rid="CR31">31</xref></sup> and semantic cognition and semantic control<sup><xref ref-type="bibr" rid="CR39">39</xref></sup> are shown in the bottom panel. ATL, anterior temporal lobe; IFG, inferior frontal gyrus; IPL, inferior parietal lobule; MTG, middle temporal gyrus; PC, precuneus; PFC, prefrontal cortex; pMTG, posterior middle temporal gyrus; SFG, superior frontal gyrus; SMA, supplementary motor area.</p></caption><graphic xlink:href="41598_2024_56897_Fig1_HTML" id="MO1"/></fig></p><p id="Par6">Overlapping neural networks may simply indicate that the semantic and social systems work alongside each other, with areas of overlap performing separate functions within each system (no shared processing) or there may be non-overlapping specialized sub-regions for processing semantic or social information (graded functioning). Alternatively, domain-general areas may perform the same function within each system (shared processing) or a known semantic or social hub may integrate information to facilitate processing both semantic and social information (shared hub). One reason to expect shared processing or a shared hub is that semantic and social cognition have been proposed to consist of analogous representation and control processes. Control processes for both systems are supported by a shared control network<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>, and the hub-and-spoke sensorimotor architecture of the semantic representation system lends itself well to multimodal social perceptual stimuli<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>. Recent research provides critical evidence in support of this claim<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>, but the social and semantic tasks used were highly simplified and thus impoverished approximations of real-world cognition. Also, the inferences were drawn from the group-level statistical map rather than overlap at the individual participant level. Stronger evidence of shared processing or a shared hub would come from using naturalistic paradigms and investigating the neural overlap of these systems within individuals because idiosyncratic variations in neuroanatomy and functioning are ignored when aggregating results at the group-level<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>. The latter is especially relevant when studying regions that may have graded functioning. Previous research attempting to isolate theory of mind (i.e., false belief) and linguistic (non-social stories) processing within the superior temporal sulcus (STS) found overlapping voxels in both posterior and anterior portions of STS that responded to both types of content within individuals<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>. These results suggest that the neural overlap reported in group studies is capturing meaningful overlap that exists within subjects, but this study did not test the broader semantic and social systems. The present study investigated whether there is evidence of shared processing in domain-general regions or within a shared hub in ATL that support both systems at the individual and group level in the same naturalistic context.</p><p id="Par7">For tractability, researchers tend to fractionate human cognition into modules and study these modules as independent, non-overlapping systems<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>. A prevalent, perhaps unintentional, example of this treatment of cognition can be seen in standard fMRI contrast analyses in which a cognitive process of interest is isolated by measuring an experimental condition (i.e., social communication) and subtracting from it a control condition that minimally requires the cognitive process of interest (i.e., non-social communication). Studies utilizing this methodology have generated significant insights into many aspects of human cognition, including both social and semantic cognition. This methodology assumes an additive relationship between the processes such that it can be undone by subtraction (i.e., control processes operate in the same way in the control and experimental conditions). Although this assumption may be approximately valid in many cases, it explicitly does not hold for integrated or interactive systems. Subtracting non-social communication from social communication to identify &#x0201c;social cognition&#x0201d; assumes that communication works the same way in social and non-social contexts (e.g., no social knowledge is nested within the subtracted semantic system, which conflicts with existing evidence<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>) and that social cognition works the same way in communication and non-communication contexts (i.e., subtracting the communication component leaves task-independent social cognition that would operate similarly in non-communication contexts). This research strategy has led to the impression that all cognitive systems are subtractable and independent in the mind and brain, rather than just being separate in the research literature.</p><p id="Par8">In addition to this general treatment of human cognition, the relationship between these two cognitive systems has been obscured by differences in the types of paradigms used to study them. Studies have tended to rely on highly simplified experiments to investigate both semantic and social processing, but there is greater diversity in the content and presentation of paradigms used to study social cognition. Semantic tasks often involve single words or pictures, whereas the stimuli used in social tasks range from single word and sentence stimuli to face stimuli and social animations. As a result, the same social cognitive process (e.g., mentalizing) can be elicited by heterogeneous tasks (e.g., false-belief vignettes, comic strips, strategic games, animations) which complicates cross-task inferences due to varied task demands<sup><xref ref-type="bibr" rid="CR42">42</xref>,<xref ref-type="bibr" rid="CR43">43</xref></sup>. These methodological differences hinder investigations of shared processing between semantic and social cognition due to the challenge of identifying stimuli and paradigms with matched processing demands that meaningfully capture both systems. This would ideally be accomplished by eliciting semantic and social processing within the same paradigm.</p><p id="Par9">Given the specific barriers that have hindered investigations of the interdependence between semantic and social cognition, it is critical to select stimuli that adequately capture varied social knowledge, including social semantic information (i.e., social concepts) and social interaction information (i.e., social events). An ideal avenue to accomplish these complementary goals is through the analysis of naturalistic neuroimaging data. Naturalistic neuroimaging provides greater ecological validity compared to studies of isolated word processing, which do not capture how the brain processes information in the real-world and disregards the context that informed the conceptual representation<sup><xref ref-type="bibr" rid="CR44">44</xref>&#x02013;<xref ref-type="bibr" rid="CR46">46</xref></sup>. Social information occurs in dynamic and multimodal contexts in which knowledge accrues over several seconds to minutes, which naturalistic paradigms more closely approximate. One type of naturalistic paradigm, movie viewing, has been shown to produce stable intrinsic connectivity networks that are more reliable than those derived from resting state data<sup><xref ref-type="bibr" rid="CR47">47</xref>,<xref ref-type="bibr" rid="CR48">48</xref></sup> and which provides the opportunity to capture temporal structure that would be lost in a traditional event-averaging fMRI analysis<sup><xref ref-type="bibr" rid="CR49">49</xref></sup>. Further, humans segment continuous experiences into discrete events<sup><xref ref-type="bibr" rid="CR50">50</xref></sup> and cortical regions have varied temporal receptive windows that are directly impacted by the duration and content of these events<sup><xref ref-type="bibr" rid="CR51">51</xref>,<xref ref-type="bibr" rid="CR52">52</xref></sup>. Naturalistic paradigms allow for the investigation of both short (i.e., 1000 ms) and long temporal processing across cortical regions in response to varied content.</p><p id="Par10">The aim of the present study was to investigate the shared and distinct neural organization of social, semantic, and semantic control brain networks by examining the response of these networks to semantic and social information in movies, while distinguishing between word-level and event-level representations. The study utilized the publicly available Naturalistic Neuroimaging Database (NNDb), which includes hours of movie viewing fMRI data for a large sample of adults (N&#x02009;=&#x02009;86)<sup><xref ref-type="bibr" rid="CR53">53</xref></sup>. Of note, the data include 10 different movies, which enables tests of generalizability of results across stimuli and provides an opportunity to sample varied social concepts and events. Independent ratings of semantic and social content from manually coded events for each movie were used as continuous event-level variables. Lexical and semantic content and smoothed factor scores indexing Semantic Flexibility and Social Impact were used as continuous word-level variables. The continuous variables were used to identify regions of the brain that respond to semantic and social content and to examine the degree that neural resources are shared between the systems at the individual and group level. The primary aims and predictions of the current study are divided into two complementary research questions (see Table <xref rid="Tab1" ref-type="table">1</xref>).</p><p>First, during naturalistic movie viewing, is semantic, social, and semantically flexible (i.e., having several uses or meanings) content associated with increased activation in the semantic, social, and semantic control networks, respectively? It was expected that clusters of voxels showing increased activation in response to greater semantic, social, and semantically flexible word-level content will fall within the semantic (hypothesis 1.1a), social (hypothesis 1.1b), and semantic control (hypothesis 1.1c) brain networks, respectively. Further, it was expected that the clusters of voxels associated with semantic and social event-level content will fall within the semantic (hypothesis 1.2a) and social (hypothesis 1.2b) brain networks, respectively.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Design table.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Question</th><th align="left">Hypothesis</th><th align="left">Analysis plan</th><th align="left">Interpretation given to different outcomes</th></tr></thead><tbody><tr><td align="left" rowspan="5">1. During naturalistic movie viewing, is semantic, social, and semantically flexible content associated with increased activation in the semantic, social, and semantic control networks, respectively?</td><td align="left"><p>1.1a (semantic words)</p><p>Clusters of voxels showing increased activation in response to greater semantic word-level content will fall within the semantic brain network</p></td><td align="left" rowspan="3"><p>The word-level analyses will be the same for semantic, social, and semantically flexible content. The following steps will be taken for each measure independently:</p><p>(1) Extract smoothed time series of scores (either residual factor scores which account for number of words or number of content words) using a sliding window within event boundaries</p><p>(2) Whole-brain parametric modulation analysis</p><p>(3) The subject-level activation maps for a given content type will be used as inputs for a second-level group analysis using linear mixed-effects modelling with a fixed effect of content type and random intercepts of subject and movie</p><p>(4) The statistical map will be corrected using a cluster-forming threshold of <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.01 and an FWE-corrected threshold of <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.05</p><p>(5) Results will be compared to the ALE-defined networks of interest, focusing on the core regions within each network, highlighted in the top panel of Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref></p></td><td align="left"><p>Null: Fewer than 20 voxels will be associated with increased semantic information</p><p>Alternatives: The clusters of voxels associated with increased semantic information will (1) include portions of the semantic network as well as regions outside the ALE-defined semantic network (partial support) or (2) fall entirely outside the ALE-defined semantic network (no support)</p></td></tr><tr><td align="left"><p>1.1b (social words)</p><p>Clusters of voxels showing increased activation in response to greater social word-level content will fall within the social brain network</p></td><td align="left"><p>Null: Fewer than 20 voxels will be associated with increased social information</p><p>Alternatives: The clusters of voxels associated with increased social information will (1) include portions of the social network as well as regions outside the ALE-defined social network (partial support) or (2) fall entirely outside the ALE-defined social network (no support)</p></td></tr><tr><td align="left"><p>1.1c (control words)</p><p>Clusters of voxels showing increased activation in response to semantically flexible word-level content will fall within the semantic control brain network</p></td><td align="left"><p>Null: Fewer than 20 voxels will be associated with increased semantically flexible content</p><p>Alternatives: The clusters of voxels associated with increased semantic flexibility will (1) include portions of the semantic control network as well as regions outside the ALE-defined semantic control network (partial support) or (2) fall entirely outside the ALE-defined semantic control network (no support)</p></td></tr><tr><td align="left">1.2a (semantic events) Clusters of voxels showing increased activation in response to semantic events (plot-progressing, informative verbal or written scenes) will fall within the semantic brain network</td><td align="left" rowspan="2"><p>The event-level analyses will be the same for semantic, social, and scrambled content. The following steps will be taken for each measure independently:</p><p>(1) Whole-brain duration modulated parametric analysis</p><p>(2) The subject-level activation maps for a given content type will be used as inputs for a second-level group analysis using linear mixed-effects modelling with a fixed effect of content type and random intercepts of subject and movie</p><p>(3) The statistical map will be corrected using a cluster-forming threshold of <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.01 and an FWE-corrected threshold of <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.05</p></td><td align="left"><p>Null: Fewer than 20 voxels will be associated with semantic events</p><p>Alternatives: The clusters of voxels associated with increased semantic information within events will (1) include portions of the semantic network as well as regions outside the ALE-defined semantic network (partial support), (2) fall entirely outside the ALE-defined semantic network (no support), or (3) produce the same clusters as the scrambled ratings (no support)</p></td></tr><tr><td align="left"><p>1.2b (social events)</p><p>Clusters of voxels showing increased activation in response to social events (scenes depicting on or off-screen interactions between/among characters) will fall within the social brain network</p></td><td align="left"><p>Null: Fewer than 20 voxels will be associated with social events</p><p>Alternatives: The clusters of voxels associated with increased social information within events will (1) include portions of the social network as well as regions outside the ALE-defined social network (partial support), (2) fall entirely outside the ALE-defined social network (no support), or (3) produce the same clusters as the scrambled ratings (no support)</p></td></tr><tr><td align="left" rowspan="4">2. To what extent are the semantic and semantic control networks involved in processing social concepts and events in individual subjects?</td><td align="left"><p>2.1a (semantic overlap)</p><p>If there are clusters of voxels that respond to social word and event-level content, then it is expected that both social concepts and social events will engage areas of overlap within the semantic brain network defined within individual participants</p></td><td align="left" rowspan="4"><p>The hypotheses of RQ2 will be tested using the following procedure:</p><p>(1) The number of overlapping voxels will be calculated between the subject-level statistical maps for processing semantic and social content (word-level and event-level results processed independently)</p><p>(2) The number of overlapping voxels will be calculated between the subject-level statistical maps for processing semantically flexible words and social content (word-level and event-level results processed independently)</p><p>(3) A second-level random effects analysis will be run using the overlap images from individual participants to determine whether stable areas of overlap exist across participants</p></td><td align="left"><p>Null: At the individual subject level, fewer than 10 voxels show increased activation in response to both semantic content and social content (either concepts or events)</p><p>Alternatives: (1) clusters of voxels will show increased activation in response to semantic content and social concepts, but not social events (partial support) or (2) clusters of voxels will show increased activation in response to semantic content and social events, but not social concepts (partial support)</p></td></tr><tr><td align="left"><p>2.1b (control overlap)</p><p>If there are clusters of voxels that respond to social word and event-level content, then it is expected that both social concepts and social events will engage areas of overlap within the semantic control brain network defined within individual participants</p></td><td align="left"><p>Null: At the individual subject level, fewer than 10 voxels show increased activation in response to both semantically flexible content and social content (either concepts or events)</p><p>Alternatives: (1) clusters of voxels will show increased activation in response to semantically flexible content and social concepts, but not social events (partial support) or (2) clusters of voxels will show increased activation in response to semantically flexible and social events, but not social concepts (partial support)</p></td></tr><tr><td align="left">2.2a (semantic non-overlap) If there are clusters of voxels that respond to social word and event-level content, then it is expected that non-overlapping, proximal clusters of voxels will differentially respond to semantic and social content</td><td align="left"><p>Null: At the individual subject level, the voxels which respond to social content will not be proximal to the voxels which respond to semantic content (i.e., the clusters of voxels will not be sub-regions within a single atlas-defined anatomical region)</p><p>Alternatives: (1) the voxels associated with processing social concepts, but not social events, will be proximal (i.e., sub-regions within a single anatomical region) to the voxels associated with processing semantic content (partial support) or (2) the voxels associated with processing social events, but not social concepts, will be proximal to the voxels associated with processing semantic content (partial support)</p></td></tr><tr><td align="left"><p>2.2b (control non-overlap)</p><p>If there are clusters of voxels that respond to social word and event-level content, it is expected that non-overlapping, proximal clusters of voxels will differentially respond to semantic control and social content</p></td><td align="left"><p>Null: At the individual subject level, the voxels which respond to social content will not be proximal to the voxels which respond to semantically flexible content (i.e., the clusters of voxels will not be sub-regions within a single anatomical region)</p><p>Alternatives: (1) the voxels associated with processing social concepts, but not social events, will be proximal (i.e., sub-regions within a single anatomical region) to the voxels associated with processing semantically flexible content (partial support) or (2) the voxels associated with processing social events, but not social concepts, will be proximal to the voxels associated with processing semantically flexible content (partial support)</p></td></tr></tbody></table><table-wrap-foot><p>The sampling plan is the same for all tested predictions. A sensitivity power analysis was conducted using using the <italic>pwr</italic> package in R. With the fixed sample size of 86, statistical power of 0.95, and an alpha of 0.05, an omnibus multiple regression analysis with 2 to 3 predictors would be sensitive to detecting medium effects (<italic>f</italic><sup>2</sup>&#x02009;=&#x02009;0.19&#x02013;0.21).</p></table-wrap-foot></table-wrap></p><p id="Par11">Second, to what extent are the semantic and semantic control networks involved in processing social concepts and events in individual subjects? If there are clusters of voxels that respond to social word-level and event-level content, then it was expected that both social concepts and social events will engage areas of overlap within the semantic (hypothesis 2.1a) and semantic control (hypothesis 2.1b) brain networks defined within individual participants. This would provide evidence of shared resources between the social and semantic systems. If that overlap occurs within the known semantic hub, ATL, this will provide support for the <italic>graded semantic hub</italic> hypothesis, suggesting that the systems leverage a shared hub. In addition to overlap, it was expected that non-overlapping, proximal clusters of voxels will differentially respond to semantic and social content (hypothesis 2.2a) and semantic control and social content (hypothesis 2.2b), providing evidence of graded functioning within network regions.</p></sec><sec id="Sec2"><title>Materials</title><sec id="Sec3"><title>Ethics information</title><p id="Par12">The research complies with all relevant ethical regulations. The project from which the data are derived was approved by the ethics committee of University College London. Participants provided written informed consent to take part in the study and have their anonymised data shared.</p></sec><sec id="Sec4"><title>Design</title><p id="Par13">The research questions were tested via secondary analyses of a publicly available dataset called the Naturalistic Neuroimaging Database (NNDb) which is accessible on OpenNeuro (<ext-link ext-link-type="uri" xlink:href="https://openneuro.org/datasets/ds002837/versions/2.0.0">https://openneuro.org/datasets/ds002837/versions/2.0.0</ext-link>). Version 2.0.0 of the database (released April 20, 2021) was used for all analyses and includes the raw and preprocessed data from 86 participants (mean age&#x02009;=&#x02009;26.81; 42 females) who watched one of ten movies (length range&#x02009;=&#x02009;5470&#x02014;8882s) while undergoing fMRI. Movie selection was decided by previous exposure, so all participants were shown a movie they had not previously watched. At least 6 and up to 20 participants watched each movie.</p><p id="Par14">None of the authors had previously analysed the participant data from any version of this dataset nor had any direct knowledge of the data at the time of pre-registration. All analyses were registered prior to any human observation of the neuroimaging data. The movie annotation files were obtained prior to registration and coded using protocols designed to (1) segment the movies into discrete events and (2) derive a range of continuous variables encoding the presence of word and event-level semantic and social information at each point in time (see below). For a detailed overview of the experimental procedures, including how the data were collected and preprocessed, see the publication describing the dataset<sup><xref ref-type="bibr" rid="CR53">53</xref></sup>.</p></sec><sec id="Sec5"><title>Sampling plan</title><p id="Par15">The current study is a secondary analysis of existing data, and, as such, the sample size is fixed. With 86 participants who each watched a full feature-length film, the NNDb is among the largest publicly available databases of naturalistic neuroimaging data to date (although see the <italic>Narratives</italic> dataset<sup><xref ref-type="bibr" rid="CR54">54</xref></sup>), and currently the largest dataset that uses movie stimuli. Comparable databases often have fewer than 30 participants, and many use stimuli that are less coherent (i.e., clips of adverts or scenes from films) or shorter in duration (i.e., single episodes or short films). Task-based fMRI studies require more than 80 participants to detect medium effect sizes (see power analysis below)<sup><xref ref-type="bibr" rid="CR55">55</xref></sup>, and scan times greater than 90 min produce more reliable results<sup><xref ref-type="bibr" rid="CR56">56</xref></sup>. With the large sample size and the longer scan duration, the NNDb provides more data per participant than many other naturalistic neuroimaging databases.</p><p id="Par16">A sensitivity power analysis was conducted using the <italic>pwr</italic> package in R<sup><xref ref-type="bibr" rid="CR57">57</xref></sup> to determine what effect size is detectable given the fixed sample size. This type of power analysis is a complement to the more common a priori power analysis which assumes an effect size and computes the sample size necessary to detect that effect. With the fixed sample size of 86, statistical power of 0.95, and an alpha of 0.05, an omnibus multiple regression analysis with 2&#x02013;3 predictors would be sensitive to detecting medium effects (<italic>f</italic><sup><italic>2</italic></sup>&#x02009;=&#x02009;0.19&#x02013;0.21). This is a conservative estimate of statistical power because it does not take into consideration the large number of observations (i.e., time points) within participants which substantially increases statistical power, especially when within participant variance in the dependent variable is high. Similar effect sizes are detectable in standard event-related and blocked design fMRI experiments but require many trials (k&#x02009;&#x0003e;&#x02009;60) or a larger sample (N&#x02009;&#x0003e;&#x02009;30)<sup><xref ref-type="bibr" rid="CR58">58</xref></sup>, both of which are far exceeded with the NNDb dataset.</p></sec><sec id="Sec6"><title>Analysis plan</title><p id="Par17">In order to investigate neural processing of social and semantic events and concepts, two primary types of scores were extracted from each movie: (1) event-level scores and (2) word-level scores. The movie event-level scores were generated via a manual coding process in which each movie was segmented into discrete events and the relative semantic and social content within events were rated independently. Movie word-level scores were generated by conducting a principal component analysis on 12 critical word property values and smoothing the resulting scores using a sliding window. Both the word-level and event-level scores were used in parametric modulation analyses to assess the neural response to varied levels of lexical and event-based semantic and social content (RQ1) and the extent to which processing lexical and event-based semantic and social information relies on overlapping regions within the semantic and social brain networks within subjects (RQ2). The sections below provide additional detail on how these data were generated and the pre-registered analyses. See Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref> for a schematic overview of the analyses.<fig id="Fig2"><label>Figure 2</label><caption><p>Schematic of analyses. Representative events from one of the movies (<italic>Back to the Future</italic>) are shown in red, blue, and yellow shaded tiles. The corresponding event number, social and semantic rating, and event description are provided below the event screenshot. These events are sampled from the Event-Level time course (below the tiles) which shows the semantic (green) and social (blue) event ratings for the movie. Event 161 (blue tile) is used to illustrate how the words within events are processed. First, word properties are generated for all transcript words. Second, missing data are imputed 5 times (ignoring closed class words which are shaded grey). Third, PCA is run on each of the imputed datasets, and the resulting factor scores from the 5 datasets are averaged. Only the averaged Semantic Flexibility and Social Impact factor scores are shown because these are the data used for analyses. Fourth, the factor scores and semantic content (i.e., number of content words) are smoothed within the event boundaries. The summed total factor score or the number of content words is calculated within a 5s sliding window sliding every second. This window stops at the end of the event, and a new sliding window starts at the beginning of each event. When no words fall within a window (demonstrated with Event 282), the calculated window value is 0. This process results in a Word-Level time course of smoothed scores which is shown to the right of the Event-Level time course. Both the Event-Level and Word-Level time courses were used as parametric modulators by convolving the time courses with whole-brain BOLD signal (bottom panel). The semantic network and simulated BOLD time series are shown as an example.</p></caption><graphic xlink:href="41598_2024_56897_Fig2_HTML" id="MO2"/></fig></p><sec id="Sec7"><title>Movie events</title><p id="Par18">To provide data at the event level, each movie was segmented into discrete events capturing subtle changes in the content or purpose of consecutive scenes. A detailed protocol was developed to provide consistent principles for segmenting. Manual subjective ratings of event boundaries have been previously applied to naturalistic movie data and have a high degree of correspondence with data-driven event segmentation models based on shifts in patterns of brain activity<sup><xref ref-type="bibr" rid="CR50">50</xref></sup>. For this study, event transitions were identified by the first author using the following criteria: (1) event boundaries are defined by a qualitative shift in the tone, setting, characters, or purpose of the scene; (2) a single event is often shot continuously with the same characters in the same setting or environment. Any sudden shift in the tone or emotional impact should be an indicator that a new event has begun; (3) the action sequences that occur within an event are more predictable than action sequences that occur between events. The latter criterion was derived from previous research on event prediction, which suggests that a good indicator of whether a new event has begun is if a sequence feels disconnected, unexpected, unrelated, or discontinuous from the previous sequence<sup><xref ref-type="bibr" rid="CR59">59</xref>,<xref ref-type="bibr" rid="CR60">60</xref></sup>. Changes in background music or camera angles alone were not sufficient for marking an event boundary. Further, a distinction was made between <italic>major events</italic>, which tend to occur less frequently, have a longer duration (i.e., several minutes), and be accompanied by a larger shift in the content or purpose of a scene, and <italic>minor events</italic>, which occur more frequently, have a shorter duration (i.e., several seconds), and are signalled by more subtle shifts in content or purpose. Excluding opening studio credits and closing credits, the number of events per movie ranged from 238 to 429 (<italic>Mdn</italic>&#x02009;=&#x02009;384).</p><p id="Par19">The semantic and social content of each minor event was rated for each movie. Both semantic and social content were rated on a scale from 1 to 10 with higher scores indicating greater semantic or social content. Semantic content was defined as narrative exposition in which movie or scene information is presented linguistically through spoken language (by a character or narrator) or in writing (such as text about the movie, timescale, or characters or any text presented during an event). Although semantic information can be expressed non-linguistically, this type of semantic knowledge requires a greater degree of inference which can be variable when manually coding events. To avoid conflating linguistic semantic information with non-linguistic semantic or pragmatic inferences, only spoken or written information was considered semantic content. For the purposes of this study, events in which new semantic information was presented were coded as more semantic relative to events with semantic content that was already known to the viewer. Critically, a distinction was made between novel information and shocking or surprising information, the latter of which did not receive a higher semantic score. Information was considered new only if it is being presented to the viewer for the first time. Events in which a character learns information the audience already knows would receive a lower semantic score. Such a scene may receive a higher social rating (described below) if the information is personally impactful or requires updating a false belief. This criterion was included because events with novel information are more informative and require greater semantic processing relative to the moments in which the information is consistent or has already been processed (because it has already been presented to the viewer). Low semantic events would have minimal to no written or spoken exchange of new information, such as an action sequence. See Supplementary Fig. <xref rid="MOESM1" ref-type="media">S1</xref> for the detailed rubric for coding semantic information.</p><p id="Par20">Social content was defined by the presence of more than one person or character, even if inanimate or off-screen. Any event that conveys information about the characters in the movie and their relationships with other characters was considered social. This could include general conversation or exchange of neutral character information, which would receive a low to moderate social rating, or could convey character attitudes, thoughts, feelings, or passions, which would receive a moderate to high social rating. The relative degree of sociality may depend on the type, duration, and significance of the interaction within the event. Events were considered more social if (1) the interpersonal connection between or among the characters was deeper and intense rather than superficial or brief based on their prior interactions throughout the movie and (2) the specific characters in the event bring a larger significance to the interaction based on who they are or the pre-defined relationship between or among the characters. A distinction was made between high social and high emotional content. Although an event may be both highly social and emotional, an event does not have to be emotionally intense in order to be considered social. Similarly, social and semantic content were coded independently as an event can be both highly (or weakly) social and semantic. The highest ratings (i.e., 9 or 10) were reserved for events in which the primary purpose of the scene was to convey semantic or social information. Importantly, a single event could not receive a 9 or 10 for <italic>both</italic> semantic and social content because the primary purpose had to be coded as either semantic or social. See Supplementary Fig. <xref rid="MOESM1" ref-type="media">S2</xref> for the detailed rubric for coding social information.</p><p id="Par21">The first author watched all of the movies and marked the minor event boundaries using the established protocol. This was done to provide the event boundaries for coding semantic and social content and to ensure that the events of primary interest were coded in a consistent way across all 10 movies. At least 1 other independent coder then marked where the major events occurred within each movie using the established timestamps from the minor events.</p><p id="Par22">After events were delineated, at least two independent coders (the first author and at least one independent coder) rated the semantic and social content of each minor event in the movie and wrote a brief description of what occurred during the event (see Table <xref rid="Tab2" ref-type="table">2</xref> for examples). Inter-rater reliability was assessed separately for the semantic and social scores for the coders of each movie using Krippendorff&#x02019;s alpha reliability coefficient. When the inter-rater reliability fell below 0.75, the coder who rated all movies identified which events were poorly aligned, rewatched the event, and made a revised consensus rating based on the content of the event and the notes of the other coder.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Example movie event annotations and smoothed word data.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="4">Event data</th><th align="left"/></tr><tr><th align="left" rowspan="2">Event number</th><th align="left">Semantic score</th><th align="left">Social score</th><th align="left" rowspan="2">Event notes</th><th align="left" rowspan="2"/></tr><tr><th align="left" colspan="2">R1 (R2)</th></tr></thead><tbody><tr><td align="left">278</td><td align="left">2 (3)</td><td align="left">1 (1)</td><td align="left">Doc waiting for Marty at the clock tower</td><td align="left"/></tr><tr><td align="left">279</td><td align="left">5 (6)</td><td align="left">6 (6)</td><td align="left">Marty arrives and Doc rushes over</td><td align="left"/></tr><tr><td align="left">280</td><td align="left">6 (6)</td><td align="left">6 (6)</td><td align="left">Marty explains how things went down with his dad. Doc seems worried</td><td align="left"/></tr><tr><td align="left">281</td><td align="left">9 (9)</td><td align="left">4 (6)</td><td align="left">Doc explains plan to Marty</td><td align="left"/></tr><tr><td align="left">282</td><td align="left">4 (5)</td><td align="left">9 (10)</td><td align="left">Marty and Doc say goodbye</td><td align="left"/></tr><tr><td align="left">283</td><td align="left">7 (7)</td><td align="left">6 (4)</td><td align="left">Doc restates part of the plan&#x02009;+&#x02009;Marty gets in the car</td><td align="left"/></tr><tr><td align="left">284</td><td align="left">7 (9)</td><td align="left">5 (3)</td><td align="left">Doc discovers letter in his coat&#x02009;+&#x02009;rips it up</td><td align="left"/></tr><tr><td align="left">285</td><td align="left">3 (4)</td><td align="left">4 (5)</td><td align="left">Tree crashes down. Doc and Marty split up to fix cables</td><td align="left"/></tr><tr><td align="left">286</td><td align="left">1 (3)</td><td align="left">3 (5)</td><td align="left">Doc runs up clock tower to throw cable over</td><td align="left"/></tr><tr><td align="left">287</td><td align="left">7 (7)</td><td align="left">6 (7)</td><td align="left">Marty tries to tell Doc about the future again</td><td align="left"/></tr></tbody></table><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="5">Word data</th></tr><tr><th align="left"/><th align="left">Word Length</th><th align="left">Semantic Flexibility</th><th align="left">Emotional Strength*</th><th align="left">Social Impact</th></tr></thead><tbody><tr><td align="left">Positive</td><td align="left">[Event 170]: <italic>&#x02026;felt sorry for him cause her dad hit him with the car he hit me with&#x02026;</italic></td><td align="left">[Event 191]: &#x02026;<italic>know what to say say anything say whatever&#x02019;s natural the first thing that comes into your mind&#x02026;</italic></td><td align="left">[Event 23]: <italic>&#x02026;Dr Brown is dangerous he&#x02019;s a real nutcase hang around with him you&#x02019;ll end up in big trouble&#x02026;</italic></td><td align="left">[Event 221]: <italic>&#x02026;I wish I wasn&#x02019;t so scared there&#x02019;s nothing to be scared of all it takes is self-confidence&#x02026;</italic></td></tr><tr><td align="left">Negative</td><td align="left">[Event 281]: <italic>&#x02026;I&#x02019;ve calculated the precise distance taking into account the acceleration&#x02026;</italic></td><td align="left">[Event 151]: <italic>&#x02026;the sink that&#x02019;s when you got the idea for the flux capacitor which&#x02026;</italic></td><td align="left">[Event 81]: <italic>&#x02026;this tells you where you&#x02019;re going this where you are and this where&#x02026;</italic></td><td align="left">[Event 38]: <italic>&#x02026;replace that clock thirty years ago lightning struck that clock tower and the clock&#x02026;</italic></td></tr></tbody></table><table-wrap-foot><p>Event Data: representative movie event annotations are taken from <italic>Back to the Future</italic>. Event 282 is used as an example in Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>. For the Semantic Score and Social Score ratings, the primary coder ratings (R1) are shown as well as ratings from a secondary coder (R2) which are shown in parentheses. Event Notes are from the primary coder (R1). Event Number refers to the Minor Event Number. Word Data: smoothed windows with high positive or negative summed total factor scores from <italic>Back to the Future</italic>. The event number from which each smoothed window is taken is indicated in brackets. *using absolute value transformed scores.</p></table-wrap-foot></table-wrap></p></sec><sec id="Sec8"><title>Movie transcripts</title><p id="Par23">To provide data at the word level, the transcript annotations made available with the public dataset were used and included the words that were spoken as well as their onset and duration times. The initial paper describing the NNDb provides greater detail on the methods used for generating this information<sup><xref ref-type="bibr" rid="CR53">53</xref></sup>. The following word properties were obtained, where available, for each word in the transcript annotations using the English Lexicon Project database<sup><xref ref-type="bibr" rid="CR61">61</xref></sup>: number of letters, number of phonemes, number of phonological neighbours, number of orthographic neighbours, word frequency, concreteness<sup><xref ref-type="bibr" rid="CR62">62</xref></sup>, semantic neighbourhood density, semantic diversity<sup><xref ref-type="bibr" rid="CR63">63</xref></sup>, emotional valence (i.e., pleasantness), emotional arousal (i.e., intensity), and emotional dominance (i.e., control)<sup><xref ref-type="bibr" rid="CR64">64</xref></sup>, and part of speech.</p><p id="Par24">To obtain ratings of socialness for each word spoken in the movies, social word ratings were generated from a previous norming study conducted with 68 participants from the University of Alabama at Birmingham. Candidate words were derived from the Glasgow norms study, which includes normative psycholinguistic ratings for over 5000 individual words<sup><xref ref-type="bibr" rid="CR65">65</xref></sup>. This initial list was filtered to remove words with high concreteness (&#x0003e;&#x02009;5) and imageability (&#x0003e;&#x02009;5) ratings in order to identify possible social concepts (which tend to be abstract, although see<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>) as norming targets. Additional target words were added from a study reporting social desirability ratings on over 500 words<sup><xref ref-type="bibr" rid="CR66">66</xref></sup>. A randomly selected subset of 688 words were included in the norming study, and words with varied parts of speech were intentionally retained. During the norming study, participants were instructed that a word is social if it describes inter-personal behaviours, motivations, intentions, or characteristics and were asked to rate how social each presented word was on a scale from 1 (not social) to 5 (very social). Each participant rated half of the words resulting in 34 ratings for each of the 688 unique words. For words not present in this set of 688 words, social ratings were extrapolated by calculating their semantic similarity to each of the words in the normed set. Semantic vectors were generated for each of the normed words as well as for the unique transcript words using word2vec. The cosine similarity between each transcript word and every normed word was calculated resulting in 688 similarity values for each transcript word. The average social rating was then calculated by taking a weighted average, using the cosine similarity, of the social scores from the 10 closest semantic neighbours.</p><p id="Par25">Prior to subsequent analyses, the unique words from all movies were combined; high frequency and closed class words were excluded, as were any words missing more than 10 of the 12 critical word properties (excluding part of speech). To avoid listwise deletion, missing data for the remaining set of words were imputed. Imputation was performed using the multiple imputation by chained equations approach implemented with the <italic>mice</italic> package in R<sup><xref ref-type="bibr" rid="CR67">67</xref></sup>, and resulted in 5 complete datasets. To reduce covariance between predictors, the 12 word property measures for each unique word were entered into a principal component analysis (PCA) with varimax rotation for each imputed dataset. The four factor result corresponded to Word Length (e.g., number of letters and phonemes, number of phonological and orthographic neighbours), Semantic Flexibility (e.g., semantic diversity, semantic neighbourhood density), Emotional Strength (e.g., emotional valence, emotional dominance), and Social Impact (e.g., socialness, emotional arousal) and accounted for approximately 29%, 17%, 16%, and 11% of the variance respectively (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>). The Emotional Strength factor scores were transformed by taking the absolute value in order to capture emotional versus neutral content rather than positively versus negatively valenced content. The resulting factors were stable across the imputed datasets and resulted in the same factors as a PCA run on a subset of the data with no missing values. Due to random variation introduced when imputing data and given the robustness of the results, the factor scores derived from the imputed datasets were averaged.<fig id="Fig3"><label>Figure 3</label><caption><p>Factors derived from PCA on word property values. Positive (blue) and negative (red) loadings are shown for each factor. The strength of the loading is indicated by the length and colour saturation of each bar. Num., Number.</p></caption><graphic xlink:href="41598_2024_56897_Fig3_HTML" id="MO3"/></fig></p></sec><sec id="Sec9"><title>Aligning annotations and events</title><p id="Par26">The transcript annotations were temporally aligned with the events using the event boundary timestamps and the onset times of each word. Different versions of the movie files may have slightly varying playback speeds (&#x000b1;&#x02009;1.5%). To ensure correct alignment, the events were marked and aligned using the same movie files that were presented to participants in the NNDb study. This was done to identify which words were present within each event. To account for hemodynamic lag, a smoothed time course of critical word-level factor scores was generated by summing values within a 5&#x000a0;s window sliding every 1&#x000a0;s. A data-driven event segmentation approach with comparable movie data found that the median duration of neural states across voxels ranged from 5 to 18.5&#x000a0;s, and these durations were reliable across participants<sup><xref ref-type="bibr" rid="CR68">68</xref></sup>. A 5&#x000a0;s window is thus advantageous as it would capture the regions with shorter neural state durations (predominately sensory processing areas) and provide multiple measurements of the neural state of those regions with longer durations (e.g., default mode network). Importantly, the sliding windows were constrained to each event&#x02019;s boundaries so word property scores from different events were not averaged together (see Table <xref rid="Tab2" ref-type="table">2</xref> for examples). Events with excessively short duration (&#x0003c;&#x02009;3&#x000a0;s; 4% of events) were merged with the subsequent event by taking the average semantic and social score across the two events. After merging short events, the event duration ranged from 4 to 131&#x000a0;s (<italic>Mdn</italic>&#x02009;=&#x02009;16.00&#x000a0;s). If an event was shorter than the window size of 5s, the sum was calculated within this smaller window. If the final portion of an event was less than 1&#x000a0;s (i.e., 500&#x000a0;ms), a slightly shorter window was defined, and the sum was calculated within the smaller window. For each factor, the residuals were extracted from a model predicting the smoothed factor time course from the number of total words within each window. This controlled for the number of words in an event. If there are no words or no words that have ratings within a window or event, a value of 0 was assigned for each factor score.</p><p id="Par27">General lexical-semantic content was quantified by counting the number of content words (i.e., open class words). Open class words with missing word property data (n&#x02009;=&#x02009;883) which were excluded from the PCA (and subsequently do not have factor scores) were still counted as semantic content by manually tagging part of speech. These include character names, dates, or movie-specific words (i.e., fictional towns, technology, slang) that were not found in psycholinguistic databases. The same sliding window approach was used to generate a smoothed time course of lexical-semantic content. This predictor, as well as the factor scores, captures the momentary quantity of basic conceptual knowledge within each window, agnostic to the preceding events, which likely under approximates the amount of semantic processing occurring and is not sensitive to detecting pragmatic inference or non-linguistic semantic processing. This approach was adopted here because it most closely aligns with how prior studies examined semantic processing of isolated words or sentences, and one of the goals of the current study was to examine these measures in a naturalistic context. The event-level semantic predictor similarly indexes only the linguistic information in events, but is informed by prior context and may better capture broader context-sensitive semantic processing.</p></sec><sec id="Sec10"><title>Network definitions</title><p id="Par28">The networks of interest were defined using statistical maps derived from independent coordinate-based activation likelihood estimation (ALE) analyses of semantic control, semantic cognition, and social cognition and are shown in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>. These network maps were used to aid in the interpretation of the results of the whole brain analyses by categorizing results as falling within or outside of the pre-defined networks. The semantic and social networks in particular are extensive, and it is likely to be minimally informative to look at percent overlap or Dice similarity coefficient in isolation. For this reason, greater emphasis was placed on <italic>where</italic> overlap between the resulting networks and the pre-defined networks occurs. Overlap in core regions within each ALE-generated network, highlighted in the top portion of Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>, was interpreted as stronger evidence of network involvement. Defining networks prior to analysis ensured that results were interpreted in a pre-specified manner.</p><p id="Par29">The semantic control network was defined based on an ALE analyses with over 120 contrasts from 87 studies which identified a large cluster centred around the left inferior frontal gyrus as well as posterior middle temporal gyrus, dorsomedial prefrontal cortex, and a smaller portion of the right inferior frontal gyrus<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>. This network has significant convergence with another ALE-generated semantic control network<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>. The same study also identified a general semantic cognition network derived from over 400 contrasts from 257 studies. In order to isolate the automatic semantic network and partial out the role of control in semantic retrieval, the semantic control ALE result was subtracted from the general semantic cognition ALE result and small clusters of voxels (&#x0003c;&#x02009;400 contiguous voxels) were removed. This resulted in a map which included left anterior temporal lobe, left medial and posterior temporal cortex, left inferior parietal lobule, insula, precentral gyrus, and right middle and superior temporal gyrus.</p><p id="Par30">The social cognition network was defined by examining the convergence of ALE generated network maps for four primary domains of social cognition from a previous study<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>. These domains included theory of mind (derived from 136 experiments), trait inference (derived from 40 experiments), empathy for pain or affective states (derived from 163 experiments), and moral reasoning (derived from 68 experiments). The ALE results for each domain were overlaid and regions which were identified in at least one of the four domains were retained. This resulted in a social network which included bilateral inferior frontal gyrus, superior frontal gyrus, medial prefrontal cortex, precuneus, bilateral inferior parietal lobule, supplementary motor area, bilateral anterior and superior middle temporal gyrus, bilateral anterior temporal poles, and precentral gyrus.</p></sec></sec><sec id="Sec11"><title>Statistical analyses</title><p id="Par31">The pre-processed MRI data were used for all analyses. The pre-processing steps are documented in the initial paper describing the NNDb dataset<sup><xref ref-type="bibr" rid="CR53">53</xref></sup>. The functional runs were concatenated into a single timeseries file after detrending and censoring TRs with excessive motion. There are no missing data for the current set of 86 participants that comprise the NNDb. The only data that are missing are word property values, but the approach to dealing with those data are outlined in detail above. The NNDb data includes quality assurance metrics indexing movement related artefacts and signal to noise. Given that the metrics indicate that the data are high quality (mean temporal signal to noise ratio [tSNR]&#x02009;&#x0003e;&#x02009;60) and the scan duration was sufficiently long for detecting activation at that tSNR level (&#x0003e;&#x02009;1&#x000a0;h)<sup><xref ref-type="bibr" rid="CR69">69</xref></sup>, none of the participants were excluded from analysis.</p><sec id="Sec12"><title>Research question 1</title><p id="Par32">For the word-level analyses, the Semantic Flexibility factor was used in the semantic control analysis because semantic diversity<sup><xref ref-type="bibr" rid="CR63">63</xref></sup> and semantic neighbourhood density<sup><xref ref-type="bibr" rid="CR70">70</xref>,<xref ref-type="bibr" rid="CR71">71</xref></sup> reflect increased selection demands which requires additional cognitive control. The Social Impact factor was used as a proxy of social content, and the number of content words was used as a coarse measure of semantic content. These measures were each separately used as parametric modulators in a regression model predicting the time series from the full movie. The analyses were conducted at the whole-brain level, and results were compared to the predefined networks of interest. The subject-level activation maps for each content type for all movies were used as inputs for a second-level group analysis using linear mixed-effects modelling with a fixed effect of content type (i.e., social, semantic, or semantically flexible) and random intercepts of subject and movie implemented using 3dLMEr in AFNI<sup><xref ref-type="bibr" rid="CR72">72</xref></sup>. The resulting statistical map were corrected using a cluster-forming threshold of <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.01 and an FWE-corrected threshold of <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.05.</p><p id="Par33">For the event-level analyses, the semantic and social event ratings for each movie were used in a first-level general linear model for each subject as parametric modulators predicting the time series from the full movie. To account for the varied event durations, a duration modulated model was used in which the onset and duration of each event were included in the regression model. Either semantic or social content were included as a nuisance regressor. In addition, the ratings were randomly scrambled to generate a null distribution which served as a comparison condition with no semantic or social content. The analyses were conducted at the whole-brain level. The subject-level activation maps across all movies were used as inputs for a second-level group analysis using linear mixed-effects modelling with a fixed effect of content type (i.e., social or semantic or null) and random intercepts of subject and movie implemented using 3dLMEr in AFNI<sup><xref ref-type="bibr" rid="CR72">72</xref></sup>. The resulting statistical map was corrected using corrected using a cluster-forming threshold of <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.01 and an FWE-corrected threshold of <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.05.</p></sec><sec id="Sec13"><title>Research question 2</title><p id="Par34">To investigate the extent to which the social system shares neural resources with the semantic and semantic control systems within individual subjects, the subject-level statistical maps generated to test research question 1 were directly compared. Specifically, the number of overlapping voxels was calculated between (1) the statistical maps for processing semantic and social content (word-level and event-level results processed independently) and (2) the statistical maps for processing semantically flexible words and social words. The presence of voxels that respond to <italic>both</italic> semantic and social concepts or events was taken as evidence of shared neural resources between the systems. The strength of the evidence was determined by the number of overlapping voxels quantified using Dice coefficient, and fewer than 10 overlapping voxels was considered functionally the same as 0 voxels. Overlap within the semantic hub in ATL will provide support for the <italic>graded semantic hub hypothesis</italic> which suggests that both systems rely on the same domain-general hub. Non-overlapping, proximal clusters of voxels that differentially respond to semantic (or semantic control) and social content in the absence of any overlapping voxels will provide weaker evidence of shared processing between the systems, and instead will be interpreted as evidence for graded functioning within a semantic or social network region. To determine the extent to which stable areas of overlap between the cognitive systems exist across participants, a second-level random effects analysis was run using the overlap images from individual participants. The group-level overlap maps were compared to the predefined ALE-derived network definitions to determine the extent to which the core regions within each network (shown in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>) were involved in each process and to isolate any regions which fall outside the expected networks.</p></sec></sec></sec><sec id="Sec16"><title>Results</title><sec id="Sec17"><title>Research Question 1</title><p id="Par37">The Words and Events results are shown in the following sections with two cluster correction thresholds applied: (1) the pre-registered threshold (cluster-forming threshold of <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.01 with an FWE-corrected threshold of <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.05) and (2) a more conservative threshold (cluster-forming threshold of <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.01 with an FWE-corrected threshold of <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.01). The latter threshold was applied in an effort to highlight areas with the strongest response to the stimulus alongside the values that fall below that threshold<sup><xref ref-type="bibr" rid="CR73">73</xref></sup>. The results figures indicate which voxels survived each cluster threshold and tables report clusters that survived the pre-registered threshold. Results figures were generated using MRIcroGL<sup><xref ref-type="bibr" rid="CR74">74</xref></sup> and the <italic>ggplot2</italic><sup><xref ref-type="bibr" rid="CR75">75</xref></sup>, <italic>ggdist</italic><sup><xref ref-type="bibr" rid="CR76">76</xref></sup>, and <italic>gghalves</italic><sup><xref ref-type="bibr" rid="CR77">77</xref></sup> packages in R<sup><xref ref-type="bibr" rid="CR78">78</xref></sup>.</p><sec id="Sec18"><title>Words analyses</title><p id="Par38">The word-level predictor variables were generated as described in the pre-registered Methods section with one minor deviation. The pre-registration indicated that when a window or event contained no words or no words that had ratings, a value of 0 would be assigned for each factor score. However, because scores were mean-centred, a score of 0 corresponds to words with an average factor score, not the absence of a score as initially intended. In addition, given the visual nature of movie stimuli there are many events that do not contain words. As a result, many windows containing few, if any, words would have been modelled as containing words with average factor scores. This was not justifiable on scientific grounds, so windows with no words or no words with ratings were removed from analysis instead. This error was realized and corrected prior to running the words analyses. The words analysis results are shown in Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref> and the coordinate information is provided in Table <xref rid="Tab3" ref-type="table">3</xref>.<fig id="Fig4"><label>Figure 4</label><caption><p>Words Analyses Results. Thresholded Z-score statistical maps showing the number of content words (top panel), Social Impact (middle panel), and Semantic Flexibility (bottom panel) results. All clusters survived the pre-registered cluster threshold. The clusters that survived an additional, more conservative threshold are indicated in yellow (lower) to red (higher). The clusters that did not survive the more conservative threshold are shown in purple (lower) to green (higher).</p></caption><graphic xlink:href="41598_2024_56897_Fig4_HTML" id="MO4"/></fig><table-wrap id="Tab3"><label>Table 3</label><caption><p>Words results coordinate table.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Variable</th><th align="left" rowspan="2">Cluster size</th><th align="left" rowspan="2">Hem</th><th align="left" rowspan="2">Brain region peak voxel</th><th align="left" rowspan="2">Brain region highest overlap [%]</th><th align="left" colspan="3">MNI coordinates</th></tr><tr><th align="left">X</th><th align="left">Y</th><th align="left">Z</th></tr></thead><tbody><tr><td align="left" rowspan="6">Content words</td><td align="left">2558</td><td align="left">L</td><td align="left">Superior Temporal Gyrus</td><td align="left">Middle Temporal Gyrus [30%]</td><td align="left">&#x02212;&#x02009;53</td><td align="left">&#x02212;&#x02009;20</td><td align="left">7</td></tr><tr><td align="left">1689</td><td align="left">R</td><td align="left">Heschl&#x02019;s Gyrus</td><td align="left">Superior Temporal Gyrus [42%]</td><td align="left">50</td><td align="left">&#x02212;&#x02009;14</td><td align="left">7</td></tr><tr><td align="left">418</td><td align="left">R</td><td align="left">Cerebellum (VII)</td><td align="left">Cerebellum (Crus 2) [32%]</td><td align="left">17</td><td align="left">&#x02212;&#x02009;83</td><td align="left">&#x02212;&#x02009;57</td></tr><tr><td align="left">175</td><td align="left">L</td><td align="left">Supplementary Motor Area</td><td align="left">Superior Frontal Gyrus [41%]</td><td align="left">&#x02212;&#x02009;5</td><td align="left">4</td><td align="left">77</td></tr><tr><td align="left">149</td><td align="left">L</td><td align="left">Postcentral Gyrus</td><td align="left">Precentral Gyrus [29%]</td><td align="left">&#x02212;&#x02009;56</td><td align="left">&#x02212;&#x02009;10</td><td align="left">57</td></tr><tr><td align="left">117</td><td align="left">L</td><td align="left">Inferior Frontal Gyrus (Triangularis)</td><td align="left">Inferior Frontal Gyrus (Triangularis) [76%]</td><td align="left">&#x02212;&#x02009;56</td><td align="left">16</td><td align="left">29</td></tr><tr><td align="left" rowspan="14">Semantic Flexibility</td><td align="left">2423</td><td align="left">R</td><td align="left">Inferior Parietal Lobule</td><td align="left">Postcentral Gyrus [17%]</td><td align="left">53</td><td align="left">&#x02212;&#x02009;57</td><td align="left">51</td></tr><tr><td align="left">802</td><td align="left">L</td><td align="left">Superior Parietal Lobule</td><td align="left">Postcentral Gyrus [27%]</td><td align="left">&#x02212;&#x02009;17</td><td align="left">&#x02212;&#x02009;64</td><td align="left">73</td></tr><tr><td align="left">471</td><td align="left">R</td><td align="left">Putamen</td><td align="left">Putamen [32%]</td><td align="left">32</td><td align="left">4</td><td align="left">5</td></tr><tr><td align="left">375</td><td align="left">R</td><td align="left">Middle Frontal Gyrus</td><td align="left">Middle Frontal Gyrus [58%]</td><td align="left">41</td><td align="left">51</td><td align="left">8</td></tr><tr><td align="left">331</td><td align="left">L</td><td align="left">Insula Lobe</td><td align="left">Insula Lobe [35%]</td><td align="left">&#x02212;&#x02009;32</td><td align="left">1</td><td align="left">5</td></tr><tr><td align="left">284</td><td align="left">R</td><td align="left">Middle Orbital Gyrus</td><td align="left">Middle Orbital Gyrus [19%]</td><td align="left">8</td><td align="left">39</td><td align="left">&#x02212;&#x02009;7</td></tr><tr><td align="left">259</td><td align="left">L</td><td align="left">Cerebellum (VI)</td><td align="left">Fusiform Gyrus [39%]</td><td align="left">&#x02212;&#x02009;26</td><td align="left">&#x02212;&#x02009;43</td><td align="left">&#x02212;&#x02009;33</td></tr><tr><td align="left">220</td><td align="left">L</td><td align="left">Inferior Occipital Gyrus</td><td align="left">Middle Occipital Gyrus [84%]</td><td align="left">&#x02212;&#x02009;26</td><td align="left">&#x02212;&#x02009;91</td><td align="left">&#x02212;&#x02009;3</td></tr><tr><td align="left">169</td><td align="left">L</td><td align="left">Precentral Gyrus</td><td align="left">Precentral Gyrus [55%]</td><td align="left">&#x02212;&#x02009;29</td><td align="left">&#x02212;&#x02009;17</td><td align="left">66</td></tr><tr><td align="left">168</td><td align="left">R</td><td align="left">Middle Occipital Gyrus</td><td align="left">Middle Occipital Gyrus [53%]</td><td align="left">29</td><td align="left">&#x02212;&#x02009;95</td><td align="left">10</td></tr><tr><td align="left">116</td><td align="left">R</td><td align="left">Superior Frontal Gyrus</td><td align="left">Superior Frontal Gyrus [83%]</td><td align="left">26</td><td align="left">&#x02212;&#x02009;11</td><td align="left">76</td></tr><tr><td align="left">110</td><td align="left">L</td><td align="left">Angular Gyrus</td><td align="left">Angular Gyrus [35%]</td><td align="left">&#x02212;&#x02009;53</td><td align="left">&#x02212;&#x02009;66</td><td align="left">44</td></tr><tr><td align="left">99</td><td align="left">L</td><td align="left">Inferior Temporal Gyrus</td><td align="left">Inferior Temporal Gyrus [67%]</td><td align="left">&#x02212;&#x02009;56</td><td align="left">&#x02212;&#x02009;12</td><td align="left">&#x02212;&#x02009;38</td></tr><tr><td align="left">99</td><td align="left">R</td><td align="left">Middle Temporal Gyrus</td><td align="left">Middle Temporal Gyrus [91%]</td><td align="left">65</td><td align="left">&#x02212;&#x02009;29</td><td align="left">&#x02212;&#x02009;14</td></tr><tr><td align="left" rowspan="14">Social Impact</td><td align="left">576</td><td align="left">L</td><td align="left">Precuneus</td><td align="left">Precuneus [30%]</td><td align="left">&#x02212;&#x02009;5</td><td align="left">&#x02212;&#x02009;68</td><td align="left">31</td></tr><tr><td align="left">463</td><td align="left">L</td><td align="left">Inferior Frontal Gyrus (Orbitalis)</td><td align="left">Inferior Frontal Gyrus (Orbitalis) [24%]</td><td align="left">&#x02212;&#x02009;32</td><td align="left">18</td><td align="left">&#x02212;&#x02009;19</td></tr><tr><td align="left">383</td><td align="left">R</td><td align="left">Inferior Frontal Gyrus (Orbitalis)</td><td align="left">Inferior Frontal Gyrus (Orbitalis) [25%]</td><td align="left">38</td><td align="left">24</td><td align="left">&#x02212;&#x02009;18</td></tr><tr><td align="left">367</td><td align="left">L</td><td align="left">Postcentral Gyrus</td><td align="left">Postcentral Gyrus [43%]</td><td align="left">&#x02212;&#x02009;71</td><td align="left">&#x02212;&#x02009;15</td><td align="left">24</td></tr><tr><td align="left">341</td><td align="left">L</td><td align="left">Supplementary Motor Area</td><td align="left">Supplementary Motor Area [44%]</td><td align="left">&#x02212;&#x02009;8</td><td align="left">20</td><td align="left">74</td></tr><tr><td align="left">335</td><td align="left">R</td><td align="left">Superior Medial Gyrus</td><td align="left">Superior Medial Gyrus [43%]</td><td align="left">5</td><td align="left">62</td><td align="left">31</td></tr><tr><td align="left">300</td><td align="left">R</td><td align="left">Postcentral Gyrus</td><td align="left">Supramarginal Gyrus [40%]</td><td align="left">62</td><td align="left">&#x02212;&#x02009;16</td><td align="left">40</td></tr><tr><td align="left">252</td><td align="left">R</td><td align="left">Superior Temporal Gyrus</td><td align="left">Superior Temporal Gyrus [43%]</td><td align="left">44</td><td align="left">&#x02212;&#x02009;29</td><td align="left">&#x02212;&#x02009;7</td></tr><tr><td align="left">222</td><td align="left">L</td><td align="left">Lingual Gyrus</td><td align="left">Inferior Occipital Gyrus [32%]</td><td align="left">&#x02212;&#x02009;17</td><td align="left">&#x02212;&#x02009;103</td><td align="left">&#x02212;&#x02009;15</td></tr><tr><td align="left">162</td><td align="left">R</td><td align="left">Superior Parietal Lobule</td><td align="left">Superior Parietal Lobule [58%]</td><td align="left">35</td><td align="left">&#x02212;&#x02009;57</td><td align="left">57</td></tr><tr><td align="left">159</td><td align="left">R</td><td align="left">Angular Gyrus</td><td align="left">Angular Gyrus [64%]</td><td align="left">50</td><td align="left">&#x02212;&#x02009;59</td><td align="left">28</td></tr><tr><td align="left">138</td><td align="left">R</td><td align="left">Cerebellum (Crus 1)</td><td align="left">Inferior Temporal Gyrus [38%]</td><td align="left">47</td><td align="left">&#x02212;&#x02009;62</td><td align="left">&#x02212;&#x02009;27</td></tr><tr><td align="left">115</td><td align="left">R</td><td align="left">Middle Cingulate Cortex</td><td align="left">Middle Cingulate Cortex [32%]</td><td align="left">&#x02212;&#x02009;2</td><td align="left">&#x02212;&#x02009;24</td><td align="left">26</td></tr><tr><td align="left">111</td><td align="left">R</td><td align="left">Precentral Gyrus</td><td align="left">Precentral Gyrus [79%]</td><td align="left">50</td><td align="left">&#x02212;&#x02009;7</td><td align="left">57</td></tr></tbody></table><table-wrap-foot><p>This table was generated based on the pre-registered cluster threshold. Cluster size is determined by the number of 2&#x000a0;mm<sup>3</sup> voxels. MNI coordinates correspond to the voxel with peak activation within each cluster. Voxels were defined as neighbours based on faces touching (NN&#x02009;=&#x02009;1). Atlas labels are based on the Eickhoff-Zilles macro labels from the N27 (MNI space) atlas. Hem, Hemisphere; L, Left; R, Right.</p></table-wrap-foot></table-wrap></p><sec id="Sec19"><title>Number of content words</title><p id="Par39">It was expected that clusters of voxels showing increased activation in response to greater semantic word-level content (i.e., number of content words) would fall within the semantic brain network (Hypothesis 1.1a). In line with this prediction, the Dice similarity coefficient was higher for this result and the semantic network (0.25) than either of the other word-level content results (0.01&#x02013;0.06; see red diamonds in Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>). An increase in the number of content words was positively associated with activation in broad bilateral clusters extending from anterior to posterior superior temporal gyri with peak voxels in auditory cortices. The left hemisphere cluster was more extensive, including the superior and lateral portions of the temporal pole (the lateral portion is sometimes labelled &#x0201c;ventrolateral ATL&#x0201d;<sup><xref ref-type="bibr" rid="CR24">24</xref>,<xref ref-type="bibr" rid="CR27">27</xref></sup>, though the present results did not extend to the ventral portion of ATL), middle temporal, supramarginal, and angular gyri. Frontal activation was observed in smaller clusters in left inferior frontal, middle frontal, and superior frontal gyri and supplementary motor area and left precentral gyri. Cerebellar activation, predominately in the right posterior lobe of the cerebellum, also positively co-varied with the number of content words.</p></sec><sec id="Sec20"><title>Social Impact</title><p id="Par40">It was expected that clusters of voxels showing increased activation in response to greater social word-level content (i.e., Social Impact scores) would fall within the social brain network (Hypothesis 1.1b). In line with this prediction, the Dice similarity coefficient was higher for this result and the social network (0.20) than either of the other word-level content results (0.01&#x02013;0.05; see dark blue diamonds in Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>). An increase in social and emotionally arousing words (indicated by positive Social Impact scores) was associated with activation in precuneus, right inferior parietal lobule (i.e., temporo-parietal junction [TPJ]), and frontal activation in bilateral inferior frontal gyri, superior medial gyrus, supplementary motor area, right precentral and middle frontal gyri, and left postcentral gyri. Activation in bilateral anterior middle (i.e., ventrolateral ATL) and superior (i.e., dorsolateral ATL) portions of the temporal pole also positively co-varied with Social Impact, as did clusters in right inferior temporal gyrus and fusiform and left inferior occipital gyrus.</p></sec><sec id="Sec21"><title>Semantic Flexibility</title><p id="Par41">It was expected that clusters of voxels showing increased activation in response to semantically flexible word-level content would fall within the semantic control brain network (Hypothesis 1.1c). Counter to this prediction, the Dice similarity coefficient was lower for this result and the semantic control network (0.00) than either of the other word-level content results (0.06&#x02013;0.07; see orange diamonds in Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>), although overlap was minimal across all word analysis results. Activation in left IFG and pMTG did not positively co-vary with Semantic Flexibility. Instead an increase in more frequent, semantically diverse words (indicated by positive Semantic Flexibility scores) was associated with activation in a large cluster with a peak voxel in right postcentral gyrus that included portions of middle cingulate cortex, inferior and superior parietal lobule, and precuneus. Activation in a smaller, analogous left hemisphere region positively co-varied with Semantic Flexibility as did clusters in anterior cingulate, right middle and superior frontal gyri, left precentral gyrus, bilateral insula, left inferior temporal and fusiform gyri, left angular gyrus, and bilateral middle occipital gyrus. These results suggest that processing Semantic Flexibile words in a movie context does not elicit semantic control processes as expected. This undermines its use in isolating the semantic control network within individual participants, an analysis planned to address Research Question 2.</p></sec></sec><sec id="Sec22"><title>Events analyses</title><p id="Par42">Correlations between the event properties, including semantic and social ratings, are shown in Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>. Predictably, event duration and the number of words within an event were moderately to highly correlated (<italic>r</italic>&#x02009;=&#x02009;0.55&#x02013;0.86). Semantic ratings were positively correlated with number of words (<italic>r</italic>&#x02009;=&#x02009;0.40&#x02013;0.76), as were social ratings to a lesser extent (<italic>r</italic>&#x02009;=&#x02009;0.32&#x02013;0.56). This is unsurprising given that highly semantic events were defined as having new or informative verbal content and, to some extent, social moments in movies often rely on, or are supplemented by, verbal input. Although positively correlated, it was not the case that event ratings were simply proxies for duration or word quantity. Further, the semantic and social ratings did not capture the same event properties, as evidenced by the low to moderate correlations between the ratings (<italic>r</italic>&#x02009;=&#x02009;0.01&#x02013;0.47).<fig id="Fig5"><label>Figure 5</label><caption><p>Event Property Correlations. Bivariate correlations between the number of words in an event, event duration, semantic rating, and social rating.</p></caption><graphic xlink:href="41598_2024_56897_Fig5_HTML" id="MO6"/></fig></p><p id="Par43">The events analysis results are shown in Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref> and the coordinate information is provided in Table <xref rid="Tab4" ref-type="table">4</xref>. The following sections provide an overview of the results for the pre-registered events analyses.<fig id="Fig6"><label>Figure 6</label><caption><p>Events Analyses Results. Thresholded Z-score statistical maps showing the Semantic Events (top panel) and Social Events (bottom panel) results. All clusters survived the pre-registered cluster threshold. The clusters the survived an additional, more conservative threshold are indicated in yellow (lower) to red (higher). The clusters that did not survive the more conservative threshold are shown in purple (lower) to green (higher).</p></caption><graphic xlink:href="41598_2024_56897_Fig6_HTML" id="MO7"/></fig><table-wrap id="Tab4"><label>Table 4</label><caption><p>Events results coordinate table.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Variable</th><th align="left" rowspan="2">Cluster size</th><th align="left" rowspan="2">Hem</th><th align="left" rowspan="2">Brain region peak voxel</th><th align="left" rowspan="2">Brain region highest overlap [%]</th><th align="left" colspan="3">MNI coordinates</th></tr><tr><th align="left">X</th><th align="left">Y</th><th align="left">Z</th></tr></thead><tbody><tr><td align="left" rowspan="7">Semantic events</td><td align="left">3690</td><td align="left">L</td><td align="left">Middle Temporal Gyrus</td><td align="left">Middle Temporal Gyrus [25%]</td><td align="left">&#x02212;&#x02009;56</td><td align="left">&#x02212;&#x02009;33</td><td align="left">&#x02212;&#x02009;0</td></tr><tr><td align="left">1916</td><td align="left">R</td><td align="left">Superior Temporal Gyrus</td><td align="left">Superior Temporal Gyrus [34%]</td><td align="left">65</td><td align="left">&#x02212;&#x02009;1</td><td align="left">&#x02212;&#x02009;2</td></tr><tr><td align="left">807</td><td align="left">R</td><td align="left">Precuneus</td><td align="left">Putamen [8%]</td><td align="left">23</td><td align="left">&#x02212;&#x02009;46</td><td align="left">16</td></tr><tr><td align="left">745</td><td align="left">R</td><td align="left">Cerebellum (Crus 2)</td><td align="left">Cerebellum (VIII) [26%]</td><td align="left">20</td><td align="left">&#x02212;&#x02009;86</td><td align="left">&#x02212;&#x02009;50</td></tr><tr><td align="left">354</td><td align="left">L</td><td align="left">Calcarine Gyrus</td><td align="left">Cuneus [35%]</td><td align="left">&#x02212;&#x02009;2</td><td align="left">&#x02212;&#x02009;83</td><td align="left">14</td></tr><tr><td align="left">232</td><td align="left">L</td><td align="left">Supplementary Motor Area</td><td align="left">Supplementary Motor Area [87%]</td><td align="left">&#x02212;&#x02009;5</td><td align="left">1</td><td align="left">74</td></tr><tr><td align="left">172</td><td align="left">L</td><td align="left">Lingual Gyrus</td><td align="left">Inferior Occipital Gyrus [31%]</td><td align="left">&#x02212;&#x02009;26</td><td align="left">&#x02212;&#x02009;100</td><td align="left">&#x02212;&#x02009;18</td></tr><tr><td align="left" rowspan="8">Social events</td><td align="left">2545</td><td align="left">R</td><td align="left">Inferior Occipital Gyrus</td><td align="left">Superior Temporal Gyrus [25%]</td><td align="left">50</td><td align="left">&#x02212;&#x02009;79</td><td align="left">&#x02212;&#x02009;6</td></tr><tr><td align="left">1576</td><td align="left">L</td><td align="left">Middle Occipital Gyrus</td><td align="left">Middle Temporal Gyrus [31%]</td><td align="left">&#x02212;&#x02009;53</td><td align="left">&#x02212;&#x02009;79</td><td align="left">7</td></tr><tr><td align="left">1035</td><td align="left">R</td><td align="left">Superior Parietal Lobule</td><td align="left">Superior Parietal Lobule [21%]</td><td align="left">35</td><td align="left">&#x02212;&#x02009;57</td><td align="left">64</td></tr><tr><td align="left">601</td><td align="left">L</td><td align="left">Superior Occipital Gyrus</td><td align="left">Calcarine Gyrus [19%]</td><td align="left">&#x02212;&#x02009;5</td><td align="left">&#x02212;&#x02009;101</td><td align="left">6</td></tr><tr><td align="left">243</td><td align="left">R</td><td align="left">Middle Frontal Gyrus</td><td align="left">Precentral Gyrus [65%]</td><td align="left">50</td><td align="left">2</td><td align="left">54</td></tr><tr><td align="left">218</td><td align="left">L</td><td align="left">Cerebellum (VIIb)</td><td align="left">Cerebellum (VII) [30%]</td><td align="left">&#x02212;&#x02009;14</td><td align="left">&#x02212;&#x02009;76</td><td align="left">&#x02212;&#x02009;60</td></tr><tr><td align="left">178</td><td align="left">L</td><td align="left">Superior Frontal Gyrus</td><td align="left">Precentral Gyrus [53%]</td><td align="left">&#x02212;&#x02009;20</td><td align="left">&#x02212;&#x02009;2</td><td align="left">77</td></tr><tr><td align="left">159</td><td align="left">R</td><td align="left">Supplementary Motor Area</td><td align="left">Supplementary Motor Area [59%]</td><td align="left">8</td><td align="left">10</td><td align="left">77</td></tr></tbody></table><table-wrap-foot><p>This table was generated based on the pre-registered cluster threshold. Cluster size is determined by the number of 2&#x000a0;mm<sup>3</sup> voxels. MNI coordinates correspond to the voxel with peak activation within each cluster. Voxels were defined as neighbours based on faces touching (NN&#x02009;=&#x02009;1). Atlas labels are based on the Eickhoff-Zilles macro labels from the N27 (MNI space) atlas. Hem, Hemisphere; L, Left; R, Right.</p></table-wrap-foot></table-wrap></p><sec id="Sec23"><title>Semantic events</title><p id="Par44">It was expected that clusters of voxels showing increased activation in response to semantic events (plot-progressing, informative verbal or written scenes) would fall within the semantic brain network (Hypothesis 1.2a). In line with this prediction and the number of content words results, the Dice similarity coefficient was higher for the semantic events result and the semantic network (0.26; see light red diamonds in Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>) than the social events results (0.12; see light blue diamonds in Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>). Similar to the content words results, there was increased activation in large bilateral clusters centred around auditory cortices and extending from posterior to anterior superior temporal gyrus as the semantic content in events increased. The left hemisphere cluster included the middle portion of the temporal pole (i.e., lateral ATL) and extended posteriorly into inferior parietal lobule. There was also a large left inferior frontal gyrus cluster and a cluster in left supplemental motor area. Additional clusters of activation were observed in left cuneus and calcarine gyrus and inferior occipital gyrus and the right posterior lobe of the cerebellum. Subcortical activation positively co-varied with semantic event content in left putamen, thalamus, caudate nucleus, and a portion of the hippocampus.<fig id="Fig7"><label>Figure 7</label><caption><p>Network Overlap. The distributions of the subject-level overlap with the ALE-derived networks, measured with Dice similarity coefficient, are shown for each result: content words (dark red), semantic events (light red), social words (dark blue), social events (light blue), and semantically flexible words (orange). Diamonds indicate the Dice similarity coefficient between each network and the group-level results presented in Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref> (words analyses) and Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref> (events analyses).</p></caption><graphic xlink:href="41598_2024_56897_Fig7_HTML" id="MO5"/></fig></p></sec><sec id="Sec24"><title>Social events</title><p id="Par45">It was expected that clusters of voxels showing increased activation in response to social events (scenes depicting on or off-screen interactions between/among characters) would fall within the social brain network (Hypothesis 1.2b). In line with this prediction, as the social content in events increased, there was increased activation in bilateral inferior parietal lobule (i.e., TPJ), right ATL extending posteriorly along superior temporal gyrus, left fusiform, precentral and middle frontal gyri, and supplementary motor area. Smaller clusters of activation in left calcarine and superior occipital gyri and a small cluster in the posterior lobe of the left cerebellum also positively co-varied with social event content. There were also prominent effects in bilateral lateral occipitotemporal cortex, which is typically associated with motion processing (V5/MT) and object recognition (LOC) rather than social cognition. Unlike the Social Impact words analysis results, social event content did not engage the left anterior temporal lobe. Further, the Dice similarity coefficient between this result and the social network was lower (0.06) than the Social Impact words result (0.20) and the semantic events result (0.10).</p></sec><sec id="Sec25"><title>Scrambled events</title><p id="Par46">Scrambled semantic and social ratings were used as a negative control condition for comparison with the critical predictors. There were no surviving clusters of activation positively associated with the scrambled ratings at either cluster correction threshold.</p></sec></sec><sec id="Sec26"><title>Correspondence with ALE-derived networks</title><p id="Par47">Additional examination of the group-level maps was undertaken to further characterize the correspondence between the results and the ALE-derived networks (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>). The similarity between the ALE-derived networks and the group-level (RQ1) and subject-level (RQ2) results was quantified using Dice similarity coefficient (Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>). With the exception of Semantic Flexibility, the semantic and social predictors engaged the semantic and social networks, respectively, as anticipated, although the social events result had substantially less overlap with the social cognition network than the social words result did. The subject-level Dice similarity coefficients are presented alongside the group-level values.</p><p id="Par48">A conjunction map showing the overlap of the group-level results within the core semantic and social network regions is presented in Fig.&#x000a0;<xref rid="Fig8" ref-type="fig">8</xref>. There was overlap between the semantic and social words results and between the social words and social events results within the left and right portions of the supplementary motor area, respectively. Within IPL, both word and event-level social content engaged the same portion of right angular gyrus. Within the ATLs, the semantic and social words results overlapped in an anterior MTG portion of left ATL, and there was overlap across all results in a dorsolateral portion of right ATL. This pattern was further investigated within and across participants for Research Question 2.<fig id="Fig8"><label>Figure 8</label><caption><p>Conjunction of Group-Level Results. The conjunction of the semantic words and events (green), social words (red), and social events (blue) results. Overlap across all results is indicated with white shading. The black circles denote the following core semantic and social network regions, defined in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>: bilateral ATL, bilateral IPL, and SMA. Overlap outside these core areas has been desaturated.</p></caption><graphic xlink:href="41598_2024_56897_Fig8_HTML" id="MO8"/></fig></p></sec></sec><sec id="Sec27"><title>Research Question 2</title><sec id="Sec28"><title>Within-subject cognitive system overlap</title><p id="Par49">The subject-level statistical maps for each analysis were thresholded using a comparable approach for thresholding the group-level analysis with a cluster-forming threshold of <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.01 and an FWE-corrected threshold of <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.05. Cluster forming thresholds were determined by computing blur estimates for each subject from the residuals generated during the first-level analysis and used as inputs for 3dClustSim in AFNI resulting in subject-specific cluster tables. These thresholded subject-level maps were compared with the ALE-derived networks (Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>) and with each other (Fig.&#x000a0;<xref rid="Fig9" ref-type="fig">9</xref>).<fig id="Fig9"><label>Figure 9</label><caption><p>Subject overlap analysis results. (<bold>A</bold>): The within-subject overlap, measured with Dice Coefficient and Number of voxels, is shown for the Social Impact&#x02009;&#x02229;&#x02009;Semantic Flexibility results (red), Social Impact&#x02009;&#x02229;&#x02009;Content Words results (orange) and Social Events&#x02009;&#x02229;&#x02009;Semantic Events results (blue). Example subjects with high, moderate, and minimal overlap are highlighted for each overlap condition with subject labels to the left of points coloured according to the overlap condition (<bold>B</bold>): The normalized overlap maps for the example subjects highlighted in (<bold>A</bold>). (<bold>C</bold>): The cross-subject cognitive system overlap. The figures correspond to the Social Impact&#x02009;&#x02229;&#x02009;Semantic Flexibility (red), Social Impact&#x02009;&#x02229;&#x02009;Content Words (orange) and Social Events&#x02009;&#x02229;&#x02009;Semantic Events (blue) cross-subject overlap.</p></caption><graphic xlink:href="41598_2024_56897_Fig9_HTML" id="MO9"/></fig></p><p id="Par50">There was considerable variability in the within-subject cognitive system overlap. This was evident by the range of Dice similarity coefficient values when comparing the subject-level results to the ALE-derived networks (Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>) and when comparing the overlap between results within subjects (Fig.&#x000a0;<xref rid="Fig9" ref-type="fig">9</xref>). There was modest overlap for Social Impact&#x02009;&#x02229;&#x02009;Semantic Flexibility: median Dice coefficient&#x02009;=&#x02009;0.05 (range: 0&#x02013;0.30), median overlapping voxels&#x02009;=&#x02009;146 (range: 0&#x02013;2481). Somewhat more overlap was observed for Social Impact&#x02009;&#x02229;&#x02009;Content Words: median Dice coefficient&#x02009;=&#x02009;0.08 (range: 0&#x02013;0.32), median overlapping voxels&#x02009;=&#x02009;417 (range: 0&#x02013;3879). Overlap for Social Events&#x02009;&#x02229;&#x02009;Semantic Events was particularly variable: median Dice coefficient&#x02009;=&#x02009;0.07 (range: 0&#x02013;0.54), median overlapping voxels&#x02009;=&#x02009;191 (range: 0&#x02013;6829). In each case, the distributions were strongly skewed such that many participants showed very little overlap and a small subset of participants showed moderate cognitive system overlap.</p></sec><sec id="Sec29"><title>Cross-subject cognitive system overlap</title><p id="Par51">In order to examine whether stable areas of overlap existed across participants, the subject-level overlap maps were used as inputs to a second-level random effects analysis. The pre-registered analysis plan was insufficiently clear on how this analysis would be carried out, resulting in ambiguity in how overlap would be quantified. As a result, we calculated overlap in two ways: (1) using binary overlap masks (e.g., areas within the thresholded subject-level statistical maps that overlapped between conditions) and (2) using statistical overlap masks (described in greater detail below). The former approach is not suitable for the pre-registered analysis strategy because a logistic modelling framework would better predict a binary (overlap or no-overlap) dependent variable. Instead of identifying consistent areas of overlap, an analysis using binary overlap masks produces an aggregate map of <italic>any</italic> overlap observed at the subject level, which is not the stated aim of Research Question 2. To avoid this issue, we opted to use method 2 (statistical overlap masks) for the analyses reported here. These masks were generated by first normalizing the thresholded subject-level statistical maps for each result by dividing by the max <italic>t</italic>-value, resulting in a range of values between 0 and 1. The normalized maps for each condition were then multiplied together (e.g., semantic events&#x02009;&#x000d7;&#x02009;social events), resulting in an overlap map where larger values indicated a greater response in <italic>both</italic> conditions. Finally, these normalized maps were used as inputs to the second-level random effects analysis with random effects of subject and movie as described in the pre-registration. Importantly, this analysis identifies whether there are voxels with values that are significantly greater than 0 associated with a given overlap type (e.g., overlap between semantic and social words). This is an anti-conservative test given the lack of negative values and the relatively large number of voxels where no overlap was observed (i.e., the value was 0) in the normalized overlap maps.</p><p id="Par52">The cross-subject overlap coordinate information is characterized in Table <xref rid="Tab5" ref-type="table">5</xref> and overlap maps showing the most consistent loci of overlap between the cognitive systems are presented in Fig.&#x000a0;<xref rid="Fig9" ref-type="fig">9</xref>C. The location of overlap varied considerably across participants, and in some cases (e.g., Fig.&#x000a0;<xref rid="Fig9" ref-type="fig">9</xref>B<bold>:</bold> Social Impact&#x02009;&#x02229;&#x02009;Semantic Flexibility) isolated entirely different regions within participants. The most consistent location of overlap between the Semantic Flexibility and Social Impact words results was in right parietal lobule, right lateral occipitotemporal cortex, and portions of the occipital cortex. Overlap between the number of content words and Social Impact result was most consistently localized to left inferior frontal gyrus and bilaterally anterior to the Sylvian fissure through the pre and postcentral gyri and rolandic operculum into posterior superior temporal gyrus and supramarginal gyrus. As illustrated in Fig.&#x000a0;<xref rid="Fig9" ref-type="fig">9</xref>B, there was within-subject overlap in left ATL in some participants (sub-49, sub-10), but this was not a consistently identified location of overlap across participants. Overlap between the social and semantic events results consistently occurred along bilateral superior temporal gyri, extending from the superior portion of ATL posteriorly into supramarginal gyri. This may be driven by the amount of verbal input (i.e., number of words) which was correlated with the event ratings.<table-wrap id="Tab5"><label>Table 5</label><caption><p>Cross-subject overlap coordinate table.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Variable</th><th align="left" rowspan="2">Cluster size</th><th align="left" rowspan="2">Hem</th><th align="left" rowspan="2">Brain region peak voxel</th><th align="left" rowspan="2">Brain region highest overlap [%]</th><th align="left" colspan="3">MNI coordinates</th></tr><tr><th align="left">X</th><th align="left">Y</th><th align="left">Z</th></tr></thead><tbody><tr><td align="left">Social Impact&#x02009;&#x02229;&#x02009;Semantic Flexibility</td><td align="left">2105</td><td align="left">R</td><td align="left">Superior Parietal Lobule</td><td align="left">Superior Parietal Lobule [15%]</td><td align="left">20</td><td align="left">&#x02212;&#x02009;73</td><td align="left">66</td></tr><tr><td align="left" rowspan="2">Social Impact&#x02009;&#x02229;&#x02009;Content Words</td><td align="left">1181</td><td align="left">L</td><td align="left">Superior Temporal Gyrus</td><td align="left">Postcentral Gyrus [22%]</td><td align="left">&#x02212;&#x02009;50</td><td align="left">&#x02212;&#x02009;40</td><td align="left">22</td></tr><tr><td align="left">831</td><td align="left">R</td><td align="left">Rolandic Operculum</td><td align="left">Rolandic Operculum [27%]</td><td align="left">59</td><td align="left">&#x02212;&#x02009;12</td><td align="left">14</td></tr><tr><td align="left" rowspan="2">Social Events&#x02009;&#x02229;&#x02009;Semantic Events</td><td align="left">2032</td><td align="left">L</td><td align="left">Middle Temporal Gyrus</td><td align="left">Middle Temporal Gyrus [38%]</td><td align="left">&#x02212;&#x02009;62</td><td align="left">&#x02212;&#x02009;51</td><td align="left">5</td></tr><tr><td align="left">1661</td><td align="left">R</td><td align="left">Middle Temporal Gyrus</td><td align="left">Superior Temporal Gyrus [48%]</td><td align="left">50</td><td align="left">&#x02212;&#x02009;33</td><td align="left">&#x02212;&#x02009;0</td></tr></tbody></table><table-wrap-foot><p>Cluster size is determined by the number of 2&#x000a0;mm<sup>3</sup> voxels. MNI coordinates correspond to the voxel with highest statistical value within each cluster. Voxels were defined as neighbours based on faces touching (NN&#x02009;=&#x02009;1). Atlas labels are based on the Eickhoff-Zilles macro labels from the N27 (MNI space) atlas. Hem, Hemisphere; L, Left; R, Right.</p></table-wrap-foot></table-wrap></p></sec></sec></sec><sec id="Sec30"><title>Discussion</title><sec id="Sec31"><title>Overview</title><p id="Par53">The present study investigated the neural basis of semantic and social processing during movie-viewing, which provides a rich estimation of the multimodal environment in which language use and social interactions take place<sup><xref ref-type="bibr" rid="CR79">79</xref></sup>. Current neurobiological models of the semantic and social cognition systems were derived from experimentally controlled stimuli presented in random order without larger-scale context. Naturalistic stimuli are less constrained, tending to evoke highly stable patterns of brain activation in regions different to those identified in minimalist experiments, allowing for different insights into fundamental aspects of human cognition<sup><xref ref-type="bibr" rid="CR80">80</xref></sup>. In order to comprehensively capture semantic and social content within the movies, word and event-level predictors were generated and used for analyses. The goals of the study were twofold. The first aim was to test the degree to which semantic and social content was processed within each network. The second, complementary aim was to test the degree to which the semantic and social systems evidence shared processing in the same regions or domain-general hub, given the conceptual and neural overlap between these systems.</p><p id="Par54">In line with our predictions (hypotheses 1.1a and 1.2a), word and event-level semantic content isolated a highly convergent, largely fronto-temporo-parietal network, despite measuring semantic content in different ways. Frequent, semantically diverse language (estimated by positive Semantic Flexibility scores) did not co-vary with activation in semantic control regions, counter to our expectations (hypothesis 1.1c). An increase in both word and event-level social content engaged portions of the social network, but the word-level social content engaged a network of regions more similar to the social network highlighted in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref> than the event-level social content did. That is, the evidence is consistent with our social word predictions (hypothesis 1.1b) and partially consistent with our social event predictions (hypothesis 1.2b). There were no positive associations with the scrambled ratings, increasing confidence that we report meaningful associations with the semantic and social event ratings. There were stable, cross-subject loci of overlap between semantic and social processing, although these loci differed between the words and events analyses, providing partial evidence of shared processing (hypothesis 2.1a). Specifically, the cross-subject word-level semantic and social overlap was localized to regions which predominately fell outside the semantic network, providing no support for the hypothesis that semantic regions would be engaged. The event-level semantic and social overlap, however, engaged much of the semantic network, providing support for the hypothesis. There was no evidence of consistent overlap between the Semantic Flexibility and Social Impact words results within the semantic control network, counter to our predictions (hypothesis 2.1b). The subject-level results were highly variable, which precluded a formal test of the non-overlap predictions at the subject-level (hypotheses 2.2a and 2.2b), but a conjunction of the group-level results indicated that there were both overlapping as well as non-overlapping but proximal areas within core semantic and social brain network regions that are engaged by semantic and social word and event-level content embedded in movies. This was most prominent in bilateral ATL: predominately verbal semantic and social content engaged a shared portion of left ATL in anterior MTG, whereas the superior portion of right ATL was engaged by word and event-level semantic and social content. In addition, there was evidence of graded functioning within ATL such that social words minimally engaged the superior, or dorsolateral, portion of ATL which was robustly engaged by semantic content. All analyses and interpretations given to results were pre-registered prior to conducting the study. The following sections provide an overview of each content type, indicating, where relevant, when an interpretation that was not pre-registered is provided.</p></sec><sec id="Sec32"><title>Semantic content</title><p id="Par55">Activation in semantic and semantic control network regions positively co-varied with an increase in both word and event-level semantic content in complex movie stimuli. This network included the core regions highlighted in the meta-analytic map shown in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>: bilateral ATL, bilateral middle temporal gyrus, left supplementary motor area, left IPL, semantic control regions in left inferior frontal gyrus and posterior middle temporal gyrus, and minimally included activation outside these networks. We made no specific predictions about the recruitment of the semantic control system in response to content words or highly semantic events because we had no corresponding measure of how cognitively demanding the words or events were (with the exception of Semantic Flexibility, discussed below). However, engagement of the semantic control system is routinely found in studies of semantic cognition and&#x02014;unless they are explicitly removed&#x02014;these control regions are found in meta-analyses of semantic cognition<sup><xref ref-type="bibr" rid="CR39">39</xref>,<xref ref-type="bibr" rid="CR81">81</xref></sup>. For the present study, semantic control regions were subtracted from the semantic system in order to distinguish automatic semantic processing regions from those regions which are involved in more effortful or controlled semantic processing. This distinction may be useful for some experimental contexts, but the present results suggest that semantic control processes are an integral part of how the semantic system operates in naturalistic comprehension. The Semantic Flexibility results (discussed below) further suggest that semantic control engagement in naturalistic contexts may be quite different from the manipulations used in minimalist experiments. That is, in naturalistic contexts, semantic control may be particularly important for comprehending semantically rich moments in the narrative (i.e., a large number of content words or highly semantic events) rather than resolving the kinds of lexical or syntactic ambiguities that are studied in minimalist experiments (because those are resolved by the context).</p><p id="Par56">The fronto-temporo-parietal network observed here appears to have considerable overlap with the proposed &#x02018;universal language network&#x02019;. This network has been identified across diverse languages and is thought to include language selective brain regions<sup><xref ref-type="bibr" rid="CR82">82</xref></sup>, although some argue that this network is the by-product of averaging over varied language representations, thus obscuring the neurobiology of the distributed language system<sup><xref ref-type="bibr" rid="CR83">83</xref></sup>. Apparent convergence with the topography of this network is notable because the &#x02018;universal language network&#x02019; was derived with a different naturalistic paradigm: story excerpts compared with acoustically degraded audio (or unfamiliar language) to identify the network of regions sensitive to language. The present study used continuous measures of high versus low semantic content to isolate regions that are particularly sensitive to an increase in semantic content. This focus on semantic content may explain why we observed more activation in the lateral portion of the ventrolateral ATL, which was only present in some of the language networks (including English) reported by Malik-Moraleda et al.</p><p id="Par57">Correspondence with the &#x02018;universal language network&#x02019; suggests that there is a robust language comprehension network that is engaged across naturalistic contexts, including narratives and movies. Indeed, this network is well positioned to serve this purpose with structural connections between orbitofrontal cortex and temporal pole (uncinate fasciculus), inferior frontal cortex to posterior superior temporal cortex (arcuate fasciculus) and inferior parietal lobule (extreme capsule)<sup><xref ref-type="bibr" rid="CR84">84</xref></sup>. Although not part of the semantic or language network, activation in right posterior cerebellar lobe may be similarly driven by the structural connections projecting into perisylvian language areas, suggesting a possible role in general language processing<sup><xref ref-type="bibr" rid="CR85">85</xref></sup>. A similar network topography has been reported in other studies that used naturalistic stimuli, predominately narratives and natural language<sup><xref ref-type="bibr" rid="CR86">86</xref>,<xref ref-type="bibr" rid="CR87">87</xref></sup>. Individual studies using minimalist stimuli tend to report highly focal results, however, aggregation of study-level data via meta-analysis reveals a network with similar topography to that observed here<sup><xref ref-type="bibr" rid="CR39">39</xref>,<xref ref-type="bibr" rid="CR81">81</xref></sup>, although naturalistic stimuli tend to evoke a more bilateral network.</p><p id="Par58">The semantic content in complex movie stimuli was quantified using a word-level and an event-level definition, and, although both measures were used as proxies of semantic processing, it is nonetheless striking that they isolated a highly convergent fronto-temporo-parietal network given the conceptual differences between the measures. The word-level measure (content word quantity) was agnostic to the context of the event or larger narrative, but that information directly informed the event-level measure (subjective ratings). The latter was sensitive to both the local context, in that ratings were given to events segmented based on the progression of the narrative, and the global context, in that ratings were given consecutively allowing for prior information to impact perception of the event. It is thus notable that the word and event semantic content predictors engage a highly similar network given the impact of context on conceptual representations<sup><xref ref-type="bibr" rid="CR88">88</xref></sup>. Conceptually and practically, both measures were strongly impacted by the total number of words, which was evidenced by the moderate-to-high correlations between number of words and semantic event ratings across movies. In naturalistic communication, especially in scripted narratives, semantic content is inherently related to verbal input (though they are not identical: semantic ratings also captured narrative moments with non-spoken information or moments in which highly important information is conveyed using few words). Statistically removing that association would create minimally interpretable event ratings; a different approach is needed for studying naturalistic semantic processing independent of verbal processing. For the present study, a more useful approach is to consider the word-level and event-level results together, noting their similarities and differences.</p><p id="Par59">There were minor differences in the topography of the word-level and event-level semantic content networks. The semantic event network engaged a larger cluster in left inferior frontal gyrus and supplementary motor area, as well precuneus, middle cingulate cortex and surrounding subcortical structures (putamen, thalamus, caudate nucleus), and left inferior and middle occipital gyrus. This may reflect differences in word versus event processing. For instance, the occipital activation observed for highly semantic events is consistent with the fact that linguistic content could be presented via spoken or written language. In addition, differences in temporal receptive windows drive regional recruitment in response to word, sentence, or paragraph presentation<sup><xref ref-type="bibr" rid="CR52">52</xref></sup>. The latter two contexts engage a large left inferior frontal region as well as posterior cingulate and precuneus, which we similarly observe in the network that co-varies with highly semantic event content. Processing movie events, which incorporate context in much the same way as sentences or paragraphs, could then drive engagement of regions which allow preceding context to have a greater influence on the integration of information. In addition, or alternatively, event content ratings may have been influenced by other types of information (e.g., emotional information), so the resulting network of regions may reflect sensitivity to both semantic and correlated information.</p><p id="Par60">In a recent study using similar word-level predictors but with an audiobook stimulus, engagement of the same lateral portion of ATL was not observed in response to an increase in the quantity of content words<sup><xref ref-type="bibr" rid="CR89">89</xref></sup>. Instead, the temporal pole, including ventrolateral ATL, was active when there was a decrease in content words. This was thought to be driven by the fact that the speech rate, and therefore approximate quantity of words, tends to be fairly consistent throughout an audiobook. The ventrolateral hub then is still engaged in semantic processing and may use the relative decrease in new, plot-progressing information to integrate the current information with the prior knowledge of the narrative. This is not the case for movies, which can have periods that are primarily (or entirely) visual, when minimal verbal information is presented. Both studies used a parametric modulation approach, but in the audiobook context, the &#x02018;low semantic&#x02019; condition still contained words (predominately closed class words) whereas the same condition in the present study likely contained no words at all (scenes with only visual information). In measuring regional covariation in response to high relative to low semantic content, it appears that ATL activation does not selectively co-vary with an increase in content words in the audiobook case where the speech rate is consistent even for the low semantic periods. Conversely, in the movie case where &#x02018;low semantic&#x02019; means limited to no verbal input, we see ATL activation co-vary with an increase in semantic content. This may indicate important differences in how unimodal (e.g., audiobook) and multimodal (e.g., movie) narratives engage the same cognitive system, which needs to be considered when defining research questions or adapting paradigms. Anticipating this difference between audiobooks and movies, for instance, the present study used summed factor scores instead of mean factor scores to better capture the total amount of each content type. Using means instead of sums appears to better approximate the relative amount of these properties when the speech rate is consistent, as in the audiobook case.</p><p id="Par61">We speculate that ventrolateral ATL, in particular the lateral portion of this hub, is engaged by internal, or endogenous, semantic processing required for updating and processing the ongoing narrative, in contrast to the exogenous process of comprehending the stimulus. With a longer temporal receptive window for accumulating and integrating information<sup><xref ref-type="bibr" rid="CR51">51</xref>,<xref ref-type="bibr" rid="CR52">52</xref></sup> and with functional connections to the broader default mode network (DMN)<sup><xref ref-type="bibr" rid="CR90">90</xref>,<xref ref-type="bibr" rid="CR91">91</xref></sup>, this region is well-suited to serving this role. The DMN, which is active in the presence and absence of external input, facilitates the construction of an continuous coherent internal narrative by relying on episodic and semantic memory<sup><xref ref-type="bibr" rid="CR92">92</xref></sup>. This is observed across naturalistic comprehension contexts. Intact story comprehension elicits robust, cross-subject stimulus induced changes in connectivity between the posterior cingulate cortex, a core DMN region, and anterior MTG (overlapping with the ventral portion of the hub)<sup><xref ref-type="bibr" rid="CR93">93</xref></sup>, and activation in the DMN covaries with high-level perception of narrative features during movie-viewing<sup><xref ref-type="bibr" rid="CR94">94</xref>,<xref ref-type="bibr" rid="CR95">95</xref></sup>. We suggest that functional connections between the default mode network and ventrolateral ATL drive narrative integration and support endogenous semantic processing of the narrative content. The endogenous processing demands placed on this hub are poorly approximated by the relative amount of semantic input. Instead, the dorsolateral ATL appears to be particularly sensitive to the quantity and informativeness of the input as evidenced by greater activation in this region in both word and event results of the present study and in the &#x02018;universal language network'.</p></sec><sec id="Sec33"><title>Semantic Flexibility</title><p id="Par62">Counter to our pre-registered hypothesis, there was no evidence of increased engagement of semantic control network regions as semantically flexible word-level content increased. This suggests that processing words with positive Semantic Flexibility scores, which are associated with more frequent, less concrete, and more semantically diverse language, does not require more semantic control. We expected words with high semantic diversity to place additional demands on the control system due to the need to select from one of several possible meanings that best fit the context<sup><xref ref-type="bibr" rid="CR63">63</xref></sup>. This prediction was based on prior studies, which tended to use highly decontextualized stimuli in which meaning selection did not benefit from the context provided in a narrative. During naturalistic language comprehension, highly semantically diverse language appears to be disambiguated by the preceding context without requiring engagement of the semantic control system. These results suggest important deviations from single-word and sentence level investigations of semantic diversity and ambiguity resolution more generally. Similar to the present study, an increase in bilateral parietal and occipital activation was observed in a previous study as positive Semantic Flexibility scores increased<sup><xref ref-type="bibr" rid="CR89">89</xref></sup>.</p></sec><sec id="Sec34"><title>Social content</title><p id="Par63">Recent evidence suggests that social knowledge is subsumed within the semantic system and, like other types of semantic information, is processed in the transmodal ventrolateral ATL hub<sup><xref ref-type="bibr" rid="CR7">7</xref>,<xref ref-type="bibr" rid="CR30">30</xref></sup>. In this view, all kinds of social stimuli are processed within the semantic system, ranging from social concepts, which have consistently been shown to recruit portions of left ATL<sup><xref ref-type="bibr" rid="CR14">14</xref>,<xref ref-type="bibr" rid="CR20">20</xref>,<xref ref-type="bibr" rid="CR26">26</xref></sup>, to more abstract social processes such as mentalizing, which have not been as thoroughly investigated (but see<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>). The present study enabled a direct test of this claim using naturalistic movie stimuli, which better approximate real-world socio-cognitive processing, across two social contexts: (1) social words, estimated using Social Impact factor scores, and (2) social events, using subjective event-level ratings. We hypothesized that the social network shown in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref> would be engaged by both content types, in particular within the core regions highlighted in the figure. The results provide partial support for this claim.</p><p id="Par64">An increase in highly social and emotionally arousing words engaged much of the social cognition network: dorsomedial prefrontal cortex, bilateral IFG, superior frontal gyrus, supramarginal gyrus, precuneus, bilateral ATL, and left IPL, with minimal engagement of bilateral MTG. These results broadly align with the pre-registered predictions, and are similar to the regions identified in separate meta-analyses of social compared to non-social concepts<sup><xref ref-type="bibr" rid="CR96">96</xref>,<xref ref-type="bibr" rid="CR97">97</xref></sup>. Unexpectedly, however, activation in left IPL did not co-vary with an increase in Social Impact. In addition to the core social cognition regions, an increase in word-level social content co-varied with activation in precentral and postcentral gyri, middle cingulate cortex, and left inferior occipital gyrus. Activation in ventrolateral ATL co-varied with an increase in social and emotional language. This provides critical support for the claim that social processing is supported by the semantic system<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>, but it is important to consider the nature of the contrast. The predictor in this analysis was the socialness of the words, with the quantity of semantic content statistically controlled by using residual scores, so the analysis should not identify regions that are responsive to general semantic or language comprehension. That is, if activation of the ventrolateral ATL hub is primarily driven by the amount of semantic content, then it should <italic>not</italic> co-vary with Social Impact after controlling for semantic content.</p><p id="Par65">If ventrolateral ATL activation during periods of high Social Impact cannot be attributed to an increase in general semantic content, what is driving this effect? Engagement of this hub for processing social relative to non-social word-level content may suggest an increased sensitivity to social information, at least in naturalistic contexts. Alternatively, and building upon our claim about ventrolateral ATL, word-level social processing may drive greater engagement of ventrolateral ATL due to a greater need for endogenous semantic processing. This may be a consequence of the general role of the DMN in social processing<sup><xref ref-type="bibr" rid="CR98">98</xref></sup> or may be due to the nature of movies in which social information is particularly salient and important to the narrative.</p><p id="Par66">Although the word-level analysis used orthogonalized factor scores, a &#x02018;pure&#x02019; social factor did not emerge from the PCA. Instead the Social Impact factor was driven by socialness and emotional arousal, making it hard to disentangle the social versus emotional effects. In complex, naturalistic stimuli, however, social and emotional content are likely to be at least moderately correlated. Highly social moments are often emotional, and, inversely, emotional moments frequently play out in social interactions between characters, given the likely oversampling of social content in compelling storytelling. Further, conceptual representations are not static<sup><xref ref-type="bibr" rid="CR88">88</xref></sup>, but the word-level predictor treated the words as independently sampled from the narrative, a limitation that the event-level predictor directly addressed.</p><p id="Par67">In accounting for the impact of context on conceptual representations, the event-level analysis may have better captured the kind of socio-cognitive processing typically isolated in studies of social cognition. Although social event ratings were moderately correlated with word quantity, the social event predictor also captured non-linguistic content, as intended. Highly interpersonal moments in a movie may contain few, if any, words and are separate from the linguistic content present in the event. Conceptually, the word and event predictors could capture different properties of the underlying stimulus, although prior work looking at the correspondence between word-level and passage level emotion ratings suggests otherwise<sup><xref ref-type="bibr" rid="CR99">99</xref></sup>.</p><p id="Par68">Highly social events engaged a network that only partially overlapped with the word-level social content network and included different core social cognition regions. Activation along bilateral superior temporal gyrus extending posteriorly into bilateral lateral occipitotemporal cortex and left angular gyrus co-varied with the social content in events. Processing dynamic social events appears to engage motion processing areas in middle temporal visual motion area (MT), face and object recognition areas in the lateral occipital cortex, and superior temporal sulcus, which may aid in face and body perception<sup><xref ref-type="bibr" rid="CR100">100</xref>&#x02013;<xref ref-type="bibr" rid="CR103">103</xref></sup>. The ATL hub was not recruited during social event processing, providing counterevidence against the claim that general social processing recruits the domain-general semantic hub<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>. However, it may be that the ventrolateral hub was equally engaged by highly and weakly social events, and, unlike the word-level results, did not evidence increased sensitivity to social events.</p><p id="Par69">The overlap between the social and semantic control system has been interpreted to suggest that socio-cognitive processing places increased demands on the semantic control system<sup><xref ref-type="bibr" rid="CR20">20</xref>,<xref ref-type="bibr" rid="CR31">31</xref></sup>. Support for this claim in the present study is mixed. Words that were more social and emotionally arousing (i.e., higher Social Impact) engaged the semantic control network in bilateral inferior frontal gyri, but this was not observed for highly social events. An important consideration in weighing the evidence is the degree to which the word and event-level predictors may have had different control demands that are hard to quantify in naturalistic stimuli. Alternatively, social event-level information may be more readily understood than word-level information. This inference is not without precedent. Many social phenomena studied out of context have been shown to increase general control demands. Processing embedded mental states (e.g., Marty <italic>understands</italic> that Doc <italic>believes</italic> that reading the letter would change the future), for instance, is effortful in a sentence or passage context<sup><xref ref-type="bibr" rid="CR104">104</xref>,<xref ref-type="bibr" rid="CR105">105</xref></sup>, but is readily understood, and even enjoyable, in the narrative context<sup><xref ref-type="bibr" rid="CR106">106</xref></sup>. Humans process information well when presented in narrative format<sup><xref ref-type="bibr" rid="CR107">107</xref></sup>, which movies provide. Socio-cognitive processing may engage the semantic control system in experimental paradigms that present de-contextualised stimuli in a random order, but not in a rich narrative context or during naturalistic social processing. Taken together, we do not find strong support for the claim that socio-cognitive processing increases semantic control demands. Prior studies isolating specific social processes that found support for this claim are challenged by the ease with which humans engage in these processes in naturalistic contexts.</p></sec><sec id="Sec35"><title>Shared processing</title><p id="Par70">One of our study aims was to investigate engagement of the semantic and semantic control networks in processing social knowledge. At the group-level, there was evidence of shared processing within the ATLs such that (1) activation in the same anterior MTG portion of left ATL was associated with verbal semantic and social content (i.e., social words) and (2) activation in the anterior STG portion of right ATL was associated with word and event-level semantic and social content. This pattern is consistent with prior research reporting an ATL asymmetry with a left hemisphere bias for verbal content and right hemisphere bias for non-verbal content<sup><xref ref-type="bibr" rid="CR108">108</xref>,<xref ref-type="bibr" rid="CR109">109</xref></sup>. We further examined the consistency of this overlap in preregistered subject-level analyses.</p><p id="Par71">The distribution of subject-level overlap, quantified using number of voxels and Dice Similarity Coefficient (Fig.&#x000a0;<xref rid="Fig9" ref-type="fig">9</xref>), suggested that cross-system overlap exists, but its location was highly variable across subjects and the median values tended to be modest. As shown in Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>, even the overlap between the subject-level results and the ALE-derived networks was inconsistent: some participants had moderate overlap but many participants had minimal to no overlap. Further, the subject-level median Dice similarity coefficient values were almost always well below the group-level values, suggesting that idiosyncratic sources of noise were captured at the subject-level that were averaged out at the group-level. It is possible that the variability is a product of statistical thresholding such that sub-threshold voxels are removed resulting in the impression of no overlap. When the full subject-level statistical maps are used in a group-level analysis, these sub-threshold voxels are accounted for in the analysis rather than removed altogether, providing a better estimate of the networks engaged in processing each content type. In addition, subject-level analyses benefit from robust localizers that consistently identify the same brain network or region across individuals. The predictors used in the current study were not validated localizers known to elicit the targeted cognitive processes. Moreover, the predictors were embedded in a naturalistic paradigm, itself a significant source of noise. Given this, the subject-level variability is not surprising. The use of alternative subject-level analysis approaches, such as using well-validated functional localizers to define functional regions of interest that reliably respond to a given content type<sup><xref ref-type="bibr" rid="CR110">110</xref></sup>, might provide better estimates of within-subject overlap between semantic and social processing. Although we did not find strong support for the preregistered hypothesis regarding shared processing within semantic and social brain regions at the subject-level, we suggest that this is driven, in part, by the predictors used and encourage future studies to make use of robust localizers to investigate this claim.</p><p id="Par72">Despite the within-subject variability, there were reliable cross-subject loci of overlap that indicate shared processing between the semantic and social systems. Interestingly, however, the consistent areas of overlap differed for the word and event predictors. As discussed in the sections above, the semantic word and event predictors both captured a similar fronto-temporo-parietal network, but the social word and event predictors captured different networks. The subject-level overlap between the word and event predictors thus resulted in different loci of overlap with the word-level predictors localized to bilateral precentral gyri and left inferior frontal gyrus and the event-level predictors localized to bilateral superior temporal and supramarginal gyri. These results provide a useful complement to the group-level results because they highlight the voxels that consistently respond strongly to <italic>both</italic> content types within subjects. The results suggest that, at the subject-level, social and semantic content both engage regions within the semantic network but word-level and event-level social content engages different regions within the semantic network.</p><p id="Par73">The consistent loci identified for the Semantic Flexibility and Social Impact words results were largely posterior regions in right inferior parietal lobule and occipitotemporal cortex. Importantly, contrary to our prediction, an increase in Semantic Flexibility did not engage the semantic control network, so the overlap between these variables is difficult to interpret because the predictor did not isolate the semantic control network within subjects. The group-level Social Impact results suggest at least partial engagement of the semantic control network in left IFG, but a stronger narrative-level manipulation of semantic control demands is required to investigate the subject-level overlap between the social and semantic control systems.</p></sec></sec><sec id="Sec36"><title>Conclusions</title><p id="Par74">Naturalistic neuroimaging data provide an exciting and rich basis for studying the neural basis of human cognition. However, this richness also makes them particularly vulnerable to adjusting analysis strategies and constructing post hoc explanations, which is common in whole-brain neuroimaging. The analyses and hypotheses described in the present study were based on well-defined theories of semantic and social cognition (and how they might interact) and pre-registered to maximize transparency about the analysis plan (and any deviations) and distinguish a priori hypotheses from post hoc speculations based on the results.</p><p id="Par75">The results suggest that, during naturalistic movie viewing, increases in semantic content are associated with increased activation in the semantic and semantic control networks, displaying a fronto-temporo-parietal topography highly similar to the universal language network<sup><xref ref-type="bibr" rid="CR82">82</xref></sup>. There is evidence of a hub architecture, consistent with the graded hub hypothesis<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>, but the ATL subregions appear to serve different functions during naturalistic comprehension. Left ATL was predominately engaged by verbal semantic and social content within the movies, whereas right dorsolateral ATL was engaged by both verbal and non-verbal semantic and social content. We suggest that the dorsolateral ATL is sensitive to the quantity and informativeness of the input, as evidenced by robust activation during language comprehension, whereas the lateral portion of ventrolateral ATL hub may be also important for endogenous semantic processing&#x02014;updating and processing the ongoing narrative&#x02014;leveraging this region&#x02019;s functional connections with the default mode network. Word, but not event-level, social content engaged the ventrolateral ATL, perhaps because social content is particularly important for movie narratives and consistent with the role of this region in endogenous semantic processing. Social events engaged a network topographically more similar to the social cognition network, with activation in bilateral TPJ. Although portions of the semantic network (ATL, right IPL) were engaged by social content and these regions overlapped at the group level, the subject-level overlap analyses suggest limited cross-subject consistency. These results are a step toward integrating theories of word-level semantic cognition with theories of narrative comprehension and understanding the relationships between social and semantic cognition.</p></sec><sec sec-type="supplementary-material"><sec id="Sec37"><title>Supplementary Information</title><p>
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="41598_2024_56897_MOESM1_ESM.docx"><caption><p>Supplementary Figures.</p></caption></media></supplementary-material></p></sec></sec></body><back><fn-group><fn><p><bold>Publisher's note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><sec><title>Supplementary Information</title><p>The online version contains supplementary material available at 10.1038/s41598-024-56897-3.</p></sec><ack><title>Acknowledgements</title><p>P.H. was supported by a grant from the Biotechnology and Biological Sciences Research Council (BB/T004444/1). The authors thank Hilary Richardson for useful recommendations on an earlier draft of this manuscript.&#x000a0;For the purpose of open access, the author has applied a Creative Commons Attribution (CC BY) licence to any Author Accepted Manuscript version arising from this submission.</p></ack><notes notes-type="author-contribution"><title>Author contributions</title><p>Conceptualization, M.T. and D.M.; Methodology, M.T., D.M., and P.H.; Software, M.T.; Formal Analysis, M.T.; Data Curation, M.T.; Visualization, M.T.; Writing &#x02013; Original Draft, M.T.; Writing &#x02013; Review &#x00026; Editing, M.T., D.M., and P.H.; Supervision, D.M.</p></notes><notes notes-type="data-availability"><title>Data availability</title><p>The raw and preprocessed data are publicly available on OpenNeuro (<ext-link ext-link-type="uri" xlink:href="https://openneuro.org/datasets/ds002837/versions/2.0.0">https://openneuro.org/datasets/ds002837/versions/2.0.0</ext-link>). All additional data and materials generated as part of this project are shared publicly on OSF: <ext-link ext-link-type="uri" xlink:href="https://osf.io/dur8a/">https://osf.io/dur8a/</ext-link>. This includes the final processed neuroimaging data and the movie annotations indicating the onset and duration of the events within each movie and the corresponding semantic and social content scores for each event.</p></notes><notes notes-type="data-availability"><title>Code availability</title><p>All analysis code associated with this project is shared on OSF: <ext-link ext-link-type="uri" xlink:href="https://osf.io/dur8a/">https://osf.io/dur8a/</ext-link>.</p></notes><notes notes-type="COI-statement"><title>Competing interests</title><p>The authors declare no competing interests.</p></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adolphs</surname><given-names>R</given-names></name></person-group><article-title>The social brain: Neural basis of social knowledge</article-title><source>Annu. Rev. Psychol.</source><year>2009</year><volume>60</volume><fpage>693</fpage><lpage>716</lpage><pub-id pub-id-type="doi">10.1146/annurev.psych.60.110707.163514</pub-id><?supplied-pmid 18771388?><pub-id pub-id-type="pmid">18771388</pub-id>
</element-citation></ref><ref id="CR2"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beaudoin</surname><given-names>C</given-names></name><name><surname>Beauchamp</surname><given-names>MH</given-names></name></person-group><article-title>Social cognition</article-title><source>Handb. Clin. Neurol.</source><year>2020</year><volume>173</volume><fpage>255</fpage><lpage>264</lpage><pub-id pub-id-type="doi">10.1016/B978-0-444-64150-2.00022-8</pub-id><?supplied-pmid 32958179?><pub-id pub-id-type="pmid">32958179</pub-id>
</element-citation></ref><ref id="CR3"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adolphs</surname><given-names>R</given-names></name></person-group><article-title>The neurobiology of social cognition</article-title><source>Curr. Opin. Neurobiol.</source><year>2001</year><volume>11</volume><fpage>231</fpage><lpage>239</lpage><pub-id pub-id-type="doi">10.1016/S0959-4388(00)00202-6</pub-id><?supplied-pmid 11301245?><pub-id pub-id-type="pmid">11301245</pub-id>
</element-citation></ref><ref id="CR4"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spunt</surname><given-names>RP</given-names></name><name><surname>Adolphs</surname><given-names>R</given-names></name></person-group><article-title>A new look at domain specificity: Insights from social neuroscience</article-title><source>Nat. Rev. Neurosci.</source><year>2017</year><volume>18</volume><fpage>559</fpage><lpage>567</lpage><pub-id pub-id-type="doi">10.1038/nrn.2017.76</pub-id><?supplied-pmid 28680161?><pub-id pub-id-type="pmid">28680161</pub-id>
</element-citation></ref><ref id="CR5"><label>5.</label><mixed-citation publication-type="other">Ramsey, R. &#x00026; Ward, R. Putting the nonsocial into social neuroscience: A role for domain-general priority maps during social interactions. 10.1177/1745691620904972<bold>15</bold>, 1076&#x02013;1094 (2020).</mixed-citation></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="other">Rice, G. E., Hoffman, P., Binney, R. J. &#x00026; Lambon Ralph, M. A. (2018) Concrete versus abstract forms of social concept: An fMRI comparison of knowledge about people versus social terms. <italic>Philos. Trans. R. Soc. B Biol. Sci.</italic>10.1098/rstb.2017.0136.</mixed-citation></ref><ref id="CR7"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Binney</surname><given-names>RJ</given-names></name><name><surname>Ramsey</surname><given-names>R</given-names></name></person-group><article-title>Social Semantics: The role of conceptual knowledge and cognitive control in a neurobiological model of the social brain</article-title><source>Neurosci. Biobehav. Rev.</source><year>2020</year><pub-id pub-id-type="doi">10.1016/j.neubiorev.2020.01.030</pub-id><?supplied-pmid 31982602?><pub-id pub-id-type="pmid">31982602</pub-id>
</element-citation></ref><ref id="CR8"><label>8.</label><mixed-citation publication-type="other">McRae, K. &#x00026; Jones, M. Semantic memory. in <italic>The Oxford Handbook of Cognitive Psychology</italic> 1&#x02013;26 (Oxford University Press, 2013). 10.1093/oxfordhb/9780195376746.013.0014.</mixed-citation></ref><ref id="CR9"><label>9.</label><mixed-citation publication-type="other">Tulving, E. Episodic and semantic memory. in <italic>Organization of memory</italic> (ed. E. Tulving &#x00026; W. Donaldson) (Academic Press, 1972).</mixed-citation></ref><ref id="CR10"><label>10.</label><mixed-citation publication-type="other">Hagoort, P. &#x00026; Levinson, S. C. Neuropragmatics. in <italic>The cognitive neurosciences</italic> (eds. Gazzaniga, M. S. &#x00026; Mangun, G. R.) 667&#x02013;674 (MIT Press, 2014).</mixed-citation></ref><ref id="CR11"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bambini</surname><given-names>V</given-names></name></person-group><article-title>Neuropragmatics: A foreword</article-title><source>Ital. J. Linguist.</source><year>2010</year><volume>22</volume><fpage>1</fpage><lpage>20</lpage></element-citation></ref><ref id="CR12"><label>12.</label><mixed-citation publication-type="other">Levinson, S. C. On the human &#x02018;interaction engine&#x02019;. in <italic>Roots of human sociality: Culture, cognition and interaction</italic> (eds. Enfield, N. J. &#x00026; Levinson, S. C.) 39&#x02013;69 (Oxford: Berg, 2006).</mixed-citation></ref><ref id="CR13"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ross</surname><given-names>LA</given-names></name><name><surname>Olson</surname><given-names>IR</given-names></name></person-group><article-title>Social cognition and the anterior temporal lobes</article-title><source>NeuroImage</source><year>2010</year><volume>49</volume><fpage>3452</fpage><lpage>3462</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.11.012</pub-id><?supplied-pmid 19931397?><pub-id pub-id-type="pmid">19931397</pub-id>
</element-citation></ref><ref id="CR14"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zahn</surname><given-names>R</given-names></name><etal/></person-group><article-title>Social concepts are represented in the superior anterior temporal cortex</article-title><source>Proc. Natl. Acad. Sci.</source><year>2007</year><volume>104</volume><fpage>6430</fpage><lpage>6435</lpage><pub-id pub-id-type="doi">10.1073/pnas.0607061104</pub-id><?supplied-pmid 17404215?><pub-id pub-id-type="pmid">17404215</pub-id>
</element-citation></ref><ref id="CR15"><label>15.</label><mixed-citation publication-type="other">Diveica, V., Pexman, P. M. &#x00026; Binney, R. J. Quantifying social semantics: An inclusive definition of socialness and ratings for 8388 English words. (2021). 10.31234/OSF.IO/6XNZG.</mixed-citation></ref><ref id="CR16"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoffman</surname><given-names>P</given-names></name></person-group><article-title>The meaning of &#x02018;life&#x02019; and other abstract words: Insights from neuropsychology</article-title><source>J. Neuropsychol.</source><year>2016</year><volume>10</volume><fpage>317</fpage><lpage>343</lpage><pub-id pub-id-type="doi">10.1111/jnp.12065</pub-id><?supplied-pmid 25708527?><pub-id pub-id-type="pmid">25708527</pub-id>
</element-citation></ref><ref id="CR17"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoffman</surname><given-names>P</given-names></name><name><surname>McClelland</surname><given-names>JL</given-names></name><name><surname>Lambon Ralph</surname><given-names>MA</given-names></name></person-group><article-title>Concepts, control and context: A connectionist account of normal and disordered semantic cognition</article-title><source>Psychol. Rev.</source><year>2018</year><volume>125</volume><fpage>293</fpage><lpage>328</lpage><pub-id pub-id-type="doi">10.1037/rev0000094</pub-id><?supplied-pmid 29733663?><pub-id pub-id-type="pmid">29733663</pub-id>
</element-citation></ref><ref id="CR18"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barsalou</surname><given-names>LW</given-names></name></person-group><article-title>Challenges and opportunities for grounding cognition</article-title><source>J. Cogn.</source><year>2020</year><volume>3</volume><fpage>1</fpage><lpage>24</lpage><pub-id pub-id-type="pmid">31934683</pub-id>
</element-citation></ref><ref id="CR19"><label>19.</label><mixed-citation publication-type="other">Borghi, A. M. &#x00026; Binkofski, F. <italic>Words as Social Tools: An Embodied View on Abstract Concepts</italic>. (Springer New York, 2014). 10.1007/978-1-4614-9539-0.</mixed-citation></ref><ref id="CR20"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Binney</surname><given-names>RJ</given-names></name><name><surname>Hoffman</surname><given-names>P</given-names></name><name><surname>Lambon Ralph</surname><given-names>MA</given-names></name></person-group><article-title>Mapping the multiple graded contributions of the anterior temporal lobe representational hub to abstract and social concepts: Evidence from distortion-corrected fMRI</article-title><source>Cereb. Cortex N. Y.</source><year>2016</year><volume>26</volume><fpage>4227</fpage><lpage>4241</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhw260</pub-id></element-citation></ref><ref id="CR21"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vigliocco</surname><given-names>G</given-names></name><etal/></person-group><article-title>The neural representation of abstract words: The role of emotion</article-title><source>Cereb. Cortex</source><year>2014</year><volume>24</volume><fpage>1767</fpage><lpage>1777</lpage><pub-id pub-id-type="doi">10.1093/cercor/bht025</pub-id><?supplied-pmid 23408565?><pub-id pub-id-type="pmid">23408565</pub-id>
</element-citation></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="other">Shea, N. Metacognition and abstract concepts. <italic>Philos. Trans. R. Soc. B Biol. Sci.</italic><bold>373</bold>, 1752 (2018).</mixed-citation></ref><ref id="CR23"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patterson</surname><given-names>K</given-names></name><name><surname>Nestor</surname><given-names>PJ</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name></person-group><article-title>Where do you know what you know? The representation of semantic knowledge in the human brain</article-title><source>Nat. Rev. Neurosci.</source><year>2007</year><volume>8</volume><fpage>976</fpage><lpage>987</lpage><pub-id pub-id-type="doi">10.1038/nrn2277</pub-id><?supplied-pmid 18026167?><pub-id pub-id-type="pmid">18026167</pub-id>
</element-citation></ref><ref id="CR24"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lambon Ralph</surname><given-names>MA</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Patterson</surname><given-names>K</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name></person-group><article-title>The neural and computational bases of semantic cognition</article-title><source>Nat. Rev. Neurosci.</source><year>2017</year><volume>18</volume><fpage>42</fpage><lpage>55</lpage><pub-id pub-id-type="doi">10.1038/nrn.2016.150</pub-id><pub-id pub-id-type="pmid">27881854</pub-id>
</element-citation></ref><ref id="CR25"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Doctor, teacher, and stethoscope: Neural representation of different types of semantic relations</article-title><source>J. Neurosci.</source><year>2018</year><volume>38</volume><fpage>3303</fpage><lpage>3317</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2562-17.2018</pub-id><?supplied-pmid 29476016?><pub-id pub-id-type="pmid">29476016</pub-id>
</element-citation></ref><ref id="CR26"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olson</surname><given-names>IR</given-names></name><name><surname>McCoy</surname><given-names>D</given-names></name><name><surname>Klobusicky</surname><given-names>E</given-names></name><name><surname>Ross</surname><given-names>LA</given-names></name></person-group><article-title>Social cognition and the anterior temporal lobes: A review and theoretical framework</article-title><source>Soc. Cogn. Affect. Neurosci.</source><year>2013</year><volume>8</volume><fpage>123</fpage><lpage>133</lpage><pub-id pub-id-type="doi">10.1093/scan/nss119</pub-id><?supplied-pmid 23051902?><pub-id pub-id-type="pmid">23051902</pub-id>
</element-citation></ref><ref id="CR27"><label>27.</label><mixed-citation publication-type="other">Binney, R. J., Embleton, K. V., Jefferies, E., Parker, G. J. M. &#x00026; Lambon Ralph, M. A. (2010) The ventral and inferolateral aspects of the anterior temporal lobe are crucial in semantic memory: Evidence from a novel direct comparison of distortion-corrected fMRI, rTMS, and semantic dementia. <italic>Cereb. Cortex</italic><bold>20</bold>, 2728&#x02013;2738.</mixed-citation></ref><ref id="CR28"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Monticelli</surname><given-names>M</given-names></name><etal/></person-group><article-title>Where we mentalize: Main cortical areas involved in mentalization</article-title><source>Front. Neurol.</source><year>2021</year><volume>12</volume><fpage>1344</fpage><pub-id pub-id-type="doi">10.3389/fneur.2021.712532</pub-id></element-citation></ref><ref id="CR29"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frith</surname><given-names>CD</given-names></name><name><surname>Frith</surname><given-names>U</given-names></name></person-group><article-title>The neural basis of mentalizing</article-title><source>Neuron</source><year>2006</year><volume>50</volume><fpage>531</fpage><lpage>534</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.05.001</pub-id><?supplied-pmid 16701204?><pub-id pub-id-type="pmid">16701204</pub-id>
</element-citation></ref><ref id="CR30"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Balgova</surname><given-names>E</given-names></name><name><surname>Diveica</surname><given-names>V</given-names></name><name><surname>Walbrin</surname><given-names>J</given-names></name><name><surname>Binney</surname><given-names>RJ</given-names></name></person-group><article-title>The role of the ventrolateral anterior temporal lobes in social cognition</article-title><source>Hum. Brain Mapp.</source><year>2022</year><pub-id pub-id-type="doi">10.1002/HBM.25976</pub-id><?supplied-pmid 35716023?><pub-id pub-id-type="pmid">35716023</pub-id>
</element-citation></ref><ref id="CR31"><label>31.</label><mixed-citation publication-type="other">Diveica, V., Koldewyn, K. &#x00026; Binney, R. J. Establishing a role of the semantic control network in social cognitive processing: A meta-analysis of functional neuroimaging studies. <italic>NeuroImage</italic><bold>245</bold>, 118702 (2021).</mixed-citation></ref><ref id="CR32"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fedorenko</surname><given-names>E</given-names></name><name><surname>Varley</surname><given-names>R</given-names></name></person-group><article-title>Language and thought are not the same thing: Evidence from neuroimaging and neurological patients</article-title><source>Ann. N. Y. Acad. Sci.</source><year>2016</year><volume>1369</volume><fpage>132</fpage><lpage>153</lpage><pub-id pub-id-type="doi">10.1111/nyas.13046</pub-id><?supplied-pmid 27096882?><pub-id pub-id-type="pmid">27096882</pub-id>
</element-citation></ref><ref id="CR33"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paunov</surname><given-names>AM</given-names></name><etal/></person-group><article-title>Differential tracking of linguistic vs. mental state content in naturalistic stimuli by language and theory of mind (ToM) brain networks</article-title><source>Neurobiol. Lang.</source><year>2022</year><volume>3</volume><fpage>413</fpage><lpage>440</lpage><pub-id pub-id-type="doi">10.1162/nol_a_00071</pub-id></element-citation></ref><ref id="CR34"><label>34.</label><mixed-citation publication-type="other">Goodwin, C. Human sociality as mutual orientation in a rich interactive environment: Multimodal utterances and pointing in Aphasia. in <italic>Roots of Human Sociality</italic> (eds. Enfield, N. J. &#x00026; Levinson, S. C.) 97&#x02013;125 (Routledge, 2006).</mixed-citation></ref><ref id="CR35"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Varley</surname><given-names>R</given-names></name><name><surname>Siegal</surname><given-names>M</given-names></name></person-group><article-title>Evidence for cognition without grammar from causal reasoning and &#x02018;theory of mind&#x02019; in an agrammatic aphasic patient</article-title><source>Curr. Biol.</source><year>2000</year><volume>10</volume><fpage>723</fpage><lpage>726</lpage><pub-id pub-id-type="doi">10.1016/S0960-9822(00)00538-8</pub-id><?supplied-pmid 10873809?><pub-id pub-id-type="pmid">10873809</pub-id>
</element-citation></ref><ref id="CR36"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duval</surname><given-names>C</given-names></name><etal/></person-group><article-title>Theory of mind impairments in patients with semantic dementia</article-title><source>Brain</source><year>2012</year><volume>135</volume><fpage>228</fpage><pub-id pub-id-type="doi">10.1093/brain/awr309</pub-id><?supplied-pmid 22232593?><pub-id pub-id-type="pmid">22232593</pub-id>
</element-citation></ref><ref id="CR37"><label>37.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patterson</surname><given-names>K</given-names></name><name><surname>Plaut</surname><given-names>DC</given-names></name></person-group><article-title>&#x0201c;Shallow draughts intoxicate the brain&#x0201d;: Lessons from cognitive science for cognitive neuropsychology</article-title><source>Top. Cogn. Sci.</source><year>2009</year><volume>1</volume><fpage>39</fpage><lpage>58</lpage><pub-id pub-id-type="doi">10.1111/j.1756-8765.2008.01012.x</pub-id><?supplied-pmid 25164799?><pub-id pub-id-type="pmid">25164799</pub-id>
</element-citation></ref><ref id="CR38"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwartz</surname><given-names>MF</given-names></name><name><surname>Dell</surname><given-names>GS</given-names></name></person-group><article-title>Case series investigations in cognitive neuropsychology</article-title><source>Cogn. Neuropsychol.</source><year>2010</year><volume>27</volume><fpage>477</fpage><pub-id pub-id-type="doi">10.1080/02643294.2011.574111</pub-id><?supplied-pmid 21714756?><pub-id pub-id-type="pmid">21714756</pub-id>
</element-citation></ref><ref id="CR39"><label>39.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jackson</surname><given-names>RL</given-names></name></person-group><article-title>The neural correlates of semantic control revisited</article-title><source>NeuroImage</source><year>2021</year><volume>224</volume><fpage>117444</fpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117444</pub-id><?supplied-pmid 33059049?><pub-id pub-id-type="pmid">33059049</pub-id>
</element-citation></ref><ref id="CR40"><label>40.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fedorenko</surname><given-names>E</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><article-title>Neuroimaging of language: Why hasn&#x02019;t a clearer picture emerged?</article-title><source>Lang. Linguist. Compass</source><year>2009</year><volume>3</volume><fpage>839</fpage><lpage>865</lpage><pub-id pub-id-type="doi">10.1111/j.1749-818X.2009.00143.x</pub-id></element-citation></ref><ref id="CR41"><label>41.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deen</surname><given-names>B</given-names></name><name><surname>Koldewyn</surname><given-names>K</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name><name><surname>Saxe</surname><given-names>R</given-names></name></person-group><article-title>Functional organization of social perception and cognition in the superior temporal sulcus</article-title><source>Cereb. Cortex</source><year>2015</year><volume>25</volume><fpage>4596</fpage><lpage>4609</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhv111</pub-id><?supplied-pmid 26048954?><pub-id pub-id-type="pmid">26048954</pub-id>
</element-citation></ref><ref id="CR42"><label>42.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schaafsma</surname><given-names>SM</given-names></name><name><surname>Pfaff</surname><given-names>DW</given-names></name><name><surname>Spunt</surname><given-names>RP</given-names></name><name><surname>Adolphs</surname><given-names>R</given-names></name></person-group><article-title>Deconstructing and reconstructing theory of mind</article-title><source>Trends Cogn. Sci.</source><year>2015</year><volume>19</volume><fpage>65</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2014.11.007</pub-id><?supplied-pmid 25496670?><pub-id pub-id-type="pmid">25496670</pub-id>
</element-citation></ref><ref id="CR43"><label>43.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kliemann</surname><given-names>D</given-names></name><name><surname>Adolphs</surname><given-names>R</given-names></name></person-group><article-title>The social neuroscience of mentalizing: Challenges and recommendations</article-title><source>Curr. Opin. Psychol.</source><year>2018</year><volume>24</volume><fpage>1</fpage><pub-id pub-id-type="doi">10.1016/j.copsyc.2018.02.015</pub-id><?supplied-pmid 29529497?><pub-id pub-id-type="pmid">29529497</pub-id>
</element-citation></ref><ref id="CR44"><label>44.</label><mixed-citation publication-type="other">Redcay, E. &#x00026; Moraczewski, D. Social cognition in context: A naturalistic imaging approach. <italic>NeuroImage</italic>. (2019). 10.1016/j.neuroimage.2019.116392.</mixed-citation></ref><ref id="CR45"><label>45.</label><mixed-citation publication-type="other">Zaki, J. &#x00026; Ochsner, K. The need for a cognitive neuroscience of naturalistic social cognition. in <italic>Annals of the New York Academy of Sciences</italic> vol. 1167 16&#x02013;30 (Blackwell Publishing Inc., 2009).</mixed-citation></ref><ref id="CR46"><label>46.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sonkusare</surname><given-names>S</given-names></name><name><surname>Breakspear</surname><given-names>M</given-names></name><name><surname>Guo</surname><given-names>C</given-names></name></person-group><article-title>Naturalistic stimuli in neuroscience: Critically acclaimed</article-title><source>Trends Cogn. Sci.</source><year>2019</year><volume>23</volume><fpage>699</fpage><lpage>714</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2019.05.004</pub-id><?supplied-pmid 31257145?><pub-id pub-id-type="pmid">31257145</pub-id>
</element-citation></ref><ref id="CR47"><label>47.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Finn</surname><given-names>ES</given-names></name><etal/></person-group><article-title>Can brain state be manipulated to emphasize individual differences in functional connectivity?</article-title><source>NeuroImage</source><year>2017</year><volume>160</volume><fpage>140</fpage><lpage>151</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.03.064</pub-id><?supplied-pmid 28373122?><pub-id pub-id-type="pmid">28373122</pub-id>
</element-citation></ref><ref id="CR48"><label>48.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vanderwal</surname><given-names>T</given-names></name><etal/></person-group><article-title>Individual differences in functional connectivity during naturalistic viewing conditions</article-title><source>NeuroImage</source><year>2017</year><volume>157</volume><fpage>521</fpage><lpage>530</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.06.027</pub-id><?supplied-pmid 28625875?><pub-id pub-id-type="pmid">28625875</pub-id>
</element-citation></ref><ref id="CR49"><label>49.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ben-Yakov</surname><given-names>A</given-names></name><name><surname>Honey</surname><given-names>CJ</given-names></name><name><surname>Lerner</surname><given-names>Y</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><article-title>Loss of reliable temporal structure in event-related averaging of naturalistic stimuli</article-title><source>NeuroImage</source><year>2012</year><volume>63</volume><fpage>501</fpage><lpage>506</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.07.008</pub-id><?supplied-pmid 22813575?><pub-id pub-id-type="pmid">22813575</pub-id>
</element-citation></ref><ref id="CR50"><label>50.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baldassano</surname><given-names>C</given-names></name><etal/></person-group><article-title>Discovering event structure in continuous narrative perception and memory</article-title><source>Neuron</source><year>2017</year><volume>95</volume><fpage>709</fpage><lpage>721.e5</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.041</pub-id><?supplied-pmid 28772125?><pub-id pub-id-type="pmid">28772125</pub-id>
</element-citation></ref><ref id="CR51"><label>51.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Yang</surname><given-names>E</given-names></name><name><surname>Vallines</surname><given-names>I</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name><name><surname>Rubin</surname><given-names>N</given-names></name></person-group><article-title>A hierarchy of temporal receptive windows in human cortex</article-title><source>J. Neurosci.</source><year>2008</year><volume>28</volume><fpage>2539</fpage><lpage>2550</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5487-07.2008</pub-id><?supplied-pmid 18322098?><pub-id pub-id-type="pmid">18322098</pub-id>
</element-citation></ref><ref id="CR52"><label>52.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lerner</surname><given-names>Y</given-names></name><name><surname>Honey</surname><given-names>CJ</given-names></name><name><surname>Silbert</surname><given-names>LJ</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><article-title>Topographic mapping of a hierarchy of temporal receptive windows using a narrated story</article-title><source>J. Neurosci.</source><year>2011</year><volume>31</volume><fpage>2906</fpage><lpage>2915</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3684-10.2011</pub-id><?supplied-pmid 21414912?><pub-id pub-id-type="pmid">21414912</pub-id>
</element-citation></ref><ref id="CR53"><label>53.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aliko</surname><given-names>S</given-names></name><name><surname>Huang</surname><given-names>J</given-names></name><name><surname>Gheorghiu</surname><given-names>F</given-names></name><name><surname>Meliss</surname><given-names>S</given-names></name><name><surname>Skipper</surname><given-names>JI</given-names></name></person-group><article-title>A naturalistic neuroimaging database for understanding the brain using ecological stimuli</article-title><source>Sci. Data</source><year>2020</year><volume>7</volume><fpage>1</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1038/s41597-020-00680-2</pub-id><pub-id pub-id-type="pmid">31896794</pub-id>
</element-citation></ref><ref id="CR54"><label>54.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nastase</surname><given-names>SA</given-names></name><etal/></person-group><article-title>The &#x0201c;Narratives&#x0201d; fMRI dataset for evaluating models of naturalistic language comprehension</article-title><source>Sci. Data.</source><year>2021</year><volume>8</volume><fpage>1</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.1038/s41597-021-01033-3</pub-id><pub-id pub-id-type="pmid">33414438</pub-id>
</element-citation></ref><ref id="CR55"><label>55.</label><mixed-citation publication-type="other">Geuter, S., Qi, G., Welsh, R. C., Wager, T. D. &#x00026; Lindquist, M. A. Effect size and power in fMRI group analysis. <italic>bioRxiv</italic> 295048 (2018). 10.1101/295048.</mixed-citation></ref><ref id="CR56"><label>56.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gordon</surname><given-names>EM</given-names></name><etal/></person-group><article-title>Precision functional mapping of individual human brains</article-title><source>Neuron</source><year>2017</year><volume>95</volume><fpage>791</fpage><lpage>807.e7</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.07.011</pub-id><?supplied-pmid 28757305?><pub-id pub-id-type="pmid">28757305</pub-id>
</element-citation></ref><ref id="CR57"><label>57.</label><mixed-citation publication-type="other">Champely, S. pwr: Basic functions for power analysis. (2020).</mixed-citation></ref><ref id="CR58"><label>58.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baker</surname><given-names>DH</given-names></name><etal/></person-group><article-title>Power contours: Optimising sample size and precision in experimental psychology and human neuroscience</article-title><source>Psychol. Methods</source><year>2021</year><volume>26</volume><fpage>295</fpage><pub-id pub-id-type="doi">10.1037/met0000337</pub-id><?supplied-pmid 32673043?><pub-id pub-id-type="pmid">32673043</pub-id>
</element-citation></ref><ref id="CR59"><label>59.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buchsbaum</surname><given-names>D</given-names></name><name><surname>Griffiths</surname><given-names>TL</given-names></name><name><surname>Plunkett</surname><given-names>D</given-names></name><name><surname>Gopnik</surname><given-names>A</given-names></name><name><surname>Baldwin</surname><given-names>D</given-names></name></person-group><article-title>Inferring action structure and causal relationships in continuous sequences of human action</article-title><source>Cognit. Psychol.</source><year>2015</year><volume>76</volume><fpage>30</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.1016/j.cogpsych.2014.10.001</pub-id><?supplied-pmid 25527974?><pub-id pub-id-type="pmid">25527974</pub-id>
</element-citation></ref><ref id="CR60"><label>60.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Kurby</surname><given-names>CA</given-names></name><name><surname>Eisenberg</surname><given-names>ML</given-names></name><name><surname>Haroutunian</surname><given-names>N</given-names></name></person-group><article-title>Prediction error associated with the perceptual segmentation of naturalistic events</article-title><source>J. Cogn. Neurosci.</source><year>2011</year><volume>23</volume><fpage>4057</fpage><lpage>4066</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00078</pub-id><?supplied-pmid 21671745?><pub-id pub-id-type="pmid">21671745</pub-id>
</element-citation></ref><ref id="CR61"><label>61.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Balota</surname><given-names>DA</given-names></name><etal/></person-group><article-title>The English Lexicon Project</article-title><source>Behav. Res. Methods</source><year>2007</year><volume>39</volume><fpage>445</fpage><lpage>459</lpage><pub-id pub-id-type="doi">10.3758/BF03193014</pub-id><?supplied-pmid 17958156?><pub-id pub-id-type="pmid">17958156</pub-id>
</element-citation></ref><ref id="CR62"><label>62.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brysbaert</surname><given-names>M</given-names></name><name><surname>New</surname><given-names>B</given-names></name></person-group><article-title>Moving beyond Ku&#x0010d;era and Francis: A critical evaluation of current word frequency norms and the introduction of a new and improved word frequency measure for American English</article-title><source>Behav. Res. Methods</source><year>2009</year><volume>41</volume><fpage>977</fpage><lpage>990</lpage><pub-id pub-id-type="doi">10.3758/BRM.41.4.977</pub-id><?supplied-pmid 19897807?><pub-id pub-id-type="pmid">19897807</pub-id>
</element-citation></ref><ref id="CR63"><label>63.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoffman</surname><given-names>P</given-names></name><name><surname>Lambon Ralph</surname><given-names>MA</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name></person-group><article-title>Semantic diversity: A measure of semantic ambiguity based on variability in the contextual usage of words</article-title><source>Behav. Res. Methods</source><year>2013</year><volume>45</volume><fpage>718</fpage><lpage>730</lpage><pub-id pub-id-type="doi">10.3758/s13428-012-0278-x</pub-id><?supplied-pmid 23239067?><pub-id pub-id-type="pmid">23239067</pub-id>
</element-citation></ref><ref id="CR64"><label>64.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Warriner</surname><given-names>AB</given-names></name><name><surname>Kuperman</surname><given-names>V</given-names></name><name><surname>Brysbaert</surname><given-names>M</given-names></name></person-group><article-title>Norms of valence, arousal, and dominance for 13,915 English lemmas</article-title><source>Behav. Res. Methods</source><year>2013</year><volume>45</volume><fpage>1191</fpage><lpage>1207</lpage><pub-id pub-id-type="doi">10.3758/s13428-012-0314-x</pub-id><?supplied-pmid 23404613?><pub-id pub-id-type="pmid">23404613</pub-id>
</element-citation></ref><ref id="CR65"><label>65.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scott</surname><given-names>GG</given-names></name><name><surname>Keitel</surname><given-names>A</given-names></name><name><surname>Becirspahic</surname><given-names>M</given-names></name><name><surname>Yao</surname><given-names>B</given-names></name><name><surname>Sereno</surname><given-names>SC</given-names></name></person-group><article-title>The Glasgow Norms: Ratings of 5,500 words on nine scales</article-title><source>Behav. Res. Methods.</source><year>2018</year><pub-id pub-id-type="doi">10.3758/s13428-018-1099-3</pub-id></element-citation></ref><ref id="CR66"><label>66.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hampson</surname><given-names>SE</given-names></name><name><surname>Goldberg</surname><given-names>LR</given-names></name><name><surname>John</surname><given-names>OP</given-names></name></person-group><article-title>Category-breadth and social-desirability values for 573 personality terms</article-title><source>Eur. J. Personal.</source><year>1987</year><volume>1</volume><fpage>241</fpage><lpage>258</lpage><pub-id pub-id-type="doi">10.1002/per.2410010405</pub-id></element-citation></ref><ref id="CR67"><label>67.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Buuren</surname><given-names>S</given-names></name><name><surname>Groothuis-Oudshoorn</surname><given-names>K</given-names></name></person-group><article-title>Multivariate imputation by chained equations in R</article-title><source>J. Stat. Softw.</source><year>2011</year><volume>45</volume><fpage>1</fpage><lpage>67</lpage><pub-id pub-id-type="doi">10.18637/jss.v045.i03</pub-id></element-citation></ref><ref id="CR68"><label>68.</label><mixed-citation publication-type="other">Geerligs, L. <italic>et al.</italic> A partially nested cortical hierarchy of neural states underlies event segmentation in the human brain. <italic>bioRxiv</italic> 2021.02.05.429165 (2022). 10.1101/2021.02.05.429165.</mixed-citation></ref><ref id="CR69"><label>69.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>K</given-names></name><name><surname>Bodurka</surname><given-names>J</given-names></name><name><surname>Bandettini</surname><given-names>PA</given-names></name></person-group><article-title>How long to scan? The relationship between fMRI temporal signal to noise ratio and necessary scan duration</article-title><source>NeuroImage</source><year>2007</year><volume>34</volume><fpage>565</fpage><lpage>574</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.09.032</pub-id><?supplied-pmid 17126038?><pub-id pub-id-type="pmid">17126038</pub-id>
</element-citation></ref><ref id="CR70"><label>70.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diaz</surname><given-names>MT</given-names></name><etal/></person-group><article-title>Neural sensitivity to semantic neighbors is stable across the adult lifespan</article-title><source>Neuropsychologia</source><year>2022</year><volume>171</volume><fpage>108237</fpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2022.108237</pub-id><?supplied-pmid 35413304?><pub-id pub-id-type="pmid">35413304</pub-id>
</element-citation></ref><ref id="CR71"><label>71.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mirman</surname><given-names>D</given-names></name><name><surname>Graziano</surname><given-names>KM</given-names></name></person-group><article-title>The neural basis of inhibitory effects of semantic and phonological neighbors in spoken word production</article-title><source>J. Cogn. Neurosci.</source><year>2013</year><volume>25</volume><fpage>1504</fpage><lpage>1516</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00408</pub-id><?supplied-pmid 23647518?><pub-id pub-id-type="pmid">23647518</pub-id>
</element-citation></ref><ref id="CR72"><label>72.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>G</given-names></name><name><surname>Saad</surname><given-names>ZS</given-names></name><name><surname>Britton</surname><given-names>JC</given-names></name><name><surname>Pine</surname><given-names>DS</given-names></name><name><surname>Cox</surname><given-names>RW</given-names></name></person-group><article-title>Linear mixed-effects modeling approach to FMRI group analysis</article-title><source>NeuroImage</source><year>2013</year><volume>73</volume><fpage>176</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.01.047</pub-id><?supplied-pmid 23376789?><pub-id pub-id-type="pmid">23376789</pub-id>
</element-citation></ref><ref id="CR73"><label>73.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname><given-names>PA</given-names></name><etal/></person-group><article-title>Highlight results, don&#x02019;t hide them: Enhance interpretation, reduce biases and improve reproducibility</article-title><source>NeuroImage</source><year>2023</year><volume>274</volume><fpage>120138</fpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2023.120138</pub-id><?supplied-pmid 37116766?><pub-id pub-id-type="pmid">37116766</pub-id>
</element-citation></ref><ref id="CR74"><label>74.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rorden</surname><given-names>C</given-names></name><name><surname>Brett</surname><given-names>M</given-names></name></person-group><article-title>Stereotaxic display of brain lesions</article-title><source>Behav. Neurol.</source><year>2000</year><volume>12</volume><fpage>191</fpage><lpage>200</lpage><pub-id pub-id-type="doi">10.1155/2000/421719</pub-id><?supplied-pmid 11568431?><pub-id pub-id-type="pmid">11568431</pub-id>
</element-citation></ref><ref id="CR75"><label>75.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wickham</surname><given-names>H</given-names></name></person-group><source>ggplot2: Elegant Graphics for Data Analysis</source><year>2016</year><publisher-name>Springer-Verlag</publisher-name></element-citation></ref><ref id="CR76"><label>76.</label><mixed-citation publication-type="other">Kay, M. ggdist: Visualizations of distributions and uncertainty. (2023). 10.5281/zenodo.3879620</mixed-citation></ref><ref id="CR77"><label>77.</label><mixed-citation publication-type="other">Tiedemann, F. gghalves: Compose half-half plots using your favourite geoms. (2022).</mixed-citation></ref><ref id="CR78"><label>78.</label><mixed-citation publication-type="other">R Core Team. R: A language and environment for statistical computing. (2023).</mixed-citation></ref><ref id="CR79"><label>79.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>J&#x000e4;&#x000e4;skel&#x000e4;inen</surname><given-names>IP</given-names></name><name><surname>Sams</surname><given-names>M</given-names></name><name><surname>Glerean</surname><given-names>E</given-names></name><name><surname>Ahveninen</surname><given-names>J</given-names></name></person-group><article-title>Movies and narratives as naturalistic stimuli in neuroimaging</article-title><source>NeuroImage</source><year>2021</year><volume>224</volume><fpage>117445</fpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117445</pub-id><?supplied-pmid 33059053?><pub-id pub-id-type="pmid">33059053</pub-id>
</element-citation></ref><ref id="CR80"><label>80.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Malach</surname><given-names>R</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><article-title>Reliability of cortical activity during natural stimulation</article-title><source>Trends Cogn. Sci.</source><year>2010</year><volume>14</volume><fpage>40</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2009.10.011</pub-id><?supplied-pmid 20004608?><pub-id pub-id-type="pmid">20004608</pub-id>
</element-citation></ref><ref id="CR81"><label>81.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Binder</surname><given-names>JR</given-names></name><name><surname>Desai</surname><given-names>RH</given-names></name><name><surname>Graves</surname><given-names>WW</given-names></name><name><surname>Conant</surname><given-names>LL</given-names></name></person-group><article-title>Where is the semantic system? A critical review and meta-analysis of 120 functional neuroimaging studies</article-title><source>Cereb. Cortex</source><year>2009</year><volume>19</volume><fpage>2767</fpage><lpage>2796</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhp055</pub-id><?supplied-pmid 19329570?><pub-id pub-id-type="pmid">19329570</pub-id>
</element-citation></ref><ref id="CR82"><label>82.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Malik-Moraleda</surname><given-names>S</given-names></name><etal/></person-group><article-title>An investigation across 45 languages and 12 language families reveals a universal language network</article-title><source>Nat. Neurosci.</source><year>2022</year><volume>25</volume><fpage>1014</fpage><lpage>1019</lpage><pub-id pub-id-type="doi">10.1038/s41593-022-01114-5</pub-id><?supplied-pmid 35856094?><pub-id pub-id-type="pmid">35856094</pub-id>
</element-citation></ref><ref id="CR83"><label>83.</label><mixed-citation publication-type="other">Aliko, S., Wang, B., Small, S. L. &#x00026; Skipper, J. I. The entire brain, more or less, is at work: &#x02018;Language regions&#x02019; are artefacts of averaging. 2023.09.01.555886. 10.1101/2023.09.01.555886 (2023).</mixed-citation></ref><ref id="CR84"><label>84.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shekari</surname><given-names>E</given-names></name><name><surname>Nozari</surname><given-names>N</given-names></name></person-group><article-title>A narrative review of the anatomy and function of the white matter tracts in language production and comprehension</article-title><source>Front. Hum. Neurosci.</source><year>2023</year><volume>17</volume><fpage>1139292</fpage><pub-id pub-id-type="doi">10.3389/fnhum.2023.1139292</pub-id><?supplied-pmid 37051488?><pub-id pub-id-type="pmid">37051488</pub-id>
</element-citation></ref><ref id="CR85"><label>85.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vias</surname><given-names>C</given-names></name><name><surname>Dick</surname><given-names>AS</given-names></name></person-group><article-title>Cerebellar contributions to language in typical and atypical development: A review</article-title><source>Dev. Neuropsychol.</source><year>2017</year><volume>42</volume><fpage>404</fpage><lpage>421</lpage><pub-id pub-id-type="doi">10.1080/87565641.2017.1334783</pub-id><?supplied-pmid 28885046?><pub-id pub-id-type="pmid">28885046</pub-id>
</element-citation></ref><ref id="CR86"><label>86.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>W</given-names></name><name><surname>Morales</surname><given-names>M</given-names></name><name><surname>Patel</surname><given-names>T</given-names></name><name><surname>Pickering</surname><given-names>MJ</given-names></name><name><surname>Hoffman</surname><given-names>P</given-names></name></person-group><article-title>Modulation of brain activity by psycholinguistic information during naturalistic speech comprehension and production</article-title><source>Cortex.</source><year>2022</year><pub-id pub-id-type="doi">10.1016/J.CORTEX.2022.08.002</pub-id><?supplied-pmid 36075141?><pub-id pub-id-type="pmid">36075141</pub-id>
</element-citation></ref><ref id="CR87"><label>87.</label><mixed-citation publication-type="other">Zhang, Y., Han, K., Worth, R. &#x00026; Liu, Z. Connecting concepts in the brain by mapping cortical representations of semantic relations. <italic>Nat. Commun.</italic><bold>11</bold>, 1877 (2020).</mixed-citation></ref><ref id="CR88"><label>88.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yee</surname><given-names>E</given-names></name><name><surname>Thompson-Schill</surname><given-names>SL</given-names></name></person-group><article-title>Putting concepts into context</article-title><source>Psychon. Bull. Rev.</source><year>2016</year><volume>23</volume><fpage>1015</fpage><lpage>1027</lpage><pub-id pub-id-type="doi">10.3758/s13423-015-0948-7</pub-id><?supplied-pmid 27282993?><pub-id pub-id-type="pmid">27282993</pub-id>
</element-citation></ref><ref id="CR89"><label>89.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thye</surname><given-names>M</given-names></name><name><surname>Hoffman</surname><given-names>P</given-names></name><name><surname>Mirman</surname><given-names>D</given-names></name></person-group><article-title>The words that little by little revealed everything: Neural response to lexical-semantic content during narrative comprehension</article-title><source>NeuroImage.</source><year>2023</year><pub-id pub-id-type="doi">10.1016/j.neuroimage.2023.120204</pub-id><?supplied-pmid 37257674?><pub-id pub-id-type="pmid">37257674</pub-id>
</element-citation></ref><ref id="CR90"><label>90.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>H</given-names></name><name><surname>Bellana</surname><given-names>B</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name></person-group><article-title>What can narratives tell us about the neural bases of human memory?</article-title><source>Curr. Opin. Behav. Sci.</source><year>2020</year><volume>32</volume><fpage>111</fpage><lpage>119</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2020.02.007</pub-id></element-citation></ref><ref id="CR91"><label>91.</label><mixed-citation publication-type="other">Raichle, M. E. The brain&#x02019;s default mode network. <italic>Httpdxdoiorg101146annurev-Neuro-071013-014030</italic><bold>38</bold>, 433&#x02013;447 (2015).</mixed-citation></ref><ref id="CR92"><label>92.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Menon</surname><given-names>V</given-names></name></person-group><article-title>20 years of the default mode network: A review and synthesis</article-title><source>Neuron</source><year>2023</year><volume>S0896&#x02013;6273</volume><issue>23</issue><fpage>00308</fpage><lpage>312</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2023.04.023</pub-id></element-citation></ref><ref id="CR93"><label>93.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simony</surname><given-names>E</given-names></name><etal/></person-group><article-title>Dynamic reconfiguration of the default mode network during narrative comprehension</article-title><source>Nat. Commun.</source><year>2016</year><volume>7</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1038/ncomms12141</pub-id></element-citation></ref><ref id="CR94"><label>94.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Betti</surname><given-names>V</given-names></name><etal/></person-group><article-title>Natural scenes viewing alters the dynamics of functional connectivity in the human brain</article-title><source>Neuron</source><year>2013</year><volume>79</volume><fpage>782</fpage><lpage>797</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.06.022</pub-id><?supplied-pmid 23891400?><pub-id pub-id-type="pmid">23891400</pub-id>
</element-citation></ref><ref id="CR95"><label>95.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brandman</surname><given-names>T</given-names></name><name><surname>Malach</surname><given-names>R</given-names></name><name><surname>Simony</surname><given-names>E</given-names></name></person-group><article-title>The surprising role of the default mode network in naturalistic perception</article-title><source>Commun. Biol.</source><year>2021</year><volume>4</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1038/s42003-020-01602-z</pub-id><pub-id pub-id-type="pmid">33398033</pub-id>
</element-citation></ref><ref id="CR96"><label>96.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arioli</surname><given-names>M</given-names></name><name><surname>Gianelli</surname><given-names>C</given-names></name><name><surname>Canessa</surname><given-names>N</given-names></name></person-group><article-title>Neural representation of social concepts: A coordinate-based meta-analysis of fMRI studies</article-title><source>Brain Imaging Behav.</source><year>2020</year><pub-id pub-id-type="doi">10.1007/s11682-020-00384-6</pub-id></element-citation></ref><ref id="CR97"><label>97.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>G</given-names></name><name><surname>Xu</surname><given-names>Y</given-names></name><name><surname>Zhang</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Lin</surname><given-names>N</given-names></name></person-group><article-title>The brain network in support of social semantic accumulation</article-title><source>Soc. Cogn. Affect. Neurosci.</source><year>2021</year><volume>16</volume><fpage>393</fpage><lpage>405</lpage><pub-id pub-id-type="doi">10.1093/scan/nsab003</pub-id><?supplied-pmid 33433627?><pub-id pub-id-type="pmid">33433627</pub-id>
</element-citation></ref><ref id="CR98"><label>98.</label><mixed-citation publication-type="other">Li, W., Mai, X. &#x00026; Liu, C. The default mode network and social understanding of others: What do brain connectivity studies tell us. <italic>Front. Hum. Neurosci.</italic><bold>8</bold>, 74 (2014).</mixed-citation></ref><ref id="CR99"><label>99.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bestgen</surname><given-names>Y</given-names></name></person-group><article-title>Can emotional valence in stories be determined from words?</article-title><source>Cogn. Emot.</source><year>1992</year><volume>8</volume><fpage>21</fpage><lpage>36</lpage><pub-id pub-id-type="doi">10.1080/02699939408408926</pub-id></element-citation></ref><ref id="CR100"><label>100.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Born</surname><given-names>RT</given-names></name><name><surname>Bradley</surname><given-names>DC</given-names></name></person-group><article-title>Structure and function of visual area MT</article-title><source>Annu. Rev. Neurosci.</source><year>2005</year><volume>28</volume><fpage>157</fpage><lpage>189</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.26.041002.131052</pub-id><?supplied-pmid 16022593?><pub-id pub-id-type="pmid">16022593</pub-id>
</element-citation></ref><ref id="CR101"><label>101.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grill-Spector</surname><given-names>K</given-names></name><name><surname>Kourtzi</surname><given-names>Z</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><article-title>The lateral occipital complex and its role in object recognition</article-title><source>Vision Res.</source><year>2001</year><volume>41</volume><fpage>1409</fpage><lpage>1422</lpage><pub-id pub-id-type="doi">10.1016/S0042-6989(01)00073-6</pub-id><?supplied-pmid 11322983?><pub-id pub-id-type="pmid">11322983</pub-id>
</element-citation></ref><ref id="CR102"><label>102.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nagy</surname><given-names>K</given-names></name><name><surname>Greenlee</surname><given-names>M</given-names></name><name><surname>Kov&#x000e1;cs</surname><given-names>G</given-names></name></person-group><article-title>The lateral occipital cortex in the face perception network: An effective connectivity study</article-title><source>Front. Psychol.</source><year>2012</year><volume>3</volume><fpage>141</fpage><pub-id pub-id-type="doi">10.3389/fpsyg.2012.00141</pub-id><?supplied-pmid 22593748?><pub-id pub-id-type="pmid">22593748</pub-id>
</element-citation></ref><ref id="CR103"><label>103.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pitcher</surname><given-names>D</given-names></name><name><surname>Ungerleider</surname><given-names>LG</given-names></name></person-group><article-title>Evidence for a third visual pathway specialized for social perception</article-title><source>Trends Cogn. Sci.</source><year>2021</year><volume>25</volume><fpage>100</fpage><lpage>110</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2020.11.006</pub-id><?supplied-pmid 33334693?><pub-id pub-id-type="pmid">33334693</pub-id>
</element-citation></ref><ref id="CR104"><label>104.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewis</surname><given-names>PA</given-names></name><name><surname>Birch</surname><given-names>A</given-names></name><name><surname>Hall</surname><given-names>A</given-names></name><name><surname>Dunbar</surname><given-names>RIM</given-names></name></person-group><article-title>Higher order intentionality tasks are cognitively more demanding</article-title><source>Soc. Cogn. Affect. Neurosci.</source><year>2017</year><volume>12</volume><fpage>1063</fpage><lpage>1071</lpage><pub-id pub-id-type="doi">10.1093/scan/nsx034</pub-id><?supplied-pmid 28338962?><pub-id pub-id-type="pmid">28338962</pub-id>
</element-citation></ref><ref id="CR105"><label>105.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stiller</surname><given-names>J</given-names></name><name><surname>Dunbar</surname><given-names>RIM</given-names></name></person-group><article-title>Perspective-taking and memory capacity predict social network size</article-title><source>Soc. Netw.</source><year>2007</year><volume>29</volume><fpage>93</fpage><lpage>104</lpage><pub-id pub-id-type="doi">10.1016/j.socnet.2006.04.001</pub-id></element-citation></ref><ref id="CR106"><label>106.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Duijn</surname><given-names>MJ</given-names></name><name><surname>Sluiter</surname><given-names>I</given-names></name><name><surname>Verhagen</surname><given-names>A</given-names></name></person-group><article-title>When narrative takes over: The representation of embedded mindstates in Shakespeare&#x02019;s Othello</article-title><source>Lang. Lit.</source><year>2015</year><volume>24</volume><fpage>148</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1177/0963947015572274</pub-id></element-citation></ref><ref id="CR107"><label>107.</label><mixed-citation publication-type="other">Bruner, J. S. <italic>Actual Minds, Possible Worlds</italic>. (Harvard University Press, 1986).</mixed-citation></ref><ref id="CR108"><label>108.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rice</surname><given-names>GE</given-names></name><name><surname>Hoffman</surname><given-names>P</given-names></name><name><surname>Lambon Ralph</surname><given-names>MA</given-names></name></person-group><article-title>Graded specialization within and between the anterior temporal lobes</article-title><source>Ann. N. Y. Acad. Sci.</source><year>2015</year><volume>1359</volume><fpage>84</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1111/nyas.12951</pub-id><?supplied-pmid 26502375?><pub-id pub-id-type="pmid">26502375</pub-id>
</element-citation></ref><ref id="CR109"><label>109.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rice</surname><given-names>GE</given-names></name><name><surname>Caswell</surname><given-names>H</given-names></name><name><surname>Moore</surname><given-names>P</given-names></name><name><surname>Hoffman</surname><given-names>P</given-names></name><name><surname>Lambon Ralph</surname><given-names>MA</given-names></name></person-group><article-title>The roles of left versus right anterior temporal lobes in semantic memory: A neuropsychological comparison of postsurgical temporal lobe epilepsy patients</article-title><source>Cereb. Cortex N. Y. NY</source><year>2018</year><volume>28</volume><fpage>1487</fpage><lpage>1501</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhx362</pub-id></element-citation></ref><ref id="CR110"><label>110.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nieto-Casta&#x000f1;&#x000f3;n</surname><given-names>A</given-names></name><name><surname>Fedorenko</surname><given-names>E</given-names></name></person-group><article-title>Subject-specific functional localizers increase sensitivity and functional resolution of multi-subject analyses</article-title><source>NeuroImage</source><year>2012</year><volume>63</volume><fpage>1646</fpage><lpage>1669</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.06.065</pub-id><?supplied-pmid 22784644?><pub-id pub-id-type="pmid">22784644</pub-id>
</element-citation></ref></ref-list></back></article>