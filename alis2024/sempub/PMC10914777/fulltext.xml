<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd"> 
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 1?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sci Rep</journal-id><journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id><journal-title-group><journal-title>Scientific Reports</journal-title></journal-title-group><issn pub-type="epub">2045-2322</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmcid">10914777</article-id><article-id pub-id-type="pmid">38443678</article-id>
<article-id pub-id-type="publisher-id">56090</article-id><article-id pub-id-type="doi">10.1038/s41598-024-56090-6</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Computer programmers show distinct, expertise-dependent brain responses to violations in form and meaning when reading code</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Kuo</surname><given-names>Chu-Hsuan</given-names></name><address><email>kuoc6@uw.edu</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Prat</surname><given-names>Chantel S.</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00cvxb145</institution-id><institution-id institution-id-type="GRID">grid.34477.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 2298 6657</institution-id><institution>Department of Psychology, </institution><institution>University of Washington, </institution></institution-wrap>Seattle, WA USA </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00cvxb145</institution-id><institution-id institution-id-type="GRID">grid.34477.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 2298 6657</institution-id><institution>Institute for Learning and Brain Sciences, </institution><institution>University of Washington, </institution></institution-wrap>Seattle, WA USA </aff></contrib-group><pub-date pub-type="epub"><day>5</day><month>3</month><year>2024</year></pub-date><pub-date pub-type="pmc-release"><day>5</day><month>3</month><year>2024</year></pub-date><pub-date pub-type="collection"><year>2024</year></pub-date><volume>14</volume><elocation-id>5404</elocation-id><history><date date-type="received"><day>7</day><month>10</month><year>2023</year></date><date date-type="accepted"><day>1</day><month>3</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2024</copyright-statement><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">As computer programming becomes more central to the workforce, the need for better models of how it is effectively learned has become more apparent. The current study addressed this gap by recording electrophysiological brain responses as 62 Python programmers with varying skill levels read lines of code with manipulations of form (syntax) and meaning (semantics). At the group level, results showed that manipulations of form resulted in P600 effects, with syntactically invalid code generating more positive deflections in the 500&#x02013;800&#x000a0;ms range than syntactically valid code. Meaning manipulations resulted in N400 effects, with semantically implausible code generating more negative deflections in the 300&#x02013;500&#x000a0;ms range than semantically plausible code. Greater Python expertise within the group was associated with greater sensitivity to violations in form. These results support the notion that skilled programming, like skilled natural language learning, is associated with the incorporation of rule-based knowledge into online comprehension processes. Conversely, programmers at all skill levels showed neural sensitivity to meaning manipulations, suggesting that reliance on pre-existing semantic relationships facilitates code comprehension across skill levels.</p></abstract><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>Language</kwd><kwd>Computer science</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000006</institution-id><institution>Office of Naval Research</institution></institution-wrap></funding-source><award-id>N00014-20-1-2393</award-id></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Springer Nature Limited 2024</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par2">As computer programming, or coding, has moved from being a niche skill to one that is broadly valued in STEM fields and the workforce, the need for improved models of what underlies skilled programming has become more apparent. Fortunately, an increasing amount of research has been devoted to understanding the cognitive and neural bases of computer literacy<sup><xref ref-type="bibr" rid="CR1">1</xref>&#x02013;<xref ref-type="bibr" rid="CR3">3</xref></sup>. This body of work is critical and timely, as converging evidence points to a mismatch between the canonical ways that computer programming is taught, and the way it is best learned<sup><xref ref-type="bibr" rid="CR4">4</xref></sup>. In fact, statistics suggest that as many as 50% of students who enroll in Intro Programming courses worldwide drop them before completion<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>.</p><p id="Par3">In their formative paper &#x0201c;The language of programming: A cognitive perspective,&#x0201d; Fedorenko and colleagues<sup><xref ref-type="bibr" rid="CR6">6</xref></sup> outlined many theoretical parallels between the cognitive bases of programming languages and natural languages. In it, they argue that similarities in the cognitive underpinnings of code and language comprehension and production offer opportunities to &#x0201c;reconceptualize the way [computer science] is taught, especially in early childhood, when children are learning to read and write.&#x0201d; The use of reading and writing as educational comparisons for learning to code is particularly compelling. Unlike the spoken and signed aspects of <italic>native</italic> language acquisition, which occur largely implicitly through reinforcement learning mechanisms, reading and writing are skills that must interface with pre-existing linguistic knowledge, and they are typically explicitly taught in classroom environments. We believe that this is an important distinction to make when it comes to learning programming languages. In the current experiment, when considering natural language learning as a model for understanding how programming languages are learned, our focus is on the explicitly taught and learned aspects of natural language. Specifically, we argue that learning to code might resemble instructed (as opposed to immersed) second language (L2) learning.</p><p id="Par4">Recent research investigating the neural and cognitive underpinnings of learning programming languages has adopted two main approaches: (1) investigating the predictors of facile code learning (e.g., those comparing the predictive utility of numeracy and literacy)<sup><xref ref-type="bibr" rid="CR3">3</xref>,<xref ref-type="bibr" rid="CR4">4</xref>,<xref ref-type="bibr" rid="CR7">7</xref></sup>; and (2) investigating the neural underpinnings of code comprehension<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR2">2</xref>,<xref ref-type="bibr" rid="CR8">8</xref></sup>. Evidence gleaned from both approaches suggests that explicit L2 learning environments may be useful models for understanding how programming languages are learned. For example, in their investigation of the predictors of learning to program in Python, Prat and colleagues<sup><xref ref-type="bibr" rid="CR3">3</xref></sup> found that the Modern Language Aptitude Test<sup><xref ref-type="bibr" rid="CR9">9</xref></sup>, developed to detect variability in the ability to learn an L2 in adulthood, explained approximately 30% of the variance in both learning rate and ultimate programming skill obtained. In an fMRI experiment exploring the neural basis of code comprehension, Floyd and collaborators<sup><xref ref-type="bibr" rid="CR1">1</xref></sup> found that the similarities in neural responses when native English speakers read either code or English were higher in expert coders than in novices. A similar pattern was observed in a series of meta-analyses of bilingual language representation conducted by Sebastian, Laird, and Kiran<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>, with higher proficiency bilinguals showing greater similarity in patterns of activation between their L2 and native languages than did bilinguals with low or moderate proficiency levels.</p><p id="Par5">In the current experiment, we aim to extend and refine this research by exploring the <italic>online</italic> neural responses of programmers at varying levels of expertise as they comprehend lines of code incrementally, in real time. To do so, we employed two electrophysiological indices, the N400 and P600, which have been used extensively to study online language comprehension processes in both native language speakers and L2 learners. Though the precise neurocomputational nature of these components remains debated<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>, the N400&#x02014;a negative deflection in the event-related potential (ERP) that peaks approximately 400&#x000a0;ms after stimulus onset&#x02014;has been shown to be sensitive to factors that influence the accessibility of a stimulus&#x02019;s meaning, or semantics, from memory (e.g., word frequency, semantic congruity, and semantic predictability)<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>. Meanwhile, the P600&#x02014;a positive deflection that peaks approximately 600&#x000a0;ms after stimulus onset&#x02014;has been shown to be sensitive to structural violations, or syntax (e.g., subject-verb agreement violations or word order violations)<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>. Although prevalent in the neurolinguistics literature, these ERP components have also been observed when participants engage in meaning-making using other familiar symbolic systems, such as mathematics<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>.</p><p id="Par6">Critically for our questions of interest, these ERP components have been shown to index expertise<sup><xref ref-type="bibr" rid="CR15">15</xref>,<xref ref-type="bibr" rid="CR16">16</xref></sup> and individual differences more broadly<sup><xref ref-type="bibr" rid="CR14">14</xref>,<xref ref-type="bibr" rid="CR17">17</xref></sup> by measuring the real-time brain processes that reflect our ability to make sense of incremental stimuli at the local (e.g., word) and broader structural (e.g., sentence) levels. Specifically, converging evidence from both longitudinal<sup><xref ref-type="bibr" rid="CR15">15</xref></sup> and cross-sectional<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> studies of L2 learning suggest that as individuals progress from novice to advanced proficiency levels in their L2s, sensitivity to violations in form (or syntax) begin to look more like native language violations, increasingly evoking the P600 response. In their review of this work, McLaughlin and colleagues<sup><xref ref-type="bibr" rid="CR15">15</xref></sup> describe these findings as evidence of &#x0201c;grammaticalization,&#x0201d; or &#x0201c;the instantiation of rule-based knowledge into the learner&#x02019;s real-time language processing systems&#x0201d; (p. 126)<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>. With respect to skilled L2 comprehension, they propose that &#x0201c;learners must somehow separate the linguistic input into those aspects related to meaning and those related to form.&#x0201d;</p><p id="Par7">In the current study, we explore the extent to which these real-time indicators of sensitivity to form and meaning might be applied to our understanding of how learners of different skill levels comprehend lines of code. We chose Python as the programming language of choice because it has quickly risen to be amongst the most popular programming languages, with a development philosophy centered on the idea of being &#x0201c;reader friendly.&#x0201d; Additionally, an increasing amount of contemporary research on code comprehension has focused on Python<sup><xref ref-type="bibr" rid="CR2">2</xref>,<xref ref-type="bibr" rid="CR3">3</xref>,<xref ref-type="bibr" rid="CR18">18</xref></sup>, though some research suggests that the central predictors of learning to code are common across programming languages<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>.</p><p id="Par8">To measure Python code comprehension, we recorded ERPs from 45 programmers of varying skill levels, assessed using an independent programming task (see "<xref rid="Sec9" ref-type="sec">Methods</xref>"), as they read lines of code presented incrementally (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>). Each trial began with the presentation of a global variable on the screen for 15&#x000a0;s. Afterward, a single line of code was presented incrementally, on an item-by-item basis. Items were defined as the parts of code that appeared between spaces. Participants were asked to read the code for comprehension and make a behavioral response about its &#x0201c;acceptability&#x0201d; (a term that was left intentionally vague to prevent biasing attention toward syntactic versus semantic aspects of the code) afterward. Participants read 160 lines of Python in total, consisting of 40 trials of each of the following conditions: (1) well-formed lines of code, (2) code with syntactic violations, (3) code with semantic implausibility, and (4) code with both semantic implausibility and syntactic violations. See the "<xref rid="Sec9" ref-type="sec">Methods</xref>" section for a more detailed description of the stimuli.<fig id="Fig1"><label>Figure 1</label><caption><p>Schematic depiction of a single trial. Following the presentation of the relevant global variable (15&#x000a0;s) for the upcoming trial, the line of code appeared incrementally on an item-by-item basis (700&#x000a0;ms, 200&#x000a0;ms ISI), with &#x0201c;item&#x0201d; defined as the elements of code that appeared between spaces. Participants made their acceptability judgment by pressing a button corresponding to Yes/No after the line of code finished presenting (30&#x000a0;s).</p></caption><graphic xlink:href="41598_2024_56090_Fig1_HTML" id="MO1"/></fig></p><p id="Par9">This research was designed to answer two questions: (1) Do the P600 and N400 ERP components index sensitivity to form and meaning when programmers comprehend lines of code incrementally? and (2) Does sensitivity to form change as a function of programming proficiency?</p><p id="Par10">Using L2 comprehension as a model, we predicted that manipulations of semantic plausibility would elicit N400 responses, while violations of syntactic validity would result in P600 responses. If evidence for increasing &#x0201c;grammaticalization&#x0201d; occurs when people learn a programming language, we would predict an interaction between Python expertise and the types of neural responses observed to our manipulations of well-formedness. Taken together, this study allows us to examine how coders of varying proficiency levels incrementally incorporate information about form and meaning into their mental representations of lines of code.</p></sec><sec id="Sec2"><title>Results</title><sec id="Sec3"><title>Behavioral code acceptability judgments</title><p id="Par11">The overall model predicting acceptability judgments has a total explanatory power of 73.70%, in which the fixed effects explain 66.30% of the variance. The model&#x02019;s intercept is at 45.59 (<italic>SE</italic>&#x02009;=&#x02009;1.96, 95% CI [41.75, 49.25], <italic>t</italic>(43)&#x02009;=&#x02009;23.29, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). Within this model, the effects of semantic plausibility and syntactic validity were both significant in predicting acceptability judgments. Specifically, participants judged well-formed code with higher acceptability rates than conditions where semantic implausibility (<italic>b</italic>&#x02009;=&#x02009;11.66, <italic>SE</italic>&#x02009;=&#x02009;2.69, 95% CI [6.39, 16.92], <italic>t</italic>(130)&#x02009;=&#x02009;4.34, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001) or syntactic violations (<italic>b</italic>&#x02009;=&#x02009;50.67, <italic>SE</italic>&#x02009;=&#x02009;2.69, 95% CI [45.51, 55.94], <italic>t</italic>(130)&#x02009;=&#x02009;18.87, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001) occurred (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>). The effect of syntactic validity was modified by an interaction with Python expertise, with higher Python expertise being associated with lower acceptability judgments to code containing syntactic violations (<italic>b</italic>&#x02009;=&#x02009;22.81, <italic>SE</italic>&#x02009;=&#x02009;2.69, 95% CI [17.53, 28.09], <italic>t</italic>(130)&#x02009;=&#x02009;8.47, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). On the contrary, the interaction between semantic plausibility and Python expertise approached significance in the opposite direction, with higher Python expertise being associated with higher acceptability judgments to code containing semantic implausibility (<italic>b</italic>&#x02009;=&#x02009;-5.30, <italic>SE</italic>&#x02009;=&#x02009;2.70, 95% CI [&#x02212;&#x02009;10.58, &#x02212;&#x02009;0.03], <italic>t</italic>(130)&#x02009;=&#x02009;&#x02212;&#x02009;1.97, <italic>p</italic>&#x02009;=&#x02009;0.051). The other fixed effects included in the model did not reach significance. Full model results for all fixed effects and random components are reported in Supplementary Tables <xref rid="MOESM1" ref-type="media">S1</xref>&#x02013;<xref rid="MOESM1" ref-type="media">S3</xref>.<fig id="Fig2"><label>Figure 2</label><caption><p>Acceptability judgments (%) for the four code conditions as a function of Python expertise (% on a Python knowledge test). The shaded region around the trend lines indicate the 95% confidence interval. The horizontal dashed lines indicate the mean code acceptability rate for each condition.</p></caption><graphic xlink:href="41598_2024_56090_Fig2_HTML" id="MO2"/></fig></p></sec><sec id="Sec4"><title>Group-level ERP analyses</title><p id="Par12">Group-level ERP responses for semantic plausibility (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>A), syntactic validity (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>B), and double anomalies (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>C) are plotted separately in Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>.<fig id="Fig3"><label>Figure 3</label><caption><p>Grand mean ERP waveforms for all participants (<italic>N</italic>&#x02009;=&#x02009;45). Well-formed code (black, solid) is compared to (<bold>a</bold>) semantically implausible code (pink, dashed), (<bold>b</bold>) syntactically invalid code (blue, dotted), and (<bold>c</bold>) doubly anomalous code (green, dash-dotted). The shaded region around the ERP waveforms indicate the 95% confidence interval. Onset of the target item of code in a given trial is indicated by the vertical bar. Calibration bar shows 3&#x000a0;&#x003bc;V of activity. Negative voltage is plotted up.</p></caption><graphic xlink:href="41598_2024_56090_Fig3_HTML" id="MO3"/></fig></p><sec id="Sec5"><title>N400 (300&#x02013;500&#x000a0;ms) time window</title><p id="Par13">The overall model predicting ERP responses within the N400 time window has a total explanatory power of 59.93%, in which the fixed effects explain 13.14% of the variance. The model&#x02019;s intercept is at &#x02212;&#x02009;0.02 (<italic>SE</italic>&#x02009;=&#x02009;0.39, 95% CI [&#x02212;&#x02009;0.78, 0.74], <italic>t</italic>(43)&#x02009;=&#x02009;&#x02212;&#x02009;0.05, <italic>p</italic>&#x02009;=&#x02009;0.964). Within this model, the effect of semantic plausibility was significant in predicting the N400 response (<italic>b</italic>&#x02009;=&#x02009;&#x02212;&#x02009;1.71, <italic>SE</italic>&#x02009;=&#x02009;0.20, 95% CI [&#x02212;&#x02009;2.11, &#x02212;&#x02009;1.32], <italic>t</italic>(488)&#x02009;=&#x02009;&#x02212;&#x02009;8.58, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). Code containing semantic implausibility resulted in larger negative deflections than did code without semantic implausibility. There was also a significant effect of syntactic validity, with syntactic anomalies resulting in larger positive deflections than well-formed code (<italic>b</italic>&#x02009;=&#x02009;1.40, <italic>SE</italic>&#x02009;=&#x02009;0.20, 95% CI [1.01, 1.70], <italic>t</italic>(488)&#x02009;=&#x02009;7.01, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). As is apparent in Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>B, this effect was likely driven by the later P600 effect described in the next section. Specifically, positive deflections to syntactically invalid code in the P600 time window were large enough to be detectable within the earlier N400 time window. There was no significant interaction between semantic plausibility and syntactic validity. However, there was a significant effect of electrode, with the effect being driven by more negative deflections at the midline central electrode than at the midline parietal electrode (<italic>b</italic>&#x02009;=&#x02009;&#x02212;&#x02009;1.18, <italic>SE</italic>&#x02009;=&#x02009;0.24, 95% CI [&#x02212;&#x02009;1.66, &#x02212;&#x02009;0.70], <italic>t</italic>(488)&#x02009;=&#x02009;&#x02212;&#x02009;4.81, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). Full model results for all fixed effects and random components are reported in Supplementary Tables <xref rid="MOESM1" ref-type="media">S4</xref>&#x02013;<xref rid="MOESM1" ref-type="media">S6</xref>.</p></sec><sec id="Sec6"><title>P600 (500&#x02013;800&#x000a0;ms) time window</title><p id="Par14">The overall model predicting ERP responses within the P600 time window has a total explanatory power of 56.76%, in which the fixed effects explain 31.87% of the variance. The model&#x02019;s intercept is at 2.07 (<italic>SE</italic>&#x02009;=&#x02009;0.28, 95% CI [1.52, 2.62], <italic>t</italic>(43)&#x02009;=&#x02009;7.35, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). Within this model, the effect of syntactic validity was significant in predicting the P600 response (<italic>b</italic>&#x02009;=&#x02009;2.97, <italic>SE</italic>&#x02009;=&#x02009;0.20, 95% CI [2.58, 3.36], <italic>t</italic>(488)&#x02009;=&#x02009;14.84, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). Code containing syntactic anomalies resulted in larger positive deflections than code without syntactic anomalies. There was no significant effect of semantic plausibility or significant interaction between semantic plausibility and syntactic validity in the P600 window. However, there was a significant effect of electrode, with all three electrode sites differing in amplitudes from each other. There were more positive deflections recorded at the midline frontal electrode than at the midline central electrode (<italic>b</italic>&#x02009;=&#x02009;0.62, <italic>SE</italic>&#x02009;=&#x02009;0.25, 95% CI [0.14, 1.10], <italic>t</italic>(488)&#x02009;=&#x02009;2.54, <italic>p</italic>&#x02009;=&#x02009;0.011), which in turn recorded more positive deflections than the midline parietal electrode (<italic>b</italic>&#x02009;=&#x02009;1.50, <italic>SE</italic>&#x02009;=&#x02009;0.25, 95% CI [1.01, 1.98], <italic>t</italic>(488)&#x02009;=&#x02009;1.71, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001). Full model results for all fixed effects and random components are reported in Supplementary Tables <xref rid="MOESM1" ref-type="media">S7</xref>&#x02013;<xref rid="MOESM1" ref-type="media">S9</xref>.</p></sec></sec><sec id="Sec7"><title>Effects of expertise on ERP responses</title><p id="Par15">Python expertise, along with its interaction with semantic plausibility and syntactic validity, were also included as fixed effects in the models predicting N400 and P600 responses. Within the P600 window, Python expertise significantly predicted ERP responses (<italic>b</italic>&#x02009;=&#x02009;0.83, <italic>SE</italic>&#x02009;=&#x02009;0.28, 95% CI [0.28, 1.38], <italic>t</italic>(43)&#x02009;=&#x02009;2.94, <italic>p</italic>&#x02009;=&#x02009;0.005). There was also a significant interaction between Python expertise and syntactic validity (<italic>b</italic>&#x02009;=&#x02009;1.04, <italic>SE</italic>&#x02009;=&#x02009;0.20, 95% CI [0.64, 1.43], <italic>t</italic>(488)&#x02009;=&#x02009;5.18, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001), but not semantic plausibility. With increasing expertise, programmers exhibited a stronger P600 effect to code containing syntactic anomalies than to code without syntactic anomalies (Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>). There was also a significant interaction between Python expertise and syntactic validity within the N400 window (<italic>b</italic>&#x02009;=&#x02009;0.45, <italic>SE</italic>&#x02009;=&#x02009;0.20, 95% CI [0.06, 0.84], <italic>t</italic>(488)&#x02009;=&#x02009;2.24, <italic>p</italic>&#x02009;=&#x02009;0.025) that was likely driven by the same interaction within the P600 window. With increasing expertise, programmers exhibited more positive deflections to syntactically invalid code in the P600 time window, causing these effects to be more detectable within the earlier N400 time window. Full details of the effect of Python expertise on ERP responses are reported in Supplementary Tables <xref rid="MOESM1" ref-type="media">4</xref>&#x02013;<xref rid="MOESM1" ref-type="media">5</xref> (N400 window) and <xref rid="MOESM1" ref-type="media">7</xref>&#x02013;<xref rid="MOESM1" ref-type="media">8</xref> (P600 window).<fig id="Fig4"><label>Figure 4</label><caption><p>Amplitude of P600 responses (&#x003bc;V) to code with (blue) and without (black) syntactic anomalies, collapsed across semantic plausibility and electrodes, as a function of Python expertise (% on a Python knowledge test). Negative voltage is plotted up to mirror the traditional ERP plotting method. The shaded region around the trend lines indicate the 95% confidence interval.</p></caption><graphic xlink:href="41598_2024_56090_Fig4_HTML" id="MO4"/></fig></p><p id="Par16">For visualization purposes, we also plotted the mean ERP responses of Python experts (<italic>N</italic>&#x02009;=&#x02009;27) and Python novices (<italic>N</italic>&#x02009;=&#x02009;18) at the midline central electrode in Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>. Python knowledge test accuracies (see "<xref rid="Sec9" ref-type="sec">Methods</xref>") were used to determine the two groups of Python expertise. Participants who scored 75% or higher on the Python knowledge test were considered experts, whereas participants who scored less than 75% were considered novices. 75% corresponds to a 2.0 on a standard 4.0 GPA scale, which is the lowest passing grade allowed for some courses with more stringent grading policies at the University of Washington, where this experiment was conducted.<fig id="Fig5"><label>Figure 5</label><caption><p>Summary of the ERP waveforms for Python experts (<italic>N</italic>&#x02009;=&#x02009;27) versus Python novices (<italic>N</italic>&#x02009;=&#x02009;18) for all four conditions at the midline central electrode. Onset of the target item of code in a given trial is indicated by the vertical bar. Calibration bar shows 3&#x000a0;&#x003bc;V of activity. Negative voltage is plotted up.</p></caption><graphic xlink:href="41598_2024_56090_Fig5_HTML" id="MO5"/></fig></p></sec></sec><sec id="Sec8"><title>Discussion</title><p id="Par17">To the best of our knowledge, this is the first empirical data supporting the cognitive comparisons between reading and code comprehension first outlined by Fedorenko et al.<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>. Specifically, our data suggest that when skilled programmers read lines of code, they use information about both statement-level form and token-level meaning to incrementally update their mental representation of what the code is trying to accomplish, much like readers of a natural language use information about grammatical structure and word-level semantics to understand what a sentence means. In our experiment, this was reflected by the distinct N400 and P600 effects exhibited by programmers to semantic and syntactic manipulations of code, respectively.</p><p id="Par18">Furthermore, results from this study suggest that as programmers gain expertise in a particular programming language, their brain responses increasingly reflect sensitivity to rule-based knowledge in their online comprehension processes. This progression, termed &#x0201c;grammaticalization&#x0201d; in natural language learning, is also observed with increasing proficiency in second natural language acquisition<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>. Although our analysis of expertise was cross-sectional, it is notable that this pattern of increased P600 effects with higher expertise has been demonstrated in both cross-sectional<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> and longitudinal<sup><xref ref-type="bibr" rid="CR15">15</xref></sup> studies of learners of a second natural language. As such, we would expect to see a similar trend in which stronger P600 effects would emerge over time with increasing exposure to programming languages. We see this as an interesting area for future research.</p><p id="Par19">It is worth noting that programming expertise may not have influenced neural sensitivity to semantic manipulations, but the manner in which we manipulated semantic plausibility reflected pre-existing semantic relations (e.g., categorical relations among variable names) rather than code-specific relations (e.g., substituting functions that are related to, but not the intended, operation in a line of code). Though our semantic manipulations are far from a complete exploration, similar categorical manipulations have been used to understand the cognitive underpinnings of mathematical comprehension<sup><xref ref-type="bibr" rid="CR14">14</xref></sup> both at the group and individual levels. Additionally, these findings suggest that programmers of varying expertise levels show neural sensitivity to pre-existing semantic relations in lines of code, even when they have little to no relevance for what the code does (e.g., in variable names). This additional neural activation has been proposed to reflect increased difficulty in either retrieving the meaning of the target item<sup><xref ref-type="bibr" rid="CR12">12</xref>,<xref ref-type="bibr" rid="CR19">19</xref>,<xref ref-type="bibr" rid="CR20">20</xref></sup> or integrating that meaning into the overall representation of the structure at hand<sup><xref ref-type="bibr" rid="CR21">21</xref></sup>. The behavioral trend we observed also suggests that less skilled programmers, whose rule-based processes have not fully come online yet, are marginally more likely to judge a well-formed line of code as unacceptable when the semantic relations among items are implausible. Taken together, these data support the notion that using pre-existing meaning associations can facilitate code comprehension for some individuals. This is consistent with previous work demonstrating that meaningful and efficient identifiers promote faster and more accurate code comprehension<sup><xref ref-type="bibr" rid="CR22">22</xref>&#x02013;<xref ref-type="bibr" rid="CR24">24</xref></sup>.</p><p id="Par20">When interpreting these results, we note that the observation of language-like responses to violations in lines of code does not, in and of itself, provide evidence that code comprehension relies on the <italic>same</italic> neural substrates as language comprehension. Such an inference would require a tool with better spatial resolution, such as fMRI, and the results from such studies have been mixed<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR2">2</xref>,<xref ref-type="bibr" rid="CR8">8</xref></sup>. Instead, these results contribute to the growing body of work indicating that the N400 and P600 components are not <italic>specific</italic> to natural language processing<sup><xref ref-type="bibr" rid="CR12">12</xref>&#x02013;<xref ref-type="bibr" rid="CR14">14</xref>,<xref ref-type="bibr" rid="CR25">25</xref>,<xref ref-type="bibr" rid="CR26">26</xref></sup>. Findings from research employing diverse stimuli including mathematical word problems<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>, natural language<sup><xref ref-type="bibr" rid="CR12">12</xref>,<xref ref-type="bibr" rid="CR13">13</xref></sup>, music<sup><xref ref-type="bibr" rid="CR25">25</xref>,<xref ref-type="bibr" rid="CR26">26</xref></sup>, and now Python code converge to demonstrate common neurocomputations that lie at the heart of integrating sequential information incrementally into a larger meaning structure. In light of these similarities, we propose that the current debate about whether code is more &#x0201c;language-like&#x0201d; or &#x0201c;mathematics-like&#x0201d; might be better framed by questioning the types of information programmers use to understand what a line of code does, and how this evolves as they become more proficient.</p><p id="Par21">In summary, we present the first study showcasing that programmers exhibit neural sensitivity to information about form and meaning as they engage in real-time incremental building of mental representations during code comprehension. When doing so, expert programmers are more sensitive to the structural relations among items, characterized by prominent brain responses to syntactic violations within 600&#x000a0;ms of seeing an item. In contrast, programmers of varying skill levels exhibit similar neural sensitivity to the pre-existing semantic relations among items in the code, with more novice programmers showing marginally greater reliance on such information when making offline behavioral &#x0201c;acceptability&#x0201d; judgments. Taken together, these results suggest that the processes that support code comprehension resemble those of other learned symbolic, rule-based systems such as reading, algebra, and classroom-based L2 learning.</p></sec><sec id="Sec9"><title>Methods</title><sec id="Sec10"><title>Participants</title><p id="Par22">Sixty-two right-handed individuals aged 18&#x02013;33&#x000a0;years with normal or corrected-to normal vision and no history of significant head injury or epilepsy were recruited for participation in this study. All participants had a minimum of the equivalent of one academic quarter&#x02019;s worth of Python instruction, either through a live course taught by an instructor or self-taught via an online course. One individual did not return for the ERP session and was removed from all analyses. Of the remaining 61 individuals, 16 exceeded the maximum 25% rejection rate threshold for their averaged ERPs and were removed from all analyses (see Data analysis). The final sample consisted of 45 English-speaking participants (23 female, 21 male, 1 other) from various natural language backgrounds. One participant wore hearing aids during EEG recording. For additional participant demographics, see Supplementary Table <xref rid="MOESM1" ref-type="media">S10</xref>. All experimental procedures were approved by the University of Washington Institutional Review Board and performed in accordance with relevant guidelines and regulations. Participants gave informed consent prior to the start of the experiment and were monetarily compensated for their time.</p></sec><sec id="Sec11"><title>Materials</title><sec id="Sec12"><title>Python knowledge test</title><p id="Par23">Participants completed a 72-question multiple-choice test as a quantitative measurement of their Python proficiency<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>. Half of the questions measured semantic knowledge, such as the purpose of functions and operators (e.g., &#x0201c;What does the print() function do?&#x0201d;). The other half measured knowledge about syntax, or structural rules of Python (e.g., &#x0201c;Why won&#x02019;t the following code compile?&#x0201d;). This measure was developed as part of another study that assessed learners&#x02019; Python knowledge following weekly lessons in the Python 2 course on Codecademy<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>. As such, the questions were created according to the material covered, including, but not limited to strings, conditionals, functions, lists, dictionaries, and loops. Python proficiency was quantified as a percentage accuracy score by dividing the total number of questions correct by 72 total possible questions. For Python knowledge test results, see Supplementary Table <xref rid="MOESM1" ref-type="media">S10</xref>.</p></sec><sec id="Sec13"><title>ERP stimuli</title><p id="Par24">Lines of Python code were created by crossing semantic plausibility and syntactic validity in a two by two design. A unique global variable preceded every line of code, which provided thematic context for an individual trial. Global variables could be strings, integers, floats, lists, or dictionaries. Each line of code contained a single item that was either semantically plausible or semantically implausible given the global variable, as well as either syntactically valid or syntactically invalid according to the syntax rules of Python 3.0. This resulted in four different code conditions: (1) well-formed, (2) semantically implausible, (3) syntactically invalid, and (4) doubly anomalous (semantically implausible and syntactically invalid). All lines of code spanned five to nine item lengths with the violation position occurring at two, three, or four.</p><p id="Par25">To provide variability in stimuli, two code structures were used in this experiment: for loops and list comprehensions (Table <xref rid="Tab1" ref-type="table">1</xref>). Violations were created by manipulating one of two code types: variables or keywords. Variables are placeholder words (i.e., iterators) that parse through each item of an iterable, such as a list or a dictionary. Although variables can be named using any combination of letters and numbers, it is common practice to give them an identifier that is thematically consistent with the object being iterated through. For example, if referencing the list <italic>pets</italic>&#x02009;=&#x02009;<italic>[&#x0201c;dog&#x0201d;, &#x0201c;cat&#x0201d;, &#x0201c;hamster&#x0201d;]</italic>, a variable named <italic>animal</italic> (e.g., <italic>for every </italic><italic><underline>animal</underline></italic><italic> in the list pets&#x02026;</italic>) rather than <italic>fruit</italic> (e.g., <italic>for every </italic><italic><underline>fruit</underline></italic><italic> in the list pets&#x02026;</italic>) would be more semantically appropriate for iterating through each list item. However, variables cannot be attached to operators or symbols, such as quotations that are used to signify a string. Therefore, a variable written as <italic>animal</italic> rather than <italic>&#x0201c;animal&#x0201d;</italic> (e.g., <italic>for every </italic><italic><underline>&#x0201c;animal&#x0201d;</underline></italic><italic> in the list pets&#x02026;</italic>) would be the syntactically appropriate form. As such, variables can be manipulated to be semantically implausible, syntactically invalid, or doubly anomalous (e.g., <italic>for every </italic><italic><underline>&#x0201c;fruit&#x0201d;</underline></italic><italic> in the list pets&#x02026;</italic>). On the contrary, keywords are reserved words that have specific roles, and they cannot be used as variable names, function names, or other identifiers. The present study manipulated two keywords, <italic>if</italic> and <italic>in</italic>, by replacing them with other English words that were either approximate synonyms or semantically dissimilar. For example, the keyword <italic>in</italic> could be replaced with <italic>within</italic> (an approximate synonym) or <italic>under</italic> (semantically dissimilar). However, because keywords are built-in, they cannot be manipulated to be semantically implausible while remaining syntactically valid according to Python syntax rules. As such, keywords can only be manipulated to be syntactically invalid (e.g., <italic>for every animal </italic><italic><underline>within</underline></italic><italic> the list pets&#x02026;</italic>) or doubly anomalous (e.g., <italic>for every animal </italic><italic><underline>under</underline></italic><italic> the list pets&#x02026;</italic>). In order to accommodate for this imbalance, additional lines of code that manipulated the variable were written to allow for a balanced, fully crossed two by two design.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Stimulus examples.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Condition</th><th align="left">Example For Loop</th><th align="left">Example List Comprehension</th></tr></thead><tbody><tr><td align="left"><italic>Global variable</italic></td><td align="left">pets&#x02009;=&#x02009;[&#x0201c;dog&#x0201d;, &#x0201c;cat&#x0201d;, &#x0201c;hamster&#x0201d;]</td><td align="left">felines&#x02009;=&#x02009;[&#x0201c;lion&#x0201d;, &#x0201c;tiger&#x0201d;, &#x0201c;leopard&#x0201d;]</td></tr><tr><td align="left">Well-formed</td><td align="left">for <underline>animal</underline> in pets: print(animal)</td><td align="left">[&#x0201c;purr&#x0201d; for <underline>cat</underline> in felines if cat&#x02009;=&#x02009;&#x02009;=&#x02009;&#x0201c;tiger&#x0201d;]</td></tr><tr><td align="left">Semantically implausible</td><td align="left">for <underline>fruit</underline> in pets: print(fruit)</td><td align="left">[&#x0201c;purr&#x0201d; for <underline>wheel</underline> in felines if cat&#x02009;=&#x02009;&#x02009;=&#x02009;&#x0201c;tiger&#x0201d;]</td></tr><tr><td align="left">Syntactically invalid</td><td align="left">for <underline>&#x0201c;animal&#x0201d;</underline> in pets: print(animal)</td><td align="left">[&#x0201c;purr&#x0201d; for <underline>&#x0201c;cat&#x0201d;</underline> in felines if cat&#x02009;=&#x02009;&#x02009;=&#x02009;&#x0201c;tiger&#x0201d;]</td></tr><tr><td align="left">Doubly anomalous</td><td align="left">for <underline>&#x0201c;fruit&#x0201d;</underline> in pets: print(fruit)</td><td align="left">[&#x0201c;purr&#x0201d; for &#x0201c;<underline>wheel&#x0201d;</underline> in felines if cat&#x02009;=&#x02009;&#x02009;=&#x02009;&#x0201c;tiger&#x0201d;]</td></tr></tbody></table><table-wrap-foot><p>The critical piece of code for ERP averaging is underlined. The second row indicates the global variable that is shown prior to that given example stimulus.</p></table-wrap-foot></table-wrap></p><p id="Par26">For the lines of code in which it was possible, the four versions corresponding to each condition were distributed across four experimental lists, such that each list only had one version of each line of code. Participants saw 160 lines of code, with 40 lines from each condition. In the well-formed, syntactically invalid, and doubly anomalous conditions, the 40 lines of code were split between 20 manipulations of variables and 20 manipulations of keywords. In the semantically implausible condition, all 40 lines of code were manipulations of variables. Each list was divided into 4 blocks of 40 sentences each, and each block contained 10 lines of code from each condition. The 20 additional lines of code written to round out the semantically implausible condition were included in each list. Lines of code were pseudo-randomized within each list, and list assignment was pseudo-randomized across participants. Complete stimulus lists can be found on OpenNeuro in the Stimulus folder (see Data availability).</p></sec></sec><sec id="Sec14"><title>Procedure</title><sec id="Sec15"><title>Main experiment</title><p id="Par27">Participants took part in two sessions, each lasting no more than two hours. With the exception of one individual, all participants completed the experiment in the same session order. Session 1 was administered over videoconference, during which participants completed all questionnaires and tasks related to demographics, natural language background, and programming experience. During Session 2 on a separate day, participants judged individual lines of Python code for acceptability while electroencephalogram recordings were obtained. After being seated in a desk chair in front of a CRT monitor, participants were instructed to relax and minimize movements and eye blinks while silently reading the stimuli in their minds. Each trial consisted of the following events: Participants were given 15&#x000a0;s to read the global variable to be referenced in the upcoming line of code, or they could proceed earlier by clicking a mouse button. Following a 1000&#x000a0;ms fixation cross and 200 ISI, the line of code appeared incrementally in the center of the screen one item at a time, as defined by blank space, at a presentation rate of 700&#x000a0;ms and 200&#x000a0;ms ISI. These slower presentation rates are standard for ERP studies of a second language, for both native speakers and learners<sup><xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR17">17</xref>,<xref ref-type="bibr" rid="CR26">26</xref>&#x02013;<xref ref-type="bibr" rid="CR28">28</xref></sup> (see Supplementary Methods for details of the behavioral pilot study that was conducted to determine optimal presentation rate). After the line of code was finished displaying, a &#x0201c;Yes/No&#x0201d; screen followed, during which participants had 30&#x000a0;s to give their acceptability judgment by pressing one of two mouse buttons. &#x0201c;Yes&#x0201d; corresponded to lines of code that were acceptable, and &#x0201c;No&#x0201d; corresponded to lines of code that were unacceptable. Participants were asked to use their own criteria for what they considered to be &#x0201c;acceptable&#x0201d; and to keep this criteria consistent throughout the session. The order of the &#x0201c;Yes/No&#x0201d; response buttons (left/right) was pseudo-randomized across participants. Once a response was given, a &#x0201c;READY?&#x0201d; prompt appeared, and participants would click either mouse button to begin the next trial.</p></sec></sec><sec id="Sec16"><title>Data analysis</title><sec id="Sec17"><title>Behavioral code acceptability judgment task</title><p id="Par28">Behavioral performance on the ERP task was assessed via acceptability judgment rates, which were calculated as the percentage of trials that participants considered to be &#x0201c;acceptable,&#x0201d; i.e., responded with &#x0201c;Yes&#x0201d; during the end-of-code judgment task. We ran a linear mixed model fit by restricted maximum likelihood (REML) using the GAMLj module in Jamovi<sup><xref ref-type="bibr" rid="CR29">29</xref>&#x02013;<xref ref-type="bibr" rid="CR31">31</xref></sup>. Acceptability rates (&#x0201c;Acceptability&#x0201d;) were predicted from fixed effects of semantic plausibility (&#x0201c;Semantics&#x0201d;), syntactic validity (&#x0201c;Syntax&#x0201d;), and Python expertise (&#x0201c;Expertise&#x0201d;). Two levels of semantic plausibility (semantically plausible, semantically implausible) and two levels of syntactic validity (syntactically valid, syntactically invalid) accounted for the four code conditions. Python expertise was entered as a participant&#x02019;s z-transformed Python knowledge test score. Interactions between semantic plausibility and syntactic validity, semantic plausibility and Python expertise, and syntactic validity and Python expertise were also included in the model as fixed effects. Participants (&#x0201c;Subject&#x0201d;) were included as a random effect in which the intercept was permitted to vary. Altogether, the model specification was as follows: Acceptability&#x02009;~&#x02009;1&#x02009;+&#x02009;Semantics&#x02009;+&#x02009;Syntax&#x02009;+&#x02009;Expertise&#x02009;+&#x02009;Semantics:Syntax&#x02009;+&#x02009;Semantics:Expertise&#x02009;+&#x02009;Syntax:Expertise&#x02009;+&#x02009;(1 | Subject). The Satterthwaite method was used to estimate degrees of freedom and generate <italic>p</italic>-values.</p></sec><sec id="Sec18"><title>EEG acquisition</title><p id="Par29">Continuous EEG was recorded from 32 scalp electrodes placed in International 10&#x02013;20 system locations attached to a Biosemi elastic cap<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>. Eye movements and blinks were monitored by two electrodes placed beneath the left eye and to the right of the right eye. Electrodes were referenced to an electrode placed over the left mastoid during recording, then subsequently re-referenced to the average of two electrodes placed over the left mastoid and right mastoid during pre-processing. EEG signals were amplified with a bandpass filter of 0.01 to 30&#x000a0;Hz by a Biosemi bioamplifier system. Impedances at scalp electrodes were held below 50&#x000a0;Hz. Continuous analog-to-digital conversion of the EEG and stimulus trigger codes was performed at a sampling frequency of 200&#x000a0;Hz.</p></sec><sec id="Sec19"><title>EEG cleaning</title><p id="Par30">For each participant, epochs of EEG signal were segmented around the critical item of code from &#x02212;&#x02009;100&#x000a0;ms to 1205&#x000a0;ms. Epochs were removed from ERP averaging if they contained changes within a sliding 200&#x000a0;ms window that were greater than 100&#x000a0;&#x000b5;V in the midline central electrode. Trials characterized by excessive eye movement, muscle artifact, and alpha were further removed prior to averaging; these were epochs that showed voltage steps more extreme than &#x02212;&#x02009;65&#x000a0;&#x000b5;V or 65&#x000a0;&#x000b5;V within any electrode. Participants who had a&#x02009;&#x0003e;&#x02009;25% artifact rejection rate were removed from analysis altogether, resulting in the final sample of 45 individuals. The average rejection rate for participants who were included in the final analyses was 6.8% (by condition: well-formed: 7.5%, semantically implausible: 6.4%, syntactically invalid: 6.9%, doubly anomalous: 6.4%). Due to a malfunction in the recording equipment, two participants in the final analyses had fewer than 160 trials (159 and 158 trials); both individuals averaged rejection rates of 3.8%.</p></sec><sec id="Sec20"><title>EEG analysis</title><p id="Par31">ERPs time-locked to the onset of the critical item of code in each line of code were averaged offline at each electrode site in each condition. The epochs that went into ERP averaging were base-line corrected from &#x02212;&#x02009;100&#x000a0;ms to 0&#x000a0;ms. As is standard, the following time windows were chosen for analysis: 300&#x02013;500&#x000a0;ms (N400) and 500&#x02013;800&#x000a0;ms (P600), with separate analyses conducted for each window. All trials (both acceptable and not acceptable judgment responses) were included in the final analysis. This decision was made for two reasons: First, previous research has shown that neural sensitivity to anomalies sometimes precedes behavioral sensitivity in L2 learners<sup><xref ref-type="bibr" rid="CR33">33</xref></sup>, and second, the definition of &#x0201c;acceptable&#x0201d; was intentionally made ambiguous so that learners could decide how to treat semantically anomalous trials. This made deciding whether trials were correct or incorrect difficult in some conditions.</p><p id="Par32">We ran linear mixed models fit by restricted maximum likelihood (REML) using the GAMLj module in Jamovi<sup><xref ref-type="bibr" rid="CR29">29</xref>&#x02013;<xref ref-type="bibr" rid="CR31">31</xref></sup>. ERP responses (&#x0201c;Amplitude&#x0201d;) were predicted from fixed effects of semantic plausibility (&#x0201c;Semantics&#x0201d;), syntactic validity (&#x0201c;Syntax&#x0201d;), Python expertise (&#x0201c;Expertise&#x0201d;), and electrode (&#x0201c;Electrode&#x0201d;) for each time window. As in the model predicting acceptability judgments, two levels of semantic plausibility (semantically plausible, semantically implausible) and two levels of syntactic validity (syntactically valid, syntactically invalid) accounted for the four code conditions. Python expertise was entered as a participant&#x02019;s z-transformed Python knowledge test score. We had no hypotheses that were centered on scalp topography; therefore, we included data from the midline frontal, central, and parietal electrodes as three levels of electrode. Interactions between semantic plausibility and syntactic validity, semantic plausibility and Python expertise, and syntactic validity and Python expertise were also included in the model as fixed effects. Participants (&#x0201c;Subject&#x0201d;) were included as a random effect in which the intercept was permitted to vary. Altogether, the model specification for both time windows was as follows: Amplitude&#x02009;~&#x02009;1&#x02009;+&#x02009;Semantics&#x02009;+&#x02009;Syntax&#x02009;+&#x02009;Expertise&#x02009;+&#x02009;Electrode&#x02009;+&#x02009;Semantics:Syntax&#x02009;+&#x02009;Semantics:Expertise&#x02009;+&#x02009;Syntax:Expertise&#x02009;+&#x02009;(1 | Subject). The Satterthwaite method was used to estimate degrees of freedom and generate <italic>p</italic>-values.</p><p id="Par33">We also conducted another set of linear mixed models that added the fixed effect of English proficiency (&#x0201c;English&#x0201d;), as well as its interactions with semantic plausibility and syntactic validity, to see if we could better predict code acceptability judgments and ERP responses. English proficiency was determined via a participant&#x02019;s score on the Nelson-Denny Reading Comprehension test<sup><xref ref-type="bibr" rid="CR34">34</xref></sup> and was entered into the models after z-transformation. The full results of the models that added English proficiency are reported in Supplementary Tables <xref rid="MOESM1" ref-type="media">S11</xref>&#x02013;<xref rid="MOESM1" ref-type="media">S13</xref> (code acceptability judgments), <xref rid="MOESM1" ref-type="media">S14</xref>&#x02013;<xref rid="MOESM1" ref-type="media">S16</xref> (N400 window), and <xref rid="MOESM1" ref-type="media">S17</xref>&#x02013;<xref rid="MOESM1" ref-type="media">S19</xref> (P600 window). Comparison of BIC values showed that these models did not improve upon the models that did not include English proficiency (Supplementary Table <xref rid="MOESM1" ref-type="media">S20</xref>). As such, we focused our discussion on the implications of Python expertise.</p></sec></sec></sec><sec sec-type="supplementary-material"><sec id="Sec21"><title>Supplementary Information</title><p>
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="41598_2024_56090_MOESM1_ESM.pdf"><caption><p>Supplementary Information.</p></caption></media></supplementary-material></p></sec></sec></body><back><fn-group><fn><p><bold>Publisher's note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><sec><title>Supplementary Information</title><p>The online version contains supplementary material available at 10.1038/s41598-024-56090-6.</p></sec><ack><title>Acknowledgements</title><p>Funding for this research was provided by the Office of Naval Research, Cognitive Science of Learning program (N00014-20-1-2393). We would like to thank Mark Pettet for assistance with data analysis and the organization of data in BIDS format, as well as the members of the Cognition and Cortical Dynamics Laboratory for help with piloting stimuli and data collection.</p></ack><notes notes-type="author-contribution"><title>Author contributions</title><p>C-H.K.&#x02014;conceptualization, formal analysis, methodology, project administration, supervision, visualization, writing-original draft, review and editing; C.P.&#x02014;conceptualization, funding acquisition, methodology, resources, writing-original draft, review and editing.</p></notes><notes notes-type="data-availability"><title>Data availability</title><p>All data is available in the manuscript, supplementary materials, or on OpenNeuro: <ext-link ext-link-type="uri" xlink:href="https://openneuro.org/datasets/ds004771">https://openneuro.org/datasets/ds004771.</ext-link></p></notes><notes id="FPar1" notes-type="COI-statement"><title>Competing interests</title><p id="Par34">The authors declare no competing interests.</p></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><mixed-citation publication-type="other">Floyd, B., Santander, T. &#x00026; Weimer, W. Decoding the representation of code in the brain: an fMRI study of code review and expertise. in <italic>2017 IEEE/ACM 39th Int Conf Softw Eng</italic>, 175&#x02013;186 (2017).</mixed-citation></ref><ref id="CR2"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ivanova</surname><given-names>AA</given-names></name><etal/></person-group><article-title>Comprehension of computer code relies primarily on domain-general executive brain regions</article-title><source>eLife</source><year>2020</year><volume>9</volume><fpage>e58906</fpage><pub-id pub-id-type="doi">10.7554/eLife.58906</pub-id><?supplied-pmid 33319744?><pub-id pub-id-type="pmid">33319744</pub-id>
</element-citation></ref><ref id="CR3"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prat</surname><given-names>CS</given-names></name><name><surname>Madhyastha</surname><given-names>TM</given-names></name><name><surname>Mottarella</surname><given-names>MJ</given-names></name><name><surname>Kuo</surname><given-names>CH</given-names></name></person-group><article-title>Relating natural language aptitude to individual differences in learning programming languages</article-title><source>Sci. Rep.</source><year>2020</year><volume>10</volume><fpage>3817</fpage><pub-id pub-id-type="doi">10.1038/s41598-020-60661-8</pub-id><?supplied-pmid 32123206?><pub-id pub-id-type="pmid">32123206</pub-id>
</element-citation></ref><ref id="CR4"><label>4.</label><mixed-citation publication-type="other">Jenkins, T. On the difficulty of learning to program. <italic>Proceedings of the 3rd Annual Conference of the LTSN Centre for Information and Computer Sciences</italic><bold>4,</bold> 53&#x02013;58 (2002).</mixed-citation></ref><ref id="CR5"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bennedsen</surname><given-names>J</given-names></name><name><surname>Caspersen</surname><given-names>ME</given-names></name></person-group><article-title>Failure rates in introductory programming: 12 years later</article-title><source>ACM Inroads</source><year>2019</year><volume>10</volume><fpage>30</fpage><lpage>36</lpage><pub-id pub-id-type="doi">10.1145/3324888</pub-id></element-citation></ref><ref id="CR6"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fedorenko</surname><given-names>E</given-names></name><name><surname>Ivanova</surname><given-names>AA</given-names></name><name><surname>Dhamala</surname><given-names>R</given-names></name><name><surname>Bers</surname><given-names>MU</given-names></name></person-group><article-title>The language of programming: A cognitive perspective</article-title><source>Trends Cogn. Sci.</source><year>2019</year><volume>23</volume><fpage>525</fpage><lpage>528</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2019.04.010</pub-id><?supplied-pmid 31153775?><pub-id pub-id-type="pmid">31153775</pub-id>
</element-citation></ref><ref id="CR7"><label>7.</label><mixed-citation publication-type="other">Kuo, C-H., Mottarella, M., Haile, T. &#x00026; Prat, C. S. Predicting programming success: how intermittent knowledge assessments, individual psychometrics, and resting-state EEG predict Python programming and debugging skills. in <italic>2022 International Conference on Software, Telecommunications and Computer Networks</italic>, 1&#x02013;6 (2022).</mixed-citation></ref><ref id="CR8"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y-F</given-names></name><name><surname>Kim</surname><given-names>J</given-names></name><name><surname>Wilson</surname><given-names>C</given-names></name><name><surname>Bedny</surname><given-names>M</given-names></name></person-group><article-title>Computer code comprehension shares neural resources with formal logical inference in the fronto-parietal network</article-title><source>eLife</source><year>2020</year><volume>9</volume><fpage>e59340</fpage><pub-id pub-id-type="doi">10.7554/eLife.59340</pub-id><?supplied-pmid 33319745?><pub-id pub-id-type="pmid">33319745</pub-id>
</element-citation></ref><ref id="CR9"><label>9.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Carroll</surname><given-names>J</given-names></name><name><surname>Sapon</surname><given-names>S</given-names></name></person-group><source>Modern Language Aptitude Test</source><year>1959</year><publisher-name>Psychological Corporation</publisher-name></element-citation></ref><ref id="CR10"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sebastian</surname><given-names>R</given-names></name><name><surname>Laird</surname><given-names>AR</given-names></name><name><surname>Kiran</surname><given-names>S</given-names></name></person-group><article-title>Meta-analysis of the neural representation of first language and second language</article-title><source>Appl. Psycholinguist.</source><year>2011</year><volume>32</volume><fpage>799</fpage><lpage>819</lpage><pub-id pub-id-type="doi">10.1017/S0142716411000075</pub-id></element-citation></ref><ref id="CR11"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brouwer</surname><given-names>H</given-names></name><name><surname>Crocker</surname><given-names>MW</given-names></name><name><surname>Venhuizen</surname><given-names>NJ</given-names></name><name><surname>Hoeks</surname><given-names>JC</given-names></name></person-group><article-title>A neurocomputational model of the N400 and the P600 in language processing</article-title><source>Cogn. Sci.</source><year>2017</year><volume>41</volume><fpage>1318</fpage><lpage>1352</lpage><pub-id pub-id-type="doi">10.1111/cogs.12461</pub-id><?supplied-pmid 28000963?><pub-id pub-id-type="pmid">28000963</pub-id>
</element-citation></ref><ref id="CR12"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kutas</surname><given-names>M</given-names></name><name><surname>Federmeier</surname><given-names>KD</given-names></name></person-group><article-title>Thirty years and counting: Finding meaning in the N400 component of the event-related brain potential (ERP)</article-title><source>Annu. Rev. Psychol.</source><year>2011</year><volume>62</volume><fpage>621</fpage><lpage>647</lpage><pub-id pub-id-type="doi">10.1146/annurev.psych.093008.131123</pub-id><?supplied-pmid 20809790?><pub-id pub-id-type="pmid">20809790</pub-id>
</element-citation></ref><ref id="CR13"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Osterhout</surname><given-names>L</given-names></name><name><surname>Holcomb</surname><given-names>PJ</given-names></name></person-group><article-title>Event-related brain potentials elicited by syntactic anomaly</article-title><source>J. Mem. Lang.</source><year>1992</year><volume>31</volume><fpage>785</fpage><lpage>806</lpage><pub-id pub-id-type="doi">10.1016/0749-596X(92)90039-Z</pub-id></element-citation></ref><ref id="CR14"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guthormsen</surname><given-names>AM</given-names></name><etal/></person-group><article-title>Conceptual integration of arithmetic operations with real-world knowledge: Evidence from event-related potentials</article-title><source>Cogn. Sci.</source><year>2016</year><volume>40</volume><fpage>723</fpage><lpage>757</lpage><pub-id pub-id-type="doi">10.1111/cogs.12238</pub-id><?supplied-pmid 25864403?><pub-id pub-id-type="pmid">25864403</pub-id>
</element-citation></ref><ref id="CR15"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McLaughlin</surname><given-names>J</given-names></name><etal/></person-group><article-title>Brain potentials reveal discrete stages of L2 grammatical learning</article-title><source>Lang. Learn.</source><year>2010</year><volume>60</volume><fpage>123</fpage><lpage>150</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9922.2010.00604.x</pub-id></element-citation></ref><ref id="CR16"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanner</surname><given-names>D</given-names></name><name><surname>McLaughlin</surname><given-names>J</given-names></name><name><surname>Herschensohn</surname><given-names>J</given-names></name><name><surname>Osterhout</surname><given-names>L</given-names></name></person-group><article-title>Individual differences reveal stages of L2 grammatical acquisition: ERP evidence</article-title><source>Biling Lang. Cogn.</source><year>2013</year><volume>16</volume><fpage>367</fpage><lpage>382</lpage><pub-id pub-id-type="doi">10.1017/S1366728912000302</pub-id></element-citation></ref><ref id="CR17"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanner</surname><given-names>D</given-names></name><name><surname>Inoue</surname><given-names>K</given-names></name><name><surname>Osterhout</surname><given-names>L</given-names></name></person-group><article-title>Brain-based individual differences in online L2 grammatical comprehension</article-title><source>Biling Lang. Cogn.</source><year>2014</year><volume>17</volume><fpage>277</fpage><lpage>293</lpage><pub-id pub-id-type="doi">10.1017/S1366728913000370</pub-id></element-citation></ref><ref id="CR18"><label>18.</label><mixed-citation publication-type="other">Quille, K. &#x00026; Bergin, S. Programming: Predicting student success early in CS1. A re-validation and replication study. in <italic>Proceedings of the 23rd Annual ACM Conference on Innovation and Technology in Computer Science Education</italic>, 15&#x02013;20 (2018).</mixed-citation></ref><ref id="CR19"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delogu</surname><given-names>F</given-names></name><name><surname>Brouwer</surname><given-names>H</given-names></name><name><surname>Crocker</surname><given-names>MW</given-names></name></person-group><article-title>Event-related potentials index lexical retrieval (N400) and integration (P600) during language comprehension</article-title><source>Brain Cogn.</source><year>2019</year><volume>135</volume><fpage>103569</fpage><pub-id pub-id-type="doi">10.1016/j.bandc.2019.05.007</pub-id><?supplied-pmid 31202158?><pub-id pub-id-type="pmid">31202158</pub-id>
</element-citation></ref><ref id="CR20"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lau</surname><given-names>EF</given-names></name><name><surname>Phillips</surname><given-names>C</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name></person-group><article-title>A cortical network for semantics: (de) Constructing the N400</article-title><source>Nat. Rev. Neurosci.</source><year>2008</year><volume>9</volume><fpage>920</fpage><lpage>933</lpage><pub-id pub-id-type="doi">10.1038/nrn2532</pub-id><?supplied-pmid 19020511?><pub-id pub-id-type="pmid">19020511</pub-id>
</element-citation></ref><ref id="CR21"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hagoort</surname><given-names>P</given-names></name></person-group><article-title>On Broca, brain, and binding: A new framework</article-title><source>Trends Cogn. Sci.</source><year>2005</year><volume>9</volume><fpage>416</fpage><lpage>423</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2005.07.004</pub-id><?supplied-pmid 16054419?><pub-id pub-id-type="pmid">16054419</pub-id>
</element-citation></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="other">Beniamini, G., Gingichashvili, S., Orbach A. K., &#x00026; Feitelson, D. G. Meaningful identifier names: the case of single-letter variables. in <italic>2017 IEEE/ACM 25th International Conference on Program Comprehension</italic>, 45&#x02013;54 (2017).</mixed-citation></ref><ref id="CR23"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Binkley</surname><given-names>D</given-names></name><name><surname>Lawrie</surname><given-names>D</given-names></name><name><surname>Maex</surname><given-names>S</given-names></name><name><surname>Morrell</surname><given-names>C</given-names></name></person-group><article-title>Identifier length and limited programmer memory</article-title><source>Sci. Comput. Program</source><year>2009</year><volume>74</volume><fpage>430</fpage><lpage>445</lpage><pub-id pub-id-type="doi">10.1016/j.scico.2009.02.006</pub-id></element-citation></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="other">Hofmeister, J., Siegmund, J. &#x00026; Holt, D. V. Shorter identifier names take longer to comprehend. in <italic>2017 IEEE 24th International Conference on Software Analysis, Evolution and Reengineering</italic>, pp 217&#x02013;227 (2017).</mixed-citation></ref><ref id="CR25"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Besson</surname><given-names>M</given-names></name><name><surname>Macar</surname><given-names>F</given-names></name></person-group><article-title>An event-related potential analysis of incongruity in music and other non-linguistic contexts</article-title><source>Psychophysiology</source><year>1987</year><volume>24</volume><fpage>14</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.1987.tb01853.x</pub-id><?supplied-pmid 3575590?><pub-id pub-id-type="pmid">3575590</pub-id>
</element-citation></ref><ref id="CR26"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Calma-Roddin</surname><given-names>N</given-names></name><name><surname>Drury</surname><given-names>JE</given-names></name></person-group><article-title>Music, language, and the N400: ERP interference patterns across cognitive domains</article-title><source>Sci. Rep.</source><year>2020</year><volume>10</volume><fpage>1</fpage><lpage>14</lpage><pub-id pub-id-type="doi">10.1038/s41598-020-66732-0</pub-id><pub-id pub-id-type="pmid">31913322</pub-id>
</element-citation></ref><ref id="CR27"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foucart</surname><given-names>A</given-names></name><name><surname>Frenck-Mestre</surname><given-names>C</given-names></name></person-group><article-title>Grammatical gender processing in L2: Electrophysiological evidence of the effect of L1&#x02013;L2 syntactic similarity</article-title><source>Biling Lang. Cogn.</source><year>2011</year><volume>14</volume><fpage>379</fpage><lpage>399</lpage><pub-id pub-id-type="doi">10.1017/S136672891000012X</pub-id></element-citation></ref><ref id="CR28"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foucart</surname><given-names>A</given-names></name><name><surname>Frenck-Mestre</surname><given-names>C</given-names></name></person-group><article-title>Can late L2 learners acquire new grammatical features? Evidence from ERPs and eye-tracking</article-title><source>J. Mem. Lang.</source><year>2012</year><volume>66</volume><fpage>226</fpage><lpage>248</lpage><pub-id pub-id-type="doi">10.1016/j.jml.2011.07.007</pub-id></element-citation></ref><ref id="CR29"><label>29.</label><mixed-citation publication-type="other">The jamovi project <italic>jamovi</italic>. (Version 2.3) [Computer Software]. Retrieved from <ext-link ext-link-type="uri" xlink:href="https://www.jamovi.org">https://www.jamovi.org</ext-link> (2022).</mixed-citation></ref><ref id="CR30"><label>30.</label><mixed-citation publication-type="other">R Core Team. <italic>R: A Language and environment for statistical computing</italic>. (Version 4.1) [Computer software]. Retrieved from <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org">https://cran.r-project.org</ext-link> (2021).</mixed-citation></ref><ref id="CR31"><label>31.</label><mixed-citation publication-type="other">Gallucci, M. <italic>GAMLj: General analyses for linear models</italic>. [jamovi module]. Retrieved from <ext-link ext-link-type="uri" xlink:href="https://gamlj.github.io/">https://gamlj.github.io/</ext-link> (2019).</mixed-citation></ref><ref id="CR32"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jasper</surname><given-names>HH</given-names></name></person-group><article-title>Ten-twenty electrode system of the international federation</article-title><source>Electroencephalogr. Clin. Neurophysiol.</source><year>1958</year><volume>10</volume><fpage>371</fpage><lpage>375</lpage></element-citation></ref><ref id="CR33"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McLaughlin</surname><given-names>J</given-names></name><name><surname>Osterhout</surname><given-names>L</given-names></name><name><surname>Kim</surname><given-names>A</given-names></name></person-group><article-title>Neural correlates of second-language word learning: Minimal instruction produces rapid change</article-title><source>Nat. Neurosci.</source><year>2004</year><volume>7</volume><fpage>703</fpage><lpage>704</lpage><pub-id pub-id-type="doi">10.1038/nn1264</pub-id><?supplied-pmid 15195094?><pub-id pub-id-type="pmid">15195094</pub-id>
</element-citation></ref><ref id="CR34"><label>34.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>JI</given-names></name></person-group><source>The Nelson-Denny Reading Test</source><year>1960</year><publisher-name>Houghton Mifflin</publisher-name></element-citation></ref></ref-list></back></article>