<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd"> 
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 1?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sci Rep</journal-id><journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id><journal-title-group><journal-title>Scientific Reports</journal-title></journal-title-group><issn pub-type="epub">2045-2322</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmcid">10924897</article-id><article-id pub-id-type="pmid">38461303</article-id>
<article-id pub-id-type="publisher-id">56518</article-id><article-id pub-id-type="doi">10.1038/s41598-024-56518-z</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Sentiment analysis of video danmakus based on MIBE-RoBERTa-FF-BiLSTM</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Zhao</surname><given-names>Jianbo</given-names></name><address><email>zhaojianbo@stu.xidian.edu.cn</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Liu</surname><given-names>Huailiang</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Yakai</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Zhang</surname><given-names>Weili</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Zhang</surname><given-names>Xiaojin</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Li</surname><given-names>Bowei</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Sun</surname><given-names>Tong</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Qi</surname><given-names>Yanwei</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Zhang</surname><given-names>Shanzhuang</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05s92vm98</institution-id><institution-id institution-id-type="GRID">grid.440736.2</institution-id><institution-id institution-id-type="ISNI">0000 0001 0707 115X</institution-id><institution>School of Economics and Management, </institution><institution>Xidian University, </institution></institution-wrap>266 Xifeng Road, Xi&#x02019;an, 710071 China </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/05s92vm98</institution-id><institution-id institution-id-type="GRID">grid.440736.2</institution-id><institution-id institution-id-type="ISNI">0000 0001 0707 115X</institution-id><institution>School of Telecommunications Engineering, </institution><institution>Xidian University, </institution></institution-wrap>266 Xifeng Road, Xi&#x02019;an, 710071 China </aff></contrib-group><pub-date pub-type="epub"><day>9</day><month>3</month><year>2024</year></pub-date><pub-date pub-type="pmc-release"><day>9</day><month>3</month><year>2024</year></pub-date><pub-date pub-type="collection"><year>2024</year></pub-date><volume>14</volume><elocation-id>5827</elocation-id><history><date date-type="received"><day>29</day><month>12</month><year>2023</year></date><date date-type="accepted"><day>7</day><month>3</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2024</copyright-statement><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">Danmakus are user-generated comments that overlay on videos, enabling real-time interactions between viewers and video content. The emotional orientation of danmakus can reflect the attitudes and opinions of viewers on video segments, which can help video platforms optimize video content recommendation and evaluate users&#x02019; abnormal emotion levels. Aiming at the problems of low transferability of traditional sentiment analysis methods in the danmaku domain, low accuracy of danmaku text segmentation, poor consistency of sentiment annotation, and insufficient semantic feature extraction, this paper proposes a video danmaku sentiment analysis method based on MIBE-RoBERTa-FF-BiLSTM. This paper constructs a &#x0201c;Bilibili Must-Watch List and Top Video Danmaku Sentiment Dataset&#x0201d; by ourselves, covering 10,000 positive and negative sentiment danmaku texts of 18 themes. A new word recognition algorithm based on mutual information (MI) and branch entropy (BE) is used to discover 2610 irregular network popular new words from trigrams to heptagrams in the dataset, forming a domain lexicon. The Maslow&#x02019;s hierarchy of needs theory is applied to guide the consistent sentiment annotation. The domain lexicon is integrated into the feature fusion layer of the RoBERTa-FF-BiLSTM model to fully learn the semantic features of word information, character information, and context information of danmaku texts and perform sentiment classification. Comparative experiments on the dataset show that the model proposed in this paper has the best comprehensive performance among the mainstream models for video danmaku text sentiment classification, with an F1 value of 94.06%, and its accuracy and robustness are also better than other models. The limitations of this paper are that the construction of the domain lexicon still requires manual participation and review, the semantic information of danmaku video content and the positive case preference are ignored.</p></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Sentiment analysis</kwd><kwd>New word discovery</kwd><kwd>Sentiment annotation</kwd><kwd>Feature fusion</kwd><kwd>MIBE-RoBERTa-FF-BiLSTM</kwd></kwd-group><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>Computational neuroscience</kwd><kwd>Data acquisition</kwd><kwd>Data mining</kwd><kwd>Data processing</kwd><kwd>Machine learning</kwd><kwd>Computer science</kwd><kwd>Information technology</kwd></kwd-group><funding-group><award-group><funding-source><institution>Ministry of Science and Technology of the People&#x000b4;s Republic of China</institution></funding-source><award-id>2021ZD0113702</award-id><principal-award-recipient><name><surname>Liu</surname><given-names>Huailiang</given-names></name></principal-award-recipient></award-group></funding-group><funding-group><award-group><funding-source><institution>Xi'an Municipal Bureau of Science and Technology,China</institution></funding-source><award-id>20KYPT0003-10</award-id><principal-award-recipient><name><surname>Liu</surname><given-names>Huailiang</given-names></name></principal-award-recipient></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Springer Nature Limited 2024</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par2">With the development of social media and video websites, user comments are rapidly increasing in quantity and diversity of forms. Danmaku is a new type of user-generated comment that scrolls in different positions on the video screen<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>, Users communicate with video producers and other users by posting danmakus containing emotions such as praise, sarcasm, ridicule, criticism, and compliments<sup><xref ref-type="bibr" rid="CR2">2</xref>,<xref ref-type="bibr" rid="CR3">3</xref></sup>. As an emerging information carrier, danmaku contains rich and real semantic information, which is an important corpus for sentiment analysis<sup><xref ref-type="bibr" rid="CR4">4</xref></sup>, and the sentiment analysis of danmakus has important academic and commercial value. In the academic field, the sentiment analysis of danmakus helps to explore the emotional characteristics, expand the research field of sentiment analysis, and enrich the existing research theories and related technologies<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>; In the commercial field, danmakus sentiment analysis can effectively provide feedback of different users toward the video content, and help video platforms optimize the recommendation of video content and the management strategy of danmakus<sup><xref ref-type="bibr" rid="CR6">6</xref>&#x02013;<xref ref-type="bibr" rid="CR9">9</xref></sup>; In the field of digital governance, danmakus sentiment analysis can be used to assess the abnormal emotion level of users, providing new methods for the detection of abnormal events on the Internet and the detection of users' mental health<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>.</p><p id="Par3">Sentiment analysis is a specific application of natural language processing, machine learning and other technologies to extract feelings, emotions, opinions and attitudes in text data.Sentiment analysis based on user-generated texts can help governments, enterprises and individuals to understand the user's emotions and opinions, and provide support for decision-making in various fields. Existing sentiment analysis methods can be divided into lexicon-based methods, machine learning-based methods and deep learning-based methods, after a long period of development, these methods have been relatively mature and have achieved wide application in data fields such as movie reviews<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>, product reviews<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>, medical discussions<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>, and so on. As an emerging user-generated comment, the danmaku has its unique emotional and content characteristics compared to traditional comment data, and needs to be combined with the video content to analyze the potential meaning between the lines<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>. Danmakus are characterized by varying lengths and colloquial phrases, and there are a large number of self-composed words, abbreviated words, and popular new words in the content of danmkus, such as interactive phrases agreed with the video producers, which increase the difficulty of semantic understanding and emotional expression of danmaku texts, and bring a great challenge to the sentiment analysis<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>. Aiming at the new features of danmakus, scholars have carried out explorations and attempts of sentiment analysis. Traditional danmaku sentiment analysis methods mostly utilize sentiment lexicon and machine learning models to judge the sentiment tendency of danmakus, Cui et al.<sup><xref ref-type="bibr" rid="CR15">15</xref></sup> expanded the traditional sentiment lexicon, innovatively proposed a sentiment lexicon based on emoticons and tone words, and set a single sentiment threshold as a threshold interval, which extends the scope of neutral danmakus; Hong et al.<sup><xref ref-type="bibr" rid="CR7">7</xref></sup> extended the scope of neutral danmakus by improving the traditional k-means clustering algorithm and introducing Dynamic Time Warping (DTW) to calculate the distance between user emotion distributions and clustered the danmaku data. In recent years, with the development of neural networks, more scholars apply deep learning methods in the danmaku sentiment analysis tasks. Zhao et al.<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> proposed a multi-head attention convolutional neural network (MH-ACNN) to analyze the sentiment of danmakus for their short content and incomplete contextual information; Hsieh and Zeng<sup><xref ref-type="bibr" rid="CR17">17</xref></sup> used ERNIE to characterize danmaku texts and then used BiLSTM to analyze danmakus.</p><p id="Par4">Although existing researches have achieved certain results, they fail to completely solve the problems of low accuracy of danmaku text disambiguation, poor consistency of sentiment labeling, and insufficient semantic feature extraction<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>. Therefore, this paper proposes a danmaku sentiment analysis method based on MIBE-RoBERTa-FF-BiLSTM, which is based on the MIBE danmaku neologism recognition algorithm to discover non-regular popular words in danmaku texts, constructs a domain lexicon for Chinese lexicon, and at the same time, applies the Maslow's hierarchy of needs theory to guide sentiment annotation, and uses the RoBERTa pre-training model to adequately extract semantic and structural information from the danmaku semantic and structural information of danmaku texts, averaging the feature encoding of words after segmentation based on the feature fusion layer, and obtaining word encoding that retain the semantic information, using the bidirectional sequence modeling capability of BiLSTM model to effectively capture the contextual information of the danmaku text, better understand the semantic and dependency relationships in the danmaku text, and improve the model's emotional tendency classification ability and generalization ability. The purpose of this paper is to comprehensively improve the effectiveness of Chinese danmaku sentiment analysis model from 3 aspects of new words discovery, sentiment annotation, and conflicts between Chinese word segmentation methods and pre-training model tokenizer methods, assistant theoretical breakthroughs, with a view to help video platforms optimize video content recommendations and assess users&#x02019; abnormal sentiment levels, et al.</p><p id="Par5">This paper is structured as follows: "<xref rid="Sec2" ref-type="sec">Related work</xref>" section, introduces the work related to video danmaku sentiment analysis; "<xref rid="Sec7" ref-type="sec">Model design</xref>" section, danmaku sentiment analysis model design; "<xref rid="Sec11" ref-type="sec">Experiments and results</xref>" section, experiments and results analysis; "<xref rid="Sec17" ref-type="sec">Discussions</xref>" secttion, discusses textual research innovations, limitations, and future perspectives; "<xref rid="Sec18" ref-type="sec">Conclusion</xref>" section, summarizes the research in this paper.</p></sec><sec id="Sec2"><title>Related work</title><p id="Par6">Currently, the main video danmaku sentiment analysis methods include sentiment lexicon-based methods, machine learning-based methods, and deep learning-based methods, and the specific research progress is as follows:</p><sec id="Sec3"><title>Lexicon-based danmaku sentiment analysis</title><p id="Par7">Sentiment analysis method for danmaku based on sentiment lexicon, by constructing a sentiment lexicon containing positive and negative sentiment words, segmenting danmakus and matching them with the sentiment lexicon, using an algorithm to classify danmakus and calculating the sentiment values<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>. Zheng et al.<sup><xref ref-type="bibr" rid="CR20">20</xref></sup> used a method based on the semantic weighting of sentiment words to calculate danmakus&#x02019; sentiment values and categorize danmakus; Wang and Xu<sup><xref ref-type="bibr" rid="CR21">21</xref></sup> combined the universal sentiment lexicons and danmaku multidimensional sentiment lexicons to construct an exclusive sentiment lexicon for danmakus, and then combined the time series to study the change trend of danmakus after calculating the sentiment values; Li et al.<sup><xref ref-type="bibr" rid="CR22">22</xref></sup> combined the lexicon-based danmaku sentiment categorization method with the plain Bayesian method; Liu et al.<sup><xref ref-type="bibr" rid="CR23">23</xref></sup> and Zeng et al.<sup><xref ref-type="bibr" rid="CR24">24</xref></sup> analyzed the influence of danmaku emotions on consumers' purchase intention by classifying danmaku emotions based on an emotion lexicon; Jin et al.<sup><xref ref-type="bibr" rid="CR25">25</xref></sup> fused the improved word forest with the HowNet similarity computation algorithm, and categorized the multidimensional lexicon according to the seven human emotion dimensions, and measured the danmaku emotion values by the improved emotion value computation method.</p><p id="Par8">Sentiment lexicon-based approaches rely too much on the quality and coverage of the sentiment lexicon, with limited scalability and objectivity. The meanings of sentiment words may vary with context and time, increasing the limitations of the lexicon<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>; In addition, the development of sentiment lexicons and judgment rules requires a great deal of manual design and priori knowledge. The difficulties of sentiment annotation make the quality of the lexicons uneven. The development of social media has led to the continuous emergence of new online terms in danmakus, and the sentiment lexicon is difficult to adapt to the diversity and variability of danmakus timely. Therefore, the effect of danmaku sentiment analysis methods based on sentiment lexicon isn&#x02019;t satisfactory.</p><p id="Par9"><italic>RQ1</italic>: How to enable annotators to accurately annotate danmaku sentiment tendencies quickly, simply, reasonably and consistently understood in conjunction with video content?</p><p id="Par10"><italic>RQ2</italic>: How to efficiently discover non-regular popular words in danmaku texts, cut danmaku texts into more reasonable words, and improve the quality of word embeddings in danmaku sentiment classification models?</p></sec><sec id="Sec4"><title>Machine learning-based danmaku sentiment analysis</title><p id="Par11">A machine learning based approach for danmaku sentiment analysis, preprocessing danmaku data, constructing datasets, selecting and vectorizing text features, and training machine learning models for danmaku sentiment classification. Yang Deng et al.<sup><xref ref-type="bibr" rid="CR6">6</xref></sup> proposed a Multi-Topic Emotion Recognition (MTER) algorithm based on the Hidden Dirichlet Distribution (LDA) model for video clips, which utilizes the implicit emotional dependencies of the words in each danmaku to compute the emotion values and compute the emotion vectors; Jun Xu et al.<sup><xref ref-type="bibr" rid="CR27">27</xref></sup> utilized the Simple Bayes and Maximum Entropy methods to improve the accuracy of comment sentiment classification by selecting semantically inclined words as feature terms, correctly handling negations, and using binary values as feature term weights; Shang et al.<sup><xref ref-type="bibr" rid="CR28">28</xref></sup> used SnowNLP in conjunction with LDA topic modeling for sentiment analysis of multi-class review data; Hu et al.<sup><xref ref-type="bibr" rid="CR29">29</xref></sup> combined stuttering disambiguation and polynomial plain Bayes to construct a classifier for comment sentiment classification.</p><p id="Par12">Machine learning-based methods require a large amount of labeled data and appropriate feature extraction methods, and have higher requirements for classification models; at the same time, this type of methods cannot fully utilize contextual information of the context, which affects the accuracy of classification to a certain extent.</p><p id="Par13"><italic>RQ3</italic>: How to extract semantic and structural information of danmaku text words in different contexts to effectively capture contextual information?</p></sec><sec id="Sec5"><title>Deep learning-based danmaku sentiment analysis</title><p id="Par14">Deep learning-based approach for danmaku sentiment analysis by multilayer neural networks. Ye et al.<sup><xref ref-type="bibr" rid="CR30">30</xref></sup> proposed a data collection algorithm based on hotspot detection and a model to analyze danmaku sentiment based on danmaku sentiment lexicon and convolutional neural network; Wang et al.<sup><xref ref-type="bibr" rid="CR31">31</xref></sup> categorized the four emotions of happiness, anger, sadness, and joy through the danmaku sentiment data analysis model based on the BiLSTM model; Bai et al.<sup><xref ref-type="bibr" rid="CR32">32</xref></sup> compared how models such as logistic regression, support vector machines, and recurrent neural networks predict the positive or negative sentiment of danmaku's comments and reflect it in video sentiment curves; Li and Mou<sup><xref ref-type="bibr" rid="CR33">33</xref></sup> used ERNIE and TextCNN to fuse danmaku's textual and temporal features, and then use BILSTM to perform sentiment analysis on the feature-fused vectors; Li et al.<sup><xref ref-type="bibr" rid="CR34">34</xref></sup> constructed a seed sentiment lexicon to compute danmaku text similarity for very short danmaku text sentiment recognition, and borrow BILSTM combined with BERT model for regular text danmaku sentiment recognition. Li et al.<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> used the XLNet model to evaluate the overall sentiment of danmaku comments as pessimistic or optimistic.</p><p id="Par15">Deep learning-based methods have stronger feature learning capabilities, reducing the cost of building and selecting features<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>, but the method needs to be based on a large amount of data, and is prone to data sparsity and overfitting problems in the case of small datasets<sup><xref ref-type="bibr" rid="CR37">37</xref></sup>; Mainstream text pre-training models use different segmentation methods, BERT and XLNet use WordPiece, RoBERTa uses Byte-Pair Encoding, and the use of Chinese segmentation tools can easily lead to the fact that there is no difference between the Chinese segmented corpus and the pre-segmented one after tokenizer processing, which loses semantic information and results in model performance degradation.</p><p id="Par16"><italic>RQ4</italic>: How to effectively extract the word information after Chinese word segmentation when the Chinese word segmentation method is inconsistent with the tokenizer method when using the text pre-training model?</p><p id="Par17">Combining the above studies, this paper proposes a danmaku sentiment analysis model based on MIBE-RoBERTa-FF-BiLSTM, a neologism recognition algorithm based on mutual information (MI) and branch entropy (BE) to identify non-regular popular words in danmaku texts, so as to quickly construct a domain lexicon for accurate Chinese word segmentation. At the same time, Maslow's hierarchy of needs theory is applied to guide consistent sentiment annotation, and Roberta's pre-training model, feature fusion layer and Bilstm model are used in combination to adequately extract semantic features of danmaku texts, which effectively improves the ability to analyze the sentiment tendency of danmaku texts.</p></sec><sec id="Sec6"><title>Ethical approval</title><p id="Par18">This article does not contain any studies with human participants performed by any of the authors.</p></sec></sec><sec id="Sec7"><title>Model design</title><p id="Par19">This paper proposed a danmaku sentiment analysis method based on MIBE-RoBERTa-FF-BiLSTM, which specifically includes the construction of danmaku domain lexicon based on MIBE neologism recognition algorithm, danmaku text sentiment annotation based on Maslow's hierarchy of needs theory, and RoBERTa-FF-BiLSTM sentiment analysis model. The overall framework of the research methodology is shown in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>.<fig id="Fig1"><label>Figure 1</label><caption><p>Framework diagram of the danmaku sentiment analysis method based on MIBE-Roberta-FF-Bilstm.</p></caption><graphic xlink:href="41598_2024_56518_Fig1_HTML" id="MO1"/></fig></p><sec id="Sec8"><title>Danmaku domain lexicon construction based on MIBE neologism recognition algorithm</title><p id="Par20">Danmaku texts are often highly colloquial, with a large number of non-standard popular words, such as "&#x07834;&#x09632;&#x04e86;", originally a game term referring to the use of skills to break through defenses, but in the context of the Internet, it expresses empathy for sensationalism or exciting videos; "&#x0868c;&#x057e0;&#x04f4f;&#x04e86;" is harmonized as "&#x07ef7;&#x04e0d;&#x04f4f;&#x04e86;", which describes the impact on the senses and can't help laughing or having an emotional meltdown. These Internet buzzwords contain rich semantic and emotional information, but are difficult to be recognized by general-purpose lexical tools. danmaku domain lexicon can effectively solve this problem by automatically recognizing and manually annotating these neologisms into the lexicon, which in turn improves the accuracy of downstream danmaku sentiment analysis task.</p><p id="Par21">This paper proposes a danmaku neologism recognition algorithm based on mutual information and branch entropy. The algorithm incrementally expands candidate words by calculating mutual information with right neighbors, identifying potential neologisms. A screening process using branch entropy eliminates words with smaller left and right neighbor entropy, along with deactivated words at the beginning and end of candidate neologisms. The algorithm automatically creates a danmaku domain lexicon by comparing recognized neologisms with existing lexical phrases in the corpus. This approach enhances lexicon precision, capturing specific language nuances in danmaku interactions. After comparing the recognized new words with the existing phrases in the corpus, the meaningful new words are filtered out, and the danmaku domain lexicon is formed automatically, and at the same time, the new words are added to the participle lexicon to improve the quality of the participle lexicon. The specific steps are as follows:</p><p id="Par22">Mutual Information (MI) is a common method used to measure the degree of co-occurrence of two variables in a corpus, and the larger the value indicates that the degree of dependence and the relationship between the two objects is also stronger. In the process of neologism discovery, it can be counted whether the probability of co-occurrence of two or more characters in the corpus reaches a certain threshold. The calculation method is shown in (<xref rid="Equ1" ref-type="disp-formula">1</xref>):<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MI(A,B)={\text{log}}2\frac{p(A,B)}{p(A),p(B)}$$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mrow><mml:mi>M</mml:mi><mml:mi>I</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext>log</mml:mtext><mml:mn>2</mml:mn><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="41598_2024_56518_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where p(A) and p(B) denote the probability of word or phrase A and B appearing individually in the corpus set, respectively, p(A,B) denotes the joint probability of A and B co-occurring in the corpus set, and <inline-formula id="IEq1"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{MI}}\left({\text{A}},{\text{B}}\right)$$\end{document}</tex-math><mml:math id="M4"><mml:mrow><mml:mtext>MI</mml:mtext><mml:mfenced close=")" open="("><mml:mtext>A</mml:mtext><mml:mo>,</mml:mo><mml:mtext>B</mml:mtext></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq1.gif"/></alternatives></inline-formula> denotes the degree of dependency between A and B. If <inline-formula id="IEq2"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{MI}}\left({\text{A}},{\text{B}}\right)&#x0003e;0$$\end{document}</tex-math><mml:math id="M6"><mml:mrow><mml:mtext>MI</mml:mtext><mml:mfenced close=")" open="("><mml:mtext>A</mml:mtext><mml:mo>,</mml:mo><mml:mtext>B</mml:mtext></mml:mfenced><mml:mo>&#x0003e;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq2.gif"/></alternatives></inline-formula>, the probability of A and B co-occurring is greater than the product of the probability of each of them occurring individually, it means that the two may be related to each other, and the larger the value of MI, it means that the stronger the correlation between the two, and the more likely that they may form a new vocabulary; and if <inline-formula id="IEq3"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{MI}}\left({\text{A}},{\text{B}}\right)&#x0003c;0$$\end{document}</tex-math><mml:math id="M8"><mml:mrow><mml:mtext>MI</mml:mtext><mml:mfenced close=")" open="("><mml:mtext>A</mml:mtext><mml:mo>,</mml:mo><mml:mtext>B</mml:mtext></mml:mfenced><mml:mo>&#x0003c;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq3.gif"/></alternatives></inline-formula>,it means that A and B are independently distributed in the corpus set.</p><p id="Par23">Branch Entropy (BE) is used to measure whether the neighboring characters of a candidate new word are stable enough, the larger the value indicates that the neighboring characters of the candidate new word contain more information, and the higher the probability of forming a word. The left neighbor entropy, right neighbor entropy are calculated as shown in (<xref rid="Equ2" ref-type="disp-formula">2</xref>) and (<xref rid="Equ3" ref-type="disp-formula">3</xref>).<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${H}_{L}(W)=-{\sum }_{{W}_{l}\in {S}_{l}}p\left({W}_{l}|W\right)\mathit{log}p\left({W}_{l}|W\right)$$\end{document}</tex-math><mml:math id="M10" display="block"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>W</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:msub><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>W</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>W</mml:mi></mml:mrow></mml:mfenced><mml:mi mathvariant="italic">log</mml:mi><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>W</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>W</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="41598_2024_56518_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${H}_{R}(W)=-{\sum }_{Wr\in Sr}p({W}_{r}|W)\mathit{log}p({W}_{r}|W)$$\end{document}</tex-math><mml:math id="M12" display="block"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>W</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:msub><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>W</mml:mi><mml:mi>r</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>S</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mi>W</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi mathvariant="italic">log</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mi>W</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic xlink:href="41598_2024_56518_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula></p><p id="Par24"><inline-formula id="IEq4"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\text{S}}}_{{\text{l}}}$$\end{document}</tex-math><mml:math id="M14"><mml:msub><mml:mtext>S</mml:mtext><mml:mtext>l</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq4.gif"/></alternatives></inline-formula> is the set of left neighbors of candidate word W, <inline-formula id="IEq5"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\text{S}}}_{{\text{r}}}$$\end{document}</tex-math><mml:math id="M16"><mml:msub><mml:mtext>S</mml:mtext><mml:mtext>r</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq5.gif"/></alternatives></inline-formula> is the set of right neighbors of candidate word W, <inline-formula id="IEq6"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{P}}({{\text{W}}}_{{\text{L}}}|{\text{W}})$$\end{document}</tex-math><mml:math id="M18"><mml:mrow><mml:mtext>P</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mtext>W</mml:mtext><mml:mtext>L</mml:mtext></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mtext>W</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq6.gif"/></alternatives></inline-formula> denotes the conditional probability that <inline-formula id="IEq7"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\text{W}}}_{{\text{L}}}$$\end{document}</tex-math><mml:math id="M20"><mml:msub><mml:mtext>W</mml:mtext><mml:mtext>L</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq7.gif"/></alternatives></inline-formula> is the left neighbor of candidate word W, <inline-formula id="IEq8"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{P}}({{\text{W}}}_{{\text{R}}}|{\text{W}})$$\end{document}</tex-math><mml:math id="M22"><mml:mrow><mml:mtext>P</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mtext>W</mml:mtext><mml:mtext>R</mml:mtext></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mtext>W</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq8.gif"/></alternatives></inline-formula> denotes the conditional probability that <inline-formula id="IEq9"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\text{W}}}_{{\text{R}}}$$\end{document}</tex-math><mml:math id="M24"><mml:msub><mml:mtext>W</mml:mtext><mml:mtext>R</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq9.gif"/></alternatives></inline-formula> is the right neighbor of candidate word W, and the computational equations for <inline-formula id="IEq10"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{P}}({{\text{W}}}_{{\text{L}}}|{\text{W}})$$\end{document}</tex-math><mml:math id="M26"><mml:mrow><mml:mtext>P</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mtext>W</mml:mtext><mml:mtext>L</mml:mtext></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mtext>W</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq10.gif"/></alternatives></inline-formula> and <inline-formula id="IEq11"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{P}}({{\text{W}}}_{{\text{R}}}|{\text{W}})$$\end{document}</tex-math><mml:math id="M28"><mml:mrow><mml:mtext>P</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mtext>W</mml:mtext><mml:mtext>R</mml:mtext></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mtext>W</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq11.gif"/></alternatives></inline-formula> are shown in (<xref rid="Equ4" ref-type="disp-formula">4</xref>) and (<xref rid="Equ5" ref-type="disp-formula">5</xref>).<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p\left({W}_{L}|W\right)=\frac{N\left({W}_{L},W\right)}{N\left(W\right)}$$\end{document}</tex-math><mml:math id="M30" display="block"><mml:mrow><mml:mi>p</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>W</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>W</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>N</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>W</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>W</mml:mi></mml:mfenced></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mfenced close=")" open="("><mml:mi>W</mml:mi></mml:mfenced></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="41598_2024_56518_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p({W}_{R}|W)=\frac{N(W,{W}_{R})}{N(W)}$$\end{document}</tex-math><mml:math id="M32" display="block"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mi>W</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>W</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>W</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="41598_2024_56518_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula></p><p id="Par25">where <inline-formula id="IEq12"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{N}}({{\text{W}}}_{{\text{L}}},{\text{W}})$$\end{document}</tex-math><mml:math id="M34"><mml:mrow><mml:mtext>N</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mtext>W</mml:mtext><mml:mtext>L</mml:mtext></mml:msub><mml:mo>,</mml:mo><mml:mtext>W</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq12.gif"/></alternatives></inline-formula> denotes the number of times <inline-formula id="IEq13"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\text{W}}}_{{\text{L}}}$$\end{document}</tex-math><mml:math id="M36"><mml:msub><mml:mtext>W</mml:mtext><mml:mtext>L</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq13.gif"/></alternatives></inline-formula> and Wco-occur and N(W) denotes the number of times W occurs. Similarly, <inline-formula id="IEq14"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{N}}({{\text{W}}}_{{\text{R}}},{\text{W}})$$\end{document}</tex-math><mml:math id="M38"><mml:mrow><mml:mtext>N</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mtext>W</mml:mtext><mml:mtext>R</mml:mtext></mml:msub><mml:mo>,</mml:mo><mml:mtext>W</mml:mtext><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq14.gif"/></alternatives></inline-formula> denotes the number of times <inline-formula id="IEq15"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\text{W}}}_{{\text{R}}}$$\end{document}</tex-math><mml:math id="M40"><mml:msub><mml:mtext>W</mml:mtext><mml:mtext>R</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq15.gif"/></alternatives></inline-formula> and Wappear together. Taking the Internet buzzword "&#x05fc3;&#x06001;&#x05d29;&#x04e86;" as an example, the prerequisite for it to become a separate word is that the words "&#x05fc3;&#x06001;" and "&#x05d29;&#x04e86;" co-occur in the corpus at a high frequency, and the randomness of the words distributed around it should be strong enough.</p><p id="Par26">The word-by-word expansion of the uncut danmaku corpus is mainly applied to the recognition of neologisms of three or more characters. Taking the neologism "&#x0868c;&#x057e0;&#x04f4f;&#x04e86;" as an example, after the binary neologism "&#x0868c;&#x057e0;" is counted, the mutual information between "&#x0868c;&#x057e0;" and "&#x04f4f;" is calculated by shifting to the right and finally expanding to "&#x0868c;&#x057e0;&#x04f4f;&#x04e86;". By calculating the mutual information and eliminating the words with low branch entropy and removing the first and last deactivated words, the new word set is obtained after eliminating the existing old words. In addition, this method achieves dynamic evolution of the danmaku lexicon by excluding new words that may contain dummy words at the beginning and end, and adding new words to the lexicon without repetition after comparing them with those in the danmaku lexicon. This approach improves the quality of word splitting and solves the problems of unrecognized new words, repetitions, and garbage strings. In this paper, a total of 9851 neologisms from three to seven dollars were identified by the above method, and after manual checking and reviewing, 2610 neologisms with realistic significance were finally retained to constitute the danmaku neologism lexicon, and Table <xref rid="Tab1" ref-type="table">1</xref> shows the statistics of some of the neologisms and their manual annotations.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Danmaku neologisms meaning.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">No</th><th align="left">Neologism</th><th align="left">Meaning</th></tr></thead><tbody><tr><td align="left">1</td><td align="left">trigger warning</td><td align="left">Self-wording: used as a reminder to the rest of the audience that what's coming up next is very exciting, so be prepared</td></tr><tr><td align="left">2</td><td align="left">I can't laugh anymore</td><td align="left">Self-wording: indicate that the content of the video is so hilarious that you can't help but let out a chuckle</td></tr><tr><td align="left">3</td><td align="left">I'll definitely do it next time</td><td align="left">The interaction between the viewer and the producer of the video is similar to the interactive behavior of "liking", when the producer of the video asks the viewer to like the video, the viewer expresses approval of the author, or teases or mocks the poor quality of the video</td></tr><tr><td align="left">4</td><td align="left">My youth is making a comeback</td><td align="left">Abbreviation: youth is back, used to express surprise and admiration when a remembered thing or person returns in a different state of appearance</td></tr><tr><td align="left">5</td><td align="left">have no martial ethics</td><td align="left">Internet buzzwords: indicate that the behavior of the characters in the video or the content of the video caught off guard, completely unexpected, mostly used to tease the video producer or the commercials inserted in the video mockery, you need to combine with the content of the video to make judgments</td></tr></tbody></table></table-wrap></p></sec><sec id="Sec9"><title>Danmaku emotion annotation based on Maslow's hierarchy of needs theory</title><p id="Par27">The danmaku texts contain internet popular neologisms, which need to be combined with the video content to analyze the potential meanings between the lines, and the emotion annotation is difficult. Currently, it is widely recognized that individuals produce emotions influenced by internal needs and external stimuli, and that when an individual's needs are met, the individual produces positive emotions, otherwise negative emotions are generated<sup><xref ref-type="bibr" rid="CR38">38</xref></sup>. Therefore, this paper decomposes and maps the hierarchy of needs contained in danmaku content, which can be combined with video content to make a more accurate judgment of danmaku emotions. This paper adopts Maslow's hierarchy of needs theory, which includes seven levels of physiological, safety, belonging and love, self-esteem, cognitive, aesthetic, and self-actualization needs, for guiding the labeling of danmaku emotions. This paper invited 10 senior Bilibili users to watch the video and then use the method to label the sentiment polarity of danmaku text. Compared with the labeling without using the method, the difficulty of the labeling is greatly reduced, and the speed and accuracy of the labeling are significantly improved. Examples of the labeling results are shown in Table <xref rid="Tab2" ref-type="table">2</xref>.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Examples of Danmaku emotion annotation based on Maslow's hierarchy of needs.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">No</th><th align="left">Danmaku texts</th><th align="left">Hierarchy of needs</th><th align="left">Sentimental polarity</th><th align="left">Traditional annotation</th><th align="left">Maslow annotation</th></tr></thead><tbody><tr><td align="left">1</td><td align="left">Play your own script anyway</td><td align="left">Self-actualization needs</td><td align="left">Positive</td><td align="left">Difficult</td><td align="left">Easy</td></tr><tr><td align="left">2</td><td align="left">Magnificent, to the boss knelt down</td><td align="left">Aesthetic needs</td><td align="left">Positive</td><td align="left">Medium</td><td align="left">Easy</td></tr><tr><td align="left">3</td><td align="left">I really want a hug, even for strangers</td><td align="left">Belonging and love needs</td><td align="left">Negative</td><td align="left">Difficult</td><td align="left">Easy</td></tr><tr><td align="left">4</td><td align="left">This is really, really Bengbu</td><td align="left">Security needs</td><td align="left">Negative</td><td align="left">Difficult</td><td align="left">Easy</td></tr><tr><td align="left">5</td><td align="left">I'm sorry I was born a man</td><td align="left">Self-esteem needs</td><td align="left">Negative</td><td align="left">Medium</td><td align="left">Easy</td></tr></tbody></table></table-wrap></p><p id="Par28">The semantic structure of danmaku text is loosely structured and contains a large number of special characters, such as numbers, meaningless symbols, traditional Chinese characters, or Japanese, etc. These symbols, which contain only a small amount of emotional information, will bring noise to the neural network, so this paper eliminates these redundant information through regular expressions.Meanwhile, this paper visualizes and analyzes the danmaku length, as shown in Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>, and finds that the danmaku length is mainly distributed between 5 and 45 characters, so this paper excludes the danmaku texts whose lengths are more than 100 or less than 5.<fig id="Fig2"><label>Figure 2</label><caption><p>Danmakus length distribution.</p></caption><graphic xlink:href="41598_2024_56518_Fig2_HTML" id="MO2"/></fig></p></sec><sec id="Sec10"><title>RoBERTa-FF-BiLSTM sentiment analysis model</title><p id="Par29">This paper uses the RoBERTa model to pre-train and extract the deep semantic information in danmaku texts, and the corresponding word vectors of the words in the Chinese phrases after word splitting are fused with the features, so that the output word embedding vectors of the RoBERTa model can contain more fine-grained information of the Chinese corpus, and then the information is inputted into the BiLSTM model to deal with the danmaku text's contextual information for sentiment classification. The model structure is shown in Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>.<fig id="Fig3"><label>Figure 3</label><caption><p>RoBERTa-FF-BiLSTM danmaku text sentiment recognition model.</p></caption><graphic xlink:href="41598_2024_56518_Fig3_HTML" id="MO3"/></fig></p><p id="Par30">By increasing the randomness and diversity of the pre-training data, RoBERTa can better learn the deep semantic information of the text and improve the accuracy of the downstream text categorization task. RoBERTa model is a bidirectional Transformer encoder based on the Bidirectional Encoder Representations from Transformers (BERT) model, which mainly utilizes Transformer-Encoder for computation. Each Encode module is composed of three parts: multi-head attention mechanism, residual connection and layer normalization, and feed-forward neural network, as shown in Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>:<fig id="Fig4"><label>Figure 4</label><caption><p>Structure of Transformer Encoder Decode.</p></caption><graphic xlink:href="41598_2024_56518_Fig4_HTML" id="MO4"/></fig></p><p id="Par31">In Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>, the word vectors are obtained by transforming the words in the input text through the one-hot encoding representation, and the positional encoding indicates the relative or absolute position of the word in the sequence, and the word embedding vectors generated by superposition of the two are used as the inputs X. The multi-head attentionmechanism, as a self-attention mechanism, is the core unit in the Transformer encoder, which uses multiple independent Attention modules to perform concurrent operations on the input information, and its operational formula is shown in (6):<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Attention\left(Q,K,V\right)=Softmax\left(\frac{Q{K}^{T}}{\sqrt{{d}_{k}}}\right)V$$\end{document}</tex-math><mml:math id="M42" display="block"><mml:mrow><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mfenced close=")" open="("><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mfenced close=")" open="("><mml:mfrac><mml:mrow><mml:mi>Q</mml:mi><mml:msup><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:msqrt><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt></mml:mfrac></mml:mfenced><mml:mi>V</mml:mi></mml:mrow></mml:math><graphic xlink:href="41598_2024_56518_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq16"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left\{Q,K,V\right\}$$\end{document}</tex-math><mml:math id="M44"><mml:mfenced close="}" open="{"><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi></mml:mfenced></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq16.gif"/></alternatives></inline-formula> is the input matrix and <inline-formula id="IEq17"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${d}_{k}$$\end{document}</tex-math><mml:math id="M46"><mml:msub><mml:mi>d</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq17.gif"/></alternatives></inline-formula> is used as the input matrix dimension. The multi-head attention mechanism delivers the resulting hidden vector twice to the next layerafter the multi-head self-attention computation: residual connectionand layer normalization. The layer normalization transforms the input into mean&#x02013;variance and the residual connection adds the input X with the result obtained from the nonlinear transformation as the output term. The inputs are then operated on by the two fully connected layers of the feedforward neural network, applying the formula shown in (7):<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${W}_{e}=max(0,X{W}_{0}+{b}_{0}){W}_{0}^{\mathrm{^{\prime}}}+{b}^{\mathrm{^{\prime}}}$$\end{document}</tex-math><mml:math id="M48" display="block"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>X</mml:mi><mml:msub><mml:mi>W</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mo>&#x02032;</mml:mo></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mo>&#x02032;</mml:mo></mml:msup></mml:mrow></mml:math><graphic xlink:href="41598_2024_56518_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq19"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left\{{W}_{e},{W}_{0}{\prime}\right\}$$\end{document}</tex-math><mml:math id="M50"><mml:mfenced close="}" open="{"><mml:msub><mml:mi>W</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&#x02032;</mml:mo></mml:mfenced></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq19.gif"/></alternatives></inline-formula> is the weight matrix of the two connected layers and <inline-formula id="IEq20"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left\{{b}_{e},{b}_{0}{\prime}\right\}$$\end{document}</tex-math><mml:math id="M52"><mml:mfenced close="}" open="{"><mml:msub><mml:mi>b</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>&#x02032;</mml:mo></mml:mfenced></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq20.gif"/></alternatives></inline-formula> is the bias term of the two connected layers. After each word embedding vector in the input layer is encoded by the RoBERTa layer encoding operation, a bidirectional correlation between word embedding vectors can be established, which enables the model to learn the semantic features contained in each word embedding vector in different contexts. For example, "&#x08fd9;&#x0771f;&#x07684;&#x0868c;&#x057e0;&#x04f4f;&#x04e86;" or "&#x0592a;&#x0611f;&#x04eba;&#x04e86;&#x0868c;&#x057e0;&#x04f4f;&#x04e86;", in which the word "&#x0868c;&#x057e0;" expresses very different semantics in different contexts, RoBERTa pre-training model can be based on large-scale text pre-training to derive a common linguistic expression, and then fine-tuned to transfer the learned knowledge to different downstream tasks. Based on this, when dealing with the problem of polysemous words in different contexts, the RoBERTa pre-training model obtains the semantic features in different contexts by pre-training the textual information, and then inputs them into the BiLSTM model for sentiment classification.</p><p id="Par32">Before inputting to the BiLSTM layer, the word embedding vectors output from RoBERTa need to be inputted to the Feature Fusion Layer for processing, and the corresponding word vectors of the words in the lexicon are fused with the features, so that the word embedding vectors output from the RoBERTa model can contain more fine-grained Chinese corpus information. In the feature fusion layer, the jieba thesaurus is first used to segment the text, for example, in the sentence "This is really Bengbu lived", the jieba segmentation tool divides this sentence into ['this', 'really', 'Bengbu', 'lived', 'had']. In this paper, the number of words contained in each word in this sentence is counted to get the vector of [1,1,1,2,2]. When the word embedding vector output by RoBERTa is obtained, this paper averages the words in the same word and fills them into the original position, thus realizing the purpose of feature fusion, the logical structure is shown in Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>.<fig id="Fig5"><label>Figure 5</label><caption><p>Logical structure diagram of Feature Fusion Layer.</p></caption><graphic xlink:href="41598_2024_56518_Fig5_HTML" id="MO5"/></fig></p><p id="Par33">In a unidirectional LSTM, neuron states are propagated from the front to the back, so the model can only take into account past information, but not future information<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>, which results in LSTM not being able to perform complex sentiment analysis tasks well. For example, in the case of the danmaku "&#x04e13;&#x05bb6;&#x08bf4;&#x07684;&#x0633a;&#x0597d;&#x07684;,&#x04e0b;&#x06b21;&#x0522b;&#x08bf4;&#x04e86;", the literal message above expresses positive appreciation, but it can only be judged in the context of the semantics of the following sentence that it is the danmaku sender's derision and flirtation, and that the danmaku does not express a positive emotion. To solve this situation it is necessary to introduce a bidirectional LSTM.The BiLSTM model of the Bi-Long Short-Term Memory Network BiLSTM is composed of a forward-processing sequence LSTM with a reverse-processing sequence LSTM as shown in Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref>. This paper establishes a BiLSTM layer after the RoBERTa layer, and utilizes BiLSTM to extract features from the contextual information of the input texts, which effectively makes up for the shortcomings of the RoBERTa layer that lacks the consideration of contextual information.<fig id="Fig6"><label>Figure 6</label><caption><p>Logical structure of BiLSTM-bidirectional LSTM.</p></caption><graphic xlink:href="41598_2024_56518_Fig6_HTML" id="MO6"/></fig></p><p id="Par34">The BiLSTM model for extracting features for contextual information takes the final output matrix <inline-formula id="IEq21"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{C}}\in {{\text{R}}}^{{\text{n}}}$$\end{document}</tex-math><mml:math id="M54"><mml:mrow><mml:mtext>C</mml:mtext><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mtext>R</mml:mtext></mml:mrow><mml:mtext>n</mml:mtext></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq21.gif"/></alternatives></inline-formula> &#x04e0e; of the RoBERTa layer with weights <inline-formula id="IEq22"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\text{W}}}_{{\text{a}}}\in {{\text{R}}}^{{{\text{d}}}_{{\text{a}}}\times {\text{n}}}$$\end{document}</tex-math><mml:math id="M56"><mml:mrow><mml:msub><mml:mtext>W</mml:mtext><mml:mtext>a</mml:mtext></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mtext>R</mml:mtext></mml:mrow><mml:mrow><mml:msub><mml:mtext>d</mml:mtext><mml:mtext>a</mml:mtext></mml:msub><mml:mo>&#x000d7;</mml:mo><mml:mtext>n</mml:mtext></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq22.gif"/></alternatives></inline-formula> and adds it as an input to the bidirectional LSTM. The computational public is shown in (8):<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${a}_{i}={g}_{1}\left({W}_{a}{C}_{i}+{b}_{a}\right)$$\end{document}</tex-math><mml:math id="M58" display="block"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi>W</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="41598_2024_56518_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula>where n is the dimension of the feature vector obtained after pre-training in the sentence; <inline-formula id="IEq23"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\text{a}}}_{{\text{i}}}\in {{\text{R}}}^{{{\text{d}}}_{{\text{a}}}}$$\end{document}</tex-math><mml:math id="M60"><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mtext>i</mml:mtext></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mtext>R</mml:mtext></mml:mrow><mml:msub><mml:mtext>d</mml:mtext><mml:mtext>a</mml:mtext></mml:msub></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq23.gif"/></alternatives></inline-formula>; <inline-formula id="IEq24"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\text{b}}}_{{\text{a}}}$$\end{document}</tex-math><mml:math id="M62"><mml:msub><mml:mtext>b</mml:mtext><mml:mtext>a</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq24.gif"/></alternatives></inline-formula> is bias vector and the dimension is <inline-formula id="IEq25"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\text{d}}}_{{\text{a}}}$$\end{document}</tex-math><mml:math id="M64"><mml:msub><mml:mtext>d</mml:mtext><mml:mtext>a</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq25.gif"/></alternatives></inline-formula>; Bidirectional LSTM is computed on the hidden layers in two different directions, and the hidden vectors <inline-formula id="IEq26"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overrightarrow{{\text{h}}}$$\end{document}</tex-math><mml:math id="M66"><mml:mover accent="true"><mml:mtext>h</mml:mtext><mml:mo stretchy="false">&#x02192;</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq26.gif"/></alternatives></inline-formula>, <inline-formula id="IEq27"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overleftarrow{{\text{h}}}$$\end{document}</tex-math><mml:math id="M68"><mml:mover accent="true"><mml:mtext>h</mml:mtext><mml:mo stretchy="false">&#x02190;</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq27.gif"/></alternatives></inline-formula> of the last layer of the forward and backward LSTMare merged and used as the output, the output vector <inline-formula id="IEq28"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\text{V}}}_{{\text{i}}}$$\end{document}</tex-math><mml:math id="M70"><mml:msub><mml:mtext>V</mml:mtext><mml:mtext>i</mml:mtext></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq28.gif"/></alternatives></inline-formula> at moment i. The computational formula is shown in (9):<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${V}_{i}=\overrightarrow{{h}_{i}}+\overleftarrow{{h}_{i}}$$\end{document}</tex-math><mml:math id="M72" display="block"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mover accent="true"><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">&#x02192;</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:mover accent="true"><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">&#x02190;</mml:mo></mml:mover></mml:mrow></mml:math><graphic xlink:href="41598_2024_56518_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq29"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overrightarrow{{{\text{h}}}_{{\text{i}}}}\in {{\text{R}}}^{{{\text{d}}}_{{\text{h}}}}$$\end{document}</tex-math><mml:math id="M74"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mtext>h</mml:mtext><mml:mtext>i</mml:mtext></mml:msub><mml:mo stretchy="false">&#x02192;</mml:mo></mml:mover><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mtext>R</mml:mtext></mml:mrow><mml:msub><mml:mtext>d</mml:mtext><mml:mtext>h</mml:mtext></mml:msub></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq29.gif"/></alternatives></inline-formula>, <inline-formula id="IEq30"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overleftarrow{{{\text{h}}}_{{\text{i}}}}\in {{\text{R}}}^{{{\text{d}}}_{{\text{h}}}}$$\end{document}</tex-math><mml:math id="M76"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mtext>h</mml:mtext><mml:mtext>i</mml:mtext></mml:msub><mml:mo stretchy="false">&#x02190;</mml:mo></mml:mover><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mtext>R</mml:mtext></mml:mrow><mml:msub><mml:mtext>d</mml:mtext><mml:mtext>h</mml:mtext></mml:msub></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq30.gif"/></alternatives></inline-formula>, The output is passed through a fully connected layer, and the Tanh function is used as the activation function <inline-formula id="IEq31"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\text{g}}}_{2}$$\end{document}</tex-math><mml:math id="M78"><mml:msub><mml:mtext>g</mml:mtext><mml:mn>2</mml:mn></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq31.gif"/></alternatives></inline-formula> to add nonlinear factors for hidden layer computation, where the computational metrics are shown in (10):<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${h}_{i}^{d}={g}_{2}\left({W}_{h}^{d}+U{h}_{i-1}^{d}+{b}_{h}^{d}\right)$$\end{document}</tex-math><mml:math id="M80" display="block"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mfenced close=")" open="("><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:mi>U</mml:mi><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>d</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>b</mml:mi><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msubsup></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="41598_2024_56518_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq32"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\text{W}}}_{{\text{h}}}^{{\text{d}}}\in {{\text{R}}}^{{{\text{d}}}_{{\text{a}}}\times {{\text{d}}}_{{\text{h}}}}$$\end{document}</tex-math><mml:math id="M82"><mml:mrow><mml:msubsup><mml:mtext>W</mml:mtext><mml:mrow><mml:mtext>h</mml:mtext></mml:mrow><mml:mtext>d</mml:mtext></mml:msubsup><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mtext>R</mml:mtext></mml:mrow><mml:mrow><mml:msub><mml:mtext>d</mml:mtext><mml:mtext>a</mml:mtext></mml:msub><mml:mo>&#x000d7;</mml:mo><mml:msub><mml:mtext>d</mml:mtext><mml:mtext>h</mml:mtext></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq32.gif"/></alternatives></inline-formula> is the weight matrix of a corresponding to the index of the dth; U is the weight matrix of the output b of the corresponding i-1 moment of the hidden layer; <inline-formula id="IEq33"><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{d}}\in \left\{\mathrm{0,1}\right\}$$\end{document}</tex-math><mml:math id="M84"><mml:mrow><mml:mtext>d</mml:mtext><mml:mo>&#x02208;</mml:mo><mml:mfenced close="}" open="{"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq33.gif"/></alternatives></inline-formula> denotes the different directions in the hidden layer; and <inline-formula id="IEq34"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\text{b}}}_{{\text{b}}}^{{\text{d}}}\in {{\text{R}}}^{{{\text{d}}}_{{\text{h}}}}$$\end{document}</tex-math><mml:math id="M86"><mml:mrow><mml:msubsup><mml:mtext>b</mml:mtext><mml:mrow><mml:mtext>b</mml:mtext></mml:mrow><mml:mtext>d</mml:mtext></mml:msubsup><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mtext>R</mml:mtext></mml:mrow><mml:msub><mml:mtext>d</mml:mtext><mml:mtext>h</mml:mtext></mml:msub></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq34.gif"/></alternatives></inline-formula> is the bias vector corresponding to the index of the <italic>d</italic>th. Afterwards, all <inline-formula id="IEq35"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\text{h}}}^{{\text{d}}}$$\end{document}</tex-math><mml:math id="M88"><mml:msup><mml:mrow><mml:mtext>h</mml:mtext></mml:mrow><mml:mtext>d</mml:mtext></mml:msup></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq35.gif"/></alternatives></inline-formula>&#x02019;s in the hidden layer are combined to form the final sentence-level feature vector <inline-formula id="IEq36"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{H}}$$\end{document}</tex-math><mml:math id="M90"><mml:mtext>H</mml:mtext></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq36.gif"/></alternatives></inline-formula>. The feature vector <inline-formula id="IEq37"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{H}}$$\end{document}</tex-math><mml:math id="M92"><mml:mtext>H</mml:mtext></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq37.gif"/></alternatives></inline-formula> is fed into the fully connected layer and the <inline-formula id="IEq38"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{ReLU}}$$\end{document}</tex-math><mml:math id="M94"><mml:mtext>ReLU</mml:mtext></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq38.gif"/></alternatives></inline-formula> activation function is used. The output of the fully connected layer is used as the input of the output layer, and the classification is performed using the <inline-formula id="IEq39"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{Softmax}}$$\end{document}</tex-math><mml:math id="M96"><mml:mtext>Softmax</mml:mtext></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq39.gif"/></alternatives></inline-formula> function, whose probability formula is shown in (11):<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{p}}\left({\text{y}}|\mathrm{ H},{{\text{W}}}_{{\text{S}}},{{\text{b}}}_{{\text{s}}}\right)={\text{Softmax}}\left({{\text{W}}}_{{\text{s}}}\cdot {\text{H}}+{{\text{b}}}_{{\text{s}}}\right)$$\end{document}</tex-math><mml:math id="M98" display="block"><mml:mrow><mml:mtext>p</mml:mtext><mml:mfenced close=")" open="("><mml:mrow><mml:mtext>y</mml:mtext><mml:mo stretchy="false">|</mml:mo><mml:mi mathvariant="normal">H</mml:mi><mml:mo>,</mml:mo></mml:mrow><mml:msub><mml:mtext>W</mml:mtext><mml:mtext>S</mml:mtext></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mtext>b</mml:mtext><mml:mtext>s</mml:mtext></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:mtext>Softmax</mml:mtext><mml:mfenced close=")" open="("><mml:msub><mml:mtext>W</mml:mtext><mml:mtext>s</mml:mtext></mml:msub><mml:mo>&#x000b7;</mml:mo><mml:mtext>H</mml:mtext><mml:mo>+</mml:mo><mml:msub><mml:mtext>b</mml:mtext><mml:mtext>s</mml:mtext></mml:msub></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="41598_2024_56518_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq40"><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\text{W}}}_{{\text{S}}}\in {{\text{R}}}^{|{\text{s}}|\times |{\text{l}}|}$$\end{document}</tex-math><mml:math id="M100"><mml:mrow><mml:msub><mml:mtext>W</mml:mtext><mml:mtext>S</mml:mtext></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mtext>R</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mtext>s</mml:mtext><mml:mo stretchy="false">|</mml:mo><mml:mo>&#x000d7;</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mtext>l</mml:mtext><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq40.gif"/></alternatives></inline-formula> and <inline-formula id="IEq41"><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\text{b}}}_{{\text{s}}}\in {{\text{R}}}^{|{\text{l}}|}$$\end{document}</tex-math><mml:math id="M102"><mml:mrow><mml:msub><mml:mtext>b</mml:mtext><mml:mtext>s</mml:mtext></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mtext>R</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mtext>l</mml:mtext><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq41.gif"/></alternatives></inline-formula> is the parameter of the output layer; <inline-formula id="IEq42"><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$|{\text{l}}|$$\end{document}</tex-math><mml:math id="M104"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mtext>l</mml:mtext><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_56518_Article_IEq42.gif"/></alternatives></inline-formula> is the number of propensity categories.</p></sec></sec><sec id="Sec11"><title>Experiments and results</title><p id="Par35">In order to verify the effectiveness and superiority of the danmaku sentiment analysis method based on MIBE-RoBerta-FF-BiLSTM proposed in this paper, this paper carries out comparative experiments on the self-constructed danmaku text dataset of "Bilibili Must-Watch List and Top Video Danmaku Sentiment Dataset", and the experimental results show that the performance of the method proposed in this paper is optimal, and the following describes the dataset used in this paper, the evaluation indexes, parameter settings, the comparative experimental method, as well as the results of the experiments and analysis, respectively.</p><sec id="Sec12"><title>Dataset</title><p id="Par36">This paper collect danmaku texts from Bilibili through web crawler, and construct a "Bilibili Must-Watch List and Top Video Danmaku Sentiment Dataset". Bilibili is one of the first video platforms in China to implement the danmaku mechanism, with rich video themes and a broad user base, and its user-generated danmaku is highly representative. This paper focuses on crawling the must-swipe list and the head video danmaku under each topic, covering 18 topics, such as dramas and documentaries. The danmakus of 50 negative sentiment videos were crawled specifically, totaling 4.1 million entries. After inviting 10 senior bilibili users to watch the video, Maslow's hierarchy of needs theory was used to guide the danmaku sentiment annotation, and 10,000 positive and negative sentiment danmaku each were obtained, with a total of 20,000 pieces of data, and the dataset was divided into a training set and a test set according to 8:2. The participle lexicon uses the jieba segmentation tool and the MIBE-based danmaku domain lexicon containing 2610 neologisms.</p></sec><sec id="Sec13"><title>Evaluation indicators</title><p id="Par37">This paper uses confusion matrix to statistically analyze and evaluate the model's sentiment classification results, using TP to denote danmaku samples with positive actual sentiment and positive prediction, FP to denote danmaku samples with negative actual sentiment predicted as positive, TN to denote danmaku samples with negative actual sentiment and negative prediction, and FN to denote danmaku samples with positive actual sentiment but negative prediction. FN denotes danmaku samples whose actual emotion is positive but the prediction result is negative. Accuracy (ACC), precision (P), recall (R), and reconciled mean F1 are used to evaluate the model, and the formulas are shown in (12)&#x02013;(15).<disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Acc=\frac{TP+TN}{TP+FP+TN+FN}$$\end{document}</tex-math><mml:math id="M106" display="block"><mml:mrow><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="41598_2024_56518_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ13"><label>13</label><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$P=\frac{TP}{TP+FP}$$\end{document}</tex-math><mml:math id="M108" display="block"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="41598_2024_56518_Article_Equ13.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ14"><label>14</label><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$R=\frac{TP}{TP+FN}$$\end{document}</tex-math><mml:math id="M110" display="block"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="41598_2024_56518_Article_Equ14.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ15"><label>15</label><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F1=\frac{2\times P\times R}{P+R}$$\end{document}</tex-math><mml:math id="M112" display="block"><mml:mrow><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mi>P</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="41598_2024_56518_Article_Equ15.gif" position="anchor"/></alternatives></disp-formula></p></sec><sec id="Sec14"><title>Parameter settings</title><p id="Par38">To evaluate the performance of the method proposed in this paper on the danmaku sentiment analysis task, experiments were conducted on NVIDIA GeForce RTX3060 using Python 3.8 and PyTorch framework. Chinese-RoBerta-WWM-EXT, Chinese-BERT-WWM-EXT and XLNet are used as pre-trained models with dropout rate of 0.1, hidden size of 768, number of hidden layers of 12, max Length of 80. BiLSTM model is used for sentiment text classification with dropout rate of 0.5, hidden size of 64, batch size of 64, and epoch of 20. The model is trained using Adam optimizer with a learning rate of 1e&#x02212;5 and weight decay of 0.01.</p></sec><sec id="Sec15"><title>Comparative experimental method</title><p id="Par39">In order to validate the effectiveness of the danmaku sentiment analysis model (MIBE-RobERTa-FF-BiLSTM) proposed in this paper, we compare its performance with the mainstream baseline models for sentiment analysis in recent years on a self-constructed dataset under the same experimental environment: BiLSTM, SVM and BernoulliNB models with Word2Vec vectorization, and BERT-BiLSTM, XLNET-BiLSTM, RoBERTa-BiLSTM, RoBERTa-LSTM, RoBERTa-RNN, RoBERTa-TextCNN models with the training paradigm of &#x0201c;pre-trained model&#x02009;+&#x02009;neural network classifier&#x0201d;; Using jieba lexicon and embedding FF feature fusion layer, compare models&#x02019; performance; Jieba-BERT-FF-BiLSTM,Jieba-XLNET-FF-BiLSTM,Jieba-RoBERTa-FF-BiLSTM,Jieba-RoBERTa-FF-LSTM,Jieba-RoBERTa-FF-RNN,Jieba-RoBERTa-FF-TextCNN;Adding danmaku neologism lexicon based on MIBE neologism recognition algorithm to jieba lexicon and embedding FF feature fusion layer, compare models&#x02019; performance; MIBE-BERT-FF-BiLSTM, MIBE-XLNET-FF-BiLSTM, MIBE-RoBERTa-FF-BiLSTM, MIBE-RoBERTa-FF-LSTM, MIBE-RoBERTa-FF-RNN, MIBE-RoBERTa-FF-TextCNN.</p></sec><sec id="Sec16"><title>Experimental results and analysis</title><p id="Par40">The results of the comparison experiment are shown in Table <xref rid="Tab3" ref-type="table">3</xref>.<table-wrap id="Tab3"><label>Table 3</label><caption><p>Performance statistics of the sentiment analysis models.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Model</th><th align="left">Accuracy (%)</th><th align="left">Recall (%)</th><th align="left">F1 (%)</th></tr></thead><tbody><tr><td align="left">SVM</td><td char="." align="char">88.50</td><td char="." align="char">88.46</td><td char="." align="char">88.68</td></tr><tr><td align="left">BernoulliNB</td><td char="." align="char">74.55</td><td char="." align="char">61.90</td><td char="." align="char">71.24</td></tr><tr><td align="left">BiLSTM</td><td char="." align="char">74.05</td><td char="." align="char">74.08</td><td char="." align="char">74.05</td></tr><tr><td align="left">BERT-BiLSTM</td><td char="." align="char">93.78</td><td char="." align="char">95.94</td><td char="." align="char">93.81</td></tr><tr><td align="left">XLNet-BiLSTM</td><td char="." align="char">93.15</td><td char="." align="char">94.79</td><td char="." align="char">93.08</td></tr><tr><td align="left">RoBERTa-BiLSTM</td><td char="." align="char">93.85</td><td char="." align="char">96.19</td><td char="." align="char">93.87</td></tr><tr><td align="left">RoBERTa-LSTM</td><td char="." align="char">93.73</td><td char="." align="char">95.79</td><td char="." align="char">93.67</td></tr><tr><td align="left">RoBERTa-RNN</td><td char="." align="char">93.65</td><td char="." align="char">95.79</td><td char="." align="char">93.69</td></tr><tr><td align="left">RoBERTa-TextCNN</td><td char="." align="char">93.73</td><td char="." align="char">95.99</td><td char="." align="char">93.70</td></tr><tr><td align="left">Jieba-BERT-FF-BiLSTM</td><td char="." align="char">93.85</td><td char="." align="char">95.94</td><td char="." align="char">93.84</td></tr><tr><td align="left">Jieba-XLNet-FF-BiLSTM</td><td char="." align="char">93.20</td><td char="." align="char">95.34</td><td char="." align="char">93.20</td></tr><tr><td align="left">Jieba-RoBERTa-FF-BiLSTM</td><td char="." align="char">93.88</td><td char="." align="char">95.69</td><td char="." align="char">93.88</td></tr><tr><td align="left">Jieba-RoBERTa-FF-LSTM</td><td char="." align="char">93.80</td><td char="." align="char">95.79</td><td char="." align="char">93.77</td></tr><tr><td align="left">Jieba-RoBERTa-FF-RNN</td><td char="." align="char">93.75</td><td char="." align="char">95.74</td><td char="." align="char">93.81</td></tr><tr><td align="left">Jieba-RoBERTa-FF-TextCNN</td><td char="." align="char">93.83</td><td char="." align="char">95.89</td><td char="." align="char">93.82</td></tr><tr><td align="left">MIBE-BERT-FF-BiLSTM</td><td char="." align="char">93.93</td><td char="." align="char">96.54</td><td char="." align="char">93.89</td></tr><tr><td align="left">MIBE-XLNet-FF-BiLSTM</td><td char="." align="char">93.33</td><td char="." align="char">94.64</td><td char="." align="char">93.25</td></tr><tr><td align="left">MIBE-RoBERTa-FF-BiLSTM</td><td char="." align="char">94.10</td><td char="." align="char">95.84</td><td char="." align="char">94.06</td></tr><tr><td align="left">MIBE-RoBERTa-FF-LSTM</td><td char="." align="char">93.98</td><td char="." align="char">95.14</td><td char="." align="char">93.95</td></tr><tr><td align="left">MIBE-RoBERTa-FF-RNN</td><td char="." align="char">94.03</td><td char="." align="char">95.24</td><td char="." align="char">94.04</td></tr><tr><td align="left">MIBE-RoBERTa-FF-TextCNN</td><td char="." align="char">93.85</td><td char="." align="char">97.34</td><td char="." align="char">93.84</td></tr></tbody></table></table-wrap></p><p id="Par41">In order to visually compare the performance of each comparative model, this paper, based on Table <xref rid="Tab3" ref-type="table">3</xref>, draws Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref> (performance statistics of mainstream baseline model for sentiment analysis), Fig.&#x000a0;<xref rid="Fig8" ref-type="fig">8</xref> (performance statistics of mainstream baseline model with the introduction of the jieba lexicon and the FF layer), Fig.&#x000a0;<xref rid="Fig9" ref-type="fig">9</xref> (performance statistics of mainstream baseline model with the introduction of the MIBE-based lexicon and the FF layer), and Fig.&#x000a0;<xref rid="Fig10" ref-type="fig">10</xref> (comprehensive statistics of the performance of the sentiment analysis model), respectively.<fig id="Fig7"><label>Figure 7</label><caption><p>Performance statistics of mainstream baseline model for sentiment analysis.</p></caption><graphic xlink:href="41598_2024_56518_Fig7_HTML" id="MO7"/></fig><fig id="Fig8"><label>Figure 8</label><caption><p>Performance statistics of mainstream baseline model with the introduction of the jieba lexicon and the FF layer.</p></caption><graphic xlink:href="41598_2024_56518_Fig8_HTML" id="MO8"/></fig><fig id="Fig9"><label>Figure 9</label><caption><p>Performance statistics of mainstream baseline model with the introduction of the MIBE-based lexicon and the FF layer.</p></caption><graphic xlink:href="41598_2024_56518_Fig9_HTML" id="MO9"/></fig><fig id="Fig10"><label>Figure 10</label><caption><p>Comprehensive statistics of the performance of the sentiment analysis model, respectively.</p></caption><graphic xlink:href="41598_2024_56518_Fig10_HTML" id="MO10"/></fig></p><p id="Par42">Based on Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>, it can be found that among the mainstream baseline models, the RoBERTa-BiLSTM model has the best performance, with accuracy, recall and F1 value exceeding 93.85%, which indicates that the RoBERTa pre-trained model is able to adequately extract the semantic and structural information of the danmaku text, and then using the bidirectional sequence modeling capability of the BiLSTM model, it can effectively capture the contextual information of danmaku text as well as fitting the textual characteristics of danmaku text with varying length and linguistic diversity, better understanding and modeling the dependency relationships in danmaku text, and improving the model's ability to classify emotional tendencies. The BERT-BiLSTM model performs slightly lower than the RoBERTa-BiLSTM model on this task, probably because the RoBERTa model uses a larger dataset, larger batch size, higher learning rate, and better masking strategy compared to the BERT model during the pre-training process, which allows it to show more robustness and higher optimization level. XLNET-BiLSTM has the worst performance on this task, probably because XLNET adopts an improved autoregressive training approach, which may lead to its performance on sentiment classification is not as good as that of the BERT and RoBERTa models that adopt an autocoding training approach; and chinese-roberta-wwm-ext and chinese-bert-wwm-ext are models specifically pre-trained for use on Chinese text, their lexical and grammatical comprehension is more powerful on Chinese text, which is more suitable for the Chinese sentiment classification task. RoBERTa-TextCNN model achieved a good performance on this task table, but there is a gap with BERT-BiLSTM and RoBERTa-BiLSTM model, probably because the TextCNN model is to use convolution kernel sliding on the text sequence to capture the local information, and get the global information through the pooling layer, and its ability to capture the global long-distance dependence is relatively weak, and it can not effectively deal with the characteristics of the danmaku text of varying lengths and linguistic diversity, and it may be the problem of information loss or noise interference. RoBERTa-RNN and RoBERTa-LSTM models perform slightly worse on this task, probably because RNN has a weak ability to capture the information before and after the danmaku text sequence and is prone to gradient vanishing and gradient explosion problems; LSTM model has a lower information utilization rate compared to BiLSTM model, which relies on unidirectional information transfer only, and some important contextual information is easy to be ignored, and the ability to capture bidirectional dependencies of the danmaku text is slightly weak. The neural network and machine learning methods without using pre-trained models performed the worst, with the overall performance far lower than the methods using pre-trained models. Among them, the SVM model performed relatively well, with the accuracy, recall and F1 values all exceeding 88.50%. The model had a strong generalization ability in dealing with binary classification problems, but it focused on the selection and representation of features. The semantic features of danmaku texts were complex, which might exceed the model&#x02019;s processing ability. The BiLSTM model performed second, and only learned simple temporal information without the support of pre-trained models. It was difficult to learn the deep and rich linguistic knowledge of danmaku texts. The BernoulliNB model performed the worst, as it required binarization of the data, which resulted in some information loss and affected the quality and integrity of the data.</p><p id="Par43">Based on Fig.&#x000a0;<xref rid="Fig8" ref-type="fig">8</xref>, it can be found that after the introduction of jieba word-splitting lexicon and embedding FF feature fusion layer in the mainstream baseline model, the performance of each model is improved, especially the F1 values of XLNET-BiLSTM, RoBERTa-LSTM, RoBERTa-RNN, and RoBERTa-TextCNN are all increased by more than 0.1%. It indicates that the introduction of jieba lexicon can cut Chinese danmaku text into more reasonable words, reduce noise and ambiguity, and improve the quality of word embedding. The FF feature fusion layer is able to average the feature encoding of the words in each word to get the word encoding that retains the semantic information of the word, which makes Chinese word splitting meaningful, and is also helpful to eliminate the effect of multiple meanings of words, express more accurate information, and enhance the semantic comprehension and generalization ability of the model.</p><p id="Par44">Based on Fig.&#x000a0;<xref rid="Fig9" ref-type="fig">9</xref>, it can be found that after adding MIBE neologism recognition to the model in Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>, the performance of each model is improved, especially the accuracy and F1 value of RoBERTa-FF-BiLSTM, RoBERTa-FF-LSTM, and RoBERTa-FF-RNN are increased by about 0.2%. It shows that the MIBE neologism recognition algorithm based on MIBE can effectively discover neologisms in danmaku text, and the introduction of jieba can enrich its participle thesaurus and improve the accuracy of Chinese participle, which in turn improves the performance of the model. Therefore, it is also demonstrated that there are a large number of non-standard and creative web-popular neologisms in danmaku text, which can negatively affect the model's semantic comprehension and sentiment categorization ability if they are not recognized.</p><p id="Par45">Based on Fig.&#x000a0;<xref rid="Fig10" ref-type="fig">10</xref>, comprehensively, the MIBE-RoBERTa-FF-BiLSTM model proposed in this paper has the best overall performance in the task of sentiment categorization of Chinese danmaku text in video, with an accuracy rate of 94.10%, a recall rate of 95.84%, and an F1 value of 94.06%. It indicates that the MIBE-RoBERTa-FF-BiLSTM model can effectively deal with the informal language of danmaku text in this task, and can effectively discover new words in danmaku text, fully extract the semantic and structural information of danmaku text, and learn the word information, character information, and contextual information of danmaku text, so as to better understand and model the semantic and dependency relationships in danmaku text, and improve the model's ability to classify emotional tendencies and generalization.</p></sec></sec><sec id="Sec17"><title>Discussions</title><p id="Par46">This paper proposes to classify the sentiment of danmaku texts based on the MIBE-RoBERTa-FF-BiLSTM model, and adopts the neologism recognition algorithm based on mutual information (MI) and branchentropy (BE), which can effectively discover the non-regular popular neologisms with more than three elements in danmaku text, and introduce the jieba lexical lexicon, which can slice the text into more reasonable words, such as "&#x07237;&#x09752;&#x056de;", "&#x0868c;&#x057e0;&#x04f4f;&#x04e86;", etc. It reduces noise and ambiguity, improves the quality of word embeddings, is more efficient and adaptable to the characteristics and variations of danmaku texts compared to traditional lexicons, and is able to capture fresh and interesting expressions in the text, which solves RQ2. Based on Maslow's hierarchy of needs theory, this paper argues that danmaku text emotion is jointly generated by individual needs and external stimuli. By parsing the hierarchy of needs in danmaku and combining it with the video content, it improves the reasonableness and consistency of the emotion annotation, which is more reflective of the psychological state and motivation of the danmaku users than the traditional annotation, reduces the difficulty of the annotation, and solves the RQ1. This paper uses RoBERTa-FF-BiLSTM model to learn the semantic features of danmaku texts, and the pre-trained model based on RoBERTa is able to fully extract the semantic and structural information of danmaku text, learn deeper and richer linguistic knowledge than traditional machine learning or shallow neural network methods, improve the model's ability to generalize on small-scale data, and solve the RQ3; Based on the feature fusion layer the feature encoding of the words in each word after word splitting is averaged and then filled into the position of the original word, compared with the traditional word encoding method, it is able to obtain the word encoding that retains the semantic information of the word, eliminates the effect of multiple meanings of the word, and solves the RQ4; Based on the BiLSTM model to capture the contextual information of danmaku text, it efficiently fits the textual characteristics of danmaku text of varying lengths and linguistic diversity, and is able to adapt to danmaku text of different lengths and styles compared to traditional convolutional neural network or recurrent neural network approaches.</p><p id="Par47">However, the study of the text has the following limitations and challenges:<list list-type="order"><list-item><p id="Par48">The danmaku text contains a large number of popular new words on the Internet, such as self-made words, abbreviations, interactive words, etc. These new words increase the difficulty of semantic understanding and emotional expression of the danmaku text. This paper uses a danmaku new word recognition algorithm based on MIBE, which can automatically discover irregular popular words in the danmaku text, but still needs manual semantic understanding and evaluation in combination with the context and video content, judging the quality of the new words, eliminating invalid words, and the degree of automation is limited. The manual review process is not only time-consuming and labor-intensive, but also may have subjective bias and inconsistency, affecting the quality and reliability of the new word dictionary.</p></list-item><list-item><p id="Par49">This paper only considers the danmaku text content, ignoring the semantic information of the danmaku video content, and the understanding and evaluation of the danmaku&#x02019;s emotional expression is relatively single. The danmaku text and video content are interrelated and influenced by each other. The emotional tendency and expression of the danmaku users are often stimulated and guided by the video content. Simply analyzing the danmaku text content may ignore some important emotional information and contextual information, resulting in the sentiment analysis results not being accurate and comprehensive enough.</p></list-item><list-item><p id="Par50">In the comparative experiment, the training paradigm of &#x0201c;pre-trained model&#x02009;+&#x02009;neural network classifier&#x0201d; was used. Although it achieved high performance, there were also some problems. The recall rate of the model under this paradigm was higher than the accuracy and F1 values, indicating that the model&#x02019;s prediction results and true labels had deviations, and the model was more inclined to predict negative cases as positive cases, resulting in positive case preference problems.</p></list-item></list></p><p id="Par51">In the future, the following aspects can be considered for optimization and improvement:<list list-type="order"><list-item><p id="Par52">We will perform topic identification on the danmaku new words identified by the MIBE algorithm, design corresponding prompts, and use large language models such as GTP4, Llama2, ChatGLM3, etc. to perform semantic analysis and quality evaluation on the danmaku new words more logically and efficiently, filter out meaningful and useful new words, automatically construct the danmaku new word dictionary, and reduce the workload and error of manual review.</p></list-item><list-item><p id="Par53">We will use multimodal representation methods such as CLIP to extract and fuse features of the danmaku text and video content, capture the interactive emotional information between the danmaku text and video content, and understand the danmaku&#x02019;s emotional expression more comprehensively and accurately.</p></list-item><list-item><p id="Par54">We will design a text quality evaluation and error correction model of &#x0201c;pre-trained model (T5, MacBERT, etc.)&#x02009;+&#x02009;external knowledge base&#x0201d;, try to evaluate and score the danmaku texts with positive and negative emotions, clean, standardize, correct, etc. the texts with low quality, improve the quality of the texts, make the texts with positive and negative emotions more close in quality, thereby reducing the model&#x02019;s positive case preference, and improve the model&#x02019;s prediction performance and generalization ability.</p></list-item></list></p></sec><sec id="Sec18"><title>Conclusion</title><p id="Par55">This paper presents a video danmaku sentiment analysis method based on MIBE-RoBERTa-FF-BiLSTM. It employs Maslow's Hierarchy of Needs theory to enhance sentiment annotation consistency, effectively identifies non-standard web-popular neologisms in danmaku text, and extracts semantic and structural information comprehensively. By learning word, character, and context information, the model better understands and models semantic and dependency relationships in danmaku text. It outperforms mainstream models in video danmaku sentiment classification. This research method offers a novel perspective on video danmaku sentiment analysis, serving as a valuable reference for related fields.</p></sec></body><back><fn-group><fn><p><bold>Publisher's note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><ack><title>Acknowledgements</title><p>This study was financially supported by the Major S&#x00026;T project (Innovation 2030) of China(2021ZD0113702), Xi'an Major Scientific and Technological Achievements Transformation and Industrialization Project(20KYPT0003-10).</p></ack><notes notes-type="author-contribution"><title>Author contributions</title><p>H.L. formulated the overall research strategy and guided the work. J.Z kept the original data on which the paper was based and verified whether the charts and conclusions accurately reflected the collected data. J.Z. W.Z. and Y.W. wrote the main manuscript text. W.Z. Y.W. and X.Z. finished collecting and sorting out the data. T.S. B.L. and Y.Q. prepared figures 1&#x02013;10, T.S. S.Z. and X.Z. prepared Tables 1&#x02013;3. All authors reviewed the manuscript.</p></notes><notes notes-type="data-availability"><title>Data availability</title><p>This paper collect danmaku texts from Bilibili through web crawler, and construct a "Bilibili Must-Watch List and Top Video Danmaku Sentiment Dataset" with a total of 20,000 pieces of data. The datasets and codes generated during the current study are available from the corresponding author on reasonable request.</p></notes><notes id="FPar1" notes-type="COI-statement"><title>Competing interests</title><p id="Par56">The authors declare no competing interests.</p></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ni</surname><given-names>W</given-names></name><name><surname>Coup&#x000e9;</surname><given-names>C</given-names></name></person-group><article-title>Time-synchronic comments on video streaming website reveal core structures of audience engagement in movie viewing</article-title><source>Front. Psychol.</source><year>2023</year><volume>13</volume><fpage>1040755</fpage><pub-id pub-id-type="doi">10.3389/fpsyg.2022.1040755</pub-id><?supplied-pmid 36743643?><pub-id pub-id-type="pmid">36743643</pub-id>
</element-citation></ref><ref id="CR2"><label>2.</label><mixed-citation publication-type="other">China Internet Network Information Center. The 47th Statistical Report on China&#x02019;s Internet Development. Preprint at <ext-link ext-link-type="uri" xlink:href="http://www.cac.gov.cn/2021-02/03/c_1613923423079314.htm">http://www.cac.gov.cn/2021-02/03/c_1613923423079314.htm</ext-link> (2022).</mixed-citation></ref><ref id="CR3"><label>3.</label><mixed-citation publication-type="other">Bo, Y. In <italic>2020 IEEE Learning With MOOCS (LWMOOCS)</italic> 100&#x02013;104 (IEEE, 2020).</mixed-citation></ref><ref id="CR4"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hao</surname><given-names>X</given-names></name><name><surname>Xu</surname><given-names>S</given-names></name><name><surname>Zhang</surname><given-names>X</given-names></name></person-group><article-title>Barrage participation and feedback in travel reality shows: The effects of media on destination image among Generation Y</article-title><source>J. Destin. Mark. Manag.</source><year>2019</year><volume>12</volume><fpage>27</fpage><lpage>36</lpage></element-citation></ref><ref id="CR5"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yuan</surname><given-names>H</given-names></name><name><surname>Fang</surname><given-names>Q</given-names></name><name><surname>Bai</surname><given-names>L</given-names></name></person-group><article-title>A study of the time-varying effects of danmaku on the process of online consumer behavior</article-title><source>J. Manag.</source><year>2020</year><volume>17</volume><fpage>1059</fpage><lpage>1066</lpage></element-citation></ref><ref id="CR6"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deng</surname><given-names>Y</given-names></name><name><surname>Zhang</surname><given-names>C</given-names></name><name><surname>Li</surname><given-names>J</given-names></name></person-group><article-title>A video clip recommendation model based on danmaku sentiment analysis</article-title><source>Comput. Appl.</source><year>2017</year><volume>37</volume><fpage>1065</fpage><lpage>1070</lpage></element-citation></ref><ref id="CR7"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hong</surname><given-names>Q</given-names></name><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Zhao</surname><given-names>Q</given-names></name><name><surname>Li</surname><given-names>J</given-names></name><name><surname>Rao</surname><given-names>W</given-names></name></person-group><article-title>Classification of video user groups based on danmaku sentiment analysis and clustering algorithm</article-title><source>Comput. Eng. Sci.</source><year>2018</year><volume>40</volume><fpage>1125</fpage><lpage>1139</lpage></element-citation></ref><ref id="CR8"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>M</given-names></name><name><surname>Yu</surname><given-names>J</given-names></name><name><surname>Jiang</surname><given-names>Z</given-names></name><name><surname>Sun</surname><given-names>Y</given-names></name></person-group><article-title>The effect of ad insertion mechanism on consumers&#x02019; impulse purchase intention based on danmaku sentiment analysis of online videos</article-title><source>J. Syst. Manag.</source><year>2021</year><volume>30</volume><fpage>1187</fpage><lpage>1197</lpage></element-citation></ref><ref id="CR9"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Z</given-names></name><name><surname>Duan</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>R</given-names></name></person-group><article-title>Dynamic advertising insertion strategy with moment-to-moment data using sentiment analysis: The case of danmaku video</article-title><source>J. Electron. Commer. Res.</source><year>2022</year><volume>23</volume><fpage>160</fpage><lpage>176</lpage></element-citation></ref><ref id="CR10"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Si</surname><given-names>Z</given-names></name><name><surname>Tan</surname><given-names>T</given-names></name></person-group><article-title>Interaction design and opinion guidance for sentiment analysis of danmaku comments</article-title><source>Young Journal.</source><year>2021</year><pub-id pub-id-type="doi">10.15997/j.cnki.qnjz.2021.10.015</pub-id></element-citation></ref><ref id="CR11"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chirgaiya</surname><given-names>S</given-names></name><name><surname>Sukheja</surname><given-names>D</given-names></name><name><surname>Shrivastava</surname><given-names>N</given-names></name><name><surname>Rawat</surname><given-names>R</given-names></name></person-group><article-title>Analysis of sentiment based movie reviews using machine learning techniques</article-title><source>J. Intell. Fuzzy Syst.</source><year>2021</year><volume>41</volume><fpage>5449</fpage><lpage>5456</lpage><pub-id pub-id-type="doi">10.3233/JIFS-189866</pub-id></element-citation></ref><ref id="CR12"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Purohit</surname><given-names>A</given-names></name><name><surname>Patheja</surname><given-names>PS</given-names></name></person-group><article-title>Product review opinion based on sentiment analysis</article-title><source>J. Intell. Fuzzy Syst.</source><year>2023</year><volume>44</volume><fpage>3153</fpage><lpage>3169</lpage><pub-id pub-id-type="doi">10.3233/JIFS-213296</pub-id></element-citation></ref><ref id="CR13"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumar</surname><given-names>P</given-names></name><name><surname>Dhinesh Babu</surname><given-names>L</given-names></name></person-group><article-title>Fuzzy based feature engineering architecture for sentiment analysis of medical discussion over online social networks</article-title><source>J. Intell. Fuzzy Syst.</source><year>2021</year><volume>40</volume><fpage>11749</fpage><lpage>11761</lpage><pub-id pub-id-type="doi">10.3233/JIFS-202874</pub-id></element-citation></ref><ref id="CR14"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>X</given-names></name><name><surname>Yao</surname><given-names>Q</given-names></name></person-group><article-title>A comparative study of user danmaku and comment features in multiple topic scenarios: based on the Bilibili website</article-title><source>Intell. Theory Pract.</source><year>2021</year><volume>44</volume><fpage>135</fpage><lpage>141</lpage><pub-id pub-id-type="doi">10.16353/j.cnki.1000-7490.2021.09.019</pub-id></element-citation></ref><ref id="CR15"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cui</surname><given-names>Z</given-names></name><etal/></person-group><article-title>A barrage sentiment analysis scheme based on expression and tone</article-title><source>IEEE Access</source><year>2019</year><volume>7</volume><fpage>180324</fpage><lpage>180335</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2019.2957279</pub-id></element-citation></ref><ref id="CR16"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>S</given-names></name><name><surname>Liu</surname><given-names>L</given-names></name><name><surname>Ma</surname><given-names>Q</given-names></name></person-group><article-title>Self-attention mechanism based danmaku text sentiment classification model</article-title><source>J. Meas. Sci. Instrum.</source><year>2021</year><volume>12</volume><fpage>479</fpage><lpage>488</lpage></element-citation></ref><ref id="CR17"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hsieh</surname><given-names>Y-H</given-names></name><name><surname>Zeng</surname><given-names>X-P</given-names></name></person-group><article-title>Sentiment analysis: An ERNIE-BiLSTM approach to bullet screen comments</article-title><source>Sensors</source><year>2022</year><volume>22</volume><fpage>5223</fpage><pub-id pub-id-type="doi">10.3390/s22145223</pub-id><?supplied-pmid 35890903?><pub-id pub-id-type="pmid">35890903</pub-id>
</element-citation></ref><ref id="CR18"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cao</surname><given-names>S</given-names></name><etal/></person-group><article-title>VisDmk: Visual analysis of massive emotional danmaku in online videos</article-title><source>Vis. Comput.</source><year>2023</year><volume>39</volume><fpage>6553</fpage><lpage>6570</lpage><pub-id pub-id-type="doi">10.1007/s00371-022-02748-z</pub-id></element-citation></ref><ref id="CR19"><label>19.</label><mixed-citation publication-type="other">Li, J. &#x00026; Li, Y. In <italic>Advanced Data Mining and Applications: 15th International Conference, ADMA 2019, Dalian, China, 21&#x02013;23 Nov, 2019, Proceedings 15</italic> 474&#x02013;488 (Springer, 2019).</mixed-citation></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="other">Zheng, X., Xu, J. &#x00026; Xiao, Z. Sentiment analysis and visualization methods in online video danmaku data analysis. <italic>Mod. Libr. Intell. Technol.</italic> 82&#x02013;90 (2015).</mixed-citation></ref><ref id="CR21"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>M</given-names></name><name><surname>Xu</surname><given-names>J</given-names></name></person-group><article-title>Sentiment analysis and comparative study of video danmaku with subtitles</article-title><source>Doc. Inf. Knowl.</source><year>2019</year><pub-id pub-id-type="doi">10.13366/j.dik.2019.05.109</pub-id></element-citation></ref><ref id="CR22"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>Z</given-names></name><name><surname>Li</surname><given-names>R</given-names></name><name><surname>Jin</surname><given-names>G</given-names></name></person-group><article-title>Sentiment analysis of danmaku videos based on na&#x000ef;ve Bayes and sentiment dictionary</article-title><source>IEEE Access</source><year>2020</year><volume>8</volume><fpage>75073</fpage><lpage>75084</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2020.2986582</pub-id></element-citation></ref><ref id="CR23"><label>23.</label><mixed-citation publication-type="other">Liu, G.-F., Li, L.-L., Xu, H.-M. &#x00026; Luo, M.-Q. In <italic>2019 5th International Conference on Social Science and Higher Education (ICSSHE 2019)</italic> 427&#x02013;432 (Atlantis Press, 2019).</mixed-citation></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="other">Zeng, Q., Guo, Q., Zhuang, W., Zhang, Y. &#x00026; Fan, W. Do real-time reviews matter? Examining how bullet screen influences consumers&#x02019; purchase intention in live streaming commerce. <italic>Inf. Syst. Front.</italic> 1&#x02013;17 (2022).</mixed-citation></ref><ref id="CR25"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jin</surname><given-names>D</given-names></name><name><surname>Yu</surname><given-names>G</given-names></name></person-group><article-title>Analysis of danmaku tendency of B station videos based on multidimensional sentiment lexicon</article-title><source>J. Fuyang Norm. Univ. (Nat. Sci. Ed.)</source><year>2022</year><volume>39</volume><fpage>99</fpage><lpage>105</lpage><pub-id pub-id-type="doi">10.14096/j.cnki.cn34-1069/n/2096-9341(2022)02-0099-07</pub-id></element-citation></ref><ref id="CR26"><label>26.</label><mixed-citation publication-type="other">Li, Y.-J., Shi, J., Zhang, F.-L. &#x00026; Wang, M. In<italic> 2022 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)</italic> 1&#x02013;10 (IEEE, 2022).</mixed-citation></ref><ref id="CR27"><label>27.</label><mixed-citation publication-type="other">Xu, J., Ding, Y. &#x00026; Wang, X. Automatic sentiment classification of news using machine learning methods. <italic>J. Chin. Inf.</italic> 95&#x02013;100 (2007).</mixed-citation></ref><ref id="CR28"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shang</surname><given-names>Y</given-names></name><name><surname>Zhao</surname><given-names>Y</given-names></name></person-group><article-title>Sentiment analysis and implementation of online comments based on machine learning</article-title><source>J. Dali Univ.</source><year>2021</year><volume>6</volume><fpage>80</fpage><lpage>86</lpage></element-citation></ref><ref id="CR29"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>M</given-names></name><name><surname>Fan</surname><given-names>C</given-names></name><name><surname>Zhu</surname><given-names>Y</given-names></name></person-group><article-title>Sentiment analysis of microblog comments based on machine learning</article-title><source>Inf. Comput. (Theor. Ed.)</source><year>2020</year><volume>32</volume><fpage>71</fpage><lpage>73</lpage></element-citation></ref><ref id="CR30"><label>30.</label><mixed-citation publication-type="other">Ye, J. &#x00026; Zhao, H. An opinion analysis model based on large-scale danmaku data listening and sentiment classification. <italic>J. East China Norm. Univ. (Nat. Sci. Ed.)</italic> 86&#x02013;100 (2019).</mixed-citation></ref><ref id="CR31"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>S</given-names></name><etal/></person-group><article-title>Improved Danmaku emotion analysis and its application based on Bi-lSTM model</article-title><source>IEEE Access</source><year>2020</year><volume>8</volume><fpage>114123</fpage><lpage>114134</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2020.3001046</pub-id></element-citation></ref><ref id="CR32"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bai</surname><given-names>Q</given-names></name><name><surname>Hu</surname><given-names>QV</given-names></name><name><surname>Ge</surname><given-names>L</given-names></name><name><surname>He</surname><given-names>L</given-names></name></person-group><article-title>Stories that big danmaku data can tell as a new media</article-title><source>IEEE Access</source><year>2019</year><volume>7</volume><fpage>53509</fpage><lpage>53519</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2019.2909054</pub-id></element-citation></ref><ref id="CR33"><label>33.</label><mixed-citation publication-type="other">Li, H. &#x00026; Mou, X. In <italic>2022 10th International Conference on Information and Education Technology (ICIET)</italic> 384&#x02013;389 (IEEE, 2022).</mixed-citation></ref><ref id="CR34"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Liao</surname><given-names>W</given-names></name></person-group><article-title>Research on intelligent recognition model of emotion information in online education danmaku - fusion of variable emotion lexicon and deep learning technology</article-title><source>Mod. Distance Educ.</source><year>2023</year><pub-id pub-id-type="doi">10.13927/j.cnki.yuan.2023.0003</pub-id></element-citation></ref><ref id="CR35"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>J</given-names></name><name><surname>Chu</surname><given-names>J</given-names></name></person-group><article-title>Joint analysis of users&#x02019; attention and emotion in online knowledge community based on barrage comments</article-title><source>Digit. Libr. Forum</source><year>2023</year><volume>19</volume><fpage>68</fpage><lpage>76</lpage></element-citation></ref><ref id="CR36"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bai</surname><given-names>Q</given-names></name><etal/></person-group><article-title>Entity-level sentiment prediction in Danmaku video interaction</article-title><source>J. Supercomput.</source><year>2021</year><volume>77</volume><fpage>1</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.1007/s11227-021-03652-4</pub-id></element-citation></ref><ref id="CR37"><label>37.</label><mixed-citation publication-type="other">Chen, Z., Tang, Y., Zhang, Z., Zhang, C. &#x00026; Wang, L. <italic>In 2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI)</italic> 1172&#x02013;1179 (IEEE, 2019).</mixed-citation></ref><ref id="CR38"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pan</surname><given-names>X</given-names></name><name><surname>Du</surname><given-names>J</given-names></name></person-group><article-title>Artificial emotion modeling of Maslow&#x02019;s hierarchical needs theory</article-title><source>J. Huaqiao Univ. (Nat. Sci. Ed.)</source><year>2010</year><volume>31</volume><fpage>23</fpage><lpage>26</lpage></element-citation></ref><ref id="CR39"><label>39.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>D</given-names></name><name><surname>Ye</surname><given-names>M</given-names></name></person-group><article-title>A review of the research on revertive neural networks and their applications</article-title><source>Small Microcomput. Syst.</source><year>2020</year><volume>41</volume><fpage>2024</fpage><lpage>2029</lpage></element-citation></ref></ref-list></back></article>