<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?DTDIdentifier.IdentifierValue -//ES//DTD journal article DTD version 5.6.0//EN//XML?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName art560.dtd?><?SourceDTD.Version 5.6.0?><?ConverterInfo.XSLTName elsevier2nlmx2.xsl?><?ConverterInfo.Version 1?><?origin publisher?><?FILEmeta_HLY30184 xml ?><?FILEmain xml ?><?FILEmain pdf ?><?FILEgr1 jpg ?><?FILEgr2 jpg ?><?FILEgr3 jpg ?><?FILEgr4 jpg ?><?FILEgr5 jpg ?><?FILEgr6 jpg ?><?properties open_access?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Heliyon</journal-id><journal-id journal-id-type="iso-abbrev">Heliyon</journal-id><journal-title-group><journal-title>Heliyon</journal-title></journal-title-group><issn pub-type="epub">2405-8440</issn><publisher><publisher-name>Elsevier</publisher-name></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmcid">11088250</article-id><article-id pub-id-type="pii">S2405-8440(24)06215-7</article-id><article-id pub-id-type="doi">10.1016/j.heliyon.2024.e30184</article-id><article-id pub-id-type="publisher-id">e30184</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>Artificial intelligence in judicial adjudication: Semantic biasness classification and identification in legal judgement (SBCILJ)</article-title></title-group><contrib-group><contrib contrib-type="author" id="au1"><name><surname>Javed</surname><given-names>Kashif</given-names></name></contrib><contrib contrib-type="author" id="au2"><name><surname>Li</surname><given-names>Jianxin</given-names></name><email>jianxinlee@zzu.edu.cn</email><xref rid="cor1" ref-type="corresp">&#x0204e;</xref></contrib><aff id="aff1">School of Law, Zhengzhou University, Zhengzhou, 450001, Henan, China</aff></contrib-group><author-notes><corresp id="cor1"><label>&#x0204e;</label>Corresponding author. <email>jianxinlee@zzu.edu.cn</email></corresp></author-notes><pub-date pub-type="pmc-release"><day>26</day><month>4</month><year>2024</year></pub-date><!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.--><pub-date pub-type="collection"><day>15</day><month>5</month><year>2024</year></pub-date><pub-date pub-type="epub"><day>26</day><month>4</month><year>2024</year></pub-date><volume>10</volume><issue>9</issue><elocation-id>e30184</elocation-id><history><date date-type="received"><day>5</day><month>2</month><year>2024</year></date><date date-type="rev-recd"><day>20</day><month>4</month><year>2024</year></date><date date-type="accepted"><day>22</day><month>4</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; 2024 The Authors</copyright-statement><copyright-year>2024</copyright-year><license><ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p>This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).</license-p></license></permissions><abstract id="abs0010"><p>History reveals that human societies have suffered in terms of social justice due to cognitive bias. Semantic bias tends to amplify cognitive bias. Therefore, the presence of cognitive biases in extensive historical data can potentially result in unethical and allegedly inhumane predictions since AI systems are trained on this data. The innovation of artificial intelligence and its rapid integration across disciplines has prompted questions regarding the subjectivity of the technology. Current research focuses the semantic bias in legal judgment to increase the legitimacy of training data. By the application of general-purpose Artificial Intelligence (AI) algorithms, we classify and detect the semantics bias that is present in the Chinese Artificial Intelligence and Law (CAIL) dataset. Our findings demonstrate that AI models acquire superior prediction power in the CAIL dataset, which is comprised of hundreds of cases, compared to a structured professional risk assessment tool. To assist legal practitioners during this process, innovative approaches that are based on AI may be implemented inside the legal arena. To accomplish this objective, we suggested a classification model for semantic bias that is related to the classification and identification of semantic biases in legal judgment. Our proposed model legal field uses the example of categorization along with the identification of the CAIL dataset. This will be accomplished by identifying the semantics biases in judicial decisions. We used different types of classifiers such as the Support Vector Machine (SVM), Na&#x000ef;ve-Bayes (NB), Multi-Layer Perceptron (MLP), and the K-Nearest Neighbour (KNN) to come across the preferred results. SVM got 96.90 %, NB has 88.80 %, MLP has 86.75 % and KNN achieved 85.66 % accuracy whereas SVM achieved greater accuracy as compared to other models. Additionally, we demonstrate that we were able to get a relatively high classification performance when predicting outcomes based just on the semantic bias categorization in judicial judgments that determine the outcome of the case.</p></abstract><abstract abstract-type="author-highlights" id="abs0015"><title>Highlights</title><p><list list-type="simple" id="ulist0010"><list-item id="u0010"><label>&#x02022;</label><p id="p0010">The study digs out the semantic biasness in legal judgements.</p></list-item><list-item id="u0015"><label>&#x02022;</label><p id="p0015">It uses CAIL dataset.</p></list-item><list-item id="u0020"><label>&#x02022;</label><p id="p0020">It uses Semantic Biasness Classification and Identification in Legal Judgement (SBCILJ).</p></list-item><list-item id="u0025"><label>&#x02022;</label><p id="p0025">It provides solution as to classification of semantic bias in legal judgement.</p></list-item><list-item id="u0030"><label>&#x02022;</label><p id="p0030">It focuses on mitigation and recommendation for legal judgement.</p></list-item></list></p></abstract><kwd-group id="kwrds0010"><title>Keywords</title><kwd>Artificial intelligence</kwd><kwd>Judicial adjudication</kwd><kwd>Semantic biasedness</kwd><kwd>Legal judgment</kwd><kwd>CAIL dataset</kwd><kwd>Natural language processing</kwd></kwd-group></article-meta></front><body><sec id="sec1"><label>1</label><title>Introduction</title><p id="p0035">The global judiciaries have been plagued by a backlog of cases, resulting in a decline in justice. Therefore, it has been seen as a significant objective of sustainability [<xref rid="bib1" ref-type="bibr">1</xref>]. AI has entered its innovative year after renewed interest from the business community. Therefore, AI is promising to solve numerous problems that are currently being faced by adversarial systems (common law) and inquisitorial systems (civil law), including the backlog of cases, delays in the administration of justice, and misuse of discretionary power by the judges as being subjective in their decisions across the globe. Like the other innovative techniques of AI, machine learning (ML) is also capable of helping the legal domain solve the above-stated issues. Che et al. [<xref rid="bib2" ref-type="bibr">2</xref>] proposed a medical vision-language pre-training with frozen language models and latent space geometry optimization (M-FLAG) that uses a frozen language model for training stability and efficiency while also introducing a novel orthogonality loss to harmonize the latent space geometry. Zhongwei et al. [<xref rid="bib3" ref-type="bibr">3</xref>] propose Unifying Cross-Lingual Medical Vision-Language Pre-Training (Med-UniC) to combine multimodal medical data from English and Spanish, the two most widely spoken languages. We propose Cross-lingual Text Alignment Regularization (CTR) to explicitly integrate medical report semantics from diverse language communities.</p><p id="p0040">Judicial systems stand for maintaining a calm, progressing, and just society, so it is in dire need to use AI techniques to solve administrative issues [<xref rid="bib4" ref-type="bibr">4</xref>,<xref rid="bib5" ref-type="bibr">5</xref>]. &#x0201c;Rule-based&#x0201d; systems have been utilized in the operation of the administration of legal processes ever since the seventh decade of the twentieth century. Until recently, the field of law has placed some imitations on the use of rule-based reasoning, case-based reasoning, and machine learning. This is because a deep understanding of settled legal principles is necessary to effectively utilize these methods in the legal domain [<xref rid="bib6" ref-type="bibr">6</xref>]. One cannot ignore the prospect that the capability of machine learning models to acquire rules from huge datasets could lead to the elimination of cognitive biases that are inherent to human beings, as well as an improvement in the precision of decision-making. In every culture, words and phrases of language are associated with specific situations and carry their relative meanings. These words may have different meanings when translated into another language, and they may even have different ways of understanding. This semantic bias may trigger the cognitive bias when judges decide the cases. This is a possibility of subjectivity that cannot be denied. The models built by Machin Learning use the available big data that carries semantic bias. Such bias data will cause bias results as it acquires rules from this data [<xref rid="bib7" ref-type="bibr">7</xref>].</p><p id="p0045">The monetary domains, sentencing, and criminal recidivism (COMPASS and JSORRAT&#x02013;II) usage for recidivism in criminal matters are three of the most significant areas in which machine learning has been utilized to assist with decision-making in the legal profession. These three areas are among the most crucial ones. Some people have expressed their worries about the likelihood that the improper implementation of artificial intelligence in a variety of fields could lead to the formation of decisions that are influenced by prejudice [<xref rid="bib6" ref-type="bibr">6</xref>]. In addition to this, they have the propensity to inherit these norms as a consequence of the data biases that were brought about by discriminatory behaviors that occurred in the past. Because machine learning models tend to inherit these rules, this is a consequence that has arisen as a result of this tendency, along with the prospect of implementing automated judgments that are biased against specific communities or groups of people who are members of minority groups [<xref rid="bib8" ref-type="bibr">8</xref>,<xref rid="bib9" ref-type="bibr">9</xref>]. Protected or sensitive factors, which are those that pertain to certain groups and may include things like gender, color, nationality, or religion, should, in an ideal world, not have any influence on the outcome of the decision about computational fairness. Because these characteristics are associated with particular groups.</p><p id="p0050">Throughout their respective histories, the fields of law and criminology have made extensive use of language analysis as a means of information collecting. Particularly in the field of forensic linguistics, for instance, text classification has been utilized in a great number of different situations. In the present day, we can automate a major percentage of the analysis that was formerly carried out manually, such as in the case of the Unabomber terrorist attack [<xref rid="bib10" ref-type="bibr">10</xref>]. It is currently possible to acquire access to computer programs that employ a technique known as "machine learning" to assess whether or not a person is masculine or feminine [<xref rid="bib11" ref-type="bibr">11</xref>].</p><p id="p0055">In the context of this work, we explore the prospects of mechanized information extraction and language analysis to facilitate statistical study in the legal domain, with a particular focus on legal judgments because these are used as judicial precedents that are legally binding, like the rules, and also termed Judge-made law. Moreover, we explore the potential of utilizing natural language processing techniques to mechanically forecast semantic bias in judicial rulings using the Chinese AI and Law Challenge datasets (CAIL, 2018) [<xref rid="bib12" ref-type="bibr">12</xref>]. The dataset is based on the information gathered from the official website of the Wenshu courts, where we can find the legal judgments of the Chinese courts. While applying machine learning models, computers are taught to make predictions about legal case outcomes by analyzing the quantitative properties of words and phrases, as well as their connections, which are extracted from unorganized legal data in raw form that has been obtained from physical legal documents generated by different courts [<xref rid="bib13" ref-type="bibr">13</xref>]. The most reliable data in the legal field is either obtained from enacted statutes or legal rulings. Statutes once enacted are not altered again and again, but the legal rulings have many new spectrums daily, as each day is a new day and each case is a new case. The most important aspect of every decision can be identified by using this method to get accurate predictions, which will aid in finding the word that has the utmost impact on the execution of the legal rulings because the gentle and proper execution of the ruling is as important as the rulings themselves, as we say that justice seems to be done [<xref rid="bib14" ref-type="bibr">14</xref>].</p><p id="p0060">Our proposed model aims to support legal professionals in addressing complex legal rulings from various perspectives. Efficiently managing the workload involves organizing the necessary information, such as plaint, written statement, oral and documentary evidence, and reasoning provided by attorneys. This helps to address the backlog of cases and streamline the legal research process. In addition, the model will accurately classify and identify the data and relevant laws for judicial verdicts, while also excluding any semantic bias. To achieve this goal, we developed an automated system that can classify legal judgments that are based on machine learning techniques. This system initially plays the role of organizing legal judgments and afterward evaluates the capability and precision of the legal classification model using (SVM), (NB), (MLP) and (KNN) classifiers. These classifiers are used to predict the most precise output and the same are used in the context of legal rulings.</p><p id="p0065">Machine learning techniques have made it possible to use computational methods for conducting quantitative analysis of the language employed in a court case. Subsequently, this analysis can be used to train the computer to make predictions regarding the court's decision. If the results can be accurately predicted, it would be possible to analyze the words that had the greatest impact on the legal decision. This could assist in determining the important factors for judicial decisions. As a limitation, it is obvious that when addressing the forecasting of legal decisions, we are solely referring to the available data and methodologies employed. This forecasting is in a generalizing way and is quite not confined to dealing with specific cases or statutes.</p><sec id="sec1.1"><label>1.1</label><title>Motivation of the study and contribution</title><p id="p0070">The judiciary is commonly referred to as the third branch of government in a state. The judiciary has a crucial role in upholding the rule of law and exercising its authority in judicial review, which is vital for the overall welfare of society. Legitimate legal decision-making is the core objective of the rule of law. It provides an executable solution for the conflicts between the parties. It decides the rights and obligations as per settled norms and enacted laws [<xref rid="bib15" ref-type="bibr">15</xref>]. The notion of judicial discretion empowers judges to render decisions based on the principles of fairness, utility, and societal certainty. However, sometimes, the discretion of the judges leads to biased decisions. The first and foremost requirement of the legal judgment that concludes the rights and duties is to be fair, accurate, and free of subjectivity. Like many other types of biasedness, semantic bias is one of the types that has importance in a legal judgment, as the judgment carries words and phrases in writing.</p><p id="p0075">The inherent subjectivity and ambiguity in language, known as semantic bias, presents a formidable obstacle to decision-making processes in the court system. Injustices and societal inequities can result from this prejudice when it shows up in the interpretation of legal texts, the creation of judgments, and the execution of decisions. The phenomenon known as semantic bias takes place when legal judgments and legal orders are influenced more by the symbolic meanings and emotional connotations of words used in the judgment for logical reasoning than objective facts. This semantic bias occurs due to the words themselves, as they have positive and negative meanings, their framing, and the structure of the judgment and stereotype writing. The use of biased language in legal documents or during court proceedings might result in unfair punishment or prejudice against particular groups of people, which would be against the legal maxim that justice seems to be done [<xref rid="bib16" ref-type="bibr">16</xref>,<xref rid="bib17" ref-type="bibr">17</xref>]. Semantic bias leads to the unfair implementation of decisions and a biased repository of judgments. Recent advances in machine learning have opened up exciting new possibilities for reducing the impact of semantic bias on automated decision-making. The investigation of machine learning methods to reduce semantic bias is driven by the urgent necessity to tackle systematic inequities in decision-making procedures. Hence the question arises of how machine learning techniques mitigate semantic bias?</p><p id="p0080">Literature reveals that research so far has found regularities, irregularities, legalities, and illegalities in judicial decisions. To our knowledge, no work has been done by scholars regarding the finding of semantic bias in judicial judgments by using any kind of dataset. So, our work on finding semantic bias in legal judgment is novel. The legitimacy of AI requires finding solutions for all probable biases in judgment, as legal judgments will be used as raw data, and this raw data will be used for the training of models and systems to help in judicial decisions. The judicial precedent (former authoritative reported judgment) is of great value in legal adjudication [<xref rid="bib15" ref-type="bibr">15</xref>]. Any AI system to help in judicial adjudication requires using judicial precedents as raw data to find regularities that might help with future predictions and solutions to conflicts. If this raw data contains any kind of bias that will result in bias as well, that would become a question mark for the legitimacy of AI in adjudication. Some studies discovered a distinct disparity in the frequency with which male-related, female-related, gender-related, bias-related, race-related, and religious-related keywords appeared in the original documents, expert-generated summaries, and model-generated summaries. After careful observation, a study determined that the general domain LLMs, such as ChatGPT and Davinci, have generated a little higher percentage. Hence, finding the biases that are already there in the data collection, algorithms, and architectures is an important step to do right now. Therefore, identifying the semantic bias that exists in court precedents is the primary emphasis of this research. This research is useful for making the use of artificial intelligence in adjudication more legitimate. This study aims to aid in creating more open, responsible, and equitable legal systems that respect the values of justice and equality for all by utilizing cutting-edge algorithms and data-driven strategies. It also opens up opportunities for academics to further contribute to the complete elimination of semantic bias in judicial precedents before using the raw data for training models.</p><p id="p0085">Referring to an experiment that demonstrated how the meaning and context of a sentence can influence its interpretation motivated this research [<xref rid="bib18" ref-type="bibr">18</xref>]. So, Semantic Biasness Classification and Identification in Legal Judgement (SBCILJ) is a kind of documentation by uses (SVM), (NB), (MLP) and (KNN) classifiers to transfer each document in vector form to preserve the semantic information. Therefore, documents with semantic bias are located near each other in the legal judgment document. This research has made some important contributions, which are emphasized as follows:<list list-type="simple" id="ulist0015"><list-item id="u0035"><label>&#x02022;</label><p id="p0090">We used the Chinese AI and Law (CAIL) dataset, the first large-scale Chinese legal dataset for judgment prediction.</p></list-item><list-item id="u0040"><label>&#x02022;</label><p id="p0095">All of the documents are pre-processed using NLP techniques that are considered mainstream.</p></list-item><list-item id="u0045"><label>&#x02022;</label><p id="p0100">We represent them in a multidimensional semantic feature space, through algorithms by SVM, NB, MLP, and KNN classifiers. Classifier to predict and classify the most accurate result.</p></list-item><list-item id="u0050"><label>&#x02022;</label><p id="p0105">The simplest equation that would distinguish biased data from each other according to the classification with the least degree of error is one that we establish.</p></list-item><list-item id="u0055"><label>&#x02022;</label><p id="p0110">We achieved a relatively high classification performance (average accuracy of 86&#x000a0;%) when predicting outcomes based only on the semantic biases of the judges who tried the case.</p></list-item></list></p><p id="p0115">After this, we shall delve into previous endeavors that applied automatic analysis to the field of law. The application of ML to the classification of legal texts is elaborated upon in Section <xref rid="sec3" ref-type="sec">3</xref>. Section <xref rid="sec4" ref-type="sec">4</xref> describes the data used in the experiments. We report the outcomes of four experiments that we conducted for this study in Section 5. In Sections 6 and 7, we analyze the findings and formulate conclusions, respectively.</p></sec></sec><sec id="sec2"><label>2</label><title>Review of literature</title><p id="p0120">In the subsequent sections, we provide a concise overview of previous studies that assist in the retrieval of legal material and the detection of anomalies in legal case judgments through the use of various methodologies, such as clustering-based techniques.</p><sec id="sec2.1"><label>2.1</label><title>Algorithmic impartiality</title><p id="p0125">Algorithmic fairness, a component of the research in Accountability, Fairness, and Transparency focuses on addressing unfairness occurring inside algorithmic systems. In this study, we examine the concept of group fairness, which refers to a process or decision being deemed fair if it avoids any kind of discrimination based on an individual's affiliation with a protected group. Despite of advancement of AI systems, there remains a lack of comprehension regarding the fundamental features of AI systems. We face challenges in determining whether an AI system is fair or if it is unintentionally perpetuating biases. The ways to detect and address these issues to ensure that AI systems align with societal decision constraints is a question mark [<xref rid="bib19" ref-type="bibr">19</xref>]. According to Katsaros et al. [<xref rid="bib20" ref-type="bibr">20</xref>] consumers' perceptions of procedural justice do not need to conflict with algorithmic decision-making. Based on existing empirical research in this sector, we believe that the antecedents for procedural fairness can be included in the algorithmic decision-making processes used by content moderation platforms. There is no assurance that the algorithm is "fair." There are many definitions of fairness in the literature, with a minimum of 21 mentioned. Multiple research studies provide an overview of different definitions of algorithmic fairness, such as those by Refs. [<xref rid="bib4" ref-type="bibr">4</xref>,<xref rid="bib21" ref-type="bibr">21</xref>]. In addition, Chouldechova et al. [<xref rid="bib22" ref-type="bibr">22</xref>] have shown that some group fairness criteria are incompatible with one another. Data-driven automated decision-making systems are growing. If not audited properly, these models can harm people, especially marginalized ones. The proliferation of such systems in our daily lives highlights the necessity of examining model biases. Group fairness approaches compare groups based on a sensitive attribute and assess model prediction evidence [<xref rid="bib23" ref-type="bibr">23</xref>]. Fairness is a concept rooted in ethics and law, driven by values. For example, the United States has implemented laws to prohibit discrimination in various areas including religion, race, and sex. In addition, it prohibits discrimination as to national origin in the Civil Rights Act, act the Immigration and Age discrimination act. Likewise, the European Convention on Human Rights (Article 14) prohibits any form of discrimination based on various factors such as &#x0201c;sex, race, color, language, religion, political or another opinion, national or social origin, association with a national minority, property, birth, or another status&#x0201d;. Implementing and evaluating fairness is challenging since it is centered around value concepts rather than a technical aspect of ML models. As machine learning models are being utilized in legal systems, the issue of fairness is gaining significant attention [<xref rid="bib24" ref-type="bibr">24</xref>]. While discrimination probably happens at several stages and throughout the process, in this case, we only discuss fairness in judicial decisions; other forms of fairness, such as process fairness, are not included. Reliable metrics show that there is a noticeable difference in the outcomes of people from different groups in our particular case, which amply demonstrates the discrimination. But meeting just one metric guarantees groups' equivalence in terms of that metric alone. Therefore, the concept of fairness is heavily influenced by specific circumstances and personal beliefs.</p></sec><sec id="sec2.2"><label>2.2</label><title>Network-based approaches</title><p id="p0130">One of the challenging problems in legal case documents is classifying the similarity between two different approaches, i.e. text-based and citation-based approaches. In this context, citation recommendation and prior-case retrieval are two famous applications [<xref rid="bib25" ref-type="bibr">25</xref>]. Network-based approaches mainly create a citation network by using referential information. The similarity score is then determined by analyzing the direct or indirect citations that were used in the previous step. Recent studies have explored network-based methods from related fields, such as analyzing the citation network of scholarly articles [<xref rid="bib6" ref-type="bibr">6</xref>]. To extract visual qualities, Heng et al. [<xref rid="bib26" ref-type="bibr">26</xref>] proposed a Convolutional Neural Network (CNN) based on hybrid pooling. Using either the maximum or average pooling functions, this technique modifies the CNN model's pooling layers at random. The effectiveness of CNN-based feature extraction models is increased by this technique. Using either the maximum or average pooling functions, this technique modifies the CNN model's pooling layers at random. The CNN-based feature extraction model may operate more efficiently as a result of this technique. Previous similar cases strongly influence the current case. Document similarity is often assessed as a whole. Because legal case materials are voluminous, it may be helpful to simply compare the key concepts or summaries. The methodologies used to compare court case papers are the topic of this survey. This study divides these efforts into citation-, content-, and summary-based methodologies. A comprehensive survey of legal document summarization methodologies was also conducted [<xref rid="bib27" ref-type="bibr">27</xref>,<xref rid="bib28" ref-type="bibr">28</xref>]. Kumar et al. [<xref rid="bib29" ref-type="bibr">29</xref>] Examined the similarity scores among judgments by utilizing co-citation analysis and bibliographic coupling for the precedent citation network. Dhanani, Mehta, and Rana introduce a cutting-edge Legal Document Recommendation System (LDRS) that utilizes graph clustering to group similar judgments and identify relevant ones within those clusters [<xref rid="bib27" ref-type="bibr">27</xref>,<xref rid="bib30" ref-type="bibr">30</xref>]. Koniaris et al. [<xref rid="bib31" ref-type="bibr">31</xref>] utilized network statistical and structural information, such as degree, to capture the resemblance among legal documents from the EU. Nonetheless, one of the most important factors determining how successful network-based techniques are is the network's degree of connectedness. Many legal cases often rely on a narrow range of precedents, statutes, and laws, resulting in a fragmented citation network [<xref rid="bib30" ref-type="bibr">30</xref>].</p><sec id="sec2.2.1"><label>2.2.1</label><title>Text-based approaches</title><p id="p0135">Methods that rely on textual evidence make an effort to record how similar the judgments are in terms of vocabulary or meaning. The cosine similarity score is commonly used in mainstream methodologies to quantify the similarity among the document vectors. Recently, legal document similarity analysis has used a lot of different vectorization methods, like TF-IDF, LDA, Word2Vec, and Doc2Vec, to quickly turn text into real-valued vectors with set lengths. There are many examples of using the type of modeling known as semantic vector space to find similarity indexes. Similarly, Kumar et al. [<xref rid="bib29" ref-type="bibr">29</xref>] put forth the strategy, namely TF-IDF, for Indian legal judgments for constructing vector space, but these appear to be high-dimensional vectors. Ayden et al. [<xref rid="bib32" ref-type="bibr">32</xref>] create language representations for text-based medical records, model numerical health data with the Gated Recurrent Unit (GRU), and automatically mix the two streams to forecast ICD-9 codes for the intensive care unit. We go over the preprocessing and classification procedures, demonstrating that our proposed two-stream model outperforms other cutting-edge studies in the literature. While Nanda et al. [<xref rid="bib33" ref-type="bibr">33</xref>] consider LDA-based top modeling to find similarity indexes, this is not suitable for long texts, i.e., legal judgments that are too long in common law legal systems because this judgment carries detailed insight and prudence of the judge who decides the case. Therefore, examining the similarity of legal documents by employing topic modeling based on LDA, may not be optimal for lengthy textual documents like judgments [<xref rid="bib34" ref-type="bibr">34</xref>]. Doc2Vec, Word2Vec, and another shallow NN-based embedding [<xref rid="bib35" ref-type="bibr">35</xref>,<xref rid="bib36" ref-type="bibr">36</xref>] Explore the semantic vector space with a focus on contextual information, which plays a crucial role in preserving the semantic relationships between words or documents. Sagathadasa et al. note that Word2Vec and lexical relevance were utilized as a process to identify domain-specific semantic similarities. Dipankar et al. [<xref rid="bib37" ref-type="bibr">37</xref>] used Word2Vec and lexical significance to identify semantic similarities within domains and built a "risk ometer" system that uses Doc2Vec and supervised machine learning to assess the legal contracts' risk. Likewise [<xref rid="bib38" ref-type="bibr">38</xref>], Doc2vec shown superior performance to TF-IDF, LDA, and Word2Vec in the empirical investigation that was carried out by Mandal et al. This was determined by the findings of the human expert similarity score [<xref rid="bib30" ref-type="bibr">30</xref>].</p></sec><sec id="sec2.2.2"><label>2.2.2</label><title>Hybrid approaches</title><p id="p0140">Using both textual and referential information, Kumar et al. [<xref rid="bib39" ref-type="bibr">39</xref>] tried a hybrid strategy to improve performance. Using prior decisions and the idea of "paragraph links" to create a citation network. A paragraph link exists between two different judgments if the cosine similarity score between the TFIDF vectors of two paragraphs from different judgments is higher than the threshold. This indicates that the two judgments are related to each other. When compared to separate methods, the performance is noticeably better. Cluster analysis was carried out by Raghav et al. [<xref rid="bib40" ref-type="bibr">40</xref>] on Indian legal papers utilizing a citation network and paragraph linkages. For US Supreme Court opinions, Leibon et al. [<xref rid="bib41" ref-type="bibr">41</xref>] have also used network-based methods and text representation approaches like LDA. This study uses sophisticated methodologies, including Fuzzy AHP, Fuzzy DEMATEL, and Logistic regression (LR) models, to build a novel strategy for mapping groundwater potential zones (GWPZs). GWPZ was conducted by integrating hydrologic, soil permeability, morphometric, topographical distribution, and anthropogenic elements into 27 distinct criteria utilizing multi-criteria decision models [<xref rid="bib42" ref-type="bibr">42</xref>]. There is a way to find relevant legal documents that Sugathadasa et al. [<xref rid="bib43" ref-type="bibr">43</xref>] suggested. It combines a text-based strategy, like Text Rank [<xref rid="bib44" ref-type="bibr">44</xref>], for finding the resemblance between different sentences with adopting a strategy known as a network-based strategy, like Node2Vec [<xref rid="bib45" ref-type="bibr">45</xref>], for node entrenching.</p></sec></sec><sec id="sec2.3"><label>2.3</label><title>Retrieval of legal information</title><p id="p0145">The use of ICTs, which generate vast quantities of digital information, has recently transformed the legal sphere. To address this, researchers have looked into more effective retrieval methods. One of these methods is knowledge extraction. The other one is the natural language processing method. In addition to it machine learning theoretical model is also used. Moreover, non-monotonic deontic logic is also famous for exploring by lawyers. Along with other techniques rule-based techniques, and expert systems also play their pivotal role, in facilitating the exploration of such archives by attorneys and judges [<xref rid="bib46" ref-type="bibr">46</xref>].</p><p id="p0150">Information retrieval (IR) methods can aid in the retrieval of legal information from preexisting databases containing legal documents. Indeed, they have already been employed profitably for numerous purposes in literature. When it comes to analyzing legal case judgments, NLP-based approaches are generally considered superior. This is because these approaches combine data-driven methods with embedding models, which makes them able to directly identify legal concepts and jurisprudence without any hindrance thereto or different kinds of representations, such as tagged feature-value pairs or some kinds of logical predicates [<xref rid="bib47" ref-type="bibr">47</xref>,<xref rid="bib48" ref-type="bibr">48</xref>]. Ashley proposes a query-based system that retrieves legal information by systematically evaluating many factors that determine the sentences' interpretive value. They amalgamate characteristics into a composite metric that takes into consideration several facets. The task formulation, data set assembly, and extensive task analysis form a strong basis for implementing a learning-to-rank approach [<xref rid="bib49" ref-type="bibr">49</xref>]. In their study, Wei et al. [<xref rid="bib50" ref-type="bibr">50</xref>] detail the case of a patient who experienced severe hemodynamic abnormalities 3&#x000a0;h after undergoing treatment due to embolization of the LAAO device into the left ventricular outflow tract, including a ruptured mitral valve and subsequent extensive mitral regurgitation. Urgent surgery was required to remove the device and repair the mitral valve as a result. Furthermore, an examination of prior studies concerning surgical methodologies employed in the removal of dislodged left atrial appendage occludes was conducted.</p><p id="p0155">In recent times, the big data paradigm and the presence of advanced technologies for big data analytics are causing legal authorities to lean towards publishing court case papers on their internet databases. However, scholars in the field of artificial intelligence are grabbing hold of this chance to improve already-conducted research and make a novel contribution to the field of legal informatics because there are some complexities in modern information technology that are even rising regularly. The importance of this study is due to its wider scope, i.e., legal information systems, legal drafting with the help of computers, and data banks of judicial decisions. The legal informatics concept prevailed in 1963 when Wolfgang Baade advanced the concept of "jurimetrics,&#x0201d; and later on in 1969, Losano's concept was "luscibernetic". Using a machine learning technique [<xref rid="bib51" ref-type="bibr">51</xref>], automated the annotation of common law report sentences with facts and principles pertaining to the law.</p><p id="p0160">To determine if a sentence is a principle, fact, or neutral text, the suggested method uses a feature selection stage in conjunction with an NBM classifier. This study depended on a very short number of reports. Besides the number of reports, the results were positive. Shao et al. [<xref rid="bib52" ref-type="bibr">52</xref>] presented a model of the two-stage system. The model showed the results in enhanced relevance estimation because it used the technique to leverage the attention on the user end. Devin et al. [<xref rid="bib53" ref-type="bibr">53</xref>] started the study in 2019 [<xref rid="bib53" ref-type="bibr">53</xref>]. The fine-tuned version was observed to have the best performance, and the model was trained from the ground up using texts that were relevant to the area. Chalkidis et al. (2020) note that LEGAL-BERT (Bidirectional Encoder Representations from Transformers) presents the textual content of the legal information obtained from different legal documents by using embedding techniques. In addition, BURT uses a technique to come across the basic relation between the words and phrases that are available in the digital textual form. Moreover, the same result was found when different forms of BERT like &#x0201c;general-purpose pre-trained&#x0201d; [<xref rid="bib54" ref-type="bibr">54</xref>], &#x0201c;domain-specific&#x0201d; or even &#x0201c;fine-tuned&#x0201d; [<xref rid="bib54" ref-type="bibr">54</xref>] BERT were compared as to their result regarding classification.</p><p id="p0165">Similarly, legal papers that are based on the Bag-of-Concept (BoC) approach can be expressed using BoLC-Th, which is an acronym that stands for Bag of Legal Concepts Based on Thesaurus. One of the distinctive characteristics of this method is that it generates weighted histograms of concepts by taking into account the proximity of each word to the synonym that corresponds to it in a thesaurus. This technique generates vectors that are most discriminative by emphasizing the words that are more appropriate to the context in which they are displayed [<xref rid="bib55" ref-type="bibr">55</xref>]. In a competition on the extraction of legal information related to the legal domain, embedding techniques were used by the participants to sort out the multidimensional problems of the related field. The BERT-PLI technique seems to be most relevant regarding the extraction of legal information [<xref rid="bib56" ref-type="bibr">56</xref>]. This technique makes use of BERT to capture the semantic associations at the paragraph level. Subsequently, it makes use of the aggregated interactions between paragraphs to determine the significance between two instances. A dataset that is connected to the legal industry is used to fine-tune the BERT model that is located in BERTPLI [<xref rid="bib56" ref-type="bibr">56</xref>], the same as in LEGAL-BERT. Although other studies have looked into the application of embedding techniques, the authors of this study believe that the approach that is described here is a novel proposition. This empirical evaluation shows that it is much more robust to the presence of data noise compared to baseline and state-of-the-art solutions. This method is the first of its kind to use a 2-step clustering approach to investigate legal domain text at the whole legal judgement and passage levels to identify their regularities.</p></sec></sec><sec id="sec3"><label>3</label><title>Fundamentals of machine learning</title><p id="p0170">When we talk about an area of study within the realm of artificial intelligence known as machine learning focuses on the creation of a specialized operational model that takes into account the required characteristics [<xref rid="bib57" ref-type="bibr">57</xref>]. It is a technique of analyzing the available data that contributes to the automation of the analytical and methodological construction of models. If we come to the basic operation it is pertinent to say that the fundamental operation of machine learning technology is dependent on the pattern of a vast amount of data, because the training of the model requires a variety of data to come across the sequences thereby [<xref rid="bib58" ref-type="bibr">58</xref>,<xref rid="bib59" ref-type="bibr">59</xref>]. After then, the obtained patterns by use of ML are categorized and can be utilized in a variety of tasks. The model is trained to produce the most appropriate outcome possible. This idea makes it possible to tackle some problems by classifying them into two major categories: classification difficulties and regression challenges. With machine learning, a system may automatically learn from its past mistakes and get better at what it does, all without human intervention or code. ML can be classified into four distinct categories: semi-supervised learning, reinforcement learning, supervised learning, and unsupervised learning. These classifications are based on the learning techniques that are used and how they are applied. Every learning technique applied to a model has its pros and cons. In supervised learning, we use a labeled dataset where we are aware of input and output. We use linear regression, KNN, and SVM. Mostly, it is used for predicting the possible outcome. There are two main types of supervised learning: classification and regression. Whereas, in classification, the output data is discrete, and in regression, the output is a continuous value. In unsupervised learning, the data is unlabeled, like we have only input in our data but not the corresponding output. In this kind of learning, the data is grouped based on similarity in the features provided in the data, and these types of groups are known as clusters. There are many other types of unsupervised learning, including clustering and association.</p><p id="p0175">In semi-supervised learning, the data is in mixed form, as some of the data has only input but no output, and some of the data has both input and output. In this way, we use a variety of data that increases the level of accuracy of the results.</p><p id="p0180">Reinforcement learning is reward-based learning in which we have agents. These agents perceive the environment, and based on these perceptions, action is taken. If the action of the agent is correct, then we reward the agent, and in the case of an incorrect action, the agent gets a penalty. In this way, agents learn which action has to be performed and from which action they need to abstain. Like in the case of legal judgments, when we make a model and train that model by reinforcement learning for bias classification if our model classifies the bias correctly from the legal judgment, we can award the agent (that is, in fact, the model we trained) a &#x0201c;good rating," and if it fails to classify the bias, we can award a &#x0201c;bad rating".</p><sec id="sec3.1"><label>3.1</label><title>Machine learning for semantic biasness classification</title><p id="p0185">When it comes to the realm of law, there are a variety of approaches that may be taken while dealing with legal matters. Systematizing the data and automating the process are the primary goals of the majority of the procedures that are carried out. Several different approaches to the automatic processing of legal documents have been studied by the authors in this section. Different techniques of AI are used to classify legal documents and later use them as big data for future prediction and solving current problems. It is humanly not possible to read all of the cases to get the guidelines for some recent problems. Therefore, finding the correlations and similarities between different legal judgments provides a basis for deciding new cases easily. This would be done to assist legal professionals in balancing their overwhelming workload of pending cases. Through the implementation of this strategy, the law will become more approachable, manageable, predictable, intelligible, and beneficial. Because it is written in natural languages, the majority of legal information is completely unstructured.</p><p id="p0190">Consequently, to process this legal information, a variety of methodologies established through the use of NLP have been developed. Current research aims to construct an automated system to find the semantic bias in legal judgments that has a strong tendency to increase cognitive bias. As we know, the basic right associated with each technology is its fare usage. If technology is harmful to society, it can never be allowed to save society from the harm of technology. AI uses big data, as in the case of legal judgment. When we train some models on big data of decided judgments, having certain biases will result in biases of high magnitude. For this purpose, the supervised learning technique has been used so far to get better results. An automated legal classification system for legal judgment is based on supervised learning techniques. The data provided to the system is legal judgments that have already been decided by the courts, i.e., the CAIL dataset. The computer recognizes the different patterns of judgment as an initial training phase. Afterward, the data is served to the system to train it. This is done to evaluate the performance of the proposed machine-learning-based categorization model. The performance that is produced from the correctness of the legal categorization model is used to substantiate the case information, which is then used to structure the case information. The other main objective of the system is to dig out the categories of the paragraph, like the details of the basic reason for litigation, supportive evidence, relevant law, arguments forwarded by the parties, prudence applied by the judges, the basis of the decision, and final verdict, because, until the system categories the basic divisions of the paragraphs, it would not be possible and appropriate to catch the semantic bias in the judgment.</p><p id="p0195">Afterward, techniques of ML are applied to get the results as depicted in <xref rid="fig1" ref-type="fig">Fig. 1</xref>. To get more accuracy, we apply SVM, NB, MLP, and KNN classifiers for forecasting as well. It is necessary to offer the machine learning program a case that does not contain the judgment (during the "testing phase") to evaluate its performance. The programmer is then required to provide the judgment that is most likely to occur. The program uses the data that it determined to be significant during the training phase to make this decision, also known as "classification".<fig id="fig1"><label>Fig. 1</label><caption><p>The architecture of the proposed paradigm.</p></caption><alt-text id="alttext0010">Fig. 1</alt-text><graphic xlink:href="gr1"/><attrib>Source: Own extracted.</attrib></fig></p></sec><sec id="sec3.2"><label>3.2</label><title>Dataset</title><p id="p0200">Our investigations are carried out using a dataset that was obtained from the China Judgements Online 1 online database. This section begins with an explanation of how we acquire such datasets, is followed by a discussion of a set of baseline systems that we compare with, and finishes with a presentation of the findings. Existing research in the field of LJP frequently conducted experiments using the CAIL dataset [<xref rid="bib12" ref-type="bibr">12</xref>] or pulled task-specific sentences from available judgment documents to generate their dataset [<xref rid="bib60" ref-type="bibr">60</xref>]. On the other hand, none of them includes all five of the responsibilities that we require. Additionally, these datasets have been subjected to some pre-processing steps, which makes it challenging to create a mapping between each instance and the initial court judgment document. In light of this, we generate a dataset on our own using the same approach as described in Ref. [<xref rid="bib12" ref-type="bibr">12</xref>]. In the first place, we distinguished between cases that had several defendants and those that did not, since various defendants correspond to different outcomes of trials. Aside from the fact that the top 102 law articles in Chinese Criminal Law are not pertinent to certain charges, we also filtered these designations. Through this method, we were able to obtain a dataset that had 225,843 criminal judgment papers, which included 200 charges and 183 law articles. To construct the test set, we chose 12,810 cases at random and made certain that it included all possible categories of charges and legal articles. Moreover, we chose 12,634 cases to form our validation set, while the remaining cases were used to construct our training set. An average of 1.06 charges are involved in each case, and each case refers to 1.14 different sections of legislation; yet, there is only one term of punishment. We provide more detailed statistics in <xref rid="tbl1" ref-type="table">Table 1</xref>.<list list-type="simple" id="olist0010"><list-item id="o0010"><label>A</label><p id="p0205">Feature Extraction</p></list-item></list><table-wrap position="float" id="tbl1"><label>Table 1</label><caption><p>CAIL dataset Statistics presenting words and exceptional words.</p></caption><alt-text id="alttext0040">Table 1</alt-text><table frame="hsides" rules="groups"><thead><tr><th/><th>Statement</th><th>Law</th><th>Charge</th><th>Punishment</th><th>Opinion</th><th>Content</th></tr></thead><tbody><tr><td align="left"><bold>No. of words</bold></td><td align="left">119.46</td><td align="left">3</td><td align="left">7.26</td><td align="left">6.41</td><td align="left">148.28</td><td align="left">137.90</td></tr><tr><td align="left"><bold>No. of Exceptional words</bold></td><td align="left">225,843</td><td align="left">183</td><td align="left">200</td><td align="left">207</td><td align="left">225,843</td><td align="left">183</td></tr></tbody></table><attrib>Source: own extracted from CAIL dataset [<xref rid="bib12" ref-type="bibr">12</xref>].</attrib></table-wrap></p><p id="p0210">The n-gram and the terms can be defined as two primary forms of combined feature extraction methods that are utilized in the process of text classification.</p><p id="p0215"><bold><italic>n-gram:</italic></bold> For the n-gram extraction method, a window of length n is utilized to move across the entirety of a corpus [<xref rid="bib61" ref-type="bibr">61</xref>]. Following that, we obtain all of the sets of consecutive words or characters that are contained within each window. To reduce the amount of ambiguity that is associated with individual words, the n-gram algorithm is designed to obtain the composite features that emerge continually. The n-grams known as bigram and trigram are frequently utilized. Nevertheless, the impact of the structure of the text, which includes things like punctuation and stop words, is not taken into account.</p><p id="p0220"><bold><italic>terms:</italic></bold> With an n-gram, composite features are solely extracted based on their co-occurrence, regardless of the order and position of the member terms [<xref rid="bib62" ref-type="bibr">62</xref>]. A term set, on the other hand, is fundamentally different from an n-gram. Alternatively, term sets can be described as arbitrary combinations of words that are paired together in the lexicon. There is, however, a difficulty that arises from this combination, and that is an explosion of combinations even for two-term sets combinations. When a vocabulary size of n is considered, this indicates that there will be 2n different sorts of pairings.<list list-type="simple" id="olist0015"><list-item id="o0015"><label>B</label><p id="p0225">Feature Selection</p></list-item></list></p><p id="p0230">To improve the performance of a text classifier and simultaneously minimize the feature dimension, feature selection is a technique that is frequently utilized. During the process of feature selection, the score of each feature is often decided by a generic criterion. Following this, the top <italic>N</italic> features are selected from the feature subset (where <italic>N</italic> is a number that has been obtained through experimentation). Chi-square is a well-known statistical method that has been useful in determining the degree to which individuals can differentiate themselves from one another [<xref rid="bib63" ref-type="bibr">63</xref>]. The formula for this method is as follows in equation <xref rid="fd1" ref-type="disp-formula">(1)</xref>.<disp-formula id="fd1"><label>(1)</label><mml:math id="M1" altimg="si1.svg" alttext="Equation 1."><mml:mrow><mml:msup><mml:mi>Z</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi>N</mml:mi><mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mi>z</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>z</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>In this equation, the variables <italic>w</italic> and <italic>y</italic> represent the number of documents that contain <italic>f</italic><sub><italic>t</italic></sub> in the positive and negative classes, respectively, while the variables <italic>x</italic> and <italic>z</italic> represent the number of documents that do not contain <italic>f</italic><sub><italic>t</italic></sub>. in the positive and negative classes, respectively. The sum of the documents that make up the training set is denoted by equation <italic>N = w&#x000a0;+&#x000a0;x&#x000a0;+&#x000a0;y&#x000a0;+&#x000a0;z.</italic> A technique that is based on <italic>Z</italic><sup><italic>2</italic></sup> was proposed by Ref. [<xref rid="bib64" ref-type="bibr">64</xref>] regarding the evaluation of term sets as given below in equation <xref rid="fd2" ref-type="disp-formula">(2)</xref>.<disp-formula id="fd2"><label>(2)</label><mml:math id="M2" altimg="si2.svg" alttext="Equation 2."><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>Z</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi>N</mml:mi><mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo>&#x02212;</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo linebreak="badbreak">+</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo linebreak="badbreak">+</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo linebreak="badbreak">+</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mo linebreak="badbreak">+</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mtext>,</mml:mtext></mml:mrow></mml:math></disp-formula>where <italic>f</italic><sub><italic>tv</italic></sub> is the abbreviation for the two-term set that is composed of the terms <italic>f</italic><sub><italic>t</italic></sub> and <italic>f</italic><sub><italic>v</italic></sub>, <inline-formula><mml:math id="M3" altimg="si3.svg"><mml:mrow><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>
<inline-formula><mml:math id="M4" altimg="si4.svg"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> respectively The numbers indicate the number of documents that contain both or either of <italic>f</italic><sub><italic>t</italic></sub> and <italic>f</italic><sub><italic>v</italic></sub> in the positive and negative classes, and <inline-formula><mml:math id="M5" altimg="si5.svg"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M6" altimg="si6.svg"><mml:mrow><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> are the number of documents that not contain any of <italic>f</italic><sub><italic>t</italic></sub> and <italic>f</italic><sub><italic>v</italic></sub> in the positive and negative classes, respectively. That a portion of the members is also capable of communicating information is indicated by this.<list list-type="simple" id="olist0020"><list-item id="o0020"><label>C</label><p id="p0235">Classification</p></list-item></list></p><p id="p0240">Numerous methods are used for processing legal documents and other related material for the sake of classification. Researchers have made efforts to automate the system for this classification by using different kinds of processes. Currently, our focus is on the use of ML and DL algorithms within the argument-based prediction system for legal judgments. Because the majority of the legal documents filed in trial courts are of an unstructured kind, they must be structured appropriately. In most of the judiciaries, the process of automation and digitalization of legal documents like patents, written statements, different types of evidence, and arguments is still incomplete. First of all, we need to prepare soft copies of all legal documents. For this purpose, we use the technique of supervised learning, where we label the documents properly to get optimal results. To calculate the outcome of our suggested legal model that is based on arguments, data is submitted to the system despite finalizing the results being determined. Another name for this phase is the testing phase, and it is responsible for producing reliable results. The flowchart for classification is shown in <xref rid="fig2" ref-type="fig">Fig. 2</xref>.<fig id="fig2"><label>Fig. 2</label><caption><p>Classification model that is proposed to be semantically biased.</p></caption><alt-text id="alttext0015">Fig. 2</alt-text><graphic xlink:href="gr2"/><attrib>Source: Own extracted.</attrib></fig></p></sec><sec id="sec3.3"><label>3.3</label><title>Support Vector Machine</title><p id="p0245">The SVM is an additional example of a supervised machine-learning technique. Although it may be used for both classification and regression, it is typically employed for problems that are associated with the classification. Through the utilization of kernels, it is utilized in both linear and non-linear processes. The SVM can identify linear separation and functions most well in situations where there are a limited number of points for a large number of observations. Additionally, it is well known that SVM can be learned throughout the entire world. Essentially, SVM can learn the linear threshold function in its most fundamental application. On the other hand, with the assistance of an easy plugin that is suited for the kernel, they can upgrade their function to an alternative future function. On the other hand, SVMs are extremely computationally intensive and theoretically complex. This is also a type of classifier that employs an N-dimensional hyperplane to classify a collection of points or data separately. Essentially, a hyperplane is nothing more than an n-dimensional line that serves the purpose of dividing data that belongs to two distinct classes. This particular classifier is used in situations involving regression as well as classification issues. To develop the classifier, we made use of the SVM module that is included in the Scikit-Learn package with Python. Presented in equation <xref rid="fd3" ref-type="disp-formula">(3)</xref> is the statement that describes the creation of the classifier:<disp-formula id="fd3"><label>(3)</label><mml:math id="M7" altimg="si7.svg" alttext="Equation 3."><mml:mrow><mml:mi>s</mml:mi><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:mi>M</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mi>s</mml:mi><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:mo>.</mml:mo><mml:mi>S</mml:mi><mml:mi>V</mml:mi><mml:mi>C</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mspace width="0.25em"/><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id="p0250">To adapt the inputs to the classifier, we have employed the fit () function from the svm, SVC () class. This function is responsible for feeding the inputs, which are data from the dataset, into the classifier that we have created. Equation <xref rid="fd4" ref-type="disp-formula">(4)</xref> is an illustration of the statement that explains how the inputs are matched to the classifier:<disp-formula id="fd4"><label>(4)</label><mml:math id="M8" altimg="si8.svg" alttext="Equation 4."><mml:mrow><mml:mi>s</mml:mi><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:mi>M</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mo>.</mml:mo><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id="p0255">After adopting the inputs to the classifier model, we obtain the classes that are predicted by our classifier from the testing input data. This is the process of discovering the predictions or classes. In the svm, SVC () class, the predict () function is used to carry out the task of prediction. Equation <xref rid="fd5" ref-type="disp-formula">(5)</xref> is a statement regarding the prediction of output classes:<disp-formula id="fd5"><label>(5)</label><mml:math id="M9" altimg="si9.svg" alttext="Equation 5."><mml:mrow><mml:mi>Y</mml:mi><mml:mspace width="0.25em"/><mml:mi>Pr</mml:mi><mml:mspace width="0.25em"/><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mi>s</mml:mi><mml:mi>v</mml:mi><mml:mi>m</mml:mi><mml:mi>M</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mo>.</mml:mo><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mi>T</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id="p0260">An example of a system that is operational is depicted in <xref rid="fig3" ref-type="fig">Fig. 3</xref>. The algorithm that is used to separate the data will determine which hyperplane is the most effective. To differentiate between the two symbols, the hyperplane serves as the center line. In this case, the support vectors are the symbols that are closest to the lines. Fixing the hyperplane in such a way that the margin that is most likely to be attained concerning the points is the goal of the algorithm known as the Support Vector Machine. Following the completion of the training, a fresh and distinct case set is utilized for an evaluation of the effectiveness of the ML approach. Every case is examined to determine whether or not the accused individual is a criminal, and the results of this examination are then compared with the documents that were first produced by the court.<fig id="fig3"><label>Fig. 3</label><caption><p>Svm diagram.</p></caption><alt-text id="alttext0020">Fig. 3</alt-text><graphic xlink:href="gr3"/><attrib>Source: take from Ref. [<xref rid="bib65" ref-type="bibr">65</xref>].</attrib></fig></p></sec><sec id="sec3.4"><label>3.4</label><title>K-Nearest Neighbour</title><p id="p0265">This algorithmic classification approach is straightforward. It yields a considerable measurement of extremely modest output in terms of cataloging precision. Furthermore, it is a direct classifier that is based on the class of objects closest to one another. On vast amounts of datasets, it functions most effectively. Each unknown test sample is assigned to a particular class in the KNN classifier, which is the class to which the majority of the sample's KNN belongs. To put it another way, it is determined by the one that has received the greatest sum of polls from its nearest neighbors, to whom the object will be assigned. There are a few different names for the KNN algorithm, which can be categorized as firstly memory-based reasoning, secondly instance-based learning, thirdly case-based reasoning, fourthly example-based reasoning, and finally lazy learning are the core topics of the discussion of current research. It is essentially non-linear and can discern between linear and nonlinear datasets, depending on the data. In our suggested legal model, we have replicated the words with things since the KNN Classifier implies that things that are similar to one another dwell close to one another. To create the classifier, we made use of the K Neighbors classifier module that is included in the Scikit-Learn package of Python. Details regarding this module are as follows in equation <xref rid="fd6" ref-type="disp-formula">(6)</xref>.<disp-formula id="fd6"><label>(6)</label><mml:math id="M10" altimg="si10.svg" alttext="Equation 6."><mml:mrow><mml:mi>k</mml:mi><mml:mi>n</mml:mi><mml:mi>n</mml:mi><mml:mi>C</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mi>K</mml:mi><mml:mi>N</mml:mi><mml:mi>e</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>b</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi><mml:mi>C</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mspace width="0.25em"/><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id="p0270">Compatibility of the inputs with the classifier: To integrate data into the recently created classifier, we have employed the fit () function of the K Neighbors Classifier class, as outlined in equation <xref rid="fd7" ref-type="disp-formula">(7)</xref>.<disp-formula id="fd7"><label>(7)</label><mml:math id="M11" altimg="si11.svg" alttext="Equation 7."><mml:mrow><mml:mi>k</mml:mi><mml:mi>n</mml:mi><mml:mi>n</mml:mi><mml:mi>C</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p id="p0275">The process of determining the predictions and classes begins with the insertion of inputs into the classifier model. Next, we use the predict () function of the K Neighbors Classifier class to determine the classes that our classifier has predicted. This function is also mentioned in equation <xref rid="fd8" ref-type="disp-formula">(8)</xref>.<disp-formula id="fd8"><label>(8)</label><mml:math id="M12" altimg="si12.svg" alttext="Equation 8."><mml:mrow><mml:mi>Y</mml:mi><mml:mspace width="0.25em"/><mml:mi>Pr</mml:mi><mml:mspace width="0.25em"/><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mi>k</mml:mi><mml:mi>n</mml:mi><mml:mi>n</mml:mi><mml:mi>C</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="italic">pr</mml:mi><mml:mspace width="0.25em"/><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mi>T</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec><sec id="sec3.5"><label>3.5</label><title>Multi-layer perception</title><p id="p0280">In the context of machine learning, an Artificial Neural Network (ANN) is a specific sort of model that mimics the organization of the human brain and its constituent neurons to classify incoming data sets within a machine. As can be seen in <xref rid="fig4" ref-type="fig">Fig. 4</xref>, the authors of this research have constructed a feed-forward network that is composed of multiple layers.<fig id="fig4"><label>Fig. 4</label><caption><p>The conceptual framework of our MLP model.</p></caption><alt-text id="alttext0025">Fig. 4</alt-text><graphic xlink:href="gr4"/><attrib>Source: Own extracted from MLP concept.</attrib></fig></p><p id="p0285">Four layers of density make up our model. The input layer, first hidden layer, second hidden layer, and output layer are the layers that are engaged in this process. The output layer is the last. A layer's nodes are connected to all of the nodes in the layer below them, and these connections are ordered in the following order:</p><sec id="sec3.5.1"><label>3.5.1</label><title>Dense layer</title><p id="p0290">A layer that is entirely connected means that every neuron is connected to every other neuron through their respective layers. This layer is a layer that is completely connected. All learning features that are derived from amalgamations of all aspects of the layers that came before it is utilized by it. The first dense layer is comprised of sixteen nodes that accept input in a single dimension with the shape (4, 1). The Rectified Linear Unit, alternatively known as ReLU, is the activation function that is utilized in this layer. Through the use of this activation function, the output is converted into the weighted sum of the inputs to the output nodes. In our model, the sum of nodes that are considered to be present in the second, third, and fourth dense layers is assumed to be 8, 4, and 1 accordingly. To obtain the class probability scores, the ReLU activation function is utilized in the second and third dense layers, whereas the SoftMax activation function is utilized in the fourth dense layer.</p></sec><sec id="sec3.5.2"><label>3.5.2</label><title>Dropout layer</title><p id="p0295">To prevent overfitting, we have implemented a dropout layer in between each consecutive dense layer. This layer has a dropout rate of 0.2, which means that one out of every five inputs will be eliminated at random during each epoch.</p><p id="p0300">It is well acknowledged that the Multilayer Perceptron (MLP) is among the most widely used supervised neural classifiers. At this point, a vast number of learning paradigms have been established, and in addition to that, they can carry out nonlinear mapping. Nonlinear activation functions are the substance that makes up MLP networks. Hidden layers and associated synaptic weights are responsible for carrying out this non-linear mapping when it comes to the MLP network. Iterative determination of the biases and weights of the MLP network is accomplished by the utilization of backpropagation, which is a general supervised optimization technique.</p><p id="p0305">Following the acquisition of anticipated class labels, the aforementioned labels are subjected to analysis utilizing the cataloging information and precision mark, which are presented in tabular format below.</p></sec></sec></sec><sec id="sec4"><label>4</label><title>Experimental results</title><p id="p0310">Our legal model which is based on the ML algorithm that we have proposed has been anticipated and performed utilizing Python 3.5. Additionally, AMDA Ryzen 5 with 16&#x000a0;GB of RAM has been utilized for the processing of the model, and it has been executed on the Windows 10 professional. To determine whether the accused individual is a criminal or a non-criminal, the final output is classified according to this distinction. Different classifiers, including SVM, NB, MLP, and KNN, have been utilized in this research. These classifiers have been utilized to analyze the data. To achieve higher levels of accuracy in classification, it has been suggested that an adequate and identifiable ensemble classifier be utilized. The Precision, recall, F1-score, and Accuracy are calculated from equations <xref rid="fd9" ref-type="disp-formula">(9)</xref>, <xref rid="fd10" ref-type="disp-formula">(10)</xref>, <xref rid="fd11" ref-type="disp-formula">(11)</xref>, <xref rid="fd12" ref-type="disp-formula">(12)</xref>.<disp-formula id="fd9"><label>(9)</label><mml:math id="M13" altimg="si13.svg" alttext="Equation 9."><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="fd10"><label>(10)</label><mml:math id="M14" altimg="si14.svg" alttext="Equation 10."><mml:mrow><mml:mtext>Re</mml:mtext><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="fd11"><label>(11)</label><mml:math id="M15" altimg="si15.svg" alttext="Equation 11."><mml:mrow><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>2</mml:mn><mml:mo>*</mml:mo><mml:mfrac><mml:mrow><mml:mi>Pr</mml:mi><mml:mspace width="0.25em"/><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo linebreak="badbreak">&#x000d7;</mml:mo><mml:mtext>Re</mml:mtext><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>Pr</mml:mi><mml:mspace width="0.25em"/><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mtext>Re</mml:mtext><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="fd12"><label>(12)</label><mml:math id="M16" altimg="si16.svg" alttext="Equation 12."><mml:mrow><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>Whereas <bold>TP</bold>&#x000a0;=&#x000a0;True Positive, <bold>FP</bold>=False Positive, <bold>TN</bold>&#x000a0;=&#x000a0;True Negative, and <bold>FN</bold>=False Negative.</p><p id="p0315">The performance measures of the classifiers are presented in <xref rid="tbl2" ref-type="table">Table 2</xref> and <xref rid="fig5" ref-type="fig">Fig. 5</xref>. As a performance metric, F1-score, Precision, and Recall have been utilized in this research project for evaluation. This was done to determine whether or not the machine learning models are feasible. Specifically, the F-1 score is the Harmonic Mean that is associated with precision and recall. The term &#x0201c;Precision&#x0201d; is the correct label that should be provided for the percentage that is relevant to the instance. The term &#x0201c;recall&#x0201d; refers to the precise identification of a specific label for the proportion that is associated with a case.<table-wrap position="float" id="tbl2"><label>Table 2</label><caption><p>Measurement of performance.</p></caption><alt-text id="alttext0045">Table 2</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Sr. No.</th><th>Name of Classifier</th><th>Precision</th><th>Recall</th><th>F1-score</th></tr></thead><tbody><tr><td align="left">1</td><td align="left">SVM</td><td align="left">0.94</td><td align="left">0.97</td><td align="left">0.95</td></tr><tr><td align="left">2</td><td align="left">NB</td><td align="left">0.88</td><td align="left">0.93</td><td align="left">0.87</td></tr><tr><td align="left">3</td><td align="left">MLP</td><td align="left">0.86</td><td align="left">0.88</td><td align="left">0.84</td></tr><tr><td align="left">4</td><td align="left">KNN</td><td align="left">0.85</td><td align="left">0.87</td><td align="left">0.82</td></tr></tbody></table><attrib>Source: own extracted from confusion matrix using equations <xref rid="fd9" ref-type="disp-formula">(9)</xref>, <xref rid="fd10" ref-type="disp-formula">(10)</xref>, <xref rid="fd11" ref-type="disp-formula">(11)</xref>, <xref rid="fd12" ref-type="disp-formula">(12)</xref>.</attrib></table-wrap><fig id="fig5"><label>Fig. 5</label><caption><p>The effectiveness of traditional machine learning routines.</p></caption><alt-text id="alttext0030">Fig. 5</alt-text><graphic xlink:href="gr5"/><attrib>Source: Own extracted from <xref rid="tbl2" ref-type="table">Table 2</xref> data.</attrib></fig></p><p id="p0320">The accuracy of classification achieved by Machine Learning classifiers through the application of the K-Fold cross-validation technique is presented in <xref rid="tbl3" ref-type="table">Table 3</xref> and <xref rid="fig6" ref-type="fig">Fig. 6</xref>. The solution to the problem of insufficient data for the formation of validation sets is the application of the cross-validation technique. The process of resampling has been carried out by k-fold cross-validation in this particular piece of research. To begin, the initial sample is divided into k independent subsets of equal size, which are denoted by the letters S1, S2, S3, &#x02026;, Sk. This division is accomplished by a stratified split. Immediately following this, a k-times implementation of the training mockup test is carried out chronologically. In this case, the value of k has been determined to be 5, and on the foundation of this, all of the mockup sets have been separated into five parts. In light of this, the execution of the entire procedure is comprised of five epochs, each of which is comprised of a different combination of training and testing samples. In conclusion, the estimated average of five procedures has been completed to deliver accuracy and computing time on the estimate of the entire classifier recitals.<table-wrap position="float" id="tbl3"><label>Table 3</label><caption><p>The accuracy of classification.</p></caption><alt-text id="alttext0050">Table 3</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Sl. No.</th><th>Classifier</th><th>Fold-1</th><th>Fold-2</th><th>Fold-3</th><th>Fold-4</th><th>Fold-5</th><th>Accuracy %</th></tr></thead><tbody><tr><td align="left">1</td><td align="left">SVM</td><td align="left">93.80</td><td align="left">95.90</td><td align="left">96.23</td><td align="left">95.95</td><td align="left">94.55</td><td align="left">96.90</td></tr><tr><td align="left">2</td><td align="left">NB</td><td align="left">87.90</td><td align="left">89.73</td><td align="left">87.50</td><td align="left">86.70</td><td align="left">85.75</td><td align="left">88.80</td></tr><tr><td align="left">3</td><td align="left">MLP</td><td align="left">82.20</td><td align="left">84.40</td><td align="left">86.75</td><td align="left">86.40</td><td align="left">85.96</td><td align="left">86.75</td></tr><tr><td align="left">4</td><td align="left">KNN</td><td align="left">81.70</td><td align="left">83.70</td><td align="left">82.63</td><td align="left">84.55</td><td align="left">83.85</td><td align="left">85.66</td></tr></tbody></table><attrib>Source: own extracted from models experiment output.</attrib></table-wrap><fig id="fig6"><label>Fig. 6</label><caption><p>The accuracy of traditional machine learning techniques is compared.</p></caption><alt-text id="alttext0035">Fig. 6</alt-text><graphic xlink:href="gr6"/><attrib>Source: Own extracted from <xref rid="tbl3" ref-type="table">Table 3</xref> data.</attrib></fig></p><sec id="sec4.1"><label>4.1</label><title>Compare to state-of-art</title><p id="p0325">We have made the comparison of our models with different state of art methods such as DT, LR, CNN-BiLSM, BERT, LSTM, and AlexNet. The resulting accuracy of the last model AlexNet was 95.15 while our model got an accuracy of 96.90 which is high compared to the other state-of-the-art methods. It speaks volumes that our model is more accurate as compared to the rest models. The comparison is shown in <xref rid="tbl4" ref-type="table">Table 4</xref>.<table-wrap position="float" id="tbl4"><label>Table 4</label><caption><p>Comparison with different state-of-art methods.</p></caption><alt-text id="alttext0055">Table 4</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Method</th><th>Year</th><th>Accuracy %</th></tr></thead><tbody><tr><td align="left">DT [<xref rid="bib66" ref-type="bibr">66</xref>]</td><td align="left">2018</td><td align="left">85.00</td></tr><tr><td align="left">LR [<xref rid="bib67" ref-type="bibr">67</xref>]</td><td align="left">2019</td><td align="left">88.87</td></tr><tr><td align="left">CNN-BiLSM [<xref rid="bib68" ref-type="bibr">68</xref>]</td><td align="left">2020</td><td align="left">81.90</td></tr><tr><td align="left">BERT [<xref rid="bib69" ref-type="bibr">69</xref>]</td><td align="left">2021</td><td align="left">94.92</td></tr><tr><td align="left">LSTM [<xref rid="bib70" ref-type="bibr">70</xref>]</td><td align="left">2022</td><td align="left">84.60</td></tr><tr><td align="left">AlexNet [<xref rid="bib71" ref-type="bibr">71</xref>]</td><td align="left">2023</td><td align="left">95.15</td></tr><tr><td align="left"><bold>SVM (Our)</bold></td><td align="left"><bold>--</bold></td><td align="left"><bold>96.90</bold></td></tr></tbody></table></table-wrap></p></sec><sec id="sec4.2"><label>4.2</label><title>Discussion</title><p id="p0330">The context of a word is an essential component of its representation. In addition to lexical definitions and even explicit knowledge, context is responsible for the creation of meaning for any given notion. Consequently, the co-occurrence of a term with a situation that is generally positive or negative may promote the development of a subtle associative meaning. Adaptive goals could be served by this, such as supporting individuals with reading comprehension by assisting them in predicting the valence of concepts that are close to one another. On the other hand, it has the potential to imbue these statements with subtle affective tones, which can then be used to shape global appraisals of other individuals [<xref rid="bib72" ref-type="bibr">72</xref>]. The GloVe word embedding was trained using a collection of text available on the internet.</p><p id="p0335">The findings suggest that language itself contains recoverable and accurate imprints of our historical biases. These biases may be morally neutral, such as when it comes to insects or flowers; problematic, such as when it comes to race or gender; or even simply veridical, reflecting the status quo for the distribution of gender concerning careers or beginning names [<xref rid="bib73" ref-type="bibr">73</xref>]. Thus, finding semantic bias in judicial decisions is optimal before we use it as raw data to learn models that could be helpful for judicial assistance in adjudication. Our model classifies semantic bias by categorizing bias into three different types i.e. i) Positive and negative connotation of words, ii) referencing phrases out of context, and iii) stereotype bias. Different judgments that contain semantic biases are given in <xref rid="tbl5" ref-type="table">Table 5</xref>.<table-wrap position="float" id="tbl5"><label>Table 5</label><caption><p>Classification of the semantic biasedness by model.</p></caption><alt-text id="alttext0060">Table 5</alt-text><table frame="hsides" rules="groups"><thead><tr><th>Ref.</th><th>Judgments</th><th>Type-1</th><th>Type-2</th><th>Type-3</th><th>Correction</th></tr></thead><tbody><tr><td align="left">[<xref rid="bib74" ref-type="bibr">74</xref>]</td><td align="left">"No evidence to reflect any substantial and objective bias toward any of the parties or attorneys involved &#x02026;,"</td><td align="left">&#x02717;</td><td align="left">&#x02717;</td><td align="left">&#x02713;</td><td align="left">Replacement of "bias" with "basis."</td></tr><tr><td align="left">[<xref rid="bib75" ref-type="bibr">75</xref>]</td><td align="left">"remove" the statement concerning biasing contacts but rather assert that the statement was merely "omitted" from the relevant patent applications.</td><td align="left">&#x02713;</td><td align="left">&#x02717;</td><td align="left">&#x02717;</td><td align="left">Replacement of &#x0201c;Omitted&#x0201d; as to &#x0201c;removal&#x0201d;</td></tr><tr><td align="left">[<xref rid="bib76" ref-type="bibr">76</xref>]</td><td align="left">The judge clearly expresses his disapproval of Mr. Miles's behavior, as evident from his use of the term "distortion" instead of a more neutral term like "operation".</td><td align="left">&#x02713;</td><td align="left">&#x02717;</td><td align="left">&#x02717;</td><td align="left">Distortion with operation</td></tr><tr><td align="left">[<xref rid="bib77" ref-type="bibr">77</xref>]</td><td align="left">great detail," "ambiguities," and "negative standpoint" instead of This/these/that/those, or misapplication, and ill-defined test, error, etc.</td><td align="left">&#x02713;</td><td align="left">&#x02713;</td><td align="left">&#x02717;</td><td align="left">These ambiguities with proper annotation</td></tr><tr><td align="left">[<xref rid="bib78" ref-type="bibr">78</xref>]</td><td align="left">to guarantee that the rights of children with disabilities and the parents of such children are safeguarded throughout history.</td><td align="left">&#x02717;</td><td align="left">&#x02713;</td><td align="left">&#x02713;</td><td align="left">Putting the rights of both</td></tr><tr><td align="left">[<xref rid="bib79" ref-type="bibr">79</xref>]</td><td align="left">a Federal Employees' Liability Act (FELA) plaintiff can reach a jury if he can demonstrate that his employer's carelessness was even the tiniest cause of his injury.</td><td align="left">&#x02717;</td><td align="left">&#x02717;</td><td align="left">&#x02713;</td><td align="left">Use of &#x02018;&#x02018;proximate&#x02019;&#x02019; cause, slightest&#x02019;&#x02019; cause.</td></tr></tbody></table><attrib>Source: own extracted from references [<xref rid="bib74" ref-type="bibr">[74]</xref>, <xref rid="bib75" ref-type="bibr">[75]</xref>, <xref rid="bib76" ref-type="bibr">[76]</xref>, <xref rid="bib77" ref-type="bibr">[77]</xref>, <xref rid="bib78" ref-type="bibr">[78]</xref>, <xref rid="bib79" ref-type="bibr">[79]</xref>].</attrib></table-wrap></p><p id="p0340">In the first case, during the writ application, the petitioner asserts that the ad hoc judge made a mistake by applying the incorrect legal standard. In the written reasons for judgment, the court stated that no evidence indicated a major and objective bias against any of the attorneys or parties engaged in the case. However, the petitioner claims that the recently modified Article 151(B) necessitates a finding of a "substantial and objective basis" for recusal, emphasizing the contrast between "bias" and "basis." The petitioner contends that the terms have distinct implications, with "bias" being a customary cause for recusal and "basis" establishing a more comprehensive required ground. Although this may at first appear to be a semantic issue, the petitioner argues that the terms have unique implications. Because the petitioner asserts that the judge may have applied the more limited criterion of "bias" in an erroneous manner and neglected to take into consideration the more general grounds of other "bases" for recusal, it is necessary to conduct a de novo review of the judgment that was handed down by the trial court in light of the newly updated legal standard.</p><p id="p0345">In the second cited case, as part of its effort to have the Tenth Counterclaim dismissed, the National Patent and Trademark Office (NPI) contends that it did not "remove" the statement that was made regarding biased contacts; rather, it says that the remark was only "omitted" from the relevant patent applications. The court categorizes the argument as a semantic issue, highlighting the fact that the core of GPS's claim is that the statement was not intentionally removed but rather that it was absent from the document. In addition, NPI asserts that the patent examiner, and not NPI, was the one who said that the previous art did not disclose any biased interactions. Nevertheless, the court makes notice of the fact that this response does not address the primary complaint against GPS. GPS asserts that the patent examiner was misled into believing that biasing contacts were a novel aspect in comparison to the previous art because the remark about biasing contacts was not included in the patent application during the examination process. Although the court does not dive into the merits of GPS's claim at this juncture, it does note that GPS has presented adequate details regarding the who, what, when, where, and how in support of its Tenth Counterclaim. This, in turn, suggests that the rejection of the counterclaim is not merited at this time.</p><p id="p0350">In the other cases, the judge describes Mr. Miles's actions, and the judge's critical attitude is made clear by the selection of the labeling word distortion rather than the more neutral operation, for example. Similarly, the judge refers back to a document that was published by Jefferson County, which includes a subject that is involved in a dispute regarding racial discrimination in the allocation of children to public schools. A significant deal of detail is provided by the court regarding the drawbacks of the internal restrictions that Jefferson County has in place; the judge has stated it in terms that are quite general and imprecise; it fails to make clear; it indicates that without providing any further explanation. In addition, he captures these remarks through these ambiguities, which plainly show the judge's critical stance towards the briefing that Jefferson County presented as evidence against the defendant. However, distortion and ambiguity are not the sole lemmas via which the Court expresses its most explicit opinion when it comes to the matter at hand.</p><p id="p0355">Similarly, "to ensure that the rights of children with disabilities and parents of such children are protected," is one of the aims that the Individuals with Disabilities Education Act (IDEA) seeks to accomplish. (B) to Section 1400(d) (1). In the language that was mentioned, the word "rights" denotes both the rights of the kid and the rights of the parents; otherwise, the grammatical structure would be completely incomprehensible. The other sections lend credence to this viewpoint.</p></sec></sec><sec id="sec5"><label>5</label><title>Conclusion</title><p id="p0360">It is undeniable that a fair society is essential for progress. The fairness of utilizing AI in legal judgments is crucial for its legitimacy. Given the potential for cognitive bias, the automation and digitalization of judicial systems in light of AI innovation pose a significant threat. For AI to be effectively used in the courtroom, it is crucial to train models using high-quality data, including ML, NLP, and LLM, while also minimizing any unnecessary data. Semantic bias is one of the important types of biases that are found in legal judgments because judges have discretionary powers to decide the cases. While preparing judgments, judges use words and phrases that can cause difficulties in understanding and implementation of the judgments. It can also cause distress in society and breach of fundamental rights, as these judgments have to be used as data warehouses so if in case of any bias carried by this judgment might result in an aggravated form of bias when used as a warehouse of AI modes. This task involves categorizing the data and preparing it for training by the standards of the legal system. In the present study, we have carried out some experiments based on Machine Learning algorithms. These experiments comprised analyzing the language of the judgments that were made using the Chinese AI and Law (CAIL) dataset to categorize the semantic biases if there were any particular semantic biases. To determine the semantic connection among the legal datasets, classification, and identification have been carried out in an organized manner. For semantic classification, four different classifiers such that SVM, NB, MLP, and KNN have been utilized and analyzed for the classification of semantic biases, which are substantially larger than in other circumstances, our models perform significantly better than those of other models. We have conducted thorough experimental evaluations, which have demonstrated that the created method is accurate and efficient when used with real data. As a result, this method can be considered a helpful tool in real-world scenarios, including situations in which massive collections of legal documents need to be analyzed. Not only have our suggested machine learning algorithms been able to outperform four existing state-of-the-art competitor systems, but they have also been able to achieve many superior performances when the amount of noise in the data is increased. However, it will be necessary to do additional studies to determine how these systems could be enhanced by employing a more sophisticated legal and linguistic understanding.</p></sec><sec id="sec6"><title>Funding</title><p id="p0365">National Social Science Foundation project "Research on the Construction of Governance System in Cyberspace in the New Era" project No.19BFX019 and National Social Science Fund major project "Big Data Sovereignty Security Guarantee System construction Research" phased results (project number: 21&#x00026;ZD168)</p></sec><sec sec-type="data-availability" id="sec7"><title>Data availability statement</title><p id="p0370">Some or all data, models, or codes that support the findings of this study are available from the corresponding author upon reasonable request.</p></sec><sec id="sec8"><title>CRediT authorship contribution statement</title><p id="p0375"><bold>Kashif Javed:</bold> Methodology, Formal analysis. <bold>Jianxin Li:</bold> Writing &#x02013; review &#x00026; editing, Supervision.</p></sec><sec sec-type="COI-statement"><title>Declaration of competing interest</title><p id="p0380">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p></sec></body><back><ref-list id="cebib0010"><title>References</title><ref id="bib1"><label>1</label><element-citation publication-type="journal" id="sref1"><person-group person-group-type="author"><name><surname>Nasir</surname><given-names>O.</given-names></name><name><surname>Javed</surname><given-names>R.T.</given-names></name><name><surname>Gupta</surname><given-names>S.</given-names></name><name><surname>Vinuesa</surname><given-names>R.</given-names></name><name><surname>Qadir</surname><given-names>J.</given-names></name></person-group><article-title>Artificial intelligence and sustainable development goals nexus via four vantage points</article-title><source>Technol. Soc.</source><volume>72</volume><year>2023</year><object-id pub-id-type="publisher-id">102171</object-id></element-citation></ref><ref id="bib2"><label>2</label><element-citation publication-type="book" id="sref2"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>C.</given-names></name><etal/></person-group><part-title>M-FLAG: medical vision-language pre-training with frozen language models and latent space geometry optimization</part-title><source>International Conference on Medical Image Computing and Computer-Assisted Intervention</source><year>2023</year><publisher-name>Springer</publisher-name><fpage>637</fpage><lpage>647</lpage></element-citation></ref><ref id="bib3"><label>3</label><element-citation publication-type="journal" id="sref3"><person-group person-group-type="author"><name><surname>Wan</surname><given-names>Z.</given-names></name><etal/></person-group><article-title>Med-unic: Unifying cross-lingual medical vision-language pre-training by diminishing bias</article-title><source>Adv. Neural Inf. Process. Syst.</source><volume>36</volume><year>2024</year></element-citation></ref><ref id="bib4"><label>4</label><element-citation publication-type="journal" id="sref4"><person-group person-group-type="author"><name><surname>Berk</surname><given-names>R.</given-names></name><name><surname>Heidari</surname><given-names>H.</given-names></name><name><surname>Jabbari</surname><given-names>S.</given-names></name><name><surname>Kearns</surname><given-names>M.</given-names></name><name><surname>Roth</surname><given-names>A.</given-names></name></person-group><article-title>Fairness in criminal justice risk assessments: the state of the art</article-title><source>Socio. Methods Res.</source><volume>50</volume><issue>1</issue><year>2021</year><fpage>3</fpage><lpage>44</lpage></element-citation></ref><ref id="bib5"><label>5</label><element-citation publication-type="book" id="sref5"><person-group person-group-type="author"><name><surname>Goel</surname><given-names>S.</given-names></name><name><surname>Shroff</surname><given-names>R.</given-names></name><name><surname>Skeem</surname><given-names>J.</given-names></name><name><surname>Slobogin</surname><given-names>C.</given-names></name></person-group><part-title>The accuracy, equity, and jurisprudence of criminal risk assessment</part-title><source>Research Handbook on Big Data Law</source><year>2021</year><fpage>9</fpage><lpage>28</lpage></element-citation></ref><ref id="bib6"><label>6</label><element-citation publication-type="journal" id="sref6"><person-group person-group-type="author"><name><surname>Zeleznikow</surname><given-names>J.</given-names></name></person-group><article-title>The benefits and dangers of using machine learning to support making legal predictions</article-title><source>Wiley Interdisciplinary Reviews: Data Min. Knowl. Discov.</source><year>2023</year><fpage>e1505</fpage></element-citation></ref><ref id="bib7"><label>7</label><element-citation publication-type="journal" id="sref7"><person-group person-group-type="author"><name><surname>Bonnefon</surname><given-names>J.-F.</given-names></name><name><surname>Rahwan</surname><given-names>I.</given-names></name><name><surname>Shariff</surname><given-names>A.</given-names></name></person-group><article-title>The moral psychology of Artificial Intelligence</article-title><source>Annu. Rev. Psychol.</source><volume>75</volume><year>2023</year></element-citation></ref><ref id="bib8"><label>8</label><element-citation publication-type="journal" id="sref8"><person-group person-group-type="author"><name><surname>Pessach</surname><given-names>D.</given-names></name><name><surname>Shmueli</surname><given-names>E.</given-names></name></person-group><article-title>A review on fairness in machine learning</article-title><source>ACM Comput. Surv.</source><volume>55</volume><issue>3</issue><year>2022</year><fpage>1</fpage><lpage>44</lpage></element-citation></ref><ref id="bib9"><label>9</label><element-citation publication-type="book" id="sref9"><person-group person-group-type="author"><name><surname>Ignatiev</surname><given-names>A.</given-names></name><name><surname>Cooper</surname><given-names>M.C.</given-names></name><name><surname>Siala</surname><given-names>M.</given-names></name><name><surname>Hebrard</surname><given-names>E.</given-names></name><name><surname>Marques-Silva</surname><given-names>J.</given-names></name></person-group><part-title>Towards formal fairness in machine learning</part-title><source>Principles and Practice of Constraint Programming: 26th International Conference, CP 2020, Louvain-La-Neuve, Belgium, September 7&#x02013;11, 2020, Proceedings 26</source><year>2020</year><publisher-name>Springer</publisher-name><fpage>846</fpage><lpage>867</lpage></element-citation></ref><ref id="bib10"><label>10</label><element-citation publication-type="journal" id="sref10"><person-group person-group-type="author"><name><surname>Oleson</surname><given-names>J.C.</given-names></name></person-group><article-title>A requiem for the Unabomber</article-title><source>Contemp. Justice Rev.</source><year>2023</year><fpage>1</fpage><lpage>29</lpage></element-citation></ref><ref id="bib11"><label>11</label><element-citation publication-type="journal" id="sref11"><person-group person-group-type="author"><name><surname>Perera</surname><given-names>J.</given-names></name><name><surname>Liu</surname><given-names>S.-H.</given-names></name><name><surname>Mernik</surname><given-names>M.</given-names></name><name><surname>&#x0010c;repin&#x00161;ek</surname><given-names>M.</given-names></name><name><surname>Ravber</surname><given-names>M.</given-names></name></person-group><article-title>A graph pointer network-based multi-objective deep reinforcement learning algorithm for solving the traveling salesman problem</article-title><source>Mathematics</source><volume>11</volume><issue>2</issue><year>2023</year><fpage>437</fpage></element-citation></ref><ref id="bib12"><label>12</label><mixed-citation publication-type="other" id="oref12">Xiao C., et al., &#x0201c;Cail2018: a large-scale legal dataset for judgment prediction,&#x0201d;, arXiv preprint arXiv:1807.02478 (2018). pp.1&#x02013;4.</mixed-citation></ref><ref id="bib13"><label>13</label><element-citation publication-type="journal" id="sref13"><person-group person-group-type="author"><name><surname>Greenstein</surname><given-names>S.</given-names></name></person-group><article-title>Preserving the rule of law in the era of artificial intelligence (AI)</article-title><source>Artif. Intell. Law</source><volume>30</volume><issue>3</issue><year>2022</year><fpage>291</fpage><lpage>323</lpage></element-citation></ref><ref id="bib14"><label>14</label><element-citation publication-type="book" id="sref14"><person-group person-group-type="author"><name><surname>Bell</surname><given-names>F.</given-names></name><name><surname>Bennett Moses</surname><given-names>L.</given-names></name><name><surname>Legg</surname><given-names>M.</given-names></name><name><surname>Silove</surname><given-names>J.</given-names></name><name><surname>Zalnieriute</surname><given-names>M.</given-names></name></person-group><part-title>AI Decision-Making and the Courts: A Guide for Judges</part-title><year>2022</year><publisher-name>Tribunal Members and Court Administrators&#x02019;," Australasian Institute of Judicial Administration</publisher-name></element-citation></ref><ref id="bib15"><label>15</label><element-citation publication-type="journal" id="sref15"><person-group person-group-type="author"><name><surname>Wr&#x000f3;blewski</surname><given-names>J.</given-names></name></person-group><article-title>Legal decision and its justification</article-title><source>Logique Anal.</source><volume>14</volume><issue>53/54</issue><year>1971</year><fpage>409</fpage><lpage>419</lpage></element-citation></ref><ref id="bib16"><label>16</label><element-citation publication-type="book" id="sref16"><person-group person-group-type="author"><name><surname>Rose</surname><given-names>People v.</given-names></name></person-group><part-title>NY: county court</part-title><series>Misc. 2d</series><volume>vol. 82</volume><year>1975</year><fpage>429</fpage></element-citation></ref><ref id="bib17"><label>17</label><element-citation publication-type="book" id="sref17"><person-group person-group-type="author"><name><surname>Ollikainen</surname><given-names>A.</given-names></name></person-group><part-title>Asset Partitioning in the Trust</part-title><year>2018</year><publisher-name>University of Oxford</publisher-name></element-citation></ref><ref id="bib18"><label>18</label><element-citation publication-type="book" id="sref18"><person-group person-group-type="author"><name><surname>Rayner</surname><given-names>K.</given-names></name><name><surname>Pollatsek</surname><given-names>A.</given-names></name><name><surname>Ashby</surname><given-names>J.</given-names></name><name><surname>Clifton</surname><given-names>C.</given-names><suffix>Jr.</suffix></name></person-group><part-title>Psychology of Reading</part-title><year>2012</year></element-citation></ref><ref id="bib19"><label>19</label><element-citation publication-type="book" id="sref19"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>J.</given-names></name><name><surname>Bareinboim</surname><given-names>E.</given-names></name></person-group><part-title>"Fairness in decision-making&#x02014;the causal explanation formula,"</part-title><source>Proceedings of the AAAI Conference on Artificial Intelligence</source><volume>vol. 32</volume><year>2018</year><comment>1</comment></element-citation></ref><ref id="bib20"><label>20</label><element-citation publication-type="journal" id="sref20"><person-group person-group-type="author"><name><surname>Katsaros</surname><given-names>M.</given-names></name><name><surname>Kim</surname><given-names>J.</given-names></name><name><surname>Tyler</surname><given-names>T.</given-names></name></person-group><article-title>Online content moderation: does justice need a human face?</article-title><source>Int. J. Hum. Comput. Interact.</source><volume>40</volume><issue>1</issue><year>2024</year><fpage>66</fpage><lpage>77</lpage></element-citation></ref><ref id="bib21"><label>21</label><element-citation publication-type="journal" id="sref21"><person-group person-group-type="author"><name><surname>Mehmood</surname><given-names>F.</given-names></name><name><surname>Chen</surname><given-names>E.</given-names></name><name><surname>Akbar</surname><given-names>M.A.</given-names></name><name><surname>Alsanad</surname><given-names>A.A.</given-names></name></person-group><article-title>Human action recognition of spatiotemporal parameters for skeleton sequences using MTLN feature learning framework</article-title><source>Electronics</source><volume>10</volume><issue>21</issue><year>2021</year><fpage>2708</fpage></element-citation></ref><ref id="bib22"><label>22</label><element-citation publication-type="journal" id="sref22"><person-group person-group-type="author"><name><surname>Chouldechova</surname><given-names>A.</given-names></name></person-group><article-title>Fair prediction with disparate impact: a study of bias in recidivism prediction instruments</article-title><source>Big Data</source><volume>5</volume><issue>2</issue><year>2017</year><fpage>153</fpage><lpage>163</lpage><pub-id pub-id-type="pmid">28632438</pub-id>
</element-citation></ref><ref id="bib23"><label>23</label><element-citation publication-type="book" id="sref23"><person-group person-group-type="author"><name><surname>Pfisterer</surname><given-names>F.</given-names></name></person-group><part-title>Algorithmic fairness</part-title><source>Applied Machine Learning Using Mlr3 in R</source><year>2024</year><publisher-name>Chapman and Hall/CRC</publisher-name><fpage>316</fpage><lpage>324</lpage></element-citation></ref><ref id="bib24"><label>24</label><element-citation publication-type="book" id="sref24"><person-group person-group-type="author"><name><surname>Barocas</surname><given-names>S.</given-names></name><name><surname>Hardt</surname><given-names>M.</given-names></name><name><surname>Narayanan</surname><given-names>A.</given-names></name></person-group><part-title>Fairness and Machine Learning: Limitations and Opportunities</part-title><year>2023</year><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib25"><label>25</label><element-citation publication-type="journal" id="sref25"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>J.</given-names></name><name><surname>Huang</surname><given-names>S.</given-names></name><name><surname>Wei</surname><given-names>C.</given-names></name></person-group><article-title>Chinese legal judgment prediction via knowledgeable prompt learning</article-title><source>Expert Syst. Appl.</source><volume>238</volume><year>2024</year><object-id pub-id-type="publisher-id">122177</object-id></element-citation></ref><ref id="bib26"><label>26</label><mixed-citation publication-type="other" id="oref26">Heng Q., Yu S., Zhang Y., A new AI-based approach for automatic identification of tea leaf disease using deep neural network based on hybrid pooling, Heliyon 10 no.5 (2024); e26465.pp.1-13.</mixed-citation></ref><ref id="bib27"><label>27</label><element-citation publication-type="journal" id="sref27"><person-group person-group-type="author"><name><surname>Trivedi</surname><given-names>A.</given-names></name><name><surname>Trivedi</surname><given-names>A.</given-names></name><name><surname>Varshney</surname><given-names>S.</given-names></name><name><surname>Joshipura</surname><given-names>V.</given-names></name><name><surname>Mehta</surname><given-names>R.</given-names></name><name><surname>Dhanani</surname><given-names>J.</given-names></name></person-group><article-title>"Similarity analysis of legal documents: a survey,"</article-title><source>ICT Analysis and Applications: Proceedings of ICT4SD</source><volume>2</volume><issue>2021</issue><year>2020</year><fpage>497</fpage><lpage>506</lpage><comment>Springer</comment></element-citation></ref><ref id="bib28"><label>28</label><element-citation publication-type="journal" id="sref28"><person-group person-group-type="author"><name><surname>Mahmood</surname><given-names>F.</given-names></name><name><surname>Abbas</surname><given-names>K.</given-names></name><name><surname>Raza</surname><given-names>A.</given-names></name><name><surname>Khan</surname><given-names>M.A.</given-names></name><name><surname>Khan</surname><given-names>P.W.</given-names></name></person-group><article-title>Three dimensional agricultural land modeling using unmanned aerial system (UAS)</article-title><source>Int. J. Adv. Comput. Sci. Appl.</source><volume>10</volume><issue>1</issue><year>2019</year></element-citation></ref><ref id="bib29"><label>29</label><element-citation publication-type="book" id="sref29"><person-group person-group-type="author"><name><surname>Kumar</surname><given-names>S.</given-names></name><name><surname>Reddy</surname><given-names>P.K.</given-names></name><name><surname>Reddy</surname><given-names>V.B.</given-names></name><name><surname>Singh</surname><given-names>A.</given-names></name></person-group><part-title>Similarity analysis of legal judgments</part-title><source>Proceedings of the Fourth Annual ACM Bangalore Conference</source><year>2011</year><fpage>1</fpage><lpage>4</lpage></element-citation></ref><ref id="bib30"><label>30</label><element-citation publication-type="book" id="sref30"><person-group person-group-type="author"><name><surname>Mandal</surname><given-names>A.</given-names></name><name><surname>Chaki</surname><given-names>R.</given-names></name><name><surname>Saha</surname><given-names>S.</given-names></name><name><surname>Ghosh</surname><given-names>K.</given-names></name><name><surname>Pal</surname><given-names>A.</given-names></name><name><surname>Ghosh</surname><given-names>S.</given-names></name></person-group><part-title>Measuring similarity among legal court case documents</part-title><source>Proceedings of the 10th Annual ACM India Compute Conference</source><year>2017</year><fpage>1</fpage><lpage>9</lpage></element-citation></ref><ref id="bib31"><label>31</label><element-citation publication-type="journal" id="sref31"><person-group person-group-type="author"><name><surname>Koniaris</surname><given-names>M.</given-names></name><name><surname>Anagnostopoulos</surname><given-names>I.</given-names></name><name><surname>Vassiliou</surname><given-names>Y.</given-names></name></person-group><article-title>Network analysis in the legal domain: a complex model for European union legal sources</article-title><source>Journal of Complex Networks</source><volume>6</volume><issue>2</issue><year>2018</year><fpage>243</fpage><lpage>268</lpage></element-citation></ref><ref id="bib32"><label>32</label><mixed-citation publication-type="other" id="oref32">Ayden M.A., Yuksel M.E., Erdem S.E.Y., A two-stream deep model for automated ICD-9 code prediction in an intensive care unit, Heliyon10, no.4 (2024); e25960. pp.1-14.</mixed-citation></ref><ref id="bib33"><label>33</label><element-citation publication-type="book" id="sref33"><person-group person-group-type="author"><name><surname>Nanda</surname><given-names>R.</given-names></name><name><surname>Adebayo</surname><given-names>K.J.</given-names></name><name><surname>Di Caro</surname><given-names>L.</given-names></name><name><surname>Boella</surname><given-names>G.</given-names></name><name><surname>Robaldo</surname><given-names>L.</given-names></name></person-group><part-title>Legal information retrieval using topic clustering and neural networks</part-title><source>COLIEE@ ICAIL</source><year>2017</year><fpage>68</fpage><lpage>78</lpage></element-citation></ref><ref id="bib34"><label>34</label><element-citation publication-type="journal" id="sref34"><person-group person-group-type="author"><name><surname>Guo</surname><given-names>C.</given-names></name><name><surname>Lu</surname><given-names>M.</given-names></name><name><surname>Wei</surname><given-names>W.</given-names></name></person-group><article-title>An improved LDA topic modeling method based on partition for medium and long texts</article-title><source>Annals of Data Science</source><volume>8</volume><year>2021</year><fpage>331</fpage><lpage>344</lpage></element-citation></ref><ref id="bib35"><label>35</label><element-citation publication-type="journal" id="sref35"><person-group person-group-type="author"><name><surname>Mikolov</surname><given-names>T.</given-names></name><name><surname>Sutskever</surname><given-names>I.</given-names></name><name><surname>Chen</surname><given-names>K.</given-names></name><name><surname>Corrado</surname><given-names>G.S.</given-names></name><name><surname>Dean</surname><given-names>J.</given-names></name></person-group><article-title>Distributed representations of words and phrases and their compositionality</article-title><source>Adv. Neural Inf. Process. Syst.</source><volume>26</volume><year>2013</year></element-citation></ref><ref id="bib36"><label>36</label><element-citation publication-type="journal" id="sref36"><person-group person-group-type="author"><name><surname>Mehmood</surname><given-names>F.</given-names></name><name><surname>Chen</surname><given-names>E.</given-names></name><name><surname>Abbas</surname><given-names>T.</given-names></name><name><surname>Akbar</surname><given-names>M.A.</given-names></name><name><surname>Khan</surname><given-names>A.A.</given-names></name></person-group><article-title>Automatically human action recognition (HAR) with view variation from skeleton means of adaptive transformer network</article-title><source>Soft Comput.</source><year>2023</year><fpage>1</fpage><lpage>20</lpage></element-citation></ref><ref id="bib37"><label>37</label><element-citation publication-type="book" id="sref37"><person-group person-group-type="author"><name><surname>Sugathadasa</surname><given-names>K.</given-names></name><etal/></person-group><part-title>Synergistic union of word2vec and lexicon for domain specific semantic similarity</part-title><source>2017 IEEE International Conference on Industrial and Information Systems (ICIIS)</source><year>2017</year><publisher-name>IEEE</publisher-name><fpage>1</fpage><lpage>6</lpage></element-citation></ref><ref id="bib38"><label>38</label><element-citation publication-type="book" id="sref38"><person-group person-group-type="author"><name><surname>Chakrabarti</surname><given-names>D.</given-names></name><etal/></person-group><part-title>Use of artificial intelligence to analyse risk in legal documents for a better decision support</part-title><source>TENCON 2018-2018 IEEE Region 10 Conference</source><year>2018</year><publisher-name>IEEE</publisher-name><fpage>683</fpage><lpage>688</lpage></element-citation></ref><ref id="bib39"><label>39</label><element-citation publication-type="book" id="sref39"><person-group person-group-type="author"><name><surname>Kumar</surname><given-names>S.</given-names></name><name><surname>Reddy</surname><given-names>P.K.</given-names></name><name><surname>Reddy</surname><given-names>V.B.</given-names></name><name><surname>Suri</surname><given-names>M.</given-names></name></person-group><part-title>Finding similar legal judgements under common law system</part-title><source>Databases in Networked Information Systems: 8th International Workshop, DNIS 2013, Aizu-Wakamatsu, Japan, March 25-27, 2013. Proceedings 8</source><year>2013</year><publisher-name>Springer</publisher-name><fpage>103</fpage><lpage>116</lpage></element-citation></ref><ref id="bib40"><label>40</label><element-citation publication-type="book" id="sref40"><person-group person-group-type="author"><name><surname>Raghav</surname><given-names>K.</given-names></name><name><surname>Balakrishna Reddy</surname><given-names>P.</given-names></name><name><surname>Balakista Reddy</surname><given-names>V.</given-names></name><name><surname>Krishna Reddy</surname><given-names>P.</given-names></name></person-group><part-title>Text and citations based cluster analysis of legal judgments</part-title><source>Mining Intelligence and Knowledge Exploration: Third International Conference, MIKE 2015, Hyderabad, India, December 9-11, 2015, Proceedings 3</source><year>2015</year><publisher-name>Springer</publisher-name><fpage>449</fpage><lpage>459</lpage></element-citation></ref><ref id="bib41"><label>41</label><element-citation publication-type="journal" id="sref41"><person-group person-group-type="author"><name><surname>Leibon</surname><given-names>G.</given-names></name><name><surname>Livermore</surname><given-names>M.</given-names></name><name><surname>Harder</surname><given-names>R.</given-names></name><name><surname>Riddell</surname><given-names>A.</given-names></name><name><surname>Rockmore</surname><given-names>D.</given-names></name></person-group><article-title>Bending the law: geometric tools for quantifying influence in the multinetwork of legal opinions</article-title><source>Artif. Intell. Law</source><volume>26</volume><year>2018</year><fpage>145</fpage><lpage>167</lpage></element-citation></ref><ref id="bib42"><label>42</label><element-citation publication-type="journal" id="sref42"><person-group person-group-type="author"><name><surname>Singha</surname><given-names>C.</given-names></name><name><surname>Swain</surname><given-names>K.C.</given-names></name><name><surname>Pradhan</surname><given-names>B.</given-names></name><name><surname>Rusia</surname><given-names>D.K.</given-names></name><name><surname>Moghimi</surname><given-names>A.</given-names></name><name><surname>Ranjgar</surname><given-names>B.</given-names></name></person-group><article-title>Mapping groundwater potential zone in the subarnarekha basin, India, using a novel hybrid multi-criteria approach in Google earth Engine</article-title><source>Heliyon</source><volume>10</volume><issue>2</issue><year>2024</year><object-id pub-id-type="publisher-id">e24308</object-id></element-citation></ref><ref id="bib43"><label>43</label><element-citation publication-type="journal" id="sref43"><person-group person-group-type="author"><name><surname>Sugathadasa</surname><given-names>K.</given-names></name><etal/></person-group><article-title>"Legal document retrieval using document vector embeddings and deep learning,"</article-title><source>Intelligent Computing: Proceedings of the 2018 Computing Conference</source><volume>2</volume><year>2019</year><fpage>160</fpage><lpage>175</lpage><comment>Springer</comment></element-citation></ref><ref id="bib44"><label>44</label><element-citation publication-type="journal" id="sref44"><person-group person-group-type="author"><name><surname>Kumari</surname><given-names>A.</given-names></name><name><surname>Lobiyal</surname><given-names>D.</given-names></name></person-group><article-title>Efficient estimation of Hindi WSD with distributed word representation in vector space</article-title><source>Journal of King Saud University-Computer and Information Sciences</source><volume>34</volume><issue>8</issue><year>2022</year><fpage>6092</fpage><lpage>6103</lpage></element-citation></ref><ref id="bib45"><label>45</label><element-citation publication-type="book" id="sref45"><person-group person-group-type="author"><name><surname>Grover</surname><given-names>A.</given-names></name><name><surname>Leskovec</surname><given-names>J.</given-names></name></person-group><part-title>node2vec: scalable feature learning for networks</part-title><source>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</source><year>2016</year><fpage>855</fpage><lpage>864</lpage></element-citation></ref><ref id="bib46"><label>46</label><element-citation publication-type="journal" id="sref46"><person-group person-group-type="author"><name><surname>Sansone</surname><given-names>C.</given-names></name><name><surname>Sperl&#x000ed;</surname><given-names>G.</given-names></name></person-group><article-title>Legal information retrieval systems: state-of-the-art and open issues</article-title><source>Inf. Syst.</source><volume>106</volume><year>2022</year><object-id pub-id-type="publisher-id">101967</object-id></element-citation></ref><ref id="bib47"><label>47</label><element-citation publication-type="book" id="sref47"><person-group person-group-type="author"><name><surname>Xiao</surname><given-names>C.</given-names></name><name><surname>Liu</surname><given-names>Z.</given-names></name><name><surname>Lin</surname><given-names>Y.</given-names></name><name><surname>Sun</surname><given-names>M.</given-names></name></person-group><part-title>Legal knowledge representation learning</part-title><source>Representation Learning for Natural Language Processing</source><year>2023</year><publisher-name>Springer Nature Singapore</publisher-name><publisher-loc>Singapore</publisher-loc><fpage>401</fpage><lpage>432</lpage></element-citation></ref><ref id="bib48"><label>48</label><element-citation publication-type="book" id="sref48"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>Z.</given-names></name><name><surname>Xu</surname><given-names>J.</given-names></name><name><surname>Zhang</surname><given-names>X.</given-names></name><name><surname>Dong</surname><given-names>Z.</given-names></name><name><surname>Wen</surname><given-names>J.-R.</given-names></name></person-group><part-title>Law Article-Enhanced Legal Case Matching: A Causal Learning Approach</part-title><year>2023</year></element-citation></ref><ref id="bib49"><label>49</label><element-citation publication-type="journal" id="sref49"><person-group person-group-type="author"><name><surname>&#x00160;avelka</surname><given-names>J.</given-names></name><name><surname>Ashley</surname><given-names>K.D.</given-names></name></person-group><article-title>Legal information retrieval for understanding statutory terms</article-title><source>Artif. Intell. Law</source><year>2022</year><fpage>1</fpage><lpage>45</lpage></element-citation></ref><ref id="bib50"><label>50</label><element-citation publication-type="journal" id="sref50"><person-group person-group-type="author"><name><surname>Ye</surname><given-names>W.</given-names></name><etal/></person-group><article-title>Emergent surgical retrieval of a left atrial appendage occluder migrated into the left ventricular outflow tract with secondary massive mitral regurgitation: a case report and literature review</article-title><source>Heliyon</source><volume>10</volume><year>2024</year><object-id pub-id-type="publisher-id">e27112</object-id><comment>PP. 1-8</comment></element-citation></ref><ref id="bib51"><label>51</label><element-citation publication-type="journal" id="sref51"><person-group person-group-type="author"><name><surname>De Martino</surname><given-names>G.</given-names></name><name><surname>Pio</surname><given-names>G.</given-names></name><name><surname>Ceci</surname><given-names>M.</given-names></name></person-group><article-title>PRILJ: an efficient two-step method based on embedding and clustering for the identification of regularities in legal case judgments</article-title><source>Artif. Intell. Law</source><volume>30</volume><issue>3</issue><year>2022</year><fpage>359</fpage><lpage>390</lpage></element-citation></ref><ref id="bib52"><label>52</label><element-citation publication-type="journal" id="sref52"><person-group person-group-type="author"><name><surname>Shao</surname><given-names>Y.</given-names></name><name><surname>Wu</surname><given-names>Y.</given-names></name><name><surname>Liu</surname><given-names>Y.</given-names></name><name><surname>Mao</surname><given-names>J.</given-names></name><name><surname>Ma</surname><given-names>S.</given-names></name></person-group><article-title>Understanding relevance judgments in legal case retrieval</article-title><source>ACM Trans. Inf. Syst.</source><volume>41</volume><issue>3</issue><year>2023</year><fpage>1</fpage><lpage>32</lpage></element-citation></ref><ref id="bib53"><label>53</label><mixed-citation publication-type="other" id="oref53">Kenton, Jacob Devlin Ming-Wei Chang, and Lee Kristina Toutanova. "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding." In <italic>Proceedings of NAACL-HLT</italic>, 2019. pp. 4171&#x02013;4186.</mixed-citation></ref><ref id="bib54"><label>54</label><element-citation publication-type="book" id="sref54"><person-group person-group-type="author"><name><surname>Chalkidis</surname><given-names>I.</given-names></name><name><surname>Fergadiotis</surname><given-names>M.</given-names></name><name><surname>Malakasiotis</surname><given-names>P.</given-names></name><name><surname>Aletras</surname><given-names>N.</given-names></name><name><surname>Androutsopoulos</surname><given-names>I.</given-names></name></person-group><part-title>LEGAL-BERT: the Muppets Straight Out of Law School</part-title><year>2020</year><comment>arXiv preprint arXiv:2010.02559</comment></element-citation></ref><ref id="bib55"><label>55</label><element-citation publication-type="journal" id="sref55"><person-group person-group-type="author"><name><surname>Costa</surname><given-names>W.M.</given-names></name><name><surname>Pedrosa</surname><given-names>G.V.</given-names></name></person-group><article-title>Legal information retrieval based on a concept-frequency representation and thesaurus</article-title><source>ICEIS</source><volume>1</volume><year>2023</year><fpage>303</fpage><lpage>311</lpage></element-citation></ref><ref id="bib56"><label>56</label><element-citation publication-type="journal" id="sref56"><person-group person-group-type="author"><name><surname>Shao</surname><given-names>Y.</given-names></name><etal/></person-group><article-title>BERT-PLI: modeling paragraph-level interactions for legal case retrieval</article-title><source>IJCAI</source><year>2020</year><fpage>3501</fpage><lpage>3507</lpage></element-citation></ref><ref id="bib57"><label>57</label><element-citation publication-type="journal" id="sref57"><person-group person-group-type="author"><name><surname>Manikandan</surname><given-names>G.</given-names></name><name><surname>Abirami</surname><given-names>S.</given-names></name></person-group><article-title>A survey on feature selection and extraction techniques for high-dimensional microarray datasets</article-title><source>Knowledge Computing and its Applications: Knowledge Computing in Specific Domains</source><volume>II</volume><year>2018</year><fpage>311</fpage><lpage>333</lpage></element-citation></ref><ref id="bib58"><label>58</label><element-citation publication-type="book" id="sref58"><person-group person-group-type="author"><name><surname>Sil</surname><given-names>R.</given-names></name><name><surname>Saha</surname><given-names>D.</given-names></name><name><surname>Roy</surname><given-names>A.</given-names></name></person-group><part-title>A study on argument-based analysis of legal model</part-title><source>Innovations in Bio-Inspired Computing and Applications: Proceedings of the 11th International Conference on Innovations in Bio-Inspired Computing and Applications (IBICA 2020) Held during December 16-18, 2020 11</source><year>2021</year><publisher-name>Springer</publisher-name><fpage>449</fpage><lpage>457</lpage></element-citation></ref><ref id="bib59"><label>59</label><element-citation publication-type="journal" id="sref59"><person-group person-group-type="author"><name><surname>Pavlyshenko</surname><given-names>B.M.</given-names></name></person-group><article-title>Machine-learning models for sales time series forecasting</article-title><source>Data</source><volume>4</volume><issue>1</issue><year>2019</year><fpage>15</fpage></element-citation></ref><ref id="bib60"><label>60</label><element-citation publication-type="journal" id="sref60"><person-group person-group-type="author"><name><surname>Zhong</surname><given-names>H.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Tu</surname><given-names>C.</given-names></name><name><surname>Zhang</surname><given-names>T.</given-names></name><name><surname>Liu</surname><given-names>Z.</given-names></name><name><surname>Sun</surname><given-names>M.</given-names></name></person-group><article-title>Iteratively questioning and answering for interpretable legal judgment prediction</article-title><source>Proc. AAAI Conf. Artif. Intell.</source><volume>34</volume><issue>1</issue><year>2020</year><fpage>1250</fpage><lpage>1257</lpage></element-citation></ref><ref id="bib61"><label>61</label><element-citation publication-type="book" id="sref61"><person-group person-group-type="author"><name><surname>Tesar</surname><given-names>R.</given-names></name><name><surname>Strnad</surname><given-names>V.</given-names></name><name><surname>Jezek</surname><given-names>K.</given-names></name><name><surname>Poesio</surname><given-names>M.</given-names></name></person-group><part-title>Extending the single words-based document model: a comparison of bigrams and 2-itemsets</part-title><source>Proceedings of the 2006 ACM Symposium on Document Engineering</source><year>2006</year><fpage>138</fpage><lpage>146</lpage></element-citation></ref><ref id="bib62"><label>62</label><element-citation publication-type="journal" id="sref62"><person-group person-group-type="author"><name><surname>Badawi</surname><given-names>D.</given-names></name><name><surname>Alt&#x00131;n&#x000e7;ay</surname><given-names>H.</given-names></name></person-group><article-title>Termset weighting by adapting term weighting schemes to utilize cardinality statistics for binary text categorization</article-title><source>Appl. Intell.</source><volume>47</volume><issue>2</issue><year>2017</year><fpage>456</fpage><lpage>472</lpage></element-citation></ref><ref id="bib63"><label>63</label><element-citation publication-type="journal" id="sref63"><person-group person-group-type="author"><name><surname>McHugh</surname><given-names>M.L.</given-names></name></person-group><article-title>The chi-square test of independence</article-title><source>Biochem. Med.</source><volume>23</volume><issue>2</issue><year>2013</year><fpage>143</fpage><lpage>149</lpage></element-citation></ref><ref id="bib64"><label>64</label><element-citation publication-type="journal" id="sref64"><person-group person-group-type="author"><name><surname>Badawi</surname><given-names>D.</given-names></name><name><surname>Alt&#x00131;n&#x000e7;ay</surname><given-names>H.</given-names></name></person-group><article-title>A novel framework for termset selection and weighting in binary text classification</article-title><source>Eng. Appl. Artif. Intell.</source><volume>35</volume><year>2014</year><fpage>38</fpage><lpage>53</lpage></element-citation></ref><ref id="bib65"><label>65</label><element-citation publication-type="book" id="sref65"><person-group person-group-type="author"><name><surname>Sil</surname><given-names>R.</given-names></name><name><surname>Roy</surname><given-names>A.</given-names></name></person-group><part-title>A novel approach on argument based legal prediction model using machine learning</part-title><source>2020 International Conference on Smart Electronics and Communication (ICOSEC)</source><year>2020</year><publisher-name>IEEE</publisher-name><fpage>487</fpage><lpage>490</lpage></element-citation></ref><ref id="bib66"><label>66</label><element-citation publication-type="journal" id="sref66"><person-group person-group-type="author"><name><surname>Asim</surname><given-names>Y.</given-names></name><name><surname>Shahid</surname><given-names>A.R.</given-names></name><name><surname>Malik</surname><given-names>A.K.</given-names></name><name><surname>Raza</surname><given-names>B.</given-names></name></person-group><article-title>Significance of machine learning algorithms in professional blogger's classification</article-title><source>Comput. Electr. Eng.</source><volume>65</volume><year>2018</year><fpage>461</fpage><lpage>473</lpage></element-citation></ref><ref id="bib67"><label>67</label><element-citation publication-type="journal" id="sref67"><person-group person-group-type="author"><name><surname>Park</surname><given-names>E.L.</given-names></name><name><surname>Cho</surname><given-names>S.</given-names></name><name><surname>Kang</surname><given-names>P.</given-names></name></person-group><article-title>Supervised paragraph vector: distributed representations of words, documents and class labels</article-title><source>IEEE Access</source><volume>7</volume><year>2019</year><fpage>29051</fpage><lpage>29064</lpage></element-citation></ref><ref id="bib68"><label>68</label><element-citation publication-type="journal" id="sref68"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>Y.</given-names></name><name><surname>Li</surname><given-names>Y.</given-names></name><name><surname>Yue</surname><given-names>Y.</given-names></name><name><surname>Qiang</surname><given-names>J.</given-names></name><name><surname>Yuan</surname><given-names>Y.</given-names></name></person-group><article-title>A hybrid classification method via character embedding in Chinese short text with few words</article-title><source>IEEE Access</source><volume>8</volume><year>2020</year><fpage>92120</fpage><lpage>92128</lpage></element-citation></ref><ref id="bib69"><label>69</label><element-citation publication-type="book" id="sref69"><person-group person-group-type="author"><name><surname>Case</surname><given-names>J.</given-names></name><name><surname>Clements</surname><given-names>A.</given-names></name></person-group><part-title>The impact of sentiment in the news media on daily and monthly stock market returns</part-title><source>Data Mining: 19th Australasian Conference on Data Mining, AusDM 2021, Brisbane, QLD, Australia, December 14-15, 2021, Proceedings 19</source><year>2021</year><publisher-name>Springer</publisher-name><fpage>180</fpage><lpage>195</lpage></element-citation></ref><ref id="bib70"><label>70</label><element-citation publication-type="book" id="sref70"><person-group person-group-type="author"><name><surname>Srivastava</surname><given-names>S.</given-names></name><name><surname>Tiwari</surname><given-names>R.</given-names></name><name><surname>Bhardwaj</surname><given-names>R.</given-names></name><name><surname>Gupta</surname><given-names>D.</given-names></name></person-group><part-title>Stock price prediction using LSTM and news sentiment analysis</part-title><source>2022 6th International Conference on Trends in Electronics and Informatics (ICOEI)</source><year>2022</year><publisher-name>IEEE</publisher-name><fpage>1660</fpage><lpage>1663</lpage></element-citation></ref><ref id="bib71"><label>71</label><element-citation publication-type="journal" id="sref71"><person-group person-group-type="author"><name><surname>Wajid</surname><given-names>M.A.</given-names></name><name><surname>Zafar</surname><given-names>A.</given-names></name><name><surname>Wajid</surname><given-names>M.S.</given-names></name></person-group><article-title>A deep learning approach for image and text classification using neutrosophy</article-title><source>Int. J. Inf. Technol.</source><year>2023</year><fpage>1</fpage><lpage>7</lpage></element-citation></ref><ref id="bib72"><label>72</label><element-citation publication-type="journal" id="sref72"><person-group person-group-type="author"><name><surname>Hauser</surname><given-names>D.J.</given-names></name><name><surname>Schwarz</surname><given-names>N.</given-names></name></person-group><article-title>How seemingly innocuous words can bias judgment: semantic prosody and impression formation</article-title><source>J. Exp. Soc. Psychol.</source><volume>75</volume><year>2018</year><fpage>11</fpage><lpage>18</lpage></element-citation></ref><ref id="bib73"><label>73</label><element-citation publication-type="journal" id="sref73"><person-group person-group-type="author"><name><surname>Caliskan</surname><given-names>A.</given-names></name><name><surname>Bryson</surname><given-names>J.J.</given-names></name><name><surname>Narayanan</surname><given-names>A.</given-names></name></person-group><article-title>Semantics derived automatically from language corpora contain human-like biases</article-title><source>Science</source><volume>356</volume><issue>6334</issue><year>2017</year><fpage>183</fpage><lpage>186</lpage><pub-id pub-id-type="pmid">28408601</pub-id>
</element-citation></ref><ref id="bib74"><label>74</label><element-citation publication-type="book" id="sref74"><part-title>"Anderson v. Dean," in So. 3d vol. 346</part-title><source>La: Court of Appeals, 5th Circuit</source><year>2022</year><fpage>356</fpage></element-citation></ref><ref id="bib75"><label>75</label><element-citation publication-type="book" id="sref75"><part-title>Dist. Court</part-title><source>NATIONAL PRODUCTS INC. v. INNOVATIVE INTELLIGENT, PRODUCTS, LLC</source><year>2021</year><publisher-name>WD</publisher-name><publisher-loc>Washington</publisher-loc></element-citation></ref><ref id="bib76"><label>76</label><element-citation publication-type="journal" id="sref76"><article-title>"Leegin creative leather products v. PSKS, inc," in US</article-title><source>Supreme Court</source><volume>551</volume><year>2007</year><fpage>877</fpage></element-citation></ref><ref id="bib77"><label>77</label><element-citation publication-type="journal" id="sref77"><article-title>"PARENTS INV. IN COMM. SCH. v. Seattle School," in US</article-title><source>Supreme Court</source><volume>551</volume><year>2007</year><fpage>701</fpage></element-citation></ref><ref id="bib78"><label>78</label><element-citation publication-type="journal" id="sref78"><article-title>"Winkelman v. Parma city school dist," in US vol</article-title><source>Supreme Court</source><volume>550</volume><year>2007</year><fpage>516</fpage></element-citation></ref><ref id="bib79"><label>79</label><element-citation publication-type="journal" id="sref79"><article-title>"Norfolk southern ry. Co. V. Sorrell," in US vol</article-title><source>Supreme Court</source><volume>549</volume><year>2007</year><fpage>158</fpage></element-citation></ref></ref-list><ack id="ack0010"><title>Acknowledgments</title><p id="p0385">The authors acknowledge Government of China for awarding the projects of National Social Science Foundation project and National Social Science Fund major project that have funded this research. Authors are also thankful to school of law, Zhengzhou University for the opportunities provided for research.</p></ack></back></article>