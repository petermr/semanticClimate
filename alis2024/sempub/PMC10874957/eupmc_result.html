
    <!doctype html>
    <html>
      <head>
          <meta http-equiv="Content-type" content="text/html; charset=utf-8">
          <script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/2.2.2/jquery.min.js">
          </script>
          <link rel="stylesheet" type="text/css" href="https://cdn.datatables.net/1.10.16/css/jquery.dataTables.css">
          <script type="text/javascript" src="https://cdn.datatables.net/1.10.16/js/jquery.dataTables.js"></script>
          <style>
          # table {
              height: 250px;
              overflow-y:scroll;
          }
          </style>
      </head>
      <body><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>downloaded</th>
      <th>htmlmade</th>
      <th>id</th>
      <th>source</th>
      <th>pmid</th>
      <th>pmcid</th>
      <th>fullTextIdList</th>
      <th>doi</th>
      <th>title</th>
      <th>authorString</th>
      <th>authorList</th>
      <th>journalInfo</th>
      <th>pubYear</th>
      <th>pageInfo</th>
      <th>abstractText</th>
      <th>affiliation</th>
      <th>publicationStatus</th>
      <th>language</th>
      <th>pubModel</th>
      <th>pubTypeList</th>
      <th>grantsList</th>
      <th>subsetList</th>
      <th>fullTextUrlList</th>
      <th>commentCorrectionList</th>
      <th>isOpenAccess</th>
      <th>inEPMC</th>
      <th>inPMC</th>
      <th>hasPDF</th>
      <th>hasBook</th>
      <th>hasSuppl</th>
      <th>citedByCount</th>
      <th>hasData</th>
      <th>hasReferences</th>
      <th>hasTextMinedTerms</th>
      <th>hasDbCrossReferences</th>
      <th>hasLabsLinks</th>
      <th>license</th>
      <th>hasEvaluations</th>
      <th>authMan</th>
      <th>epmcAuthMan</th>
      <th>nihAuthMan</th>
      <th>hasTMAccessionNumbers</th>
      <th>dateOfCreation</th>
      <th>firstIndexDate</th>
      <th>fullTextReceivedDate</th>
      <th>dateOfRevision</th>
      <th>electronicPublicationDate</th>
      <th>firstPublicationDate</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>PMC10874957</th>
      <td>True</td>
      <td>False</td>
      <td>38369571</td>
      <td>MED</td>
      <td>38369571</td>
      <td>PMC10874957</td>
      <td>{'fullTextId': 'PMC10874957'}</td>
      <td>10.1038/s41598-024-54640-6</td>
      <td>Transductive meta-learning with enhanced feature ensemble for few-shot semantic segmentation.</td>
      <td>Karimi A, Poullis C.</td>
      <td>{'author': [{'fullName': 'Karimi A', 'firstName': 'Amin', 'lastName': 'Karimi', 'initials': 'A', 'authorAffiliationDetailsList': OrderedDict([('authorAffiliation', OrderedDict([('affiliation', 'Immersive and Creative Technologies Lab, Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada.')]))])}, {'fullName': 'Poullis C', 'firstName': 'Charalambos', 'lastName': 'Poullis', 'initials': 'C', 'authorAffiliationDetailsList': OrderedDict([('authorAffiliation', OrderedDict([('affiliation', 'Immersive and Creative Technologies Lab, Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada. charalambos@poullis.org.')]))])}]}</td>
      <td>{'issue': '1', 'volume': '14', 'journalIssueId': '3704658', 'dateOfPublication': '2024 Feb', 'monthOfPublication': '2', 'yearOfPublication': '2024', 'printPublicationDate': '2024-02-01', 'journal': {'title': 'Scientific reports', 'ISOAbbreviation': 'Sci Rep', 'medlineAbbreviation': 'Sci Rep', 'NLMid': '101563288', 'ISSN': '2045-2322', 'ESSN': '2045-2322'}}</td>
      <td>2024</td>
      <td>4028</td>
      <td>This paper addresses few-shot semantic segmentation and proposes a novel transductive end-to-end method that overcomes three key problems affecting performance. First, we present a novel ensemble of visual features learned from pretrained classification and semantic segmentation networks with the same architecture. Our approach leverages the varying discriminative power of these networks, resulting in rich and diverse visual features that are more informative than a pretrained classification backbone that is not optimized for dense pixel-wise classification tasks used in most state-of-the-art methods. Secondly, the pretrained semantic segmentation network serves as a base class extractor, which effectively mitigates false positives that occur during inference time and are caused by base objects other than the object of interest. Thirdly, a two-step segmentation approach using transductive meta-learning is presented to address the episodes with poor similarity between the support and query images. The proposed transductive meta-learning method addresses the prediction by first learning the relationship between labeled and unlabeled data points with matching support foreground to query features (intra-class similarity) and then applying this knowledge to predict on the unlabeled query image (intra-object similarity), which simultaneously learns propagation and false positive suppression. To evaluate our method, we performed experiments on benchmark datasets, and the results demonstrate significant improvement with minimal trainable parameters of 2.98M. Specifically, using Resnet-101, we achieve state-of-the-art performance for both 1-shot and 5-shot Pascal-[Formula: see text], as well as for 1-shot and 5-shot COCO-[Formula: see text].</td>
      <td>Immersive and Creative Technologies Lab, Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada.</td>
      <td>epublish</td>
      <td>eng</td>
      <td>Electronic</td>
      <td>{'pubType': ['research-article', 'Journal Article']}</td>
      <td>{'grant': {'grantId': 'RGPIN-2021-03479', 'agency': 'Natural Sciences and Engineering Research Council of Canada', 'orderIn': '0'}}</td>
      <td>{'subset': {'code': 'IM', 'name': 'Index Medicus'}}</td>
      <td>{'fullTextUrl': [{'availability': 'Subscription required', 'availabilityCode': 'S', 'documentStyle': 'doi', 'site': 'DOI', 'url': 'https://doi.org/10.1038/s41598-024-54640-6'}, {'availability': 'Open access', 'availabilityCode': 'OA', 'documentStyle': 'html', 'site': 'Europe_PMC', 'url': 'https://europepmc.org/articles/PMC10874957'}, {'availability': 'Open access', 'availabilityCode': 'OA', 'documentStyle': 'pdf', 'site': 'Europe_PMC', 'url': 'https://europepmc.org/articles/PMC10874957?pdf=render'}]}</td>
      <td>{'commentCorrection': {'id': 'PPR757288', 'source': 'PPR', 'type': 'Preprint in', 'note': 'CrossRef Pre-print loader', 'orderIn': '10002'}}</td>
      <td>Y</td>
      <td>Y</td>
      <td>N</td>
      <td>Y</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>Y</td>
      <td>Y</td>
      <td>Y</td>
      <td>N</td>
      <td>N</td>
      <td>cc by</td>
      <td>N</td>
      <td>N</td>
      <td>N</td>
      <td>N</td>
      <td>N</td>
      <td>2024-02-18</td>
      <td>2024-02-19</td>
      <td>2024-02-23</td>
      <td>2024-02-21</td>
      <td>2024-02-18</td>
      <td>2024-02-18</td>
    </tr>
  </tbody>
</table><script type="text/javascript">$(document).ready(function(){$('table').DataTable({
      "pageLength": 20
      });});</script>
      </body>
    </html>
    