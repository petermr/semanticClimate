<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd"> 
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 1?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">BioData Min</journal-id><journal-id journal-id-type="iso-abbrev">BioData Min</journal-id><journal-title-group><journal-title>BioData Mining</journal-title></journal-title-group><issn pub-type="epub">1756-0381</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmcid">11184879</article-id><article-id pub-id-type="publisher-id">371</article-id><article-id pub-id-type="doi">10.1186/s13040-024-00371-3</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research</subject></subj-group></article-categories><title-group><article-title>Using GPT-4 to write a scientific review article: a pilot evaluation study</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Zhiping Paul</given-names></name><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author"><name><surname>Bhandary</surname><given-names>Priyanka</given-names></name><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Yizhou</given-names></name><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Moore</surname><given-names>Jason H.</given-names></name><address><email>jason.moore@csmc.edu</email></address><xref ref-type="aff" rid="Aff1"/></contrib><aff id="Aff1"><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02pammg90</institution-id><institution-id institution-id-type="GRID">grid.50956.3f</institution-id><institution-id institution-id-type="ISNI">0000 0001 2152 9905</institution-id><institution>Department of Computational Biomedicine, </institution><institution>Cedars Sinai Medical Center, </institution></institution-wrap>700 N. San Vicente Blvd, Pacific Design Center, Suite G-541, West Hollywood, CA 90069 USA </aff></contrib-group><pub-date pub-type="epub"><day>18</day><month>6</month><year>2024</year></pub-date><pub-date pub-type="pmc-release"><day>18</day><month>6</month><year>2024</year></pub-date><pub-date pub-type="collection"><year>2024</year></pub-date><volume>17</volume><elocation-id>16</elocation-id><history><date date-type="received"><day>26</day><month>4</month><year>2024</year></date><date date-type="accepted"><day>11</day><month>6</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2024</copyright-statement><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article&#x02019;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#x02019;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">GPT-4, as the most advanced version of OpenAI&#x02019;s large language models, has attracted widespread attention, rapidly becoming an indispensable AI tool across various areas. This includes its exploration by scientists for diverse applications. Our study focused on assessing GPT-4&#x02019;s capabilities in generating text, tables, and diagrams for biomedical review papers. We also assessed the consistency in text generation by GPT-4, along with potential plagiarism issues when employing this model for the composition of scientific review papers. Based on the results, we suggest the development of enhanced functionalities in ChatGPT, aiming to meet the needs of the scientific community more effectively. This includes enhancements in uploaded document processing for reference materials, a deeper grasp of intricate biomedical concepts, more precise and efficient information distillation for table generation, and a further refined model specifically tailored for scientific diagram creation.</p></abstract><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; BioMed Central Ltd., part of Springer Nature 2024</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1" sec-type="introduction"><title>Introduction</title><p id="Par2">A comprehensive review of a research field can significantly aid researchers in quickly grasping the nuances of a specific domain, leading to well-informed research strategies, efficient resource utilization, and enhanced productivity. However, the process of writing such reviews is intricate, involving multiple time-intensive steps. These include the collection of relevant papers and materials, the distillation of key points from potentially hundreds or even thousands of sources into a cohesive overview, the synthesis of this information into a meaningful and impactful knowledge framework, and the illumination of potential future research directions within the domain. Given the breadth and depth of biomedical research&#x02014;one of the most expansive and dynamic fields&#x02014;crafting a literature review in this area can be particularly challenging and time-consuming, often requiring months of dedicated effort from domain experts to sift through the extensive body of work and produce a valuable review paper [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>].</p><p id="Par3">The swift progress in Natural Language Processing (NLP) technology, particularly with the rise of Generative Pre-trained Transformers (GPT) and other Large Language Models (LLMs), has equipped researchers with a potent tool for swiftly processing extensive literature. A recent survey indicates that ChatGPT has become an asset for researchers across various fields [<xref ref-type="bibr" rid="CR3">3</xref>]. For instance, a PubMed search for &#x0201c;ChatGPT&#x0201d; yielded over 1,400 articles with ChatGPT in their titles as of November 30th, 2023, marking a significant uptake just one year after ChatGPT&#x02019;s introduction.</p><p id="Par4">The exploration of NLP technology&#x02019;s capability to synthesize scientific publications into comprehensive reviews is ongoing. The interest in ChatGPT&#x02019;s application across scientific domains is evident. Studies have evaluated ChatGPT&#x02019;s potential in clinical and academic writing [<xref ref-type="bibr" rid="CR3">3</xref>&#x02013;<xref ref-type="bibr" rid="CR10">10</xref>], and discussions are underway about its use as a scientific review article generator [<xref ref-type="bibr" rid="CR11">11</xref>&#x02013;<xref ref-type="bibr" rid="CR13">13</xref>]. However, many of these studies predate the release of the more advanced GPT-4, which may render their findings outdated. In addition, there is no study specifically evaluating ChatGPT (GPT-4) for writing biomedical review papers.</p><p id="Par5">As the applications of ChatGPT are explored, the scientific community is also examining the evolving role of AI in research. Unlike any tool previously utilized in the history of science, ChatGPT has been accorded a role akin to that of a scientist, even being credited as an author in scholarly articles [<xref ref-type="bibr" rid="CR14">14</xref>]. This development has sparked ethical debates. While thorough evaluations of the quality of AI-generated scientific review articles are yet to be conducted, some AI tools, such as Scopus AI [<xref ref-type="bibr" rid="CR15">15</xref>], are already being employed to summarize and synthesize knowledge from scientific literature databases. However, these tools often come with disclaimers cautioning users about the possibility of AI generating erroneous or offensive content. Concurrently, as ChatGPT&#x02019;s potential contributions to science are probed, concerns about the possible detrimental effects of ChatGPT and other AI tools on scientific integrity have been raised [<xref ref-type="bibr" rid="CR16">16</xref>]. These considerations highlight the necessity for more comprehensive evaluations of ChatGPT from various perspectives.</p><p id="Par6">In this study, we hypothesized that ChatGPT can compose text, tables and figures for a biomedical research paper using two cancer research papers as benchmarks. To test this hypothesis, we used the first paper [<xref ref-type="bibr" rid="CR17">17</xref>] to prompt ChatGPT to generate the main ideas and summarize text. Next, we used the second paper [<xref ref-type="bibr" rid="CR18">18</xref>] to assess its ability to create tables and figures/graphs. We simulated the steps a scientist would take in writing a cancer research review and assessed GPT-4&#x02019;s performance at each stage. Our findings are presented across four dimensions: the ability to summarize insights from reference papers on specific topics, the semantic similarity of GPT-4 generated text to benchmark texts, the projection of future research directions based on current publications, and the synthesis of context in the form of tables and graphs. We conclude with a discussion of our overall experience and the insights gained from this study.</p></sec><sec id="Sec2"><title>Methods</title><sec id="Sec3"><title>Review text content generation by ChatGPT</title><p id="Par7">The design of this study aims to replicate the process a scientist undergoes when composing a biomedical review paper. This involves the meticulous collection, examination, and organization of pertinent references, followed by the articulation of key topics of interest into a structured format of sections, subsections, and main points. The scientist then synthesizes information from the relevant references to develop a comprehensive narrative. A primary objective of this study is to assess ChatGPT&#x02019;s proficiency in distilling insights from references into coherent text. To this end, a review paper on sex differences in cancer [<xref ref-type="bibr" rid="CR17">17</xref>] was chosen as a benchmark, referred to as BRP1 (Benchmark Review Paper 1). Using BRP1 for comparison, ChatGPT&#x02019;s content generation was evaluated across three dimensions: (1) summarization of main points; (2) generation of review content for each main point; and (3) synthesis of information from references to project future research directions.</p><sec id="Sec4"><title>Main point summarization</title><p id="Par8">The effectiveness of GPT-4 in summarizing information was tested by providing it with the 113 reference articles from BRP1 to generate a list of potential sections for a review paper. The generated sections were then compared with BRP1&#x02019;s actual section titles for coverage evaluation (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>(A)). Additionally, GPT-4 was tasked with creating possible subsections using the BRP1 section titles and reference articles, which were compared with the actual subsection titles in BRP1.</p></sec></sec><sec id="Sec5"><title>Review content generation</title><p id="Par9">The review content generation test involved comparing GPT-4&#x02019;s ability to summarize a given point with the actual text content from BRP1 (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>(B)). BRP1 comprises three sections with seven subsections, presenting a total of eight main points. The corresponding text content for each point was manually extracted from BRP1. Three strategies were employed for GPT-4 to generate detailed elaborations for these main points: (1) providing a point only in a prompt for baseline content generation; (2) feeding all references used by BRP1 to GPT-4 for reference-based content generation; (3) using only the references corresponding to a main point, i.e., articles being referred in a subsection of BRP1, for content generation to make a main point. The semantic similarity of the text content generated by these strategies was then compared with the manually extracted content from BRP1.</p><p id="Par10">
<fig id="Fig1"><label>Fig. 1</label><caption><p>(<bold>A</bold>) GPT-4 summarizes sections and subsections; (<bold>B</bold>) GPT-4 generated review content evaluation</p></caption><graphic xlink:href="13040_2024_371_Fig1_HTML" id="d33e234"/></fig>
</p></sec><sec id="Sec6"><title>Projections on future research</title><p id="Par11">The section on &#x0201c;outstanding questions&#x0201d; in the Concluding Remarks of BRP1 serves a dual purpose: it summarizes conclusions and sets a trajectory for future research into sex differences in cancer. This is a common feature in biomedical review papers, where a forward-looking analysis is synthesized from the main discussions within the paper. The pivotal inquiry is whether ChatGPT, without further refinement, can emulate this forward projection using all referenced articles. The relevance of such a projection is contingent upon its alignment with the main points and references of the review. Moreover, it raises the question of whether the baseline GPT-4 LLM would perform comparably.</p><p id="Par12">To address these queries, all references from BRP1 were inputted into GPT-4 to generate a section akin to Concluding Remarks, encompassing a description of sex differences in cancer, future work, and potential research trajectories. Additionally, three distinct strategies were employed to assess GPT-4&#x02019;s ability to formulate specific &#x0201c;outstanding questions,&#x0201d; thereby evaluating ChatGPT&#x02019;s predictive capabilities for future research. These strategies involved uploading all BRP1 reference articles to GPT-4 for projection: (1) without any contextual information; (2) with the inclusion of BRP1&#x02019;s main points; (3) with a brief description of broad areas of interest. The outputs from these strategies, along with the base model&#x02019;s output&#x02014;GPT-4 without reference articles&#x02014;were juxtaposed with BRP1&#x02019;s original &#x0201c;outstanding questions&#x0201d; for comparison.</p></sec><sec id="Sec7"><title>Data process</title><sec id="Sec8"><title>ChatGPT query</title><p id="Par13">In initiating this study, we utilized the ChatGPT web application (<ext-link ext-link-type="uri" xlink:href="https://chat.openai.com/">https://chat.openai.com/</ext-link>). However, we encountered several limitations that impeded our progress:</p><p id="Par14">
<list list-type="order"><list-item><p id="Par15">A cap of ten file uploads, which restricts the analysis of content synthesized from over ten articles.</p></list-item><list-item><p id="Par16">A file size limit of 50&#x000a0;MB, hindering the consolidation of multiple articles into a single file to circumvent the upload constraint.</p></list-item><list-item><p id="Par17">Inconsistencies in text file interpretation when converted from PDF format, rendering the conversion of large PDFs to smaller text files ineffective.</p></list-item><list-item><p id="Par18">Anomalies in file scanning, where ChatGPT would occasionally process only one of several uploaded files, despite instructions to utilize all provided files.</p></list-item></list>
</p><p id="Par19">Due to these constraints, we transitioned to using GPT-4 API calls for all tests involving document processing. The GPT-4 API accommodates up to twenty file uploads simultaneously, efficiently processes text files converted from PDFs, and demonstrates reliable file scanning for multiple documents. The Python code, ChatGPT prompts, and outputs pertinent to this study are available in the supplementary materials.</p><p id="Par20">The web version of ChatGPT cannot read from all the PDFs uploaded and is able to process only a subset of them. However, the API version of ChatGPT was set up to be able to upload and process 20 PDFs at a time. Several validation tests were carried out to make sure that it is able to read from all of them equally well. One common validation test was to ask ChatGPT if it could reiterate the <xref rid="Sec2" ref-type="sec">Methods</xref> section of the 18th PDF and so on. This test was carried out randomly multiple times with a different PDF each time to see if ChatGPT is truly able to upload and process the PDFs.</p></sec><sec id="Sec9"><title>Text similarity comparison</title><p id="Par21">To assess text content similarity, we employed a transformer network-based pre-trained model [<xref ref-type="bibr" rid="CR19">19</xref>] to calculate the semantic similarity between the original text in BRP1 and the text generated by GPT-4. We utilized the <italic>util.pytorch_cos_sim</italic> function from the <italic>sentence_transformers</italic> package to compute the cosine similarity of semantic content. Additionally, we conducted a manual validation where one of the authors compared the two texts and then categorized the similarity between the GPT-4 generated content and the original BRP1 content into three distinct levels: semantically very similar (Y), partially similar (P), and not similar (N).</p></sec></sec><sec id="Sec10"><title>Reproducibility and plagiarism evaluation</title><p id="Par22">The inherent randomness in ChatGPT&#x02019;s output, attributable to the probabilistic nature of large language models (LLMs), necessitates the validation of reproducibility for results derived from ChatGPT outputs. To obtain relatively consistent responses from ChatGPT, it is advantageous to provide detailed context within the prompt, thereby guiding the model towards the desired response. Consequently, we replicated two review content generation tests, as depicted in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>(B)&#x02014;one based on point references and the other on the GPT-4 base model&#x02014;one week apart using identical reference articles and prompts via API calls to GPT-4. The first test aimed to evaluate the consistency of file-based content generation by GPT-4, while the second assessed the base model. We compared the outputs from the subsequent run with those from the initial run to determine the reproducibility of the text content generated by ChatGPT.</p><p id="Par23">Prior to considering the utilization of ChatGPT for generating content suitable for publication in a review paper, it is critical to address potential plagiarism concerns. The pivotal question is whether text produced by GPT-4 would be flagged as plagiarized by anti-plagiarism software. In this study, GPT-4 generated a substantial volume of text, particularly for the text content comparison test (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>(B)). We subjected both the base model-generated review content and the reference-based GPT-4 review content to scrutiny using iThenticate to ascertain the presence of plagiarism.</p></sec><sec id="Sec11"><title>Table and figure generation by ChatGPT</title><p id="Par24">Review papers often distill the content from references into tables and further synthesize this information into figures. In this study, we evaluated ChatGPT&#x02019;s proficiency in generating content in tabular and diagrammatic formats, using benchmark review paper 2 (BRP2) [<xref ref-type="bibr" rid="CR18">18</xref>] as a reference, as illustrated in Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>. The authors of BRP2 developed the seminal Cancer-Immunity Cycle concept, encapsulated in a cycle diagram, which has since become a structural foundational for research in cancer immunotherapy.</p><sec id="Sec12"><title>Table content generation</title><p id="Par25">Analogous to the file scan anomaly, ChatGPT may disproportionately prioritize one task over others when presented with multiple tasks simultaneously. To mitigate this in the table generation test, we adopted a divide-and-conquer approach, submitting separate GPT-4 prompts to generate content for each column of the table. This strategy facilitated the straightforward assembly of the individual outputs into a comprehensive table, either through GPT-4 or manual compilation.</p><p id="Par26">In BRP2, eleven reference articles were utilized to construct a table (specifically, Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref> of BRP2) that categorized positive and negative regulators at each stage of the Cancer-Immunity Cycle. These articles were compiled and inputted into ChatGPT, prompting GPT-4 to summarize information for corresponding table columns: Steps, Stimulators, Inhibitors, Other Considerations, and Example References. The content for each column was generated through separate GPT-4 API calls and subsequently compared manually with the content in the original BRP2 table. The semantic similarity and manual validations were carried out for each row of the Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref> from BRP2. With the API version, we uploaded the references cited within the corresponding row in the table and used that to generate the contents of the row.</p></sec><sec id="Sec13"><title>Diagram creation</title><p id="Par27">ChatGPT is primarily designed for text handling, yet its capabilities in graph generation are increasingly being explored [<xref ref-type="bibr" rid="CR20">20</xref>]. DALL-E, the model utilized by ChatGPT for diagram creation, has been trained on a diverse array of images, encompassing various subjects, styles, contexts, and including scientific and technical imagery. To direct ChatGPT towards producing a diagram that closely aligns with the intended visualization, a precise and succinct description of the diagram is essential. Like the approach for table generation, multiple prompts may be required to facilitate incremental revisions in the drawing process.</p><p id="Par28">In this evaluation, we implemented three distinct strategies for diagram generation, as demonstrated in Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>. Initially, the 11 reference articles used for table generation were also employed by GPT-4 to generate a description for the cancer immunity cycle, followed by the creation of a diagrammatic representation of the cycle by GPT-4. This approach not only tested the information synthesis capability of GPT-4 but also its diagram drawing proficiency. Secondly, we extracted the paragraph under the section titled &#x02018;The Cancer-Immunity Cycle&#x02019; from BRP2 to serve as the diagram description. Terms indicative of a cyclical structure, such as &#x02018;cycle&#x02019; and &#x02018;step 1 again,&#x02019; were omitted from the description prior to its use as a prompt for diagram drawing. This tested GPT-4&#x02019;s ability to synthesize the provided information into an innovative cyclical structure for cancer immunotherapy. Lastly, the GPT-4 base model was tasked with generating a cancer immunity mechanism and its diagrammatic representation without any given context. The diagrams produced through these three strategies were scrutinized and compared with the original cancer immunity cycle figure in BRP2 to assess the scientific diagram drawing capabilities of GPT-4.</p><p id="Par29">
<fig id="Fig2"><label>Fig. 2</label><caption><p>GPT-4 table generation and figure creation</p></caption><graphic xlink:href="13040_2024_371_Fig2_HTML" id="d33e350"/></fig>
</p></sec></sec></sec><sec id="Sec14"><title>Results and discussions</title><sec id="Sec15"><title>Review content generation</title><sec id="Sec16"><title>Main point summary</title><p id="Par30">As depicted in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>A, GPT-4 generated nine potential sections for a proposed paper entitled &#x02018;The Spectrum of Sex Differences in Cancer,&#x02019; utilizing the 113 reference articles uploaded, which encompassed all three sections in BRP1. Upon request to generate possible subsections using BRP1 section titles and references, GPT-4 produced four subsections for each section, totaling twelve subsections that encompassed all seven subsections in BRP1. Detailed information regarding GPT-4 prompts, outputs, and comparisons with BRP1 section and subsection titles is provided in the supplementary materials.</p><p id="Par31">The results suggest that ChatGPT can effectively summarize the key points from a comprehensive list of documents, which is particularly beneficial when composing a review paper that references hundreds of articles. With ChatGPT&#x02019;s assistance, authors can swiftly summarize a list of main topics for further refinement, organization, and editing. Once the topics are finalized, GPT-4 can easily summarize different aspects for each topic, aiding authors in organizing the subsections. This indicates a novel approach to review paper composition that could be more efficient and productive than traditional methods. It represents a collaborative effort between ChatGPT and the review writer, with ChatGPT sorting and summarizing articles, and the author conducting high-level and creative analysis and editing.</p><p id="Par32">During this evaluation, one limitation of GPT-4 was identified: its inability to provide an accurate list of articles referenced for point generation. This presents a challenge in developing an automated pipeline that enables both information summarization and file classification.</p></sec><sec id="Sec17"><title>Review content generation</title><p id="Par33">Figure&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref> illustrates a sample of the text content generation, including the original BRP1 text, the prompt, and ChatGPT&#x02019;s output. The evaluation results for GPT-4&#x02019;s review content generation are presented in Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref> (refer to Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>B). When generating review content using corresponding references as in BRP1, GPT-4 achieved an average similarity score of 0.748 with the original content in BRP1 across all main points. Manual similarity validation confirmed that GPT-4 generated content that was semantically similar for all 8 points, with 6 points matching very well (Y) and 2 points matching partially (P). When utilizing all reference articles for GPT-4 to generate review content for a point, the mean similarity score was slightly lower at 0.699, with a manual validation result of 5Y3P. The results from the GPT-4 based model were comparable to the corresponding reference-based results, with a mean similarity score of 0.755 and a 6Y2P manual validation outcome.</p><p id="Par34">
<fig id="Fig3"><label>Fig. 3</label><caption><p>Text generation using GPT4 with specific references (<bold>A</bold>) Original section in BRP1 (<bold>B</bold>) Prompt for same section (<bold>C</bold>) Response from GPT4</p></caption><graphic xlink:href="13040_2024_371_Fig3_HTML" id="d33e398"/></fig>
</p><p id="Par35">
<table-wrap id="Tab1"><label>Table 1</label><caption><p>evaluation of GPT-4 generated content by comparing with the corresponding text from the original review paper (BRP1)</p></caption><graphic position="anchor" xlink:href="13040_2024_371_Tab1_HTML" id="d33e408"/></table-wrap>
</p><p id="Par36">As the GPT-4 base model has been trained on an extensive corpus of scientific literature, including journals and articles that explore sex differences in cancer, it is plausible for it to generate text content similar to the original review paper, even for a defined point without any contextual input. The performance when using corresponding references is notably better than when using all references, suggesting that GPT-4 processes information more effectively with relevant and less noisy input.</p><p id="Par37">The similarity score represents only the level of semantic similarity between the GPT-4 output and the original review paper text. It should not be construed as a measure of the quality of the text content generated by GPT-4. While it is relatively straightforward to assess the relevance of content for a point, gauging comprehensiveness is nearly impossible without a gold standard. However, scientific review papers are often required in research areas where such standards do not yet exist. Consequently, this review content similarity test merely indicates whether GPT-4 can produce text content that is semantically akin to that of a human scholar. Based on the results presented in Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>, GPT-4 has demonstrated adequate capability in this regard.</p></sec><sec id="Sec18"><title>Projection</title><p id="Par38">In this evaluation, GPT-4 initially synthesized content analogous to the <italic>Concluding Remarks</italic> section of BRP1 by utilizing all reference articles, further assessing its capability to integrate information into coherent conclusions. Subsequently, GPT-4 projected future research directions using three distinct methodologies. The findings, as detailed in Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>, reveal that GPT-4&#x02019;s content generation performance significantly increased from 0.45 to 0.71 upon the integration of all pertinent references, indicating that the provision of relevant information markedly enhances the model&#x02019;s guidance. Consequently, although GPT-4 may face challenges in precisely replicating future research due to thematic discrepancies, equipping it with a distinct theme can empower it to produce content that more accurately represents the intended research trajectory. In contrast, the performance of the GPT-4 base model remained comparably stable, regardless of additional contextual cues. Manual verification confirmed GPT-4&#x02019;s ability to synthesize information from the provided documents and to make reasonably accurate predictions about future research trajectories.</p><p id="Par39">
<table-wrap id="Tab2"><label>Table 2</label><caption><p>GPT-4 projection performance</p></caption><graphic position="anchor" xlink:href="13040_2024_371_Tab2_HTML" id="d33e435"/></table-wrap>
</p></sec></sec><sec id="Sec19"><title>Reproducibility</title><p id="Par40">The comparative analysis of GPT-4 outputs from different runs is presented in Table&#x000a0;<xref rid="Tab3" ref-type="table">3</xref>. Based on previous similarity assessments, a similarity score of 0.7 is generally indicative of a strong semantic correlation in the context of this review paper. In this instance, GPT-4 outputs using corresponding references exhibited an average similarity score of 0.8 between two runs, while the base model scored 0.9. A manual review confirmed that both outputs expressed the same semantic meaning at different times. Consequently, it can be concluded that GPT-4 consistently generates uniform text responses when provided with identical prompts and reference materials.</p><p id="Par41">
<table-wrap id="Tab3"><label>Table 3</label><caption><p>GPT-4 text content reproducibility evaluation</p></caption><graphic position="anchor" xlink:href="13040_2024_371_Tab3_HTML" id="d33e452"/></table-wrap>
</p><p id="Par42">An intriguing observation is that the GPT-4 base model appears to be more stable than when utilizing uploaded documents. This may suggest limitations in GPT-4&#x02019;s ability to process external documents, particularly those that are unstructured or highly specialized in scientific content. This limitation aligns with our previous observation regarding GPT-4&#x02019;s deficiency in cataloging citations within its content summaries.</p></sec><sec id="Sec20"><title>Plagiarism check</title><p id="Par43">The plagiarism assessment conducted via iThenticate (<ext-link ext-link-type="uri" xlink:href="https://www.ithenticate.com/">https://www.ithenticate.com/</ext-link>) yielded a percentage score of 34% for reference-based GPT-4 content generation and 10% for the base model. Of these percentages, only 2% and 3%, respectively, were attributed to matches with the original review paper (BRP1), predominantly due to title similarities, as we maintained the same section and subsection titles. A score of 34% is typically indicative of significant plagiarism concerns, whereas 10% is considered minimal. These results demonstrate the GPT-4 base model&#x02019;s capacity to expound upon designated points in a novel manner, minimally influenced by the original paper. However, the reference-based content generation raised concerns due to a couple of instances of &#x02018;copy-paste&#x02019; style matches from two paragraphs in BRP1 references [<xref ref-type="bibr" rid="CR21">21</xref>, <xref ref-type="bibr" rid="CR22">22</xref>], which contributed to the elevated 34% score. In summary, while the overall content generated by ChatGPT appears to be novel, the occurrence of sporadic close matches warrants scrutiny.</p><p id="Par44">This finding aligns with the theoretical low risk of direct plagiarism by ChatGPT, as AI-generated text responses are based on learned patterns and information, rather than direct &#x02018;copy-paste&#x02019; from specific sources. Nonetheless, the potential for plagiarism and related academic integrity issues are of serious concern in academia. Researchers have been exploring appropriate methods to disclose ChatGPT&#x02019;s contributions in publications and strategies to detect AI-generated content [<xref ref-type="bibr" rid="CR23">23</xref>&#x02013;<xref ref-type="bibr" rid="CR25">25</xref>].</p></sec><sec id="Sec21"><title>Table content generation</title><p id="Par45">Table construction in scientific publications often necessitates a more succinct representation of relationships and key terms compared to text content summarization and synthesis. This requires ChatGPT to extract information with greater precision. For the five columns of information compiled by GPT-4 for Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref> in BRP2, the <italic>Steps</italic> column is akin to summarizing section and subsection titles in BRP1. &#x02018;<italic>Stimulators&#x02019;</italic> and &#x02018;<italic>Inhibitors&#x02019;</italic> involve listing immune regulation factors, demanding more concise and precise information extraction. &#x02018;<italic>Other Considerations</italic>&#x02019; encompasses additional relevant information, while &#x02018;<italic>Example References</italic>&#x02019; lists citations.</p><p id="Par46">For the <italic>Steps</italic> column, GPT-4 partially succeeded but struggled to accurately summarize information into numbered steps. For the remaining columns, GPT-4 was unable to extract the corresponding information accurately. Extracting concise and precise information from uploaded documents for specific scientific categories remains a significant challenge for GPT-4, which also lacks the ability to provide reference citations, as observed in previous tests. All results, including GPT prompts, outputs, and evaluations, are detailed in the supplementary materials.</p><p id="Par47">In summary, GPT-4 has not yet achieved the capability to generate table content with the necessary conciseness and accuracy for information summary and synthesis.</p></sec><sec id="Sec22"><title>Figure creation</title><p id="Par48">In the diagram drawing test, we removed all terms indicative of a cyclical graph from the diagram description in the prompt to evaluate whether GPT-4 could independently recreate the original, pioneering depiction of the cancer immune system cycle. We employed three strategies for diagram generation, as depicted in Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>, which included: (1) using a diagram description generated from references and incorporated into the drawing prompt; (2) using the description from BRP2; (3) relying on the GPT-4 base model. The resulting diagrams produced by GPT-4 are presented in Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>, with detailed information provided in the supplementary materials.</p><p id="Par49">
<fig id="Fig4"><label>Fig. 4</label><caption><p>(<bold>A</bold>) Original figure (<bold>B</bold>) reference description (<bold>C</bold>) BRP2 description (<bold>D</bold>) base model</p></caption><graphic xlink:href="13040_2024_371_Fig4_HTML" id="d33e539"/></fig>
</p><p id="Par50">These diagrams highlight common inaccuracies in GPT-4&#x02019;s drawings, such as misspelled words, omitted numbers, and a lack of visual clarity due to superfluous icons and cluttered labeling. Despite these issues, GPT-4 demonstrated remarkable proficiency in constructing an accurate cycle architecture, even without explicit instructions to do so.</p><p id="Par51">In conclusion, while GPT-4 can serve as a valuable tool for conceptualizing diagrams for various biomedical reactions, mechanisms, or systems, professional graph drawing tools are essential for the actual creation of diagrams.</p></sec></sec><sec id="Sec23" sec-type="conclusion"><title>Conclusions</title><p id="Par52">In this study, we evaluated the capabilities of the language model GPT-4 within ChatGPT for composing a biomedical review article. We focused on four key areas: (1) summarizing insights from reference papers; (2) generating text content based on these insights; (3) suggesting avenues for future research; and (4) creating tables and graphs. GPT-4 exhibited commendable performance in the first three tasks but was unable to fulfill the fourth.</p><p id="Par53">ChatGPT&#x02019;s design is centered around text generation, with its language model finely tuned for this purpose through extensive training on a wide array of sources, including scientific literature. Consequently, GPT-4&#x02019;s proficiency in text summarization and synthesis is anticipated. When specifically comparing the API GPT model performance on a section providing specific references (references only limited to that section) and all references from the entire paper, the model does better when it is given specific references because providing all references could bring in a lot of noise. One more thing to note is that the prompt specifically mentions not to use external knowledge and hence it must process over a hundred publications and discover relevant information for the section and then compose a reply. This could explain why giving specific references improves performance over giving all references. Remarkably, the GPT-4 base model&#x02019;s performance is on par with, or in some cases, slightly surpasses that of reference-based text content generation, owing to its training on a diverse collection of research articles and web text. Hence, when given a prompt and some basic points, it performs well since it already possesses all the information needed to generate an appropriate response. Furthermore, reproducibility tests have demonstrated GPT-4&#x02019;s ability to generate consistent text content, whether utilizing references or solely relying on its base model.</p><p id="Par54">In addition, we assessed GPT-4&#x02019;s proficiency in extracting precise and pertinent information for the construction of research-related tables. GPT-4 encountered difficulties with this task, indicating that ChatGPT&#x02019;s language model requires additional training to enhance its ability to discern and comprehend specialized scientific terminology from literature. This improvement necessitates addressing complex scientific concepts and integrating knowledge across various disciplines.</p><p id="Par55">Moreover, GPT-4&#x02019;s capability to produce scientific diagrams does not meet the standards required for publication. This shortfall may stem from its associated image generation module, DALL-E, being trained on a broad spectrum of images that encompass both scientific and general content. However, with ongoing updates and targeted retraining to include a greater volume of scientific imagery, the prospect of a more sophisticated language model with improved diagrammatic capabilities could be a foreseeable advancement.</p><p id="Par56">To advance the assessment of ChatGPT&#x02019;s utility in publishing biomedical review articles, we executed a plagiarism analysis on the text generated by GPT-4. This analysis revealed potential issues when references were employed, with GPT-4 occasionally producing outputs that closely resemble content from reference articles. Although GPT-4 predominantly generates original text, we advise conducting a plagiarism check on ChatGPT&#x02019;s output before any formal dissemination. Moreover, despite the possibility that the original review paper BRP1 was part of GPT-4&#x02019;s training dataset, the plagiarism evaluation suggests that the output does not unduly prioritize it, considering the extensive data corpus used for training the language model.</p><p id="Par57">Our study also highlights the robust performance of the GPT-4 base model, which shows adeptness even without specific reference articles. This observation leads to the conjecture that incorporating the entirety of scientific literature into the training of a future ChatGPT language model could facilitate the on-demand extraction of review materials. Thus, it posits the potential for ChatGPT to eventually author comprehensive summary and synthesis-based scientific review articles. ChatGPT did not offer any citations for the PDFs that were provided to it at the time this work was written. Therefore, it is advised in such a situation to go section by section, supply a single paper, and obtain a summary of that publication alone so that the user can write a few phrases for that portion and properly credit the paper. On the other hand, the user can supply all articles for commonly recognized knowledge to produce a well-rounded set of statements that require a set of citations.</p><p id="Par58">ChatGPT&#x02019;s power and versatility warrant additional exploration of various facets. While these are beyond the scope of the current paper, we will highlight selected topics that are instrumental in fostering a more science oriented ChatGPT environment. Holistically speaking, to thoroughly assess ChatGPT&#x02019;s proficiency in generating biomedical review papers, it is imperative to include a diverse range of review paper types in the evaluation process. For instance, ChatGPT is already equipped to devise data analysis strategies and perform data science tasks in real-time. This capability suggests potential for generating review papers that include performance comparisons and benchmarks of computational tools. However, this extends beyond the scope of our pilot study, which serves as a foundational step toward more extensive research endeavors.</p><p id="Par59">Ideally, ChatGPT would conduct essential statistical analyses of uploaded documents, such as ranking insights, categorizing documents per insight, and assigning relevance weights to each document. This functionality would enable scientists to quickly synthesize the progression and extensively studied areas within a field. When it comes to mitigating hallucination, employing uploaded documents as reference material can reduce the occurrence of generating inaccurate or &#x02018;hallucinated&#x02019; content. However, when queries exceed the scope of these documents, ChatGPT may still integrate its intrinsic knowledge base. In such cases, verifying ChatGPT&#x02019;s responses against the documents&#x02019; content is vital. A feasible method is to cross-reference responses with the documents, although this may require significant manual effort. Alternatively, requesting ChatGPT to annotate its output with corresponding references from the documents could be explored, despite being a current limitation of GPT-4.</p><p id="Par60">To address academic integrity concerns, as the development of LLMs progresses towards features that could potentially expedite or even automate the creation of scientific review papers, the establishment of a widely accepted ethical practice guide becomes paramount. Until such guidelines are in place, it remains essential to conduct plagiarism checks on AI-generated content and transparently disclose the extent of AI&#x02019;s contribution to the published work. The advent of large language models like Google&#x02019;s Gemini AI [<xref ref-type="bibr" rid="CR26">26</xref>] and Perplexity.ai has showcased NLP capabilities comparable to those of GPT-4. This, coupled with the emergence of specialized models such as BioBert [<xref ref-type="bibr" rid="CR27">27</xref>], BioBART [<xref ref-type="bibr" rid="CR28">28</xref>], and BioGPT [<xref ref-type="bibr" rid="CR29">29</xref>] for biomedical applications, highlights the imperative for in-depth comparative studies. These assessments are vital for identifying the optimal AI tool for particular tasks, taking into account aspects such as multimodal functionalities, domain-specific precision, and ethical considerations. Conducting such comparative analyses will not only aid users in making informed choices but also promote the ethical and efficacious application of these sophisticated AI technologies across diverse sectors, including healthcare and education.</p></sec></body><back><fn-group><fn><p><bold>Publisher&#x02019;s Note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><notes notes-type="author-contribution"><title>Author contributions</title><p>Z. Wang authored the main manuscript text, while P. Bhandary conducted most of the tests and collected the results. Y. Wang and J. Moore contributed scientific suggestions and collaborated on the project. All authors reviewed the manuscript.</p></notes><notes notes-type="funding-information"><title>Funding</title><p>This research received no specific grant from any funding agency.</p></notes><notes notes-type="data-availability"><title>Data availability</title><p>All source codes, GPT4 generated contents and results are available at the GitHub repository.</p></notes><notes><title>Declarations</title><notes id="FPar2"><title>Supplements</title><p id="Par66">All supplementary materials are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/EpistasisLab/GPT4_and_Review">https://github.com/EpistasisLab/GPT4_and_Review</ext-link>.</p></notes><notes id="FPar1" notes-type="COI-statement"><title>Competing interests</title><p id="Par65">The authors declare no competing interests.</p></notes></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dhillon</surname><given-names>P</given-names></name></person-group><article-title>How to write a good scientific review article</article-title><source>FEBS J</source><year>2022</year><volume>289</volume><fpage>3592</fpage><lpage>602</lpage><pub-id pub-id-type="doi">10.1111/febs.16565</pub-id><?supplied-pmid 35792782?><pub-id pub-id-type="pmid">35792782</pub-id>
</element-citation></ref><ref id="CR2"><label>2.</label><mixed-citation publication-type="other">Health sciences added to the Nature Index. | News | Nature Index. <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/nature-index/news/health-sciences-added-to-nature-index">https://www.nature.com/nature-index/news/health-sciences-added-to-nature-index</ext-link>.</mixed-citation></ref><ref id="CR3"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Noorden</surname><given-names>R</given-names></name><name><surname>Perkel</surname><given-names>JM</given-names></name></person-group><article-title>AI and science: what 1,600 researchers think</article-title><source>Nature</source><year>2023</year><volume>621</volume><fpage>672</fpage><lpage>5</lpage><pub-id pub-id-type="doi">10.1038/d41586-023-02980-0</pub-id><?supplied-pmid 37758894?><pub-id pub-id-type="pmid">37758894</pub-id>
</element-citation></ref><ref id="CR4"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ariyaratne</surname><given-names>S</given-names></name><name><surname>Iyengar</surname><given-names>KP</given-names></name><name><surname>Nischal</surname><given-names>N</given-names></name><name><surname>Chitti Babu</surname><given-names>N</given-names></name><name><surname>Botchu</surname><given-names>R</given-names></name></person-group><article-title>A comparison of ChatGPT-generated articles with human-written articles</article-title><source>Skeletal Radiol</source><year>2023</year><volume>52</volume><fpage>1755</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1007/s00256-023-04340-5</pub-id><?supplied-pmid 37059827?><pub-id pub-id-type="pmid">37059827</pub-id>
</element-citation></ref><ref id="CR5"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumar</surname><given-names>AH</given-names></name></person-group><article-title>Analysis of ChatGPT Tool to assess the potential of its utility for academic writing in Biomedical Domain</article-title><source>Biology Eng Med Sci Rep</source><year>2023</year><volume>9</volume><fpage>24</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.5530/bems.9.1.5</pub-id></element-citation></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="other">Alkaissi H, McFarlane SI. Artificial Hallucinations in ChatGPT: implications in Scientific writing. Cureus 15, e35179.</mixed-citation></ref><ref id="CR7"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>JG</given-names></name><etal/></person-group><article-title>ChatGPT and large language models in academia: opportunities and challenges</article-title><source>BioData Min</source><year>2023</year><volume>16</volume><fpage>20</fpage><pub-id pub-id-type="doi">10.1186/s13040-023-00339-9</pub-id><?supplied-pmid 37443040?><pub-id pub-id-type="pmid">37443040</pub-id>
</element-citation></ref><ref id="CR8"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mondal</surname><given-names>H</given-names></name><name><surname>Mondal</surname><given-names>S</given-names></name></person-group><article-title>ChatGPT in academic writing: maximizing its benefits and minimizing the risks</article-title><source>Indian J Ophthalmol</source><year>2023</year><volume>71</volume><fpage>3600</fpage><pub-id pub-id-type="doi">10.4103/IJO.IJO_718_23</pub-id><?supplied-pmid 37991290?><pub-id pub-id-type="pmid">37991290</pub-id>
</element-citation></ref><ref id="CR9"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Misra</surname><given-names>DP</given-names></name><name><surname>Chandwar</surname><given-names>K</given-names></name></person-group><article-title>ChatGPT, artificial intelligence and scientific writing: what authors, peer reviewers and editors should know</article-title><source>J R Coll Physicians Edinb</source><year>2023</year><volume>53</volume><fpage>90</fpage><lpage>3</lpage><pub-id pub-id-type="doi">10.1177/14782715231181023</pub-id><?supplied-pmid 37305993?><pub-id pub-id-type="pmid">37305993</pub-id>
</element-citation></ref><ref id="CR10"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ali</surname><given-names>SR</given-names></name><name><surname>Dobbs</surname><given-names>TD</given-names></name><name><surname>Hutchings</surname><given-names>HA</given-names></name><name><surname>Whitaker</surname><given-names>IS</given-names></name></person-group><article-title>Using ChatGPT to write patient clinic letters</article-title><source>Lancet Digit Health</source><year>2023</year><volume>5</volume><fpage>e179</fpage><lpage>81</lpage><pub-id pub-id-type="doi">10.1016/S2589-7500(23)00048-1</pub-id><?supplied-pmid 36894409?><pub-id pub-id-type="pmid">36894409</pub-id>
</element-citation></ref><ref id="CR11"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alshami</surname><given-names>A</given-names></name><name><surname>Elsayed</surname><given-names>M</given-names></name><name><surname>Ali</surname><given-names>E</given-names></name><name><surname>Eltoukhy</surname><given-names>AEE</given-names></name><name><surname>Zayed</surname><given-names>T</given-names></name></person-group><article-title>Harnessing the power of ChatGPT for automating systematic review process: Methodology, Case Study, limitations, and future directions</article-title><source>Systems</source><year>2023</year><volume>11</volume><fpage>351</fpage><pub-id pub-id-type="doi">10.3390/systems11070351</pub-id></element-citation></ref><ref id="CR12"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>J</given-names></name><name><surname>Tan</surname><given-names>M</given-names></name></person-group><article-title>The role of ChatGPT in scientific communication: writing better scientific review articles</article-title><source>Am J Cancer Res</source><year>2023</year><volume>13</volume><fpage>1148</fpage><lpage>54</lpage><?supplied-pmid 37168339?><pub-id pub-id-type="pmid">37168339</pub-id>
</element-citation></ref><ref id="CR13"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haman</surname><given-names>M</given-names></name><name><surname>&#x00160;koln&#x000ed;k</surname><given-names>M</given-names></name></person-group><article-title>Using ChatGPT to conduct a literature review</article-title><source>Account Res</source><year>2023</year><volume>0</volume><fpage>1</fpage><lpage>3</lpage><pub-id pub-id-type="doi">10.1080/08989621.2023.2185514</pub-id></element-citation></ref><ref id="CR14"><label>14.</label><mixed-citation publication-type="other">ChatGPT listed as author on research papers. many scientists disapprove. <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/d41586-023-00107-z">https://www.nature.com/articles/d41586-023-00107-z</ext-link>.</mixed-citation></ref><ref id="CR15"><label>15.</label><mixed-citation publication-type="other">Scopus AI. Trusted content. Powered by responsible AI. www.elsevier.com <ext-link ext-link-type="uri" xlink:href="https://www.elsevier.com/products/scopus/scopus-ai">https://www.elsevier.com/products/scopus/scopus-ai</ext-link>.</mixed-citation></ref><ref id="CR16"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Conroy</surname><given-names>G</given-names></name></person-group><article-title>How ChatGPT and other AI tools could disrupt scientific publishing</article-title><source>Nature</source><year>2023</year><volume>622</volume><fpage>234</fpage><lpage>6</lpage><pub-id pub-id-type="doi">10.1038/d41586-023-03144-w</pub-id><?supplied-pmid 37817033?><pub-id pub-id-type="pmid">37817033</pub-id>
</element-citation></ref><ref id="CR17"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rubin</surname><given-names>JB</given-names></name></person-group><article-title>The spectrum of sex differences in cancer</article-title><source>Trends Cancer</source><year>2022</year><volume>8</volume><fpage>303</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1016/j.trecan.2022.01.013</pub-id><?supplied-pmid 35190302?><pub-id pub-id-type="pmid">35190302</pub-id>
</element-citation></ref><ref id="CR18"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>DS</given-names></name><name><surname>Mellman</surname><given-names>I</given-names></name></person-group><article-title>Oncology meets immunology: the Cancer-Immunity cycle</article-title><source>Immunity</source><year>2013</year><volume>39</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1016/j.immuni.2013.07.012</pub-id><?supplied-pmid 23890059?><pub-id pub-id-type="pmid">23890059</pub-id>
</element-citation></ref><ref id="CR19"><label>19.</label><mixed-citation publication-type="other">Reimers N, Gurevych I, Sentence-BERT. Sentence Embeddings using Siamese BERT-Networks. in Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) (eds. Inui, K., Jiang, J., Ng, V. &#x00026; Wan, X.) 3982&#x02013;3992Association for Computational Linguistics, Hong Kong, China, (2019). 10.18653/v1/D19-1410.</mixed-citation></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="other">Jin B et al. Large Language Models on Graphs: A Comprehensive Survey. Preprint at 10.48550/arXiv.2312.02783 (2024).</mixed-citation></ref><ref id="CR21"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Polkinghorn</surname><given-names>WR</given-names></name><etal/></person-group><article-title>Androgen receptor signaling regulates DNA repair in prostate cancers</article-title><source>Cancer Discov</source><year>2013</year><volume>3</volume><fpage>1245</fpage><lpage>53</lpage><pub-id pub-id-type="doi">10.1158/2159-8290.CD-13-0172</pub-id><?supplied-pmid 24027196?><pub-id pub-id-type="pmid">24027196</pub-id>
</element-citation></ref><ref id="CR22"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Broestl</surname><given-names>L</given-names></name><name><surname>Rubin</surname><given-names>JB</given-names></name></person-group><article-title>Sexual differentiation specifies Cellular responses to DNA damage</article-title><source>Endocrinology</source><year>2021</year><volume>162</volume><fpage>bqab192</fpage><pub-id pub-id-type="doi">10.1210/endocr/bqab192</pub-id><?supplied-pmid 34478502?><pub-id pub-id-type="pmid">34478502</pub-id>
</element-citation></ref><ref id="CR23"><label>23.</label><mixed-citation publication-type="other">ChatGPT and Academic Integrity Concerns. Detecting Artificial Intelligence Generated Content | Language Education and Technology. <ext-link ext-link-type="uri" xlink:href="https://www.langedutech.com/letjournal/index.php/let/article/view/49">https://www.langedutech.com/letjournal/index.php/let/article/view/49</ext-link>.</mixed-citation></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="other">Gao CA et al. Comparing scientific abstracts generated by ChatGPT to original abstracts using an artificial intelligence output detector, plagiarism detector, and blinded human reviewers. 2022.12.23.521610 Preprint at 10.1101/2022.12.23.521610 (2022).</mixed-citation></ref><ref id="CR25"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Homolak</surname><given-names>J</given-names></name></person-group><article-title>In reply: we do not stand a ghost of a chance of detecting plagiarism with ChatGPT employed as a ghost author</article-title><source>Croat Med J</source><year>2023</year><volume>64</volume><fpage>293</fpage><lpage>4</lpage><pub-id pub-id-type="doi">10.3325/cmj.2023.64.293</pub-id></element-citation></ref><ref id="CR26"><label>26.</label><mixed-citation publication-type="other">Introducing Gemini. Google&#x02019;s most capable AI model yet. <ext-link ext-link-type="uri" xlink:href="https://blog.google/technology/ai/google-gemini-ai/#sundar-note">https://blog.google/technology/ai/google-gemini-ai/#sundar-note</ext-link>.</mixed-citation></ref><ref id="CR27"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>J</given-names></name><etal/></person-group><article-title>BioBERT: a pre-trained biomedical language representation model for biomedical text mining</article-title><source>Bioinformatics</source><year>2020</year><volume>36</volume><fpage>1234</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btz682</pub-id><?supplied-pmid 31501885?><pub-id pub-id-type="pmid">31501885</pub-id>
</element-citation></ref><ref id="CR28"><label>28.</label><mixed-citation publication-type="other">Yuan H et al. Association for Computational Linguistics, Dublin, Ireland,. BioBART: Pretraining and Evaluation of A Biomedical Generative Language Model. in Proceedings of the 21st Workshop on Biomedical Language Processing (eds. Demner-Fushman, D., Cohen, K. B., Ananiadou, S. &#x00026; Tsujii, J.) 97&#x02013;109 (2022). 10.18653/v1/2022.bionlp-1.9.</mixed-citation></ref><ref id="CR29"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luo</surname><given-names>R</given-names></name><etal/></person-group><article-title>BioGPT: generative pre-trained transformer for biomedical text generation and mining</article-title><source>Brief Bioinform</source><year>2022</year><volume>23</volume><fpage>bbac409</fpage><pub-id pub-id-type="doi">10.1093/bib/bbac409</pub-id><?supplied-pmid 36156661?><pub-id pub-id-type="pmid">36156661</pub-id>
</element-citation></ref></ref-list></back></article>