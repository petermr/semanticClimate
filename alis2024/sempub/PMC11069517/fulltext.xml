<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd"> 
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="data-paper" dtd-version="1.3"><?properties open_access?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 1?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sci Data</journal-id><journal-id journal-id-type="iso-abbrev">Sci Data</journal-id><journal-title-group><journal-title>Scientific Data</journal-title></journal-title-group><issn pub-type="epub">2052-4463</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmcid">11069517</article-id><article-id pub-id-type="publisher-id">3317</article-id><article-id pub-id-type="doi">10.1038/s41597-024-03317-w</article-id><article-categories><subj-group subj-group-type="heading"><subject>Data Descriptor</subject></subj-group></article-categories><title-group><article-title>A Dataset for Evaluating Contextualized Representation of Biomedical Concepts in Language Models</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Rouhizadeh</surname><given-names>Hossein</given-names></name><address><email>hossein.rouhizadeh@unige.ch</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Nikishina</surname><given-names>Irina</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3309-6128</contrib-id><name><surname>Yazdani</surname><given-names>Anthony</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Bornet</surname><given-names>Alban</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Zhang</surname><given-names>Boya</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Ehrsam</surname><given-names>Julien</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6527-5898</contrib-id><name><surname>Gaudet-Blavignac</surname><given-names>Christophe</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff3">3</xref></contrib><contrib contrib-type="author"><name><surname>Naderi</surname><given-names>Nona</given-names></name><xref ref-type="aff" rid="Aff4">4</xref></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6238-4503</contrib-id><name><surname>Teodoro</surname><given-names>Douglas</given-names></name><address><email>douglas.teodoro@unige.ch</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01swzsf04</institution-id><institution-id institution-id-type="GRID">grid.8591.5</institution-id><institution-id institution-id-type="ISNI">0000 0001 2175 2154</institution-id><institution>Department of Radiology and Medical Informatics, Faculty of Medicine, </institution><institution>University of Geneva, </institution></institution-wrap>Geneva, Switzerland </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00g30e956</institution-id><institution-id institution-id-type="GRID">grid.9026.d</institution-id><institution-id institution-id-type="ISNI">0000 0001 2287 2617</institution-id><institution>Department of Informatics, </institution><institution>University of Hamburg, </institution></institution-wrap>Hamburg, Germany </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.150338.c</institution-id><institution-id institution-id-type="ISNI">0000 0001 0721 9812</institution-id><institution>Division of Medical Information Sciences, Diagnostic Department, </institution><institution>Geneva University Hospitals, </institution></institution-wrap>Geneva, Switzerland </aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.460789.4</institution-id><institution-id institution-id-type="ISNI">0000 0004 4910 6535</institution-id><institution>Laboratoire Interdisciplinaire des Sciences du Numerique, CNRS, </institution><institution>Paris-Saclay University, </institution></institution-wrap>Orsay, France </aff></contrib-group><pub-date pub-type="epub"><day>4</day><month>5</month><year>2024</year></pub-date><pub-date pub-type="pmc-release"><day>4</day><month>5</month><year>2024</year></pub-date><pub-date pub-type="collection"><year>2024</year></pub-date><volume>11</volume><elocation-id>455</elocation-id><history><date date-type="received"><day>8</day><month>11</month><year>2023</year></date><date date-type="accepted"><day>25</day><month>4</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2024</copyright-statement><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article&#x02019;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#x02019;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">Due to the complexity of the biomedical domain, the ability to capture semantically meaningful representations of terms in context is a long-standing challenge. Despite important progress in the past years, no evaluation benchmark has been developed to evaluate how well language models represent biomedical concepts according to their corresponding context. Inspired by the Word-in-Context (WiC) benchmark, in which word sense disambiguation is reformulated as a binary classification task, we propose a novel dataset, BioWiC, to evaluate the ability of language models to encode biomedical terms in context. BioWiC comprises 20&#x02019;156 instances, covering over 7&#x02019;400 unique biomedical terms, making it the largest WiC dataset in the biomedical domain. We evaluate BioWiC both intrinsically and extrinsically and show that it could be used as a reliable benchmark for evaluating context-dependent embeddings in biomedical corpora. In addition, we conduct several experiments using a variety of discriminative and generative large language models to establish robust baselines that can serve as a foundation for future research.</p></abstract><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>Health care</kwd><kwd>Medical research</kwd></kwd-group><funding-group><award-group><funding-source><institution>This work was funded by the Innosuisse - project no.: 55441.1 IP ICT.</institution></funding-source></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Springer Nature Limited 2024</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Background &#x00026; Summary</title><p id="Par2">Biomedical corpora, such as scientific articles and patient reports, contain a wealth of knowledge and information that can be used to enable high-quality research. However, the extraction of knowledge from these free-text sources is a challenging task as it requires the ability to understand the meaning of natural language and the idiosyncrasies of the biomedical domain but also due to the volume of the data<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. Biomedical natural language processing (NLP) techniques have been used to analyze information from free-text sources at scale, enabling the extraction and synthesis of biomedical information, and transforming unstructured data into a structured format<sup><xref ref-type="bibr" rid="CR2">2</xref>,<xref ref-type="bibr" rid="CR3">3</xref></sup>.</p><p id="Par3">Compared to general corpora, NLP models face three main challenges for semantic representation of biomedical data<sup><xref ref-type="bibr" rid="CR4">4</xref>&#x02013;<xref ref-type="bibr" rid="CR7">7</xref></sup>. First, the number of biomedical entities is extremely high. For example, the SNOMED-CT ontology<sup><xref ref-type="bibr" rid="CR8">8</xref></sup> defines more than 300&#x02019;000 medical concepts while the UniProt Knowledgebase (UniProtKB)<sup><xref ref-type="bibr" rid="CR9">9</xref></sup> contains more than 550&#x02019;000 curated proteins. Combined, the number of concepts described in these two knowledge organization systems is higher than the number of terms defined in dictionaries for many natural languages. Second, biomedical concepts have many synonyms and alternative expressions for the same concept. For example, in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref> the concept <italic>&#x0201c;C0007134&#x0201d;</italic> defined in the Unified Medical Language System (UMLS) thesaurus can be represented with at least four terms: &#x0201c;<italic>Renal Cell Carcinoma</italic>&#x0201d;, &#x0201c;<italic>RCC</italic>&#x0201d;, &#x0201c;<italic>Nephroid Carcinoma</italic>&#x0201d;, and &#x0201c;<italic>Adenocarcinoma</italic>&#x0201d;. Third, biomedical corpora are notorious for their overabundance of abbreviations and acronyms<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>. These abbreviations and acronyms are often polysemous, e.g., the acronym <italic>&#x0201c;RCC&#x0201d;</italic> in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref> belongs to two concepts &#x02013; <italic>&#x0201c;C2826323&#x0201d;</italic> and <italic>&#x0201c;C0007134&#x0201d;</italic> &#x02013; making their semantic representation even more challenging.<fig id="Fig1"><label>Fig. 1</label><caption><p>Illustration of concept ambiguity in the biomedical domain. Left: Example of the UMLS 2021AB data structure, where one term refers to different concepts as well and one concept may be represented with different mentions. Right: Example of a paragraph with numerous polysemous acronyms and abbreviations from a biomedical journal<sup><xref ref-type="bibr" rid="CR52">52</xref></sup>. Acronyms and abbreviations are highlighted in bold.</p></caption><graphic xlink:href="41597_2024_3317_Fig1_HTML" id="d33e283"/></fig></p><p id="Par4">Entity linking<sup><xref ref-type="bibr" rid="CR11">11</xref></sup> and word sense disambiguation (WSD)<sup><xref ref-type="bibr" rid="CR12">12</xref></sup> are two NLP tasks trying to address the issue of semantic representation in the biomedical field. Entity linking systems aim to connect terms mentioned in a text with corresponding concepts in a knowledge organization system<sup><xref ref-type="bibr" rid="CR13">13</xref>,<xref ref-type="bibr" rid="CR14">14</xref></sup>. For instance, the abbreviation <italic>&#x0201c;CA&#x0201d;</italic> in biomedical contexts can stand for either <italic>&#x0201c;calcium&#x0201d;</italic>, an essential mineral in the human body, or <italic>&#x0201c;cancer&#x0201d;</italic>, a group of diseases characterized by abnormal cell growth. An ideal entity linking system would employ contextual cues to correctly map<italic>&#x0201c;CA&#x0201d;</italic> to its standardized form in a chosen knowledge base, e.g., UMLS. This proper alignment assists in reducing ambiguity, enhancing the understanding of biomedical corpora<sup><xref ref-type="bibr" rid="CR15">15</xref>,<xref ref-type="bibr" rid="CR16">16</xref></sup>. In the biomedical domain, a wide array of datasets exists for entity linking, each employing distinct text corpora as their primary contextual resource. For instance, MedMentions<sup><xref ref-type="bibr" rid="CR17">17</xref></sup> and BC5CDR<sup><xref ref-type="bibr" rid="CR18">18</xref></sup> focus on biomedical abstracts, N2C2 2019<sup><xref ref-type="bibr" rid="CR19">19</xref></sup> on clinical notes, and COMETA<sup><xref ref-type="bibr" rid="CR20">20</xref></sup> on social media content. These datasets are also differentiated by their target ontologies. For instance, MedMentions<sup><xref ref-type="bibr" rid="CR17">17</xref></sup> aligns with UMLS, BC5CDR<sup><xref ref-type="bibr" rid="CR18">18</xref></sup> connects to MeSH, and SMM4H<sup><xref ref-type="bibr" rid="CR21">21</xref></sup> links with the MedDRA ontology. Each dataset serves a unique purpose within the biomedical entity linking landscape.</p><p id="Par5">Given a word in context, the objective of WSD is to associate the word with its correct meaning in a sense inventory<sup><xref ref-type="bibr" rid="CR22">22</xref>,<xref ref-type="bibr" rid="CR23">23</xref></sup>. For example, in the sentence <italic>&#x0201c;The patient has been suffering from a cold.&#x0201d;</italic>, the sense for the word <italic>cold</italic> should be associated with its <italic>medical</italic> meaning as opposed to <italic>temperature</italic> or <italic>literature</italic> (i.e., James Bond novel by John Gardner) meanings. Two of the most prominent biomedical WSD datasets are MSH WSD<sup><xref ref-type="bibr" rid="CR24">24</xref></sup> and NLM WSD<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>. The MSH WSD dataset, created by the National Library of Medicine, comprises 37&#x02019;888 instances across 203 ambiguous terms and abbreviations from the Medical Literature Analysis and Retrieval System Online (MEDLINE) 2010 baseline, each linked to the MeSH ontology. Similarly, the NLM WSD dataset, also developed by the National Library of Medicine, includes 5&#x02019;000 instances for 50 ambiguous biomedical terms, with each instance linked to UMLS. Despite the steps forward in this promising research direction, the main limitation of the current approach to the WSD task lies in the restriction on the range of word and sense representations defined by the predefined sense inventories<sup><xref ref-type="bibr" rid="CR26">26</xref>,<xref ref-type="bibr" rid="CR27">27</xref></sup>.</p><p id="Par6">To bridge this gap, the Word-in-Context (WiC) benchmark<sup><xref ref-type="bibr" rid="CR26">26</xref></sup> presented a novel perspective on WSD, dropping the requirement of traditional formulation of WSD task to the fixed sense inventory<sup><xref ref-type="bibr" rid="CR27">27</xref></sup>. WiC formulates WSD as a binary classification task, where a polysemous word appears in two different sentences, and the task is to infer whether the word holds the same meaning or not. WiC has been integrated as a component of SuperGLUE<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>, a comprehensive evaluation framework designed to assess the performance of natural language understanding systems. XL-WiC<sup><xref ref-type="bibr" rid="CR27">27</xref></sup> and TempoWiC<sup><xref ref-type="bibr" rid="CR29">29</xref></sup> are two recent extensions of WiC adapting it to 12 different languages and targeting the detection of meaning shifts in Twitter, respectively. The WiC-TSV (Target Sense Verification of Words in Context) dataset<sup><xref ref-type="bibr" rid="CR30">30</xref></sup> is closely related to WiC and focuses on a binary disambiguation task, determining if the contextually intended sense of a word aligns with a pre-defined target sense. This dataset comprises general domain instances in its training and development sets, but the test set is distinctively composed of instances in the general domain as well as three domain-specific subsets: cocktails, medicine, and computer science. For all instances, the primary context source is the Wikilinks dataset<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>. For the biomedical domain instances in WiC-TSV specifically, the target sense definitions are sourced from the MeSH ontology. The main limitation of this dataset is the small number of biomedical instances it offers &#x02014; 205 instances representing 8 unique biomedical terms. Moreover, the dataset&#x02019;s scope is limited as it only includes target terms and definitions from the MeSH ontology. These constraints could potentially limit the effectiveness of the dataset in the development and evaluation of comprehensive WSD systems in the biomedical domain.</p><p id="Par7">Despite significant progress both in WSD and entity linking tasks in the biomedical domain<sup><xref ref-type="bibr" rid="CR15">15</xref>,<xref ref-type="bibr" rid="CR31">31</xref>&#x02013;<xref ref-type="bibr" rid="CR34">34</xref></sup>, there exists no benchmark that specifically targets the semantic representation of biomedical terms as a WiC-style task. To bridge this gap, we present the BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> benchmark, a novel dataset that provides high-quality annotations for the evaluation of contextualized term representations in the biomedical domain. Inspired by the WiC<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>, we formulate BioWiC as a binary classification task, whose aim is to identify whether two target terms in their respective contexts have the same meaning. In addition to its focus on biomedical concepts, BioWiC differs from WiC in several ways. First, in contrast to WiC which focuses on single token words, as targets, BioWiC allows for terms that can be single words, phrases, or multiword expressions. Second, BioWiC terms may be represented not only by the same terms in different contexts but also by different term forms referring to the same concept (or not). The dataset is named &#x0201c;BioWiC&#x0201d;, reflecting its design for the biomedical domain while showcasing its relation to the WiC task.</p><p id="Par8">A key attribute of BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> is its flexibility and scalability. Unlike WSD and entity linking that is restricted to concepts covered by existing knowledge graphs, BioWiC can be expanded independently of such resources. This is because expanding the dataset for a novel concept can be accomplished by annotating instances where two sentences contain the target concept, regardless of whether or not it is included in any existing knowledge organization resource. This flexibility allows for continual evolution and improvement, independent of updates to standardized resources, providing a more comprehensive and up-to-date resource for research in the biomedical field.</p></sec><sec id="Sec2"><title>Methods</title><p id="Par9">In this section, we present BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> &#x02013; a novel benchmark dataset for evaluating in-context biomedical concept representations. First, we explain the resources we used to create the corpus and the pre-processing steps. We then provide an overview of the methodology used to create the dataset and discuss the processes for instance generation, dataset splitting, and quality assessment.</p><sec id="Sec3"><title>BioWiC resources</title><p id="Par10">As shown in Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>, BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> instances were built using annotations from the following manually curated biomedical entity linking datasets:<table-wrap id="Tab1"><label>Table 1</label><caption><p>General statistics of BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> resources.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Dataset</th><th>Ontologies</th><th>Semantic types</th><th>Documents</th><th>Sentences</th><th>Mentions</th></tr></thead><tbody><tr><td>Medmentions</td><td>UMLS</td><td>21 UMLS types</td><td>4392</td><td>44903</td><td>203&#x02019;282</td></tr><tr><td>BC5CDR</td><td>MeSH</td><td>Disease, Chemical</td><td>1500</td><td>11562</td><td>13&#x02019;343</td></tr><tr><td>NCBI Disease</td><td>MeSH, OMIM</td><td>Disease</td><td>792</td><td>3891</td><td>6&#x02019;892</td></tr></tbody></table><table-wrap-foot><p>The sentence count in each source is determined using the PySBD library<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>, version 0.3.4.</p></table-wrap-foot></table-wrap></p><p id="Par11"><bold>MedMentions</bold><sup><xref ref-type="bibr" rid="CR17">17</xref></sup>: this is the largest entity linking dataset in the biomedical domain. It includes 4&#x02019;392 PubMed abstracts and over 350&#x02019;000 mentions linked to UMLS. The full MedMentions version covers 128 UMLS semantic types. However, as stated by<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>, the concepts can be either too expansive (e.g., &#x0201c;Group, South Asia&#x0201d;) or cover peripheral and supplementary topics (e.g., &#x0201c;Rural Area, No difference&#x0201d;). Thus, we follow<sup><xref ref-type="bibr" rid="CR36">36</xref>,<xref ref-type="bibr" rid="CR37">37</xref></sup> and focus on the officially released subset of MedMentions called ST21pv (21 Semantic Types from Preferred Vocabularies), which contains 203&#x02019;282 biomedical mentions from 21 UMLS semantic types.</p><p id="Par12"><bold>BC5CDR</bold><sup><xref ref-type="bibr" rid="CR18">18</xref></sup>: introduced in the BioCreative challenge, this dataset comprises 1&#x02019;500 PubMed abstracts and 13&#x02019;343 mentions linked to Medical Subject Headings (MeSH) concepts. The dataset covers a wide range of biomedical entities, including 4&#x02019;409 chemicals, 5&#x02019;818 diseases, and 3&#x02019;116 instances of chemical-disease interactions.</p><p id="Par13"><bold>NCBI Disease</bold><sup><xref ref-type="bibr" rid="CR38">38</xref></sup>: developed by the National Center for Biotechnology Information (NCBI), this dataset includes biomedical information derived from 793 PubMed abstracts. It comprises 6&#x02019;892 disease mentions, each associated with their relevant standardized forms in the MeSH or Online Mendelian Inheritance in Man (OMIM) terminologies.</p></sec><sec id="Sec4"><title>Data pre-processing</title><p id="Par14">To have homogeneous word-in-context instances from different resources, we unified their format using the following steps:<list list-type="bullet"><list-item><p id="Par15"><bold>Sentence segmentation</bold>: Each BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> instance is composed of a pair of target terms together with their respective sentences. We use the PySBD library<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>, version 0.3.4, to determine sentence boundaries in the initial source texts (i.e., abstracts of publications). We parse documents and keep only sentences that contain mapped mentions.</p></list-item><list-item><p id="Par16"><bold>Label unification</bold>: The source datasets of BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> map mentions (i.e., terms) have different target knowledge organization resources, i.e., MeSH, OMIM, and UMLS. This results in concept codes, i.e., unique identifiers in the target ontology, that cannot be directly comparable. To address this issue, we used UMLS as the main reference and transferred the concept identifiers from MeSH and OMIM to UMLS using available ontology mappings in UMLS 2021AB. To avoid ambiguity, MeSH or OMIM concepts with multiple mappings in UMLS 2021AB were removed.</p></list-item></list></p></sec><sec id="Sec5"><title>BioWiC construction</title><p id="Par17">BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> instances follow a similar format to WiC, where each instance involves a pair of biomedical terms (<italic>w</italic><sub>1</sub> and <italic>w</italic><sub>2</sub>) and their corresponding sentences (<italic>s</italic><sub>1</sub> and <italic>s</italic><sub>2</sub>). The task is to classify each instance as <italic>True</italic> if the target terms carry the same meaning across both sentences or <italic>False</italic> if they do not. We represent each instance as a tuple pair <italic>t</italic>&#x02009;=&#x02009;[(<italic>s</italic><sub>1</sub><italic>,w</italic><sub>1</sub>),(<italic>s</italic><sub>2</sub><italic>,w</italic><sub>2</sub>)]: <italic>y</italic> where <italic>w</italic><sub>1</sub> and <italic>w</italic><sub>2</sub> are the target terms, <italic>s</italic><sub>1</sub> and <italic>s</italic><sub>2</sub> are the corresponding sentences, and <italic>y</italic> is the associated binary label. Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref> presents some examples of BioWiC instances. In contrast to WiC, where both target terms of each instance always share the same lemma, BioWiC allows for variations such as abbreviations, synonyms, identical terms, and terms with similar surface forms.<table-wrap id="Tab2"><label>Table 2</label><caption><p>BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> instances, drawn from the test split.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Instance group</th><th>#</th><th>Sentence 1</th><th>Sentence 2</th><th>Label</th></tr></thead><tbody><tr><td rowspan="2">Term identity</td><td>1</td><td>&#x02026; clinical use of the anthracycline doxorubicin (DOX) is limited by its <bold>cardiotoxic</bold> effects &#x02026;</td><td>&#x02026; mitomycin C (MMC) has been suggested to be <bold>cardiotoxic</bold>, especially when combined with or given &#x02026;</td><td>T</td></tr><tr><td>2</td><td>&#x02026; a wide range of key concepts and terms of <bold>PE</bold> from clinical and biomedical researc &#x02026;</td><td>&#x02026; associated with mortality in COPD patients with low-risk <bold>PE</bold> (adjusted OR 1.11; 95% CI, 1.04-1.66) &#x02026;</td><td>F</td></tr><tr><td rowspan="2">Abbreviations</td><td>3</td><td>&#x02026; the gene responsible for <bold>FEO</bold> to an interval of less than 5&#x02009;cM between D18S64 and D18S51&#x02026;</td><td>&#x02026; affecting the signal peptide of RANK, cause <bold>familial expansile osteolysis</bold>.</td><td>T</td></tr><tr><td>4</td><td><bold>Periodontal disease</bold> has risk factors in common with a number of other non-communicable diseases &#x02026;</td><td>&#x02026; allosteric activator of mGlu7 receptors, were thus tested in different rodent models of <bold>PD</bold>.</td><td>F</td></tr><tr><td rowspan="2">Synonyms</td><td>5</td><td>Initial low levels of <bold>IL-10</bold> were associated with an increase in physical disability &#x02026;</td><td>Assessment of Interleukin-17A, <bold>Interleukin-10</bold> and Transforming Growth &#x02026;</td><td>T</td></tr><tr><td>6</td><td>&#x02026; variations of heart period (HP), systolic arterial pressure (SAP) and <bold>respiration (R)</bold>.</td><td>&#x02026; subjects who fail <bold>ventilation</bold> with the C-E technique can be ventilated effectively &#x02026;</td><td>F</td></tr><tr><td rowspan="2">Label similarity</td><td>7</td><td>&#x02026; deletion of the KIT and PDGFRA genes may account for the <bold>piebald</bold>phenotype in this patient &#x02026;</td><td><bold>Piebaldism</bold> in this family thus appears to be the human homologue to dominant white spotting (W) &#x02026;</td><td>T</td></tr><tr><td>8</td><td>More <bold>anemic</bold> than non-anemic FDS2 patients died (28.7% versus 8.0%; P&#x02009;&#x0003c;&#x02009;0.001) &#x02026;</td><td>&#x02026; observed were comparable in AZT and PHZ treated mice with similar degrees of <bold>anaemia</bold>.</td><td>F</td></tr></tbody></table><table-wrap-foot><p>The target terms of each instance are in bold.</p></table-wrap-foot></table-wrap></p><p id="Par18">To evaluate challenging scenarios for semantic representation, such as synonymy, polysemy, and abbreviations, BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> is divided into four main groups of instances. Group A (term identity) contains instances where the target terms <italic>w</italic><sub>1</sub> and <italic>w</italic><sub>2</sub> are identical. In group B (abbreviations), either <italic>w</italic><sub>1</sub> or <italic>w</italic><sub>2</sub> could represent the abbreviation of the other one. Group C (synonyms), consists of instances where <italic>w</italic><sub>1</sub> and <italic>w</italic><sub>2</sub> could be synonyms (according to UMLS). Lastly, group D (label similarity) includes instances where <italic>w</italic><sub>1</sub> and <italic>w</italic><sub>2</sub> share similar surface forms. We employed the following five steps to generate the BioWiC instances:<list list-type="simple"><list-item><label>(i)</label><p id="Par19"><bold>Sentence collection</bold>: We first gathered all the sentences from the source datasets manually annotated with terms <italic>M</italic>(<italic>W,C</italic>)&#x02009;=&#x02009;{(<italic>w</italic><sub>1</sub><italic>, c</italic><sub>1</sub>), (<italic>w</italic><sub>2</sub><italic>, c</italic><sub>2</sub>)<italic>, &#x02026;</italic>, (<italic>w</italic><sub><italic>n</italic></sub><italic>, c</italic><sub><italic>n</italic></sub>)}, where <italic>w</italic>&#x02009;&#x02208;&#x02009;<italic>W</italic> is a term and <italic>c</italic>&#x02009;&#x02208;&#x02009;<italic>C</italic> is a concept defined in UMLS. Then, we created a set <italic>S</italic>&#x02009;=&#x02009;{<italic>s</italic><sub>1</sub><italic>, &#x02026;, s</italic><sub><italic>n</italic></sub>}, where each sentence <italic>s</italic>&#x02009;&#x02208;&#x02009;<italic>S</italic> has at least one mention <italic>w</italic>&#x02009;&#x02208;&#x02009;<italic>W</italic> linked to <italic>c</italic>&#x02009;&#x02208;&#x02009;<italic>C</italic>.</p></list-item><list-item><label>(ii)</label><p id="Par20"><bold>Tuple creation</bold>: For each sentence <italic>s</italic>&#x02009;&#x02208;&#x02009;<italic>S</italic>, we randomly chose one of the annotated mentions <italic>w</italic> and created a set of sentence-term tuples <italic>P</italic>&#x02009;=&#x02009;{(<italic>s</italic><sub>1</sub><italic>, w</italic><sub>1</sub>), (<italic>s</italic><sub>2</sub><italic>, w</italic><sub>2</sub>)<italic>,&#x02026;</italic>,(<italic>s</italic><sub><italic>n</italic></sub><italic>, w</italic><sub><italic>n</italic></sub>)}, where for each (<italic>s</italic><sub><italic>i</italic></sub><italic>, w</italic><sub><italic>i</italic></sub>)&#x02009;&#x02208;&#x02009;<italic>P</italic>, <italic>s</italic><sub><italic>i</italic></sub> includes <italic>w</italic><sub><italic>i</italic></sub>. We then paired the tuples of <italic>P</italic> and created a collection of tuple pairs:<disp-formula id="Equa"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$T=\left\{\left[({s}_{1},{w}_{1}),({s}_{2},{w}_{2})\right],\left[({s}_{1},{w}_{1}),({s}_{3},{w}_{3})\right],\ldots ,\left[({s}_{m},{w}_{m}),({s}_{n},{w}_{n})\right]\right\}.$$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:mrow><mml:mfenced close="]" open="["><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mfenced close="]" open="["><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mfenced close="]" open="["><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:math><graphic xlink:href="41597_2024_3317_Article_Equa.gif" position="anchor"/></alternatives></disp-formula></p></list-item><list-item><label>(iii)</label><p id="Par21"><bold>Instance definition and labeling</bold>: We considered each pair <italic>t</italic>&#x02009;=&#x02009;[(<italic>s</italic><sub><italic>i</italic></sub><italic>,w</italic><sub><italic>i</italic></sub>), (<italic>s</italic><sub><italic>j</italic></sub><italic>,w</italic><sub><italic>j</italic></sub>)]&#x02009;&#x02208;&#x02009;<italic>T</italic> as a potential BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> instance, where <italic>w</italic><sub><italic>i</italic></sub> and <italic>w</italic><sub><italic>j</italic></sub> serve as target terms and <italic>s</italic><sub><italic>i</italic></sub> and <italic>s</italic><sub><italic>j</italic></sub> are their corresponding sentences, respectively. Each instance is labeled as <italic>y</italic>&#x02009;=&#x02009;<italic>True</italic> if the target terms <italic>w</italic><sub><italic>i</italic></sub> and <italic>w</italic><sub><italic>j</italic></sub> were linked to the same or synonym UMLS concept, and as <italic>y</italic>&#x02009;=&#x02009;<italic>False</italic> if they were not. We then added the label <italic>y</italic> to each tuple pair to create the dataset of possible BioWiC instances <italic>t</italic>&#x02009;=&#x02009;[(<italic>s</italic><sub><italic>i</italic></sub><italic>,w</italic><sub><italic>i</italic></sub>),(<italic>s</italic><sub><italic>j</italic></sub><italic>,w</italic><sub><italic>j</italic></sub>)]: <italic>y</italic>.</p></list-item><list-item><label>(iv)</label><p id="Par22"><bold>Tuple selection</bold>: We categorized each instance <italic>t</italic>: <italic>y</italic> to one of the main groups of BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>. Group A included instances for which <italic>w</italic><sub><italic>i</italic></sub> and <italic>w</italic><sub><italic>j</italic></sub> are identical. Group B included instances where <italic>w</italic><sub><italic>i</italic></sub> is the abbreviated form of <italic>w</italic><sub><italic>j</italic></sub> or vice-versa. Group C included instances where <italic>w</italic><sub><italic>i</italic></sub> and <italic>w</italic><sub><italic>j</italic></sub> could be synonyms. Group D included instances where <italic>w</italic><sub><italic>i</italic></sub> and <italic>w</italic><sub><italic>j</italic></sub> are not identical but share similar surface characteristics.</p></list-item><list-item><label>(v)</label><p id="Par23"><bold>Dataset splitting</bold>: We divided the instances into three parts: training set, development set, and test set, providing a consistent and reliable framework for model training and evaluation.</p></list-item></list></p><p id="Par24">For clarity, in Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref> we provide an example of building BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> instances for the target term &#x0201c;delivery&#x0201d;. Initially, we preprocess the resource data and extract all sentences in which &#x0201c;delivery&#x0201d; is linked to UMLS. We transform each sentence to the sentence-term tuple (<italic>s</italic><sub><italic>i</italic></sub><italic>,w</italic>) format where <italic>s</italic><sub><italic>i</italic></sub> represents a sentence containing the term <italic>w&#x02009;=&#x02009;</italic>&#x0201c;delivery&#x0201d;. Subsequently, we permute all possible combinations of tuples (<italic>s</italic><sub><italic>i</italic></sub><italic>,w</italic>) identified in the preceding step to generate BioWiC instances <italic>t</italic>&#x02009;=&#x02009;[(<italic>s</italic><sub><italic>i</italic></sub><italic>,w</italic>),(<italic>s</italic><sub><italic>j</italic></sub><italic>,w</italic>)], where &#x0201c;delivery&#x0201d; serves as the target term in both sentences. Finally, we classify each instance as <italic>True</italic> when &#x0201c;delivery&#x0201d; is mapped to the same CUI code in both sentences and as <italic>False</italic> when it is not.<fig id="Fig2"><label>Fig. 2</label><caption><p>The overall pipeline of the BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> construction process. Step 1: Pre-process the source documents to a consistent format. Step 2: Identify and retrieve sentences including the term &#x0201c;delivery&#x0201d; linked to UMLS. Step 3: Pair the retrieved sentences to generate BioWiC instances. In Step 3, the green box shows an example of a BioWiC instance with the same target concept, while the red boxes show examples of different target concepts.</p></caption><graphic xlink:href="41597_2024_3317_Fig2_HTML" id="d33e1443"/></fig></p></sec><sec id="Sec6"><title>Instance generation</title><p id="Par25">To build the BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> instances, we considered two main challenges of biomedical texts: semantic and lexical ambiguities. The presence of <italic>semantically ambiguous terms</italic>, that is, terms that can have multiple meanings in different contexts, is one of the most difficult aspects of biomedical text processing<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>. For instance, the term s<italic>taph</italic> can be used either as a type of <italic>disease</italic> (usually followed by infection) or <italic>bacteria</italic> in other contexts. In addition, one concept can be used in different domains to represent meaning. To assess the capability of language models to provide context-sensitive representations for a term across different contexts, we included a group of instances (group A) in BioWiC in which a target biomedical term appears in two different contexts. Another key challenge in the biomedical domain is that terms can be expressed in various forms or using different <italic>lexical formats</italic>, even if they refer to the same biomedical concepts. To account for this challenge, we developed three other groups of BioWiC instances to measure language models&#x02019; ability to use context and produce similar representations for synonym terms with different surface strings. We categorize synonyms into three different groups: <italic>i</italic>) abbreviations, <italic>ii</italic>) synonyms, and <italic>iii</italic>) concepts with similar surface characteristics. Each instance in these groups contains two target terms with different surfaces, each occurring in a different context and the models should identify whether these terms refer to the same biomedical concept or not.</p></sec><sec id="Sec7"><title>Instance groups</title><p id="Par26">In what follows, we discuss how we created the instances for each group:<list list-type="simple"><list-item><label>(A)</label><p id="Par27"><bold>Term identity:</bold> To create these instances, we use the tuple pair list, built-in step 3 of the construction pipeline, and consider every pair <italic>t&#x02009;=&#x02009;</italic>[(<italic>s</italic><sub><italic>i</italic></sub><italic>,w</italic><sub><italic>i</italic></sub>),(<italic>s</italic><sub><italic>j</italic></sub><italic>,w</italic><sub><italic>j</italic></sub>)]&#x02009;&#x02208;&#x02009;<italic>T</italic> as an instance of group A if <italic>w</italic><sub><italic>i</italic></sub> and <italic>w</italic><sub><italic>j</italic></sub> are identical. We classified each <italic>t</italic> as <italic>True</italic> if both terms were linked to the same UMLS CUI and <italic>False</italic> otherwise. Two instances of this type are shown in Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref> (examples one and two). In the first example, both target terms refer to the same concept and have the same meaning (i.e., toxicity that impairs or damages the heart, UMLS CUI C0876994). So, the instance label is <italic>True</italic>. In the second instance, however, the target terms are mapped to different CUIs (C0032914 and C0034065), and thus the instance label is <italic>False</italic>.</p></list-item><list-item><label>(B)</label><p id="Par28"><bold>Abbreviations</bold>: In this group, one of the target terms is the abbreviated form of the other one, e.g., <italic>heart rate</italic> and <italic>hr</italic>. From the tuple pair list, we pick up all the pairs <italic>t</italic>&#x02009;=&#x02009;[(<italic>s</italic><sub><italic>i</italic></sub><italic>, w</italic><sub><italic>i</italic></sub>),(<italic>s</italic><sub><italic>j</italic></sub><italic>,w</italic><sub><italic>j</italic></sub>)]&#x02009;&#x02208;&#x02009;<italic>T</italic> if <italic>w</italic><sub><italic>i</italic></sub> is the abbreviated form of <italic>w</italic><sub><italic>j</italic></sub> or vise-versa. To verify this, we generate the abbreviated form of <italic>w</italic><sub><italic>i</italic></sub> by combining the initial letters from each part obtained after splitting it (e.g., &#x0201c;FEO&#x0201d; is considered as the abbreviation of &#x0201c;familial expansile osteolysis&#x0201d;). Next, we compare whether <italic>w</italic><sub><italic>j</italic></sub> is the same as the abbreviation of <italic>w</italic><sub><italic>i</italic></sub>. We perform the same procedure for <italic>w</italic><sub><italic>j</italic></sub> as well. If either of the <italic>w</italic><sub><italic>i</italic></sub> or <italic>w</italic><sub><italic>j</italic></sub> is the abbreviation of the other, we categorize the tuple pair into this group. Each tuple pair then is assigned to the label <italic>True</italic> if <italic>w</italic><sub><italic>i</italic></sub> and <italic>w</italic><sub><italic>j</italic></sub> are mapped to the same UMLS and <italic>False</italic> otherwise. As shown in example 3 of Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>, <italic>&#x0201c;FEO&#x0201d;</italic> in sentence 1 is used as the abbreviation of <italic>&#x0201c;familial expansile osteolysis&#x0201d;</italic>. So the instance is labeled as <italic>True</italic>. In example 4, however, the target term <italic>PD</italic> does not have the same meaning as <italic>&#x0201c;Periodontal disease&#x0201d;</italic> and thus the instance is labeled as <italic>False</italic>.</p></list-item><list-item><label>(C)</label><p id="Par29"><bold>Synonyms</bold>: This group refers to instances in which the target terms <italic>w</italic><sub>1</sub> and <italic>w</italic><sub>2</sub> belong to the same UMLS concept. Each UMLS synonym set consists of a group of biomedical synonym concepts that express the same meaning. As shown in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>, due to semantic ambiguity, biomedical concepts with several distinct meanings can be represented by several distinct synonym sets. For instance, <italic>&#x0201c;Adenocarcinoma&#x0201d;</italic> could have the same meaning as either <italic>&#x0201c;Renal Cell Carcinoma&#x0201d;</italic> (CUI C0007134) or <italic>&#x0201c;Carcinoma in adenoma&#x0201d;</italic> (CUI C0001418). Consequently, we consider these concepts as potential synonyms, which may or may not hold the same meaning depending on their context. To create the instances, we collect all the tuple pairs <italic>t</italic>&#x02009;=&#x02009;[(<italic>s</italic><sub><italic>i</italic></sub><italic>,w</italic><sub><italic>i</italic></sub>),(<italic>s</italic><sub><italic>j</italic></sub><italic>,w</italic><sub><italic>j</italic></sub>)] from <italic>T</italic> in which <italic>w</italic><sub><italic>i</italic></sub> and <italic>w</italic><sub><italic>j</italic></sub> both are present in a UMLS synonym set. We then assigned the label <italic>True</italic> to each instance if <italic>w</italic><sub><italic>i</italic></sub> and <italic>w</italic><sub><italic>j</italic></sub> are linked to the same UMLS CUI code, and <italic>False</italic> if they are not. Two examples of this group of instances are shown in Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>.</p></list-item><list-item><label>(D)</label><p id="Par30"><bold>Label similarity</bold>: Despite broad coverage of synonyms and semantic types, UMLS synonym sets still suffer a lack of a large number of reformed concepts that can be used in biomedical contexts. For instance, the concept &#x0201c;chronic pseudomonas aeruginosa infection&#x0201d; can be reformed as &#x0201c;chronic PA infection&#x0201d;, which is not covered by UMLS. To deal with this and to cover a wide range of target concepts with different formats in the dataset, we developed the fourth group of instances in which the corresponding terms have a high Levenshtein distance ratio (see examples 7 and 8 in Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>). To create such instances, we retrieve all tuple pairs <italic>t</italic>&#x02009;=&#x02009;[(<italic>s</italic><sub><italic>i</italic></sub><italic>,w</italic><sub><italic>i</italic></sub>),(<italic>s</italic><sub><italic>j</italic></sub><italic>,w</italic><sub><italic>j</italic></sub>)]&#x02009;&#x02208;&#x02009;<italic>T</italic> in which the Levenshtein distance between <italic>w</italic><sub><italic>i</italic></sub> and <italic>w</italic><sub><italic>j</italic></sub> surpasses the threshold of 0.75. Each tuple <italic>t</italic> is marked as <italic>True</italic> when <italic>w</italic><sub><italic>i</italic></sub> and <italic>w</italic><sub><italic>j</italic></sub> correspond to the identical UMLS entry, and <italic>False</italic> in the other case. The main idea behind this strategy was to include instances where target terms have similar surface forms but refer to different medical concepts. Two instances of this group are shown in Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>. In example 7, both &#x0201c;piebald&#x0201d; and &#x0201c;piebaldism&#x0201d; refer to the same concept, whereas in example 8, &#x0201c;anemic&#x0201d; and &#x0201c;anaemia&#x0201d; refer to two different concepts.</p></list-item></list></p></sec></sec><sec id="Sec8"><title>Data Records</title><p id="Par31">BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> dataset is available on Figshare (10.6084/m9.figshare.25611591.v2), HuggingFace (<ext-link ext-link-type="uri" xlink:href="https://huggingface.co/datasets/hrouhizadeh/BioWiC">https://huggingface.co/datasets/hrouhizadeh/BioWiC</ext-link>), and GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/hrouhizadeh/BioWiC">https://github.com/hrouhizadeh/BioWiC</ext-link>). It comprises three distinct JSON files: training set, development set, and test set. Each instance within a JSON file includes ten parts. The first two items, <italic>term1</italic> and <italic>term2</italic>, followed by <italic>sentence1</italic> and <italic>sentence2</italic>, correspond respectively to the two target terms and two sentences within each instance. The character-level positioning of target terms is defined by <italic>start1</italic> and <italic>start2</italic>, indicating the starting positions, and <italic>end1</italic> and <italic>end2</italic>, marking the end positions within their respective sentences. Furthermore, the <italic>cat</italic> attribute classifies each instance into one of the BioWiC groups, i.e<italic>., term_identity, abbreviations, synonyms, or label_similairty</italic>. Lastly, a binary <italic>label</italic> is attached to each instance, taking the value of either 1 (<italic>True</italic>) or 0 (<italic>False</italic>).</p></sec><sec id="Sec9"><title>Technical Validation</title><sec id="Sec10"><title>Dataset splits</title><p id="Par32">We divided the BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> instances into three main parts i.e., training set, development set, and test set, thereby establishing a structured and robust framework for model development and evaluation. To do so, we first built the test set including 2&#x02019;000 instances with three constraints: 1) only one instance for each unique pair of target terms, 2) no sentence repetition between instances, and 3) no overlap between sentences and term pairs of the test set and training or development sets. The primary objective of rules 1 and 2 was to ensure a diverse range of term pairs and sentences in the test set. Rule 3 was also introduced to assess the generalization power of the language models, i.e., the model&#x02019;s ability to adapt to new, previously unseen data. Taking into account the constraints mentioned, we randomly sampled a set of 2000 term pair instances from the groups defined in section 2.3.1 (800, 200, 800, and 200 samples for term identity, abbreviations, synonyms, and label similarity groups, respectively) to build the testing data set. Finally, we used the remaining instances to create the training set. General statistics of the different splits of BioWiC are reported in Table&#x000a0;<xref rid="Tab3" ref-type="table">3</xref>. In addition, following WiC, we balanced all the data splits in terms of the number of tags, i.e., 50% <italic>True</italic> and 50% <italic>False</italic>.<table-wrap id="Tab3"><label>Table 3</label><caption><p>General statistics of BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>, divided by splits.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Split</th><th colspan="5">Instance group</th><th rowspan="2">Words per sentence</th><th rowspan="2">Unique sentences</th><th rowspan="2">Unique term pairs</th><th rowspan="2">Unique CUIs</th><th rowspan="2">Unique semantic types</th><th rowspan="2">Unique semantic groups</th></tr><tr><th>Term idn</th><th>Abbs</th><th>Syns</th><th>Label sim</th><th>All</th></tr></thead><tbody><tr><td>Train</td><td>3606</td><td>2480</td><td>7072</td><td>3998</td><td>17156</td><td>22.8</td><td>14522</td><td>5243</td><td>4448</td><td>98</td><td>15</td></tr><tr><td>Dev</td><td>400</td><td>100</td><td>400</td><td>100</td><td>1000</td><td>22.8</td><td>1820</td><td>821</td><td>1052</td><td>81</td><td>14</td></tr><tr><td>Test</td><td>800</td><td>200</td><td>800</td><td>200</td><td>2000</td><td>23.0</td><td>4000</td><td>2000</td><td>1870</td><td>88</td><td>15</td></tr><tr><td>All</td><td>4806</td><td>2780</td><td>8272</td><td>4298</td><td>20156</td><td>22.9</td><td>20102</td><td>8064</td><td>5303</td><td>99</td><td>15</td></tr></tbody></table><table-wrap-foot><p>&#x0201c;term idn&#x0201d;, &#x0201c;abbs&#x0201d;, &#x0201c;syns&#x0201d;, and &#x0201c;label sim&#x0201d;, stand for &#x0201c;term identity&#x0201d;, &#x0201c;abbreviations&#x0201d;, &#x0201c;synonyms&#x0201d;, and &#x0201c;label similarity&#x0201d;, respectively. The number of words per instance is calculated using the BERT (bert-base-uncased) tokenizer.</p></table-wrap-foot></table-wrap></p><p id="Par33">During the compilation of the training set, we adopted a simple approach where we only included examples of their corresponding sentences that did not exceed a certain frequency threshold. We built the training set with various thresholds, ranging from 1 to 200, to determine the most appropriate limit. As illustrated in Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>, the size of the training set, the number of unique concepts, and the number of semantic types in the training set varied based on these thresholds. It was observed that once a sentence recurrence surpassed 100 times, the incremental growth of the training set size as well as the number of unique concepts was marginal, registering below 2%. Furthermore, if the threshold is set higher, the number of unique semantic types included in the training set will not exceed 98. As a result, we chose 100 as our cut-off point.<fig id="Fig3"><label>Fig. 3</label><caption><p>Impact of different thresholds for max sentence repetition in the training set. Left: Impact on the training set size; Center: Impact on the frequency of unique concepts; Right: Impact on the frequency of unique UMLS semantic types.</p></caption><graphic xlink:href="41597_2024_3317_Fig3_HTML" id="d33e2106"/></fig></p></sec><sec id="Sec11"><title>Quality control</title><p id="Par34">UMLS is known as a broadly used resource in the biomedical domain, covering a wide range of biomedical concepts. A key feature of UMLS is its capability to connect a wide range of concepts from different biomedical terminologies, such as SNOMED CT, LOINC, MeSH, RxNorm, etc. Through this mapping, one single code from a source terminology can be mapped to several UMLS CUI codes. For instance, MeSH code D020274, which represents &#x0201c;Depressive Disorder&#x0201d; is mapped to three distinct UMLS CUIs, C5671289, C0751871, and C0751872, for &#x0201c;Autoimmune Encephalitis&#x0201d;, &#x0201c;Autoimmune Diseases of the Nervous System&#x0201d; and &#x0201c;Immune Disorders, Nervous System&#x0201d;, respectively. In our dataset, there are instances where different CUI codes are assigned to the target concepts, resulting in the <italic>False</italic> label. However, the CUI codes and the confusion and same code in alternative ontologies, underlying concepts represented by those codes are equivalent. To prevent any confusion and to ensure the dataset&#x02019;s reliability, we have employed a pruning strategy and removed the instances in which the target terms are mapped to multiple UMLS codes, while those UMLS codes correspond to the same code in another ontology. The process also involved eliminating any pairs whose CUIs are considered synonyms as per the <italic>MRREL.RRF</italic> file from UMLS. We also followed WiC<sup><xref ref-type="bibr" rid="CR26">26</xref></sup> and XL-WiC<sup><xref ref-type="bibr" rid="CR27">27</xref></sup> and filtered out all the pairs where one CUI is directly related to the other as a broader concept in the UMLS hierarchy.</p></sec><sec id="Sec12"><title>Cross-mapping validation</title><p id="Par35">To determine the quality of BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>, we extracted two random subsets of 100 instances (with 50 mutual instances) from the test set and asked two domain experts to label them. Both annotators were medical doctors with vast experience in semantic annotation. They were provided with a set of instructions including a short description of the task as well as a few examples of labeled instances. During the annotation process, no external information from UMLS or any other resources was provided to the experts. The annotators had Cohen&#x02019;s Kappa score of 0.84 which is representative of the high quality of the dataset. An average human-level accuracy of 0.80 (0.80 and 0.81 for annotator 1 and annotator 2 respectively) was obtained through the annotation process, which can be viewed as the upper bound for model performance.</p></sec><sec id="Sec13"><title>Dataset coverage</title><p id="Par36">In this section, we focus on the scope of the dataset by studying the unique CUI codes and comparing them to the total CUI present in UMLS. Additionally, we investigate the semantic types within the dataset, examining both the number included and the proportions among them. Table&#x000a0;<xref rid="Tab3" ref-type="table">3</xref> shows that BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> covers over 5,000 unique CUI codes from UMLS. Additionally, BioWiC includes almost 80% of UMLS semantic types, i.e., 99 out of 127, across different splits. This wide coverage is indicative of the dataset&#x02019;s comprehensive and its potential as a valuable resource for biomedical research. In Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>, we present the ratio of the top 10 semantic types and semantic groups included in BioWiC. Additionally, Table&#x000a0;<xref rid="Tab4" ref-type="table">4</xref> shows the frequency and proportion of target terms across different BioWiC splits, categorized by their token counts.<fig id="Fig4"><label>Fig. 4</label><caption><p>Distribution of UMLS semantic types and semantic groups in BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>. Left: Top 10 semantic types; Right: Top 10 semantic groups.</p></caption><graphic xlink:href="41597_2024_3317_Fig4_HTML" id="d33e2161"/></fig><table-wrap id="Tab4"><label>Table 4</label><caption><p>Distribution of terms based on token count across different BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> splits, presented in counts and corresponding proportion.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Tokens per term</th><th colspan="2">Train</th><th colspan="2">Dev</th><th colspan="2">Test</th><th colspan="2">All</th></tr><tr><th>#</th><th>%</th><th>#</th><th>%</th><th>#</th><th>%</th><th>#</th><th>%</th></tr></thead><tbody><tr><td>1</td><td>22011</td><td>64</td><td>1385</td><td>69</td><td>2987</td><td>74</td><td>26383</td><td>65</td></tr><tr><td>2</td><td>8893</td><td>26</td><td>458</td><td>23</td><td>784</td><td>20</td><td>10135</td><td>25</td></tr><tr><td>3</td><td>2406</td><td>7</td><td>118</td><td>06</td><td>166</td><td>4</td><td>2690</td><td>7</td></tr><tr><td>4+</td><td>1030</td><td>3</td><td>39</td><td>02</td><td>63</td><td>2</td><td>1132</td><td>3</td></tr><tr><td>All</td><td>34340</td><td>100</td><td>2000</td><td>100</td><td>4000</td><td>100</td><td>40340</td><td>100</td></tr></tbody></table><table-wrap-foot><p>&#x0201c;4+&#x0201d; indicates terms with four or more tokens.</p></table-wrap-foot></table-wrap></p><p id="Par37">Compared to WSD datasets in the biomedical domain, BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> stands out as the most comprehensive in terms of the variety of unique biomedical terms it includes, covering a total of 7&#x02019;413 distinct terms. This range far surpasses that of other datasets, such as MSH WSD<sup><xref ref-type="bibr" rid="CR24">24</xref></sup> with 203 terms, NLM WSD<sup><xref ref-type="bibr" rid="CR25">25</xref></sup> with 50 terms, and WiC-TSV<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>, which includes only 8 terms. Moreover, the extensive scope of BioWiC is emphasized by its incorporation of 99 different semantic types from UMLS, in contrast to the narrower range covered by other datasets, i.e., MSH WSD<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>, NLM WSD<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>, and WiC-TSV<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>, which include 81, 46, and 8 UMLS semantic types respectively.</p></sec><sec id="Sec14"><title>Baseline experiments</title><p id="Par38">We have implemented several baseline models, covering all the SuperGLUE<sup><xref ref-type="bibr" rid="CR28">28</xref></sup> benchmark suites. Considering that all divisions of BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> are balanced in terms of positive and negative instances, we take the same approach as WiC<sup><xref ref-type="bibr" rid="CR26">26</xref></sup> and use the <italic>accuracy</italic> metric to measure the performance of different models. This is determined by the percentage of correctly predicted cases (whether they are true positives or true negatives) compared to the total number of samples. The baselines include:</p><p id="Par39"><bold>Random:</bold> We provide a lower bound for the performance by randomly assigning a class to each instance.</p><p id="Par40"><bold>GloVe:</bold> In this baseline, we used GloVe-840B<sup><xref ref-type="bibr" rid="CR40">40</xref></sup> pre-trained embeddings. We averaged token embeddings to represent each sentence and fed the resulting feature vector to an MLP classifier (with 128 neurons in the hidden layer and one neuron in the output layer).</p><p id="Par41"><bold>Bi-LSTM:</bold> We also trained a BiLSTM model (with 128 hidden units) to capture both the forward and backward context information of the sentence. The BiLSTM model output was fed into a fully connected layer with one output neuron for binary classification.</p><p id="Par42"><bold>BERT:</bold> We explored the performance of several BERT-based models to provide stronger baselines for the BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> task. To evaluate well language model&#x02019;s performance generalized to concepts of the biomedical domain, our baseline includes three general transformer-based language models &#x02013; BERT<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>, RoBERTa<sup><xref ref-type="bibr" rid="CR42">42</xref></sup>, and ELECTRA<sup><xref ref-type="bibr" rid="CR43">43</xref></sup>. In addition, to assess the effect of prior knowledge of language models on biomedical concept representation, we evaluated the performance of three language models pre-trained with biomedical and clinical data &#x02013; BioBERT<sup><xref ref-type="bibr" rid="CR44">44</xref></sup>, Bio_ClinicalBERT<sup><xref ref-type="bibr" rid="CR45">45</xref></sup>, and SciBERT<sup><xref ref-type="bibr" rid="CR46">46</xref></sup> trained on PubMed abstracts and PubMed Central, the MIMIC-III database<sup><xref ref-type="bibr" rid="CR47">47</xref></sup>, and papers from Semantic Scholar (mostly in the biomedical domain), respectively. To fine-tune each model, we used the Sentence-BERT<sup><xref ref-type="bibr" rid="CR48">48</xref></sup> framework, which incorporates siamese and triplet network architectures to generate semantically meaningful embeddings. We pre-processed each input sentence by enclosing the target terms within double quotes, emphasizing their significance, and fed the modified sentences into the BERT architecture for further processing. We have also used a different pre-processing technique for input sentences in our BERT models. Supplemental Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref> in the Supplementary Information section compares the results of both strategies.</p><p id="Par43"><bold>Llama-2:</bold> We also conducted experiments using three different versions of the Llama-2 language model, i.e., Llama-2-7b, Llama-2-13b, and Llama-2-70b<sup><xref ref-type="bibr" rid="CR49">49</xref></sup>. Our experiments involve a few-shot approach where the language model receives a small number of examples before making predictions and a fine-tuning approach, where we utilized the BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> instances to fine-tune the language models.</p><p id="Par44"><bold>BERT/Llama-2++:</bold> We conducted additional experiments where we incorporated the general domain data from the WiC dataset<sup><xref ref-type="bibr" rid="CR26">26</xref></sup> as additional training data for fine-tuning the transformer-base models. By expanding our training data with extra instances from the general domain, we aim to explore the potential benefits of leveraging diverse sources of information for the BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> task.</p></sec></sec><sec id="Sec15" sec-type="results"><title>Results</title><p id="Par45">The performance of the baseline models on the BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> benchmark is presented in Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>. The results indicate that the state-of-the-art language models fine-tuned on the BioWiC training set, surpass the random baseline by a margin of 18% to 26% (<italic>p</italic>-value&#x02009;&#x0003c;&#x02009;0.001). Both GloVe and BiLSTM baselines are unable to compete with the fine-tuned large language models. Overall, Llama-2-70b outperforms all competing methods, achieving the highest accuracy. The closest to the Llama-2-70b model in terms of accuracy are BioBERT, BioBERT++, and SciBERT++, which Llama-2-70b outperforms by 2% (<italic>p</italic>-value&#x02009;=&#x02009;0.04). It is worth noting that in contrast to the different variations of the Lamma-2 language model, which are pre-trained on general domain corpora, BioBERT is pre-trained on large biomedical data, allowing it to understand complex biomedical texts effectively<sup><xref ref-type="bibr" rid="CR44">44</xref></sup>. However, Llama-2-70b achieves state-of-the-art performance, illustrating its high capability for adapting to the task of representing biomedical terms in context.<fig id="Fig5"><label>Fig. 5</label><caption><p>Accuracy of the baseline models on the BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> test set. ++ indicates that data from WiC was added to the training set. Min, mean, median, and max statistics exclude the random performance.</p></caption><graphic xlink:href="41597_2024_3317_Fig5_HTML" id="d33e2476"/></fig></p><p id="Par46">In our analysis of different Llama-2 models, we observe a significant difference in performance depending on the method used in our evaluation, i.e., few-shot learning or fine-tuning. As shown in Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>, Llama-2-7b surpassed the random baseline by a slight margin in the few-shot setting; however, its performance increased by 17% upon fine-tuning (<italic>p</italic>-value&#x02009;&#x0003c;&#x02009;0.001). This pattern of performance boost was consistent with the other Llama-2 variants. Specifically, after the fine-tuning process, the accuracy of Llama-2-13b improved from 0.61 to 0.73 (<italic>p</italic>-value&#x02009;&#x0003c;&#x02009;0.001), while Llama-2-70b experienced an increase from 0.68 to 0.78 (<italic>p</italic>-value&#x02009;&#x0003c;&#x02009;0.001). These observations emphasize the crucial role of the fine-tuning phase in enhancing the contextualized representation of biomedical terms. Additionally, our results are consistent with a prior study<sup><xref ref-type="bibr" rid="CR50">50</xref></sup>, which demonstrated that the GPT-3 language model failed to surpass random baseline performance on the WiC dataset under a few-shot evaluation.</p><p id="Par47">Comparing the performance of different BERT-based models shows that BioBERT and SciBERT achieve the highest performance among different groups of the test set. Overall, BioBERT outperforms SciBERT by a slight margin of 1% accuracy, i.e., 0.75 and 0.76 (<italic>p</italic>-value&#x02009;=&#x02009;0.04), respectively. The potential reason for the superior performance of BioBERT and SciBERT can be attributed to their pre-training phase on large biomedical corpora. This provides them with an in-depth knowledge of biomedical terminologies and concepts, leading to more accurate representations of terms and expressions when compared to BERT-based models pre-trained on the general domain corpora<sup><xref ref-type="bibr" rid="CR44">44</xref></sup>. Surprisingly, Bio_ClinicalBERT performance is similar to the general domain BERT models and does not align with other superior biomedical BERT variants.</p><p id="Par48">Further analysis of the results for different groups indicates that the &#x0201c;term identity&#x0201d; and &#x0201c;synonyms&#x0201d; groups present a greater challenge compared to the other groups for all models. Regarding model performance for the &#x0201c;label similarity&#x0201d; group, it is plausible that minor changes in term structure carry meaningful distinctions in biomedical contexts. Models might utilize structural alterations, such as the addition of suffixes or prefixes, influencing the meanings of terms. This understanding of term structure can be particularly relevant and beneficial for performance in the &#x0201c;label similarity&#x0201d; group. As for the &#x0201c;abbreviations&#x0201d; group, it is important to note that abbreviations are commonly used in the biomedical domain. The models may have come across these abbreviations (along with their full form) in various contexts during both the pre-training and fine-tuning phases. This exposure to abbreviations in diverse settings helps the models to effectively learn and capture their meanings. The group of &#x0201c;synonym&#x0201d; instances appears to be more difficult for models to handle. This might be because, in the biomedical field, a single term can have multiple synonyms with varied forms and each synonym can have multiple meanings (as shown in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>) which makes it hard for the models to recognize synonym terms with different shapes across different contexts. For the &#x0201c;term identity&#x0201d; group, since this group of instances doesn&#x02019;t present any difference between the target terms, the models cannot rely on lexical cues and must prioritize the comprehension of the contextual information from the surrounding context, which makes the task more challenging.</p><p id="Par49">In our study, we also conducted experiments in which we incorporated general domain training data from WiC<sup><xref ref-type="bibr" rid="CR26">26</xref></sup> into our dataset (denoted by adding++ to the name of the language model). We observe slight fluctuations in the performance of the models when merging general and biomedical domain datasets. It could be possibly explained by the fact that the model faces potential distribution shifts due to the distinct nature of each domain. Despite the increased volume of training data, this misalignment in data distributions can offset the advantages of the added samples. Thus, while the combined dataset is larger, it may not necessarily lead to improved model performance in the biomedical context.</p><sec id="Sec16"><title>Alternative evaluation scenarios</title><p id="Par50">To gain a deeper understanding of how models perform in the BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> benchmark, we analyzed their performance in two alternative scenarios. First, we assessed how the data distribution impact their results. Here, we considered seen and unseen data distributions. Second, we assessed what is the influence of the training corpus on the performance. Differently, in this scenario, we are interested to see whether learning from general corpus examples would enable models to generalise to the biomedical domain.</p><p id="Par51"><bold>Seen vs unseen:</bold> In this analysis, the aim is to evaluate the variation in performance based on whether the target terms in the instances have been previously seen during training or not. For this purpose, we used the models fine-tuned on the BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> training set and divided the test set into two categories: &#x0201c;seen&#x0201d; and &#x0201c;unseen&#x0201d;. The first category includes instances where the model has been exposed to at least one of the target terms during training, while the second category involves instances where both target terms are new to the model. Table&#x000a0;<xref rid="Tab5" ref-type="table">5</xref> reports the number and proportion of seen and unseen data across different groups within the BioWiC test set. Note that term pairs (the two target terms of each instance) and the sentences in the test set are unique and were not presented to the model during its training phase.<table-wrap id="Tab5"><label>Table 5</label><caption><p>Distribution of seen and unseen instances in different groups of BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> test set.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Instance group</th><th colspan="2">Seen</th><th colspan="2">Unseen</th><th colspan="2">All</th></tr><tr><th>#</th><th>%</th><th>#</th><th>%</th><th>#</th><th>%</th></tr></thead><tbody><tr><td>Term identity</td><td>412</td><td>52</td><td>388</td><td>48</td><td>800</td><td>100</td></tr><tr><td>Abbreviations</td><td>190</td><td>95</td><td>10</td><td>5</td><td>200</td><td>100</td></tr><tr><td>Synonyms</td><td>675</td><td>84</td><td>125</td><td>16</td><td>800</td><td>100</td></tr><tr><td>Label similarity</td><td>179</td><td>90</td><td>21</td><td>10</td><td>200</td><td>100</td></tr><tr><td>All</td><td>1457</td><td>73</td><td>543</td><td>27</td><td>2000</td><td>100</td></tr></tbody></table></table-wrap></p><p id="Par52">Table&#x000a0;<xref rid="Tab6" ref-type="table">6</xref> shows the accuracy of different models, fine-tuned on the BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> training set when tested on seen and unseen data sets. As we can see, the models exhibit a significant decline in performance, i.e., between 5% and 13%, when classifying unseen instances. Interestingly, models demonstrate improved performance on the unseen data in the &#x0201c;abbreviation&#x0201d; groups, aligning with the notion that abbreviations are prevalent across contexts and models may possess prior knowledge in this aspect. Overal, the findings suggest that there is huge scope for improvement in this field, particularly as the performance of models decreases when encountering novel data.<table-wrap id="Tab6"><label>Table 6</label><caption><p>Comparative analysis of model accuracy on BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> test set.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Model</th><th colspan="2">Distribution</th><th colspan="2">Training set</th></tr><tr><th>Seen</th><th>Unseen</th><th>WiC</th><th>BioWiC</th></tr></thead><tbody><tr><td>BERT</td><td>0.72</td><td>0.67</td><td>0.63</td><td>0.70</td></tr><tr><td>ELECTRA</td><td>0.69</td><td>0.64</td><td>0.62</td><td>0.68</td></tr><tr><td>RoBERTa</td><td>0.74</td><td>0.64</td><td>0.63</td><td>0.71</td></tr><tr><td>BioBERT</td><td>0.79</td><td>0.67</td><td>0.64</td><td>0.76</td></tr><tr><td>Bio_ClinicalBERT</td><td>0.73</td><td>0.62</td><td>0.62</td><td>0.70</td></tr><tr><td>SciBERT</td><td>0.77</td><td>0.68</td><td>0.64</td><td>0.75</td></tr><tr><td>Llama-2-7b-fine-tuned</td><td>0.72</td><td>0.59</td><td>0.50</td><td>0.68</td></tr><tr><td>Llama-2-13b-fine-tuned</td><td>0.76</td><td>0.64</td><td>0.51</td><td>0.73</td></tr><tr><td>Llama-2-70b-fine-tuned</td><td>0.80</td><td>0.70</td><td>0.51</td><td>0.78</td></tr></tbody></table><table-wrap-foot><p>Left: performance of the models trained using BioWiC on the seen data vs unseen data distributions. Right: performance using WiC or BioWiC as the training set.</p></table-wrap-foot></table-wrap></p><p id="Par53"><bold>Cross-domain analysis:</bold> We conducted additional experiments to assess the performance of language models when fine-tuned exclusively on data from the general domain, specifically WiC. The results indicate that all models experience a substantial decrease in performance when fine-tuned only with WiC data (Table&#x000a0;<xref rid="Tab6" ref-type="table">6</xref>). This highlights the importance of the training data provided by BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> in enhancing the ability of language models in the representation of different forms of concepts within the biomedical field. Furthermore, this suggests that the differences in terminology and linguistic patterns between the biomedical and general domains might be a reason why models fine-tuned on BioWiC exhibit superior performance.</p><p id="Par54"><bold>Evaluating models&#x02019; upper bound:</bold> To assess whether state-of-the-art models have reached an upper bound on the BioWiC dataset, we leveraged two subsets of 100 instances from the BioWiC test set that were manually annotated by subject matter experts (see the cross-mapping validation section for more details). On the 50 instances annotated by both experts, we observed strong inter-annotator agreement (Cohen&#x02019;s Kappa score&#x02009;=&#x02009;0.84), confirming the quality of the dataset annotations. However, the best-performing model (Llama-2-70b) exhibited low agreement with the human annotators on this mutually annotated subset (Cohen&#x02019;s Kappa scores of 0.35 and 0.36). The pattern of discrepancies between human and model annotations persisted across the two subsets of 100 instances (Cohen&#x02019;s Kappa scores of 0.33 and 0.47 for annotators 1 and 2, respectively). These results highlight the substantial room for improvement of language models to represent contextualized biomedical terms.</p></sec></sec><sec id="Sec17"><title>Usage Notes</title><p id="Par55">The primary objective of this study is to develop a novel biomedical dataset, BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>, introducing unique challenges for biomedical concept representation. The complexity of the biomedical language, with its abundance of polysemous terms, abbreviations, and acronyms, highlights the need for models to accurately disambiguate the intended meanings of terms based on the context they appear. We propose that BioWiC can serve as a robust benchmark dataset, enabling NLP models to better understand the intended meaning of biomedical terms within their given textual context, allowing models to generate representations that precisely capture those intended meanings across different contexts. This enhanced contextual understanding is critical for several downstream NLP tasks in the biomedical domain, such as information retrieval, question-answering, and machine translation, where accurately interpreting the meaning of terms within their specific context is essential for optimal model performance<sup><xref ref-type="bibr" rid="CR51">51</xref></sup>.</p><p id="Par56">The proposed benchmark has certain limitations that should be taken into consideration. The breadth of coverage of concepts is rather limited as BioWiC<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> only deals with a small subset of the concepts present in the biomedical domain, i.e., 5&#x02019;000 CUIs out of 4.5&#x02009;M CUI codes available in UMLS. Moreover, it may not be adequate for certain use cases that require a specific coverage of concepts, e.g., genomics and proteomics. Additionally, our benchmark is currently designed to work with medical documents written in English only. Lastly, it is a static benchmark, in the sense that it does not currently provide a seamless platform (i.e., web service) for users to contribute to it through crowd-sourcing. This limits the ability to keep the benchmark up-to-date and reflective of the latest developments in the biomedical domain. These limitations can be addressed in future versions of the benchmark.</p></sec><sec sec-type="supplementary-material"><sec id="Sec18"><title>Supplementary information</title><p>
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="41597_2024_3317_MOESM1_ESM.docx"><caption><p>Supplementary information</p></caption></media></supplementary-material>
</p></sec></sec></body><back><fn-group><fn><p><bold>Publisher&#x02019;s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><sec><title>Supplementary information</title><p>The online version contains supplementary material available at 10.1038/s41597-024-03317-w.</p></sec><notes notes-type="author-contribution"><title>Author contributions</title><p>H.R. and D.T. conceptualized the study, and H.R., A.Y. and B.Z. implemented the codes for the creation and evaluation of the dataset. J.E. and C.G. performed human annotation. The manuscript was drafted by H.R., D.T. and I.N. and edited by A.B., A.Y. and N.N. All authors reviewed the final version.</p></notes><notes notes-type="data-availability"><title>Code availability</title><p>The entire process, including the development of the dataset<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> and the conduction of experiments, was implemented using the Python programming language. The complete code and dataset are hosted on GitHub at: <ext-link ext-link-type="uri" xlink:href="https://github.com/hrouhizadeh/BioWiC">https://github.com/hrouhizadeh/BioWiC</ext-link>.</p></notes><notes id="FPar1" notes-type="COI-statement"><title>Competing interests</title><p id="Par57">The authors declare no competing interests.</p></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><mixed-citation publication-type="other">Detroja, K., Bhensdadia, C. &#x00026; Bhatt, B. S. A survey on relation extraction. <italic>Intell. Syst. with Appl</italic>. 200244 (2023).</mixed-citation></ref><ref id="CR2"><label>2.</label><mixed-citation publication-type="other">Shi, J. <italic>et al</italic>. Knowledge-graph-enabled biomedical entity linking: a survey. <italic>World Wide Web</italic> 1&#x02013;30 (2023).</mixed-citation></ref><ref id="CR3"><label>3.</label><mixed-citation publication-type="other">French, E. &#x00026; McInnes, B. T. An overview of biomedical entity linking throughout the years. <italic>J. Biomed. Informatic</italic> 104252 (2022).</mixed-citation></ref><ref id="CR4"><label>4.</label><mixed-citation publication-type="other">Yazdani, A., Proios, D., Rouhizadeh, H. &#x00026; Teodoro, D. Efficient joint learning for clinical named entity recognition and relation extraction using Fourier networks:a use case in adverse drug events. In Akhtar, M. S. &#x00026; Chakraborty, T. (eds.) Proceedings of the 19th International Conference on Natural Language Processing (ICON), 212&#x02013;223 (Association for Computational Linguistics, New Delhi, India, 2022)</mixed-citation></ref><ref id="CR5"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Naderi</surname><given-names>N</given-names></name><name><surname>Knafou</surname><given-names>J</given-names></name><name><surname>Copara</surname><given-names>J</given-names></name><name><surname>Ruch</surname><given-names>P</given-names></name><name><surname>Teodoro</surname><given-names>D</given-names></name></person-group><article-title>Ensemble of deep masked language models for effective named entity recognition in health and life science corpora</article-title><source>Front. research metrics analytics</source><year>2021</year><volume>6</volume><fpage>689803</fpage><pub-id pub-id-type="doi">10.3389/frma.2021.689803</pub-id></element-citation></ref><ref id="CR6"><label>6.</label><mixed-citation publication-type="other">Copara, J. <italic>et al</italic>. Contextualized french language models for biomedical named entity recognition. In Actes de la 6e conf&#x000e9;rence conjointe Journ&#x000e9;es d&#x02019;&#x000c9;tudes sur la Parole (JEP, 33e &#x000e9;dition), Traitement Automatique des Langues Naturelles (TALN, 27e &#x000e9;dition), Rencontre des &#x000c9;tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R&#x000c9;CITAL, 22e &#x000e9;dition). Atelier D&#x000c9;fi Fouille de Textes, 36&#x02013;48 (2020).</mixed-citation></ref><ref id="CR7"><label>7.</label><mixed-citation publication-type="other">He, J. <italic>et al</italic>. An extended overview of the clef 2020 chemu lab: information extraction of chemical reactions from patents. In <italic>Proceedings of the CLEF 2020 conference</italic> (22-25 September 2020, 2020).</mixed-citation></ref><ref id="CR8"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Donnelly</surname><given-names>K</given-names></name><etal/></person-group><article-title>Snomed-ct: The advanced terminology and coding system for ehealth</article-title><source>Stud. health technology informatics</source><year>2006</year><volume>121</volume><fpage>279</fpage><?supplied-pmid 17095826?><pub-id pub-id-type="pmid">17095826</pub-id>
</element-citation></ref><ref id="CR9"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Consortium</surname><given-names>U</given-names></name><etal/></person-group><article-title>Uniprot: the universal protein knowledgebase in 2021</article-title><source>Nucleic acids research</source><year>2021</year><volume>49</volume><fpage>D480</fpage><lpage>D489</lpage><pub-id pub-id-type="doi">10.1093/nar/gkaa1100</pub-id><pub-id pub-id-type="pmid">33237286</pub-id>
</element-citation></ref><ref id="CR10"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Erhardt</surname><given-names>RA</given-names></name><name><surname>Schneider</surname><given-names>R</given-names></name><name><surname>Blaschke</surname><given-names>C</given-names></name></person-group><article-title>Status of text-mining techniques applied to biomedical text</article-title><source>Drug discoverytoday</source><year>2006</year><volume>11</volume><fpage>315</fpage><lpage>325</lpage></element-citation></ref><ref id="CR11"><label>11.</label><mixed-citation publication-type="other">Sung, M., Jeon, H., Lee, J. &#x00026; Kang, J. Biomedical entity representations with synonym marginalization. In Jurafsky, D., Chai, J., Schluter, N. &#x00026; Tetreault, J. (eds.) <italic>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</italic>, 3641&#x02013;3650, 10.18653/v1/2020.acl-main.335 (Association for Computational Linguistics, Online, 2020).</mixed-citation></ref><ref id="CR12"><label>12.</label><mixed-citation publication-type="other">Alexopoulou, D. <italic>et al</italic>. Biomedical word sense disambiguation with ontologies and metadata: automation meets accuracy.<italic>BMC bioinformatics</italic><bold>10</bold>, 1&#x02013;15 (2009).</mixed-citation></ref><ref id="CR13"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miftahutdinov</surname><given-names>Z</given-names></name><name><surname>Kadurin</surname><given-names>A</given-names></name><name><surname>Kudrin</surname><given-names>R</given-names></name><name><surname>Tutubalina</surname><given-names>E</given-names></name></person-group><article-title>Medical concept normalization in clinical trials with drug anddisease representation learning</article-title><source>Bioinformatics</source><year>2021</year><volume>37</volume><fpage>3856</fpage><lpage>3864</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btab474</pub-id><?supplied-pmid 34213526?><pub-id pub-id-type="pmid">34213526</pub-id>
</element-citation></ref><ref id="CR14"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tutubalina</surname><given-names>E</given-names></name><name><surname>Miftahutdinov</surname><given-names>Z</given-names></name><name><surname>Nikolenko</surname><given-names>S</given-names></name><name><surname>Malykh</surname><given-names>V</given-names></name></person-group><article-title>Medical concept normalization in social media posts with recurrent neural networks</article-title><source>J. biomedical informatics</source><year>2018</year><volume>84</volume><fpage>93</fpage><lpage>102</lpage><pub-id pub-id-type="doi">10.1016/j.jbi.2018.06.006</pub-id><?supplied-pmid 29906585?><pub-id pub-id-type="pmid">29906585</pub-id>
</element-citation></ref><ref id="CR15"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niu</surname><given-names>J</given-names></name><name><surname>Yang</surname><given-names>Y</given-names></name><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>Sun</surname><given-names>Z</given-names></name><name><surname>Zhang</surname><given-names>W</given-names></name></person-group><article-title>Multi-task character-level attentional networks for medical concept normalization</article-title><source>Neural Process. Lett.</source><year>2019</year><volume>49</volume><fpage>1239</fpage><lpage>1256</lpage><pub-id pub-id-type="doi">10.1007/s11063-018-9873-x</pub-id></element-citation></ref><ref id="CR16"><label>16.</label><mixed-citation publication-type="other">Limsopatham, N. &#x00026; Collier, N. Normalising medical concepts in social media texts by learning semantic representation. In <italic>Proceedings of the 54th annual meeting of the association for computational linguistics (volume 1: long papers)</italic>, 1014&#x02013;1023 (2016).</mixed-citation></ref><ref id="CR17"><label>17.</label><mixed-citation publication-type="other">Mohan, S. &#x00026; Li, D. Medmentions: A large biomedical corpus annotated with umls concepts. In <italic>Automated Knowledge Base Construction (AKBC)</italic> (2019).</mixed-citation></ref><ref id="CR18"><label>18.</label><mixed-citation publication-type="other">Li, J. <italic>et al</italic>. Biocreative v cdr task corpus: a resource for chemical disease relation extraction. <italic>Database</italic><bold>2016</bold> (2016).</mixed-citation></ref><ref id="CR19"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luo</surname><given-names>Y-F</given-names></name><name><surname>Sun</surname><given-names>W</given-names></name><name><surname>Rumshisky</surname><given-names>A</given-names></name></person-group><article-title>MCN: a comprehensive corpus for medical concept normalization</article-title><source>J. biomedical informatics</source><year>2019</year><volume>92</volume><fpage>103132</fpage><pub-id pub-id-type="doi">10.1016/j.jbi.2019.103132</pub-id><?supplied-pmid 30802545?><pub-id pub-id-type="pmid">30802545</pub-id>
</element-citation></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="other">Basaldella, M., Liu, F., Shareghi, E. &#x00026; Collier, N. COMETA: A corpus for medical entity linking in the social media. In <italic>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), 3122&#x02013;3137,7010.18653/v1/2020.emnlp-main</italic>. (Association for Computational Linguistics, Online, 2020).</mixed-citation></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="other">Yazdani, A., Rouhizadeh, H., Alvarez, D. V. &#x00026; Teodoro, D. Ds4dh at# smm4h 2023: zero-shot adverse drug events normalization using sentence transformers and reciprocal-rank fusion. arXiv preprint arXiv:2308.12877 (2023).</mixed-citation></ref><ref id="CR22"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Navigli</surname><given-names>R</given-names></name></person-group><article-title>Word sense disambiguation: A survey</article-title><source>ACM computing surveys (CSUR)</source><year>2009</year><volume>41</volume><fpage>1</fpage><lpage>69</lpage><pub-id pub-id-type="doi">10.1145/1459352.1459355</pub-id></element-citation></ref><ref id="CR23"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moro</surname><given-names>A</given-names></name><name><surname>Raganato</surname><given-names>A</given-names></name><name><surname>Navigli</surname><given-names>R</given-names></name></person-group><article-title>Entity linking meets word sense disambiguation: a unified approach</article-title><source>Transactions Assoc. for Comput. Linguist.</source><year>2014</year><volume>2</volume><fpage>231</fpage><lpage>244</lpage><pub-id pub-id-type="doi">10.1162/tacl_a_00179</pub-id></element-citation></ref><ref id="CR24"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jimen-Yepes</surname><given-names>A</given-names></name><name><surname>McInnes</surname><given-names>B</given-names></name><name><surname>Aronson</surname><given-names>A</given-names></name></person-group><article-title>Exploiting MeSH indexing in MEDLINE to generate a data set for word sense disambiguation</article-title><source>BMC Bioinformatics</source><year>2011</year><volume>12</volume><issue>1</issue><fpage>223</fpage><pub-id pub-id-type="doi">10.1186/1471-2105-12-223</pub-id><pub-id pub-id-type="pmid">21635749</pub-id>
</element-citation></ref><ref id="CR25"><label>25.</label><mixed-citation publication-type="other">Weeber M, Mork J, Aronson A: Developing a test collection for biomedical word sense disambiguation. <italic>Proceedings of the AMIA Symposium, American Medical Informatics Association</italic><bold>2001</bold>, 746.</mixed-citation></ref><ref id="CR26"><label>26.</label><mixed-citation publication-type="other">Pilehvar, M. T. &#x00026; Camacho-Collados, J. WiC: the word-in-context dataset for evaluating context-sensitive meaning representations. In <italic>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</italic>, 1267&#x02013;1273, 10.18653/v1/N19-1128 (Association for Computational Linguistics, Minneapolis, Minnesota, 2019).</mixed-citation></ref><ref id="CR27"><label>27.</label><mixed-citation publication-type="other">Raganato, A., Pasini, T., Camacho-Collados, J. &#x00026; Pilehvar, M. T. XL-WiC: A multilingual benchmark for evaluating semantic contextualization. In <italic>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</italic>, 7193&#x02013;7206, 10.18653/v1/2020.emnlp-main.584 (Association for Computational Linguistics, Online, 2020).</mixed-citation></ref><ref id="CR28"><label>28.</label><mixed-citation publication-type="other">Wang, A. <italic>et al</italic>. Superglue: A stickier benchmark for general-purpose language understanding systems. <italic>Adv. neural information processing systems</italic><bold>32</bold> (2019).</mixed-citation></ref><ref id="CR29"><label>29.</label><mixed-citation publication-type="other">Loureiro, D. <italic>et al</italic>. TempoWiC: An evaluation benchmark for detecting meaning shift in social media. In Calzolari, N. <italic>et al</italic>. (eds.) <italic>Proceedings of the 29th International Conference on Computational Linguistics</italic>, 3353&#x02013;3359 (International Committee on Computational Linguistics, Gyeongju, Republic of Korea, 2022).</mixed-citation></ref><ref id="CR30"><label>30.</label><mixed-citation publication-type="other">Breit, A., Revenko, A., Rezaee, K., Pilehvar, M. T. &#x00026; Camacho-Collados, J. WiC-TSV: An evaluation benchmark for target sense verification of words in context. In <italic>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</italic>, 1635&#x02013;1645, 10.18653/v1/2021.eacl-main.140 (Association for Computational6Linguistics, 2021).</mixed-citation></ref><ref id="CR31"><label>31.</label><mixed-citation publication-type="other">Sameer Singh, Amarnag Subramanya, Fernando Pereira, and Andrew McCallum. 2012. Wikilinks: A large-scale cross-document coreference corpus labeled via links to Wikipedia. Technical Report UM-CS-2012-015, University of Massachusetts, Amherst.</mixed-citation></ref><ref id="CR32"><label>32.</label><mixed-citation publication-type="other">Miftahutdinov, Z. &#x00026; Tutubalina, E. Deep neural models for medical concept normalization in user-generated texts. In <italic>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</italic>, 393&#x02013;399, 10.18653/v1/P19-2055 (Association for Computational Linguistics, Florence, Italy, 2019).</mixed-citation></ref><ref id="CR33"><label>33.</label><mixed-citation publication-type="other">Liu, F., <italic>et al</italic>. (eds.) <italic>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</italic>, 4228&#x02013;4238, 10.18653/v1/2021.naacl-main.334 (Association for Computational Linguistics, Online, 2021).</mixed-citation></ref><ref id="CR34"><label>34.</label><mixed-citation publication-type="other">Angell, R., <italic>et al</italic>. (eds.) <italic>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</italic>, 2598&#x02013;2608, 10.18653/v1/2021.naacl-main.205 (Association for Computational Linguistics, Online, 2021).</mixed-citation></ref><ref id="CR35"><label>35.</label><element-citation publication-type="data"><name><surname>Rouhizadeh</surname><given-names>H</given-names></name><etal/><year>2024</year><data-title>A Dataset for Evaluating Contextualized Representation of Biomedical Concepts in Language Models</data-title><source>figshare</source><pub-id pub-id-type="doi">10.6084/m9.figshare.25611591.v2</pub-id></element-citation></ref><ref id="CR36"><label>36.</label><mixed-citation publication-type="other">Loureiro, D. &#x00026; Jorge, A. M. Medlinker: Medical entity linking with neural representations and dictionary matching. In <italic>European Conference on Information Retrieval</italic>, 230&#x02013;237 (Springer, 2020).</mixed-citation></ref><ref id="CR37"><label>37.</label><mixed-citation publication-type="other">Mohan, S., Angell, R., Monath, N. &#x00026; McCallum, A. Low resource recognition and linking of biomedical concepts from a large ontology. In <italic>Proceedings of the 12th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics</italic>, 1&#x02013;10 (2021).</mixed-citation></ref><ref id="CR38"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dogan</surname><given-names>RI</given-names></name><name><surname>Leaman</surname><given-names>R</given-names></name><name><surname>Lu</surname><given-names>Z</given-names></name></person-group><article-title>NCBI disease corpus: a resource for disease name recognition and concept normalization</article-title><source>J. biomedical informatics</source><year>2014</year><volume>47</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1016/j.jbi.2013.12.006</pub-id><?supplied-pmid 24393765?><pub-id pub-id-type="pmid">24393765</pub-id>
</element-citation></ref><ref id="CR39"><label>39.</label><mixed-citation publication-type="other">Sadvilkar, N. &#x00026; Neumann, M. PySBD: Pragmatic sentence boundary disambiguation. In <italic>Proceedings of Second Workshop for NLP Open Source Software (NLP-OSS)</italic>, 110&#x02013;114, 10.18653/v1/2020.nlposs-1.15 (Association for Computational Linguistics, Online, 2020).</mixed-citation></ref><ref id="CR40"><label>40.</label><mixed-citation publication-type="other">Pennington, J., Socher, R. &#x00026; Manning, C. D. Glove: Global vectors for word representation. In <italic>Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</italic>, 1532&#x02013;1543 (2014).</mixed-citation></ref><ref id="CR41"><label>41.</label><mixed-citation publication-type="other">Devlin, J., <italic>et al</italic> (eds.) <italic>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</italic>, 4171&#x02013;4186, 10.18653/v1/N19-1423 (Association for Computational Linguistics, Minneapolis, Minnesota, 2019).</mixed-citation></ref><ref id="CR42"><label>42.</label><mixed-citation publication-type="other">Liu, Y. <italic>et al</italic>. Roberta: A robustly optimized bert pretraining approach. <italic>arXiv preprint arXiv:1907.11692</italic> (2019).</mixed-citation></ref><ref id="CR43"><label>43.</label><mixed-citation publication-type="other">Clark, K., Luong, M.-T., Le, Q. V. &#x00026; Manning, C. D. Electra: Pre-training text encoders as discriminators rather than generators. <italic>arXiv preprint arXiv:2003.10555</italic> (2020).</mixed-citation></ref><ref id="CR44"><label>44.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>J</given-names></name><etal/></person-group><article-title>Biobert: a pre-trained biomedical language representation model for biomedical text mining</article-title><source>Bioinformatics</source><year>2020</year><volume>36</volume><fpage>1234</fpage><lpage>1240</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btz682</pub-id><?supplied-pmid 31501885?><pub-id pub-id-type="pmid">31501885</pub-id>
</element-citation></ref><ref id="CR45"><label>45.</label><mixed-citation publication-type="other">Alsentzer, E. <italic>et al</italic>. Publicly available clinical BERT embeddings. In <italic>Proceedings of the 2nd Clinical Natural Language Processing Workshop</italic>, 72&#x02013;78, 10.18653/v1/W19-1909 (Association for Computational Linguistics, Minneapolis, Minnesota, USA, 2019).</mixed-citation></ref><ref id="CR46"><label>46.</label><mixed-citation publication-type="other">Beltagy, I., Lo, K. &#x00026; Cohan, A. SciBERT: A pretrained language model for scientific text. In Inui, K., Jiang, J., Ng, V. &#x00026; Wan, X. (eds.) <italic>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9</italic><sup><italic>th</italic></sup><italic>International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</italic>, 3615&#x02013;3620, 10.18653/v1/D19-1371 (Association for Computational Linguistics, Hong Kong, China, 2019).</mixed-citation></ref><ref id="CR47"><label>47.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>AE</given-names></name><etal/></person-group><article-title>Mimic-iii, a freely accessible critical care database</article-title><source>Sci. data</source><year>2016</year><volume>3</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1038/sdata.2016.35</pub-id></element-citation></ref><ref id="CR48"><label>48.</label><mixed-citation publication-type="other">Reimers, N. &#x00026; Gurevych, I. Sentence-BERT: Sentence embeddings using Siamese BERT-networks. In Inui, K., Jiang, J., Ng, V. &#x00026; Wan, X. (eds.) <italic>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9</italic><sup><italic>th</italic></sup><italic>International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</italic>, 3982&#x02013;3992, 10.18653/v1/D19-1410 (Association for Computational Linguistics, Hong Kong, China, 2019).</mixed-citation></ref><ref id="CR49"><label>49.</label><mixed-citation publication-type="other">Touvron, H. <italic>et al</italic>. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288 (2023).</mixed-citation></ref><ref id="CR50"><label>50.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brwon</surname><given-names>T</given-names></name><etal/></person-group><article-title>Language models are few-shot learners</article-title><source>Adv. neural information processing systems</source><year>2020</year><volume>33</volume><fpage>1877</fpage><lpage>1901 454</lpage></element-citation></ref><ref id="CR51"><label>51.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hristea</surname><given-names>F</given-names></name><name><surname>Colhon</surname><given-names>M</given-names></name></person-group><article-title>The long road from performing word sense disambiguation to successfully using it in information retrieval: An overview of the unsupervised approach</article-title><source>Comput. Intell.</source><year>2020</year><volume>36</volume><fpage>1026</fpage><lpage>1062</lpage><pub-id pub-id-type="doi">10.1111/coin.12303</pub-id></element-citation></ref><ref id="CR52"><label>52.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fr&#x000e9;nal</surname><given-names>K</given-names></name><name><surname>Kemp</surname><given-names>LE</given-names></name><name><surname>Soldati-Favre</surname><given-names>D</given-names></name></person-group><article-title>Emerging roles for protein s-palmitoylation in toxoplasma biology</article-title><source>Int. J. forParasitol.</source><year>2014</year><volume>44</volume><fpage>121</fpage><lpage>131</lpage><pub-id pub-id-type="doi">10.1016/j.ijpara.2013.09.004</pub-id></element-citation></ref></ref-list></back></article>