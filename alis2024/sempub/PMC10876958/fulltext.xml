<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN" "JATS-archivearticle1-3-mathml3.dtd"> 
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><?properties open_access?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 1?><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sci Rep</journal-id><journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id><journal-title-group><journal-title>Scientific Reports</journal-title></journal-title-group><issn pub-type="epub">2045-2322</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="pmcid">10876958</article-id><article-id pub-id-type="publisher-id">54809</article-id><article-id pub-id-type="doi">10.1038/s41598-024-54809-z</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>SEGCN: a subgraph encoding based graph convolutional network model for social bot detection</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Liu</surname><given-names>Feng</given-names></name><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Li</surname><given-names>Zhenyu</given-names></name><address><email>li1989zhenyu@126.com</email></address><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Yang</surname><given-names>Chunfang</given-names></name><address><email>chunfangyang@126.com</email></address><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Gong</surname><given-names>Daofu</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Lu</surname><given-names>Haoyu</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><name><surname>Liu</surname><given-names>Fenlin</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/04ypx8c21</institution-id><institution-id institution-id-type="GRID">grid.207374.5</institution-id><institution-id institution-id-type="ISNI">0000 0001 2189 3846</institution-id><institution>School of Cyber Science and Engineering, </institution><institution>Zhengzhou University, </institution></institution-wrap>Zhengzhou, 450002 China </aff><aff id="Aff2"><label>2</label>Henan Provincial Key Laboratory of Cyberspace Situational Awareness, Zhenzhou, 450001 China </aff></contrib-group><pub-date pub-type="epub"><day>19</day><month>2</month><year>2024</year></pub-date><pub-date pub-type="pmc-release"><day>19</day><month>2</month><year>2024</year></pub-date><pub-date pub-type="collection"><year>2024</year></pub-date><volume>14</volume><elocation-id>4122</elocation-id><history><date date-type="received"><day>22</day><month>7</month><year>2023</year></date><date date-type="accepted"><day>16</day><month>2</month><year>2024</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2024</copyright-statement><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article&#x02019;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#x02019;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">Message passing neural networks such as graph convolutional networks (GCN) can jointly consider various types of features for social bot detection. However, the expressive power of GCN is upper-bounded by the 1st-order Weisfeiler&#x02013;Leman isomorphism test, which limits the detection performance for the social bots. In this paper, we propose a subgraph encoding based GCN model, SEGCN, with stronger expressive power for social bot detection. Each node representation of this model is computed as the encoding of a surrounding induced subgraph rather than encoding of immediate neighbors only. Extensive experimental results on two publicly available datasets, Twibot-20 and Twibot-22, showed that the proposed model improves the accuracy of the state-of-the-art social bot detection models by around 2.4%, 3.1%, respectively.</p></abstract><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>Computer science</kwd><kwd>Information technology</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>61872448</award-id><award-id>62002387</award-id><award-id>61772549</award-id><award-id>U1804263</award-id><award-id>62002386</award-id></award-group></funding-group><funding-group><award-group><funding-source><institution>the Science and Technology Research Project of Henan Province</institution></funding-source><award-id>No. 222102210075</award-id></award-group></funding-group><funding-group><award-group><funding-source><institution>the Key Research and Development Project of Henan Province, China</institution></funding-source><award-id>No. 221111321200</award-id></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; Springer Nature Limited 2024</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par2">With the rapid development of Internet technology, cybersecurity incidents in cyberspace are frequent and have a great impact. Countries around the world regard network security situation awareness as the key to the strategic layout of cybersecurity. As an indispensable part of cyberspace, the security of online social networks has aroused widespread concern. Social bots pose a great challenge to online social network security. Social bots are social accounts that controlled by automated programs<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. Bot manipulators use bots to perform various malicious activities in social networks (e.g., spreading rumors<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR2">2</xref></sup>, polarizing online discussions<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>, amplifying popularity<sup><xref ref-type="bibr" rid="CR4">4</xref>,<xref ref-type="bibr" rid="CR5">5</xref></sup>, etc.) seriously jeopardize the security of cyberspace and cause adverse effects on society. Social bots have been found in different domains, including politics<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>, health<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>, and business<sup><xref ref-type="bibr" rid="CR8">8</xref>,<xref ref-type="bibr" rid="CR9">9</xref></sup>.</p><p id="Par3">As social networks become increasingly connected to people&#x02019;s lives, we are vulnerable to potential manipulation by bots. For example, in Mumbai, social bot spread rumors on social media that the vaccines were a plot by the government to sterilize Muslim children, which led to that only 50% of those who were expected to be vaccinated actually got the vaccine<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>. During the 2016 U.S. election bots posted numerous smear tweets against their competitors, swaying their supporters<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>.</p><p id="Par4">Social platforms and researchers proposed a series of social bot detection models to minimize the impact of malicious social bots, with early success. These detection methods can be grouped into two categories&#x02014;account feature-based methods and graph structure-based methods.</p><p id="Par5">Existing feature-based detection methods for social bot use many hand-crafted features from different categories of information, such as profiles, content, networks, properties and train machine learning models to separate the bots from benign users. However, many of the existing features are effectless when facing the manually aided created profile property and scheduled activities of social bot generated by complex stochastic algorithms. For instance, the rapid development of deep forgery techniques allows social bots to have identical profile information as normal accounts and automatically establish social relationships with other accounts, interspersing small amounts of malicious information with many neutral ones, which is very different from the traditionally considered bot behavior<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>. The study on Twitter bots<sup><xref ref-type="bibr" rid="CR11">11</xref>,<xref ref-type="bibr" rid="CR12">12</xref></sup> indicates that current social bots can more delicately disguise themselves as normal accounts and work in concert to achieve certain specific purposes, such as spreading rumors, posting advertisements.</p><p id="Par6">To address these challenges, several studies used the interactions of accounts in social networks to construct social graphs which are then divided into cohesive subgraphs using graph mining techniques. This type of approach usually considers only leveraging the links of social bots in online social networks but misses the automated cues embedded in the text, time, and profile information. Therefore, these methods are unable to detect social bots that have successfully established enough attack edges (links) with normal users<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>.</p><p id="Par7">Inspired by graph neural network (GNN) models that utilize both structural and property features of nodes, some researchers used GCN, graph attention networks (GAT), and other Message passing neural networks (MPNN) models to integrate account property features and structural features for social bot detection<sup><xref ref-type="bibr" rid="CR11">11</xref>,<xref ref-type="bibr" rid="CR14">14</xref></sup>, with promising results. However, MPNN&#x02019;s expressive power is upper-bounded by the 1st-order Weisfeiler&#x02013;Leman (WL) isomorphism test<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>. The WL algorithm can be <italic>k</italic>-dimensional, which considers the <italic>k</italic>-tuple of the vertices when calculating the graph isomorphism problem. If only one vertex&#x02019;s characteristics (such as labels, properties, etc.) are considered, then it is a 1-dimensional WL (1-WL) algorithm. The 1-WL algorithm results in a unique set of features on most graphs, which means that each node on the graph has a unique role positioning. Therefore, for most irregular graph structures, the features obtained using 1-WL algorithm can be used as the basis for determining whether the graph is isomorphic, that is 1st-order Weisfeiler&#x02013;Leman test. Importantly, researchers found that such method cannot capture basic graph structure features such as cycles and triangles<sup><xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR17">17</xref></sup>. Yang et al.<sup><xref ref-type="bibr" rid="CR18">18</xref></sup> proposed that cycles or triangles are important features in social bot detection tasks.</p><p id="Par8">To improve the expressive power of GCN, capture the basic structure in the graph, and improve the detection performance of the model, we design a subgraph encoding-based GCN model for social bot detection.</p><sec id="Sec2"><title>Motivation</title><p id="Par9">Bot operators are easily aware of the property features used by the bot detection model and they tend to evade detection by avoiding these features<sup><xref ref-type="bibr" rid="CR10">10</xref>,<xref ref-type="bibr" rid="CR18">18</xref></sup>. Social bot detection models using purely structural features are unable to detect social bots that have successfully established sufficient attack edges (links) with ordinary users<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>. The MPNN-based social bot detection model proposed by Feng et al.<sup><xref ref-type="bibr" rid="CR11">11</xref></sup> achieved good results in the social bot detection task, but it ignored the limitations of the expressive power of the MPNN.</p><p id="Par10">In general, motivation can be summarized into the following two points:<list list-type="bullet"><list-item><p id="Par11">Basic graph structure features, such as rings and triangles, are important to detecting social bots. However, these features cannot be captured by directly using messaging neural networks in the entire social graph.</p></list-item><list-item><p id="Par12">Considering various types of features, rather than one type of features, can boost the social bot detection performance.</p></list-item></list></p></sec><sec id="Sec3"><title>Contributions</title><p id="Par13">To address the above problem, we propose an end-to-end social bot detection model with combined account semantic features, property features and structural features. Specifically, first, we vectorize the semantic and property information of the account and concatenate them into the initial representation vector of the nodes. Then, a random walk is used to extract a fixed-length subgraph of each node, and the final representation of the node is obtained using subgraph encoding. Finally, Softmax is used to identify machine accounts and human accounts.<list list-type="bullet"><list-item><p id="Par14">A GCN-based social bot detection model is proposed. The model detects social bots using semantic features, property features, and structural features of accounts simultaneously.</p></list-item><list-item><p id="Par15">Improve the expressive power of the GCN by using subgraph encoding to capture differences in the basic structure (e.g., cycles or triangles, etc.) between accounts.</p></list-item><list-item><p id="Par16">We analyze the impact of different types of features on model performance. Extensive experimental results show that the proposed model achieves better performance compared to the state-of-the-art models.</p></list-item></list></p></sec></sec><sec id="Sec4"><title>Related work</title><p id="Par17">The earliest work on social bot detection dates back to 2010<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>, honeypot traps were designed to detect social bots. Over time, the development of social bots has shown two main trends: single-account feature-based social bot detection and groups-based one. This section introduces the characteristics of these two categories of methods.</p><sec id="Sec5"><title>Single-account feature-based social bot detection</title><p id="Par18">Early social bot detection methods were mainly based on feature engineering of account properties, using traditional classifiers for classification. The work from<sup><xref ref-type="bibr" rid="CR20">20</xref></sup> filters social bots by analyzing Twitter account profiles. Specifically, it designed 16-dimensional features, for instance, screen name length, active days, the number of posted tweets, by analyzing account properties, tweet content, historical activity, and friend lists. Afterwards, it feeds these features into a random forest classifier to distinguish bots from humans, which is one of the foundational work on social bot detection based on individual accounts. Many follow-up studies continue to mine more features from accounts to improve the accuracy of model detection<sup><xref ref-type="bibr" rid="CR18">18</xref>,<xref ref-type="bibr" rid="CR21">21</xref>,<xref ref-type="bibr" rid="CR22">22</xref></sup>. Some researchers, considering that social accounts should not be classified only as bots and non-bots due to the hijacking of human accounts in social networks, studied the differences between humans, bots and cyborgs in terms of tweets (number of tweets, time of posts) and account properties (external URL ratio, account reputation, etc.)<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>. This work laid down the idea of designing different classifiers for different types of bots. Cresci et al.<sup><xref ref-type="bibr" rid="CR24">24</xref></sup> designed digital DNA, a string of characters that encodes the sequence of the accounts&#x02019; action, to train different classifiers to detect different bots.</p><p id="Par19">However, over time, bot operators gradually learned about classical bot detection features and managed to evade detection. The traces of the continuous evolution of bots can be found from<sup><xref ref-type="bibr" rid="CR10">10</xref>,<xref ref-type="bibr" rid="CR11">11</xref>,<xref ref-type="bibr" rid="CR18">18</xref></sup>. In response to this trend, researchers continue to exploit individual account features. Yang et al.<sup><xref ref-type="bibr" rid="CR18">18</xref></sup> mined 10 new features from the data, such as account clustering coefficients, two-way following ratio, and tweet similarity, to train classifiers against the evolution of bots. Beskow et al.<sup><xref ref-type="bibr" rid="CR21">21</xref></sup> extracted differentiated account profile features (degree centrality, K-betweenness centrality, mean eigen centrality, etc.) and tweet features (mean/max mentions, number of languages, etc.) from the collected data and used the random forest as the classifier. Subsequent researchers designed new features to combat the continuous evolution of bots and achieved good performance<sup><xref ref-type="bibr" rid="CR25">25</xref>,<xref ref-type="bibr" rid="CR26">26</xref></sup>. But it should be noted that the designed features are subject to the specific social platforms, which limits the generalization ability of these models.</p><p id="Par20">To address the challenge of generalization ability and design generic social bot detection models, some researchers<sup><xref ref-type="bibr" rid="CR27">27</xref></sup> designed various classifiers for bots using different datasets and combined these classifiers into an ensemble; Botometer-v3<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>, a social bot detection system that incorporates 1700-dimensional features to improve generalization, boosted a series of research works on social bots detection<sup><xref ref-type="bibr" rid="CR28">28</xref>&#x02013;<xref ref-type="bibr" rid="CR30">30</xref></sup>; Some scholars used natural language processing methods to extract semantic differences from account tweets to detect social bots. For example, the work from<sup><xref ref-type="bibr" rid="CR31">31</xref></sup> designed a long short-term memory network (LSTM) based model to extract content features and temporal features of tweets to distinguish bots and people. Pre-training models in natural language processing are also applied in social bot detection<sup><xref ref-type="bibr" rid="CR11">11</xref>,<xref ref-type="bibr" rid="CR32">32</xref></sup>.</p><p id="Par21">The confrontation between bot detectors and operators is a never-ending race. The properties of a single account are easy to be forged and tampered. Dealing with this challenge, researchers work on group-based social bot detection methods.</p></sec><sec id="Sec6"><title>Group-based social bot detection</title><p id="Par22">The group-based social bot detection method utilizes the structural differences between the social graphs generated by humans and bots. The relationships that are used to build the social graph are usually friend relationships<sup><xref ref-type="bibr" rid="CR33">33</xref></sup>, following/follower<sup><xref ref-type="bibr" rid="CR34">34</xref>,<xref ref-type="bibr" rid="CR35">35</xref></sup>, retweet/retweeted<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>. The detection mechanism is to use the homogeneity of social networks, in another word, the neighbor nodes of the bot tend to be bots, and the neighbor nodes of the human tend to be humans<sup><xref ref-type="bibr" rid="CR34">34</xref>,<xref ref-type="bibr" rid="CR37">37</xref>&#x02013;<xref ref-type="bibr" rid="CR39">39</xref></sup>. A label-enhanced network integrates labels with social networks and uses the defined badness score based on the random walk of nodes to distinguish bot and human<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>. Wang et al.<sup><xref ref-type="bibr" rid="CR38">38</xref></sup> proposed paired Markov random field models to estimate the posterior probability of each user by loopy belief propagation and predict the user&#x02019;s label based on the posterior probability. Moreover, they proposed a framework to unify random walk and loopy belief propagation in<sup><xref ref-type="bibr" rid="CR37">37</xref>,<xref ref-type="bibr" rid="CR40">40</xref></sup> to address the limitation of the method<sup><xref ref-type="bibr" rid="CR39">39</xref></sup> that it cannot utilize the label of bot and human, meanwhile, avoiding the problems of the method<sup><xref ref-type="bibr" rid="CR38">38</xref></sup> that it is not scalable and does not guarantee convergence. The study from<sup><xref ref-type="bibr" rid="CR41">41</xref></sup> trained a local classifier to calculate the local trust scores of nodes and edges, and then the local trust scores used for prediction are propagated through the global network structure by a weighted random walk and loopy belief propagation mechanism.</p><p id="Par23">These group-based social bot detection methods largely improve the generalization of the model and avoid manual feature engineering<sup><xref ref-type="bibr" rid="CR42">42</xref>,<xref ref-type="bibr" rid="CR43">43</xref></sup>. However, this type of method only utilizes the link information between accounts, and its detection performance is greatly reduced when enough attack links are established between accounts<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>.</p><p id="Par24">With the rise of GCN<sup><xref ref-type="bibr" rid="CR44">44</xref></sup>, it has been widely used in various occasions, such as link prediction, node classification, community division. Researchers introduce GCN to detect social bots because GCN can utilize the link information between accounts as well as lots of other information. Sun et al.<sup><xref ref-type="bibr" rid="CR45">45</xref></sup> designed a GCN with trust mechanism. First, the method starts a short random walk from a known real node, and its walk probability is the trust score of the node. Then, it uses these trust scores as edge weights, and uses graph convolution operations to aggregate features from local graph neighborhoods onto a weighted graph for classification. This work<sup><xref ref-type="bibr" rid="CR14">14</xref></sup> proposed a GCN-based spam bot detection model which utilizes both account property features and neighborhood features. Following this direction, researchers designed a social bot detection model using the semantic features and property features of the relational graph convolutional network (RGCN<sup><xref ref-type="bibr" rid="CR46">46</xref></sup>). First, it vectorizes the property features and semantic features of the accounts and concatenates the two types of vectors together. Then, the spliced semantic vectors are fed into a neural network model for training to detect social bots. This method achieves state-of-the-art results on homogenous graph social bot detection.</p><p id="Par25">Recently, RoSGAS<sup><xref ref-type="bibr" rid="CR47">47</xref></sup> designed an adaptive search GNN structure for social bot detection model, which gets rid of the a priori of people designing GNN structures and searches for appropriate GNN structures through reinforcement learning. RF-GNN<sup><xref ref-type="bibr" rid="CR48">48</xref></sup> utilized the idea of integrated learning to detect social bots by combining the Random Forest algorithm and GNN. They both directly aggregate information from the direct neighbors of the account, which may fails to capture the differences in the basic structures (rings or triangles, etc.).</p></sec></sec><sec id="Sec7"><title>Proposed approach</title><p id="Par26">To address the above challenges, we design a subgraph encoding-based approach for social bot detection, dividing the social network into multiple subgraphs and coding each node in the subgraphs with a GCN, which significantly differs from the existing methods. Since a node may belong to multiple subgraphs, so there are multiple representation vectors of a node, which enhances the representation of the node. Compared to GCNs where the central node features originate from the aggregation of its immediate neighbors, subgraph encoding considers both immediate and non-immediate neighbors, making it capable of capturing basic structural information such as rings and triangles, and therefore, more suitable for social bot detection. This is the difference between our approach and existing social bot detection methods. The framework of our model is shown in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref> and the implementation details of the model are specifically described in the following subsections.<fig id="Fig1"><label>Figure 1</label><caption><p>The framework of the proposed social bot detection model.</p></caption><graphic xlink:href="41598_2024_54809_Fig1_HTML" id="MO1"/></fig></p><sec id="Sec8"><title>Input</title><p id="Par27">Social accounts contain abundant data information, and existing social bot detection methods identify bot accounts by mining the information contained in social accounts. This paper proposes to use account semantic features, property features, and structure features for learning account representation. The semantic features are extracted from the account&#x02019;s descriptions and tweets. The account&#x02019;s profile, such as account ID, screen name, profile image, is the source of the property features. The social graph whose edge represents the following and follower relationship between accounts is the input for extracting the structure features.</p></sec><sec id="Sec9"><title>Node representation</title><p id="Par28">Learning the node (account) representation is a very important process for downstream tasks, and the node representation directly affects the model performance.</p><sec id="Sec10"><title>Semantic representation</title><p id="Par29">Tweets can largely reflect the characteristics of the accounts and are widely used by the existing bot detection methods. We use the RoBERTa<sup><xref ref-type="bibr" rid="CR49">49</xref></sup> language model in Transformer.pipeline to encode account semantic information. The semantic feature vector <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{N}_s^u$$\end{document}</tex-math><mml:math id="M2"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mi>u</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq1.gif"/></alternatives></inline-formula> for a given account <italic>u</italic> consists of two components: the account description semantic vector <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{N}_d^u$$\end{document}</tex-math><mml:math id="M4"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mi>d</mml:mi><mml:mi>u</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq2.gif"/></alternatives></inline-formula>, the tweet semantic vector <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{N}_t^u$$\end{document}</tex-math><mml:math id="M6"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mi>u</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq3.gif"/></alternatives></inline-formula>. The account description is a paragraph set by Twitter users to briefly introduce themselves.</p><p id="Par30">First, we use RoBERTa to learn the representation vector <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{N}_d^u$$\end{document}</tex-math><mml:math id="M8"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mi>d</mml:mi><mml:mi>u</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq4.gif"/></alternatives></inline-formula> of the <italic>u</italic>-th account description information (see as Eq. (<xref rid="Equ1" ref-type="disp-formula">1</xref>)),<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \varvec{N}_d^u=\sigma (W_d\cdot \frac{1}{n}\sum _{i=1}^{n}RoBERTa(\{{d_i}\}_{i=1}^n)+b_d), \end{aligned}$$\end{document}</tex-math><mml:math id="M10" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mi>d</mml:mi><mml:mi>u</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mo>&#x000b7;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mi>R</mml:mi><mml:mi>o</mml:mi><mml:mi>B</mml:mi><mml:mi>E</mml:mi><mml:mi>R</mml:mi><mml:mi>T</mml:mi><mml:mi>a</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_54809_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq5"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${d_i}\in {\mathbb {R}}^{D_R\times 1}$$\end{document}</tex-math><mml:math id="M12"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq5.gif"/></alternatives></inline-formula> and <inline-formula id="IEq6"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\{{d_i}\}_{i=1}^n$$\end{document}</tex-math><mml:math id="M14"><mml:msubsup><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq6.gif"/></alternatives></inline-formula> is the <italic>u</italic>-th account description that consists of <italic>n</italic> words and <italic>i</italic> represents the index of the word in the description. <inline-formula id="IEq7"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D_R$$\end{document}</tex-math><mml:math id="M16"><mml:msub><mml:mi>D</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq7.gif"/></alternatives></inline-formula> is the embedding dimension which is predefined in RoBERTa. <inline-formula id="IEq8"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_d$$\end{document}</tex-math><mml:math id="M18"><mml:msub><mml:mi>W</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq8.gif"/></alternatives></inline-formula> and <inline-formula id="IEq9"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b_d$$\end{document}</tex-math><mml:math id="M20"><mml:msub><mml:mi>b</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq9.gif"/></alternatives></inline-formula> are learnable parameters. <inline-formula id="IEq10"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{N}_d^u\in {\mathbb {R}}^{D\times 1}$$\end{document}</tex-math><mml:math id="M22"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mi>d</mml:mi><mml:mi>u</mml:mi></mml:msubsup><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq10.gif"/></alternatives></inline-formula>, <italic>D</italic> is the dimensionof the output vector of the MLP. <inline-formula id="IEq11"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sigma$$\end{document}</tex-math><mml:math id="M24"><mml:mi>&#x003c3;</mml:mi></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq11.gif"/></alternatives></inline-formula> is the activation function. In this paper, Leaky-ReLU<sup><xref ref-type="bibr" rid="CR50">50</xref></sup> is used as the activation function.</p><p id="Par31">The semantic vector of account tweets can be obtained in a similar method (see as Eq.&#x000a0;<xref rid="Equ2" ref-type="disp-formula">2</xref>)<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \varvec{N}_t^u=\sigma (W_s\cdot \frac{1}{M_u}\frac{1}{m_u}\sum _{i=1}^{M_u}\sum _{j=1}^{m_u}RoBERTa(\{{w_j^i}\}_{j=1}^{m_u}+b_s), \end{aligned}$$\end{document}</tex-math><mml:math id="M26" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mi>u</mml:mi></mml:msubsup><mml:mrow><mml:mo>=</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:mo stretchy="false">(</mml:mo></mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>&#x000b7;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>M</mml:mi><mml:mi>u</mml:mi></mml:msub></mml:mfrac><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>m</mml:mi><mml:mi>u</mml:mi></mml:msub></mml:mfrac><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mi>u</mml:mi></mml:msub></mml:munderover><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>u</mml:mi></mml:msub></mml:munderover><mml:mi>R</mml:mi><mml:mi>o</mml:mi><mml:mi>B</mml:mi><mml:mi>E</mml:mi><mml:mi>R</mml:mi><mml:mi>T</mml:mi><mml:mi>a</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:msubsup><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>u</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_54809_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq12"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$w_j^i\in {\mathbb {R}}^{D_R\times 1}$$\end{document}</tex-math><mml:math id="M28"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:msubsup><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq12.gif"/></alternatives></inline-formula> and <inline-formula id="IEq13"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\{{w_j^i}\}_{i=1}^{m_u}$$\end{document}</tex-math><mml:math id="M30"><mml:msubsup><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:msubsup><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>u</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq13.gif"/></alternatives></inline-formula> is the <italic>i</italic>-th word of the <italic>j</italic>-th tweet, and the tweet length is <inline-formula id="IEq14"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$m_u$$\end{document}</tex-math><mml:math id="M32"><mml:msub><mml:mi>m</mml:mi><mml:mi>u</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq14.gif"/></alternatives></inline-formula>. <inline-formula id="IEq15"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_s$$\end{document}</tex-math><mml:math id="M34"><mml:msub><mml:mi>W</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq15.gif"/></alternatives></inline-formula> and <inline-formula id="IEq16"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b_s$$\end{document}</tex-math><mml:math id="M36"><mml:msub><mml:mi>b</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq16.gif"/></alternatives></inline-formula> are learnable parameters. <inline-formula id="IEq17"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_u$$\end{document}</tex-math><mml:math id="M38"><mml:msub><mml:mi>M</mml:mi><mml:mi>u</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq17.gif"/></alternatives></inline-formula> is the number of tweets from the <italic>u</italic>-th account. <inline-formula id="IEq18"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{N}_t^u\in {\mathbb {R}}^{D\times 1}$$\end{document}</tex-math><mml:math id="M40"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mi>u</mml:mi></mml:msubsup><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq18.gif"/></alternatives></inline-formula>.</p><p id="Par32">Combing the two parts obtained above, we can get the semantic feature vector of the <italic>u</italic>-th account, namely, <inline-formula id="IEq19"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{N}_s^u=\left[ \varvec{N}_t^u,\varvec{N}_d^u\right] , \varvec{N}_s^u\in \ {\mathbb {R}}^{2D\times 1}$$\end{document}</tex-math><mml:math id="M42"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mi>u</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mfenced close="]" open="["><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mi>u</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mi>d</mml:mi><mml:mi>u</mml:mi></mml:msubsup></mml:mfenced><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mi>u</mml:mi></mml:msubsup><mml:mo>&#x02208;</mml:mo><mml:mspace width="4pt"/><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>D</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq19.gif"/></alternatives></inline-formula>.</p></sec><sec id="Sec11"><title>Property representation</title><p id="Par33">Many early social bot detection studies were successful in distinguishing bot accounts from benign accounts based on the property features of the accounts<sup><xref ref-type="bibr" rid="CR10">10</xref>,<xref ref-type="bibr" rid="CR18">18</xref></sup>. In this paper, the properties of accounts are divided into statistical features (e.g., number of followers, likes, retweets) and category features (e.g., whether the account is authenticated, whether it uses default profile information, whether it displays location information). All the property features used for account representation are shown in Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>. Concerning vectorization to the property features, we use Z-Score normalization for the numerical features and One-hot encoding for the category features. The processing details can be referred to<sup><xref ref-type="bibr" rid="CR11">11</xref></sup><table-wrap id="Tab1"><label>Table 1</label><caption><p>Property features used in our model.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Feature name</th><th align="left">Description</th></tr></thead><tbody><tr><td align="left">Followers</td><td align="left">The number of followers an account has</td></tr><tr><td align="left">Followings</td><td align="left">The number of accounts that the account follows</td></tr><tr><td align="left">Favorites</td><td align="left">The number of favorites or likes an account receives</td></tr><tr><td align="left">Statuses</td><td align="left">The number of statuses an account posts</td></tr><tr><td align="left">Active days</td><td align="left">The number of days from the account&#x02019;s registration to current</td></tr><tr><td align="left">Screen name length</td><td align="left">The length of the account&#x02019;s current screen name</td></tr><tr><td align="left">Protected</td><td align="left">Whether the account is currently protected</td></tr><tr><td align="left">Contributors enabled</td><td align="left">Whether contributors are enabled or not</td></tr><tr><td align="left">Is translator</td><td align="left">Whether there is a translator or not</td></tr><tr><td align="left">Is translation enabled</td><td align="left">Whether the translation is available or not?</td></tr><tr><td align="left">Geo enabled</td><td align="left">Whether the account is geo enabled or not</td></tr><tr><td align="left">Background tile</td><td align="left">Whether the account uses a background tile</td></tr><tr><td align="left">Background image</td><td align="left">Whether the account uses a background image</td></tr><tr><td align="left">Extended profile</td><td align="left">Whether the account has extended profile or not</td></tr><tr><td align="left">Default profile</td><td align="left">Whether the account uses a default profile</td></tr><tr><td align="left">Default profile image</td><td align="left">Whether the account uses a default profile image</td></tr><tr><td align="left">Verified</td><td align="left">Whether the account is verified or not</td></tr></tbody></table></table-wrap></p><p id="Par34">The property feature vector <inline-formula id="IEq20"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$N_p^u$$\end{document}</tex-math><mml:math id="M44"><mml:msubsup><mml:mi>N</mml:mi><mml:mi>p</mml:mi><mml:mi>u</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq20.gif"/></alternatives></inline-formula> for the <italic>u</italic>-th account is combined as <inline-formula id="IEq21"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{N}_p^u=[\varvec{N}_{P_n}^u,\varvec{N}_{P_c}^u],\varvec{N}_p^u\in {\mathbb {R}}^{2D\times 1}$$\end{document}</tex-math><mml:math id="M46"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mi>p</mml:mi><mml:mi>u</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mi>u</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow><mml:mi>u</mml:mi></mml:msubsup><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mi>p</mml:mi><mml:mi>u</mml:mi></mml:msubsup><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>D</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq21.gif"/></alternatives></inline-formula>.</p><p id="Par35">Ultimately, the initial feature representation vector of account <italic>u</italic> can be expressed as <inline-formula id="IEq22"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{N}_{init}^u=[{\varvec{N}_s^u},\varvec{N}_p^u], \varvec{N}_{init}^u\in \ {\mathbb {R}}^{4D\times 1}$$\end{document}</tex-math><mml:math id="M48"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">init</mml:mi></mml:mrow><mml:mi>u</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mi>u</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mi>p</mml:mi><mml:mi>u</mml:mi></mml:msubsup><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">init</mml:mi></mml:mrow><mml:mi>u</mml:mi></mml:msubsup><mml:mo>&#x02208;</mml:mo><mml:mspace width="4pt"/><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>D</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq22.gif"/></alternatives></inline-formula>.</p></sec><sec id="Sec12"><title>Subgraph encoding</title><p id="Par36">The core idea of subgraph coding is to obtain more expressive structural features of the whole graph by encoding the subgraphs extracted from the graph, which is similar to the idea of word segmentation in natural language processing. In this paper, GCN is used as encoding model for the subgraphs.</p><p id="Par37">Graph nodes contain rich structural and property information. In MPNNs, each node aggregates its neighbor features in a star pattern. Therefore, MPNNs cannot distinguish the non-isomorphic regular graphs with the same star structure<sup><xref ref-type="bibr" rid="CR51">51</xref></sup>. However, two non-isomorphic graphs with the same star structure but their subgraphs may differ (see as Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>). The star structure of node &#x0201c;1&#x0201d; in Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>A,B are identical, but there are differences in their subgraph structures. Subgraphs retain basic structural features such as cycles or triangles.<fig id="Fig2"><label>Figure 2</label><caption><p>Illustration of the Two 4-regular graphs that cannot be distinguished by 1-WL. Colored edges are the difference between two graphs. There are differences in the first-order subgraph of some nodes in the graph.</p></caption><graphic xlink:href="41598_2024_54809_Fig2_HTML" id="MO2"/></fig></p><sec id="Sec31"><title>Subgraph extraction</title><p id="Par38">:n social networks, the <italic>k</italic>-hop egonet of a node as a subgraph may be too large<sup><xref ref-type="bibr" rid="CR52">52</xref></sup>. Therefore, we use random walking to extract subgraphs that limit the subgraph size (see as Eq. (<xref rid="Equ3" ref-type="disp-formula">3</xref>)). In practice, We use the random walking rule in Node2vec [46].<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} G(N_{rw}(u)) ={Random\ walk}_{W_l}\ (u|u\in V), \end{aligned}$$\end{document}</tex-math><mml:math id="M50" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">rw</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mspace width="4pt"/><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:msub><mml:mspace width="4pt"/><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>u</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_54809_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq23"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$W_l$$\end{document}</tex-math><mml:math id="M52"><mml:msub><mml:mi>W</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq23.gif"/></alternatives></inline-formula> is the random walking length. <italic>u</italic> is a subgraph root node. <inline-formula id="IEq24"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$N_{rw}(u)$$\end{document}</tex-math><mml:math id="M54"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">rw</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq24.gif"/></alternatives></inline-formula> denotes the set of nodes visited by the random walker. <inline-formula id="IEq25"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G(N_{rw}(u))$$\end{document}</tex-math><mml:math id="M56"><mml:mrow><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">rw</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq25.gif"/></alternatives></inline-formula> denotes the subgraph whose root node is <italic>u</italic>.</p></sec><sec id="Sec32"><title>Subgraph encoding</title><p id="Par39">Subgraph encoding can improve the expressive power of GCN, and<sup><xref ref-type="bibr" rid="CR51">51</xref></sup> demonstrated both theoretically and experimentally that subgraph encoding surpasses 1-WL and 2-WL and can be no weaker than 3-WL. The principle is similar to the convolution operation in convolutional neural networks.</p><p id="Par40">The GCN is viewed as a kernel (GCN as kernel (GCN-AK)), and a new node representation vector is obtained by convolving it with the initial feature vector of the nodes in the subgraph. Specifically, the GCN is used as a subgraph encoder. Then, GCN-AK computes <inline-formula id="IEq26"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h_G$$\end{document}</tex-math><mml:math id="M58"><mml:msub><mml:mi>h</mml:mi><mml:mi>G</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq26.gif"/></alternatives></inline-formula> by Eq. (<xref rid="Equ4" ref-type="disp-formula">4</xref>)<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} &#x00026;h_u^{l+1}={GCN}^l{(G}^l\left( N_{rw}\left( u\right) \right) ),&#x00026;l=0,\cdots ,L-1;h_G=pooling({h_v^l|u\in V}), \end{aligned}$$\end{document}</tex-math><mml:math id="M60" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>u</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="italic">GCN</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>G</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msup><mml:mfenced close=")" open="("><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">rw</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:mi>u</mml:mi></mml:mfenced></mml:mfenced><mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="right"><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x022ef;</mml:mo><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x0037e;</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>v</mml:mi><mml:mi>l</mml:mi></mml:msubsup><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>u</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_54809_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>where <italic>G</italic> is graph, <inline-formula id="IEq27"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G=(V,E)$$\end{document}</tex-math><mml:math id="M62"><mml:mrow><mml:mi>G</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>E</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq27.gif"/></alternatives></inline-formula>. <inline-formula id="IEq28"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G(N_{rw}(u))$$\end{document}</tex-math><mml:math id="M64"><mml:mrow><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">rw</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq28.gif"/></alternatives></inline-formula> is the subgraph generated by random walking from the root node <italic>u</italic>. <inline-formula id="IEq29"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G^l\left( N_{rw}\left( u\right) \right)$$\end{document}</tex-math><mml:math id="M66"><mml:mrow><mml:msup><mml:mi>G</mml:mi><mml:mi>l</mml:mi></mml:msup><mml:mfenced close=")" open="("><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi mathvariant="italic">rw</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:mi>u</mml:mi></mml:mfenced></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq29.gif"/></alternatives></inline-formula> is the subgraph with hidden features at the <italic>l</italic>-th layer. <inline-formula id="IEq30"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h_u^l$$\end{document}</tex-math><mml:math id="M68"><mml:msubsup><mml:mi>h</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi></mml:msubsup></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq30.gif"/></alternatives></inline-formula> denotes the hidden representation of node <italic>u</italic> in GNN-AK layer <italic>l</italic>. <inline-formula id="IEq31"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$u\in N_k(u), h_u^{(0)}=\varvec{N}_{init}^u$$\end{document}</tex-math><mml:math id="M70"><mml:mrow><mml:mi>u</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mi>u</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">init</mml:mi></mml:mrow><mml:mi>u</mml:mi></mml:msubsup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq31.gif"/></alternatives></inline-formula>.</p><p id="Par41">We use <inline-formula id="IEq32"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${Subgraph}^l\left( u\right)$$\end{document}</tex-math><mml:math id="M72"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="italic">Subgraph</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msup><mml:mfenced close=")" open="("><mml:mi>u</mml:mi></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq32.gif"/></alternatives></inline-formula> instead of <inline-formula id="IEq33"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G^{(l)}(N_k(u))$$\end{document}</tex-math><mml:math id="M74"><mml:mrow><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq33.gif"/></alternatives></inline-formula> to denote the induced subgraph of <italic>u</italic> and use GCN to encode node <italic>i</italic> in subgraph <italic>j</italic> yields the representation vector <inline-formula id="IEq34"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Emb(i|{Subgraph}^l\left( j\right) )$$\end{document}</tex-math><mml:math id="M76"><mml:mrow><mml:mi>E</mml:mi><mml:mi>m</mml:mi><mml:mi>b</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="italic">Subgraph</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msup><mml:mfenced close=")" open="("><mml:mi>j</mml:mi></mml:mfenced><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq34.gif"/></alternatives></inline-formula>. We consider the embedding of all <inline-formula id="IEq35"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j\in V$$\end{document}</tex-math><mml:math id="M78"><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq35.gif"/></alternatives></inline-formula> and all nodes of <inline-formula id="IEq36"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i\in {Subgraph}^l\left( j\right)$$\end{document}</tex-math><mml:math id="M80"><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="italic">Subgraph</mml:mi></mml:mrow><mml:mi>l</mml:mi></mml:msup><mml:mfenced close=")" open="("><mml:mi>j</mml:mi></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq36.gif"/></alternatives></inline-formula>. That the base GCN can have multiple convolutional layers, and <italic>Emb</italic> refers to the node embeddings at the last layer before global pooling <inline-formula id="IEq37"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${pooling}_{GCN}$$\end{document}</tex-math><mml:math id="M82"><mml:msub><mml:mrow><mml:mi mathvariant="italic">pooling</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">GCN</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq37.gif"/></alternatives></inline-formula> that generates subgraph-level encoding.<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \begin{aligned} h_u^{(l+1)|subgraph}={GCN}^{(l)}\left( Subgraph^{(l)}\left( u\right) \right) :={pooling}_{{GCN}^{(l)}}\left( \{Emb\left( i|{Subgraph}^{(l)}\left( u\right) \right) |i\in N_k(u)\}\right) , \end{aligned} \end{aligned}$$\end{document}</tex-math><mml:math id="M84" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>u</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>b</mml:mi><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>p</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="italic">GCN</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mfenced close=")" open="("><mml:mi>S</mml:mi><mml:mi>u</mml:mi><mml:mi>b</mml:mi><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>p</mml:mi><mml:msup><mml:mi>h</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mfenced close=")" open="("><mml:mi>u</mml:mi></mml:mfenced></mml:mfenced><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="italic">pooling</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="italic">GCN</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:msub><mml:mfenced close=")" open="("><mml:mo stretchy="false">{</mml:mo><mml:mi>E</mml:mi><mml:mi>m</mml:mi><mml:mi>b</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>i</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="italic">Subgraph</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mfenced close=")" open="("><mml:mi>u</mml:mi></mml:mfenced></mml:mfenced><mml:mo stretchy="false">|</mml:mo><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">}</mml:mo></mml:mfenced><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_54809_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula></p><p id="Par42">We refer to the encoding of the rooted subgraph <inline-formula id="IEq38"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${Subgraph}^{(l)}\left( u\right)$$\end{document}</tex-math><mml:math id="M86"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="italic">Subgraph</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mfenced close=")" open="("><mml:mi>u</mml:mi></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq38.gif"/></alternatives></inline-formula> in Eq. (<xref rid="Equ5" ref-type="disp-formula">5</xref>) as the subgraph encoding. Typical choices of <inline-formula id="IEq39"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${pooling}_{{GCN}^{(l)}}$$\end{document}</tex-math><mml:math id="M88"><mml:msub><mml:mrow><mml:mi mathvariant="italic">pooling</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="italic">GCN</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq39.gif"/></alternatives></inline-formula> are <italic>SUM</italic> and <italic>MEAN</italic>. As each rooted subgraph has a root node, <inline-formula id="IEq40"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${pooling}_{{GCN}^{(l)}}$$\end{document}</tex-math><mml:math id="M90"><mml:msub><mml:mrow><mml:mi mathvariant="italic">pooling</mml:mi></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="italic">GCN</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:msub></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq40.gif"/></alternatives></inline-formula> can be additionally realized to differentiate the root node by self-concatenating its own representation, which is &#x0201c;centroid encoding&#x0201d;, resulting in the following realization as each layer of GCN-AK:<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} h_u^{(l+1)}=FUSE(h_u^{(l+1)|centroid},h_u^{(l+1)|subgraph}) \end{aligned}$$\end{document}</tex-math><mml:math id="M92" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>u</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mi>U</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mi>u</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mi>u</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>b</mml:mi><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>p</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_54809_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq41"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$h_u^{(l+1)|centroid} := Emb(u|{(Subgraph}^{(l+1)}\left( u\right)$$\end{document}</tex-math><mml:math id="M94"><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mi>u</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msubsup><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mi>m</mml:mi><mml:mi>b</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mi>u</mml:mi><mml:mi>b</mml:mi><mml:mi>g</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>p</mml:mi><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mfenced close=")" open="("><mml:mi>u</mml:mi></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq41.gif"/></alternatives></inline-formula><sup><xref ref-type="bibr" rid="CR40">40</xref></sup>. <italic>FUSE</italic> is concatenation.</p><p id="Par43">To improve the scalability of the model, we use the subgraph drop strategy, more details refer to. The final node representation vector is <inline-formula id="IEq42"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$N^u$$\end{document}</tex-math><mml:math id="M96"><mml:msup><mml:mi>N</mml:mi><mml:mi>u</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq42.gif"/></alternatives></inline-formula>.<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \varvec{N^u}=\sigma (W\cdot h_u^{(l)}+b) \end{aligned}$$\end{document}</tex-math><mml:math id="M98" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">N</mml:mi><mml:mi mathvariant="bold-italic">u</mml:mi></mml:msup></mml:mrow><mml:mo>=</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>W</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:msubsup><mml:mi>h</mml:mi><mml:mi>u</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_54809_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq43"><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{N}^u\in {\mathbb {R}}^{\psi \times 1}$$\end{document}</tex-math><mml:math id="M100"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mi>u</mml:mi></mml:msup><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003c8;</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq43.gif"/></alternatives></inline-formula>, and <italic>W</italic> and <italic>b</italic> are learnable parameters. <inline-formula id="IEq44"><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\psi$$\end{document}</tex-math><mml:math id="M102"><mml:mi>&#x003c8;</mml:mi></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq44.gif"/></alternatives></inline-formula> is the final output dimension of the model.</p></sec></sec></sec><sec id="Sec13"><title>Output</title><p id="Par44">The node representation vector <inline-formula id="IEq45"><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{N}^u$$\end{document}</tex-math><mml:math id="M104"><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mi>u</mml:mi></mml:msup></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq45.gif"/></alternatives></inline-formula> is obtained based on the processing in the previous subsection, and our model classifies node <italic>u</italic> as a social bot or human by the softmax layer (see as Eq. (<xref rid="Equ8" ref-type="disp-formula">8</xref>)).<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} {{\hat{y}}}_i=SoftMax(W\cdot \varvec{N}^u+b),\ \end{aligned}$$\end{document}</tex-math><mml:math id="M106" display="block"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>W</mml:mi><mml:mo>&#x000b7;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mi>u</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="4pt"/></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="41598_2024_54809_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula>where <italic>W</italic> and <italic>b</italic> are learnable parameters.</p><p id="Par45">The loss function used in model training is the cross-entropy loss function which is commonly used in classification tasks. The proposed model is named as SEGCN and its pseudo-code is given as Algorithm&#x000a0;1.</p><p id="Par46">
<fig position="anchor" id="Figa"><label>Algorithm 1</label><caption><p>SEGCN</p></caption><graphic position="anchor" xlink:href="41598_2024_54809_Figa_HTML" id="MO3"/></fig>
</p></sec></sec><sec id="Sec14"><title>Experiments</title><p id="Par47">In this section, we perform extensive experiments on two benchmark datasets to validate the performance of the proposed model. All experiments are conducted on a server with Intel (R) Xeon (R) Gold 6234 CPU (4 <inline-formula id="IEq46"><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M108"><mml:mo>&#x000d7;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq46.gif"/></alternatives></inline-formula> 8 cores, 128 GB, 3.3 GHz) and RTX 3090 (2 <inline-formula id="IEq47"><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M110"><mml:mo>&#x000d7;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq47.gif"/></alternatives></inline-formula> 24 GB) GPU running Ubuntu 20.04 (64-bit).</p><sec id="Sec15"><title>Datasets</title><p id="Par48">The experiments are based on two different publicly available datasets, namely, the TwiBot-20 dataset<sup><xref ref-type="bibr" rid="CR53">53</xref></sup> and the TwiBot-22 dataset<sup><xref ref-type="bibr" rid="CR54">54</xref></sup>. The TwiBot-20 dataset is a social bot dataset made public by Feng et al.<sup><xref ref-type="bibr" rid="CR53">53</xref></sup> in 2020, which includes 229,573 Twitter users, 33,488,192 tweets, 8,723,736 user property items and 455,958 following relationships. The TwiBot-22 dataset is a larger social bot dataset made public by Feng et al.<sup><xref ref-type="bibr" rid="CR54">54</xref></sup> in 2022, which includes 1,000,000 Twitter users (human: 860,057, bot: 139,943), 86,764,167 tweets and 170,185,937 following relationships. An overview of the datasets is presented in Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Overview of the benchmark dataset.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Datasets</th><th align="left">Total account</th><th align="left">Bot account</th><th align="left">Human account</th></tr></thead><tbody><tr><td align="left">TwiBot-20<sup><xref ref-type="bibr" rid="CR53">53</xref></sup></td><td align="left">229,573</td><td align="left">5273</td><td align="left">6589</td></tr><tr><td align="left">TwiBot-22<sup><xref ref-type="bibr" rid="CR54">54</xref></sup></td><td align="left">1,000,000</td><td align="left">139,943</td><td align="left">860,057</td></tr></tbody></table></table-wrap></p></sec><sec id="Sec16"><title>Baseline methods</title><p id="Par49">In this section, we give a brief introduction of the baseline bot detection models compared with our model.</p><sec id="Sec17"><title>Deepwalk<sup><xref ref-type="bibr" rid="CR55">55</xref></sup></title><p id="Par50">Deepwalk is a graph embedding algorithm that combines random walk and word2vec, which is able to represent the nodes in a graph as a vector containing potential information. It is widely used in downstream tasks such as node classification, link prediction, and community discovery.</p></sec><sec id="Sec18"><title>Node2vec<sup><xref ref-type="bibr" rid="CR56">56</xref></sup></title><p id="Par51">Node2vec is a graph embedding model that integrates node structure equivalence and neighbor similarity. Specifically, it introduces breadth-first search (BFS) and depth-first search (DFS) to capture the homogeneity and structural equivalence of nodes, and can be seen as the Deepwalk model that combines BFS and DFS random walks.</p></sec><sec id="Sec19"><title>GCN<sup><xref ref-type="bibr" rid="CR44">44</xref></sup></title><p id="Par52">GCN is a kind of MPNN. MPNN aggregates the information of neighboring nodes to update the information of central nodes, and it extends the convolution operator to the field of irregular data to realize the connection between the graph and the neural network. It has been widely used for tasks such as node classification, and link prediction.</p></sec><sec id="Sec20"><title>GAT<sup><xref ref-type="bibr" rid="CR57">57</xref></sup></title><p id="Par53">GAT follows the same message-passing paradigm, which introduces an attention mechanism that takes into account the differences in the influence of neighboring nodes on the central node. It is also widely used for downstream tasks such as link prediction, node classification and graph clustering.</p></sec><sec id="Sec21"><title>Bot2vec<sup><xref ref-type="bibr" rid="CR34">34</xref></sup></title><p id="Par54">Bot2vec is a social bot detection algorithm using only structural features proposed by Pham et al. in 2021. It is an improved version of Node2vec that introduces community detection algorithms to capture the structural equivalence of nodes.</p></sec><sec id="Sec22"><title>SATAR<sup><xref ref-type="bibr" rid="CR32">32</xref></sup></title><p id="Par55">SATAR is a self-supervised Twitter account representation model combining account semantic information, property information and neighbor information proposed by Feng et al.<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>. It achieved very good results in the task of detecting novel bots.</p></sec><sec id="Sec23"><title>BotRGCN<sup><xref ref-type="bibr" rid="CR11">11</xref></sup></title><p id="Par56">BotRGCN is an RGCN-based social bot detection model and it is similar to GCN following the message passing paradigm. Compared to GCN which aggregates on undirected graphs, it can aggregate information about surrounding neighbors in a directed graph format.</p></sec><sec id="Sec24"><title>RFGNN<sup><xref ref-type="bibr" rid="CR48">48</xref></sup></title><p id="Par57">RFGNN is a method that combines Random Forest and GNNs, which employs GNNs as the base classifiers to construct a random forest, effectively combining the advantages of ensemble learning and GNNs to improve the accuracy and robustness of the model. We use the best-performing RF-RGCN model in RF-GNN as our comparison method. Notably, this method utilizes the BERT model to extract semantic features from tweets and account descriptions.</p></sec><sec id="Sec25"><title>RFGNN-R</title><p id="Par58">RFGNN-R, in comparison to RFGNN, uses the RoBERTa model to extract semantic features, meaning that its method of feature extraction beyond structural features remains consistent with that of GCN, GAT, SATAR, BotRGCN, and our model.</p><p id="Par59">To explicitly compare with the detection models, we present an overview of the account features used by each model in Table&#x000a0;<xref rid="Tab3" ref-type="table">3</xref>. Deepwak/Node2vc/Bot2vec exploit the structural features of accounts, and GCN, GAT, SATAR, BotRGCN and our model all exploit the semantic features, property features, and structural features of accounts. &#x0201c;&#x02013;&#x0201d; is None.<table-wrap id="Tab3"><label>Table 3</label><caption><p>Overview of account information used by the compared models.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Model</th><th align="left">Published</th><th align="left">Semantic</th><th align="left">Property</th><th align="left">Structure</th></tr></thead><tbody><tr><td align="left">Deepwalk</td><td align="left">2014</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left"><inline-formula id="IEq48"><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M112"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq48.gif"/></alternatives></inline-formula></td></tr><tr><td align="left">Node2vec</td><td align="left">2017</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left"><inline-formula id="IEq49"><alternatives><tex-math id="M113">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M114"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq49.gif"/></alternatives></inline-formula></td></tr><tr><td align="left">Bot2vec</td><td align="left">2022</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left"><inline-formula id="IEq50"><alternatives><tex-math id="M115">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M116"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq50.gif"/></alternatives></inline-formula></td></tr><tr><td align="left">GCN</td><td align="left">2017</td><td align="left"><inline-formula id="IEq51"><alternatives><tex-math id="M117">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M118"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq51.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq52"><alternatives><tex-math id="M119">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M120"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq52.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq53"><alternatives><tex-math id="M121">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M122"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq53.gif"/></alternatives></inline-formula></td></tr><tr><td align="left">GAT</td><td align="left">2018</td><td align="left"><inline-formula id="IEq54"><alternatives><tex-math id="M123">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M124"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq54.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq55"><alternatives><tex-math id="M125">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M126"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq55.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq56"><alternatives><tex-math id="M127">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M128"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq56.gif"/></alternatives></inline-formula></td></tr><tr><td align="left">SATAR</td><td align="left">2021</td><td align="left"><inline-formula id="IEq57"><alternatives><tex-math id="M129">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M130"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq57.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq58"><alternatives><tex-math id="M131">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M132"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq58.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq59"><alternatives><tex-math id="M133">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M134"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq59.gif"/></alternatives></inline-formula></td></tr><tr><td align="left">BotRGCN</td><td align="left">2021</td><td align="left"><inline-formula id="IEq60"><alternatives><tex-math id="M135">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M136"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq60.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq61"><alternatives><tex-math id="M137">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M138"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq61.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq62"><alternatives><tex-math id="M139">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M140"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq62.gif"/></alternatives></inline-formula></td></tr><tr><td align="left">RFGNN</td><td align="left">2023</td><td align="left"><inline-formula id="IEq63"><alternatives><tex-math id="M141">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M142"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq63.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq64"><alternatives><tex-math id="M143">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M144"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq64.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq65"><alternatives><tex-math id="M145">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M146"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq65.gif"/></alternatives></inline-formula></td></tr><tr><td align="left">Ours</td><td align="left">&#x02013;</td><td align="left"><inline-formula id="IEq66"><alternatives><tex-math id="M147">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M148"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq66.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq67"><alternatives><tex-math id="M149">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M150"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq67.gif"/></alternatives></inline-formula></td><td align="left"><inline-formula id="IEq68"><alternatives><tex-math id="M151">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\checkmark$$\end{document}</tex-math><mml:math id="M152"><mml:mo stretchy="false">&#x02713;</mml:mo></mml:math><inline-graphic xlink:href="41598_2024_54809_Article_IEq68.gif"/></alternatives></inline-formula></td></tr></tbody></table></table-wrap><table-wrap id="Tab4"><label>Table 4</label><caption><p>Overview of models&#x02019; parameter configuration.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Parameter</th><th align="left">Deepwalk</th><th align="left">Node2vec</th><th align="left">Bot2vec</th><th align="left">GCN</th><th align="left">GAT</th><th align="left">SATAR</th><th align="left">BotRGCN</th><th align="left">RFGNN</th><th align="left">Ours</th></tr></thead><tbody><tr><td align="left">Network layers</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">2</td><td align="left">2</td><td align="left">1</td><td align="left">2</td><td align="left">2</td><td align="left">2</td></tr><tr><td align="left">Dropout value</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">0.3</td><td align="left">0.3</td><td align="left">0.6</td><td align="left">0.3</td><td align="left">0.3</td><td align="left">0.3</td></tr><tr><td align="left">Embedding size</td><td align="left">128</td><td align="left">128</td><td align="left">128</td><td align="left">128</td><td align="left">128</td><td align="left">128</td><td align="left">128</td><td align="left">128</td><td align="left">128</td></tr><tr><td align="left">Learning rate</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">0.001</td><td align="left">0.001</td><td align="left">0.01</td><td align="left">0.001</td><td align="left">0.001</td><td align="left">0.01</td></tr><tr><td align="left">Weight decay</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">0.005</td><td align="left">0.005</td><td align="left">0</td><td align="left">0.005</td><td align="left">0.005</td><td align="left">0.005</td></tr><tr><td align="left">Optimizer</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">AdamW</td><td align="left">AdamW</td><td align="left">SGD</td><td align="left">AdamW</td><td align="left">AdamW</td><td align="left">AdamW</td></tr><tr><td align="left">Epochs</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">100</td><td align="left">100</td><td align="left">100</td><td align="left">100</td><td align="left">100</td><td align="left">100</td></tr><tr><td align="left">Window size</td><td align="left">7</td><td align="left">7</td><td align="left">7</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td></tr><tr><td align="left">Negative sampling</td><td align="left">5</td><td align="left">5</td><td align="left">5</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td></tr><tr><td align="left">Walk length</td><td align="left">30</td><td align="left">30</td><td align="left">30</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">30</td></tr><tr><td align="left">Number of walks</td><td align="left">20</td><td align="left">20</td><td align="left">20</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02014;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td></tr><tr><td align="left">Return parameter</td><td align="left">&#x02013;</td><td align="left">1</td><td align="left">1</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td></tr><tr><td align="left">In-out parameter</td><td align="left">&#x02013;</td><td align="left">1</td><td align="left">1</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td><td align="left">&#x02013;</td></tr></tbody></table></table-wrap></p></sec></sec><sec id="Sec26"><title>Implementation details</title><p id="Par60">We conducted the experiments based on the source code provided by the authors. For model-specific parameters, we used the default configuration of the code, and we tried our best to ensure that the common parameters have the same configuration. The parameter configuration of all models in the experiments is shown in Table&#x000a0;<xref rid="Tab4" ref-type="table">4</xref>. &#x0201c;&#x02013;&#x0201d; is None. The source code for these baseline models can be found in the original paper as well as in TwiBot-22.</p></sec><sec id="Sec27"><title>Experimental results</title><p id="Par61">To validate the performance of the models, we followed the data setting approach used in baseline models such as BotRGCN, SATAR and Bot2vec. The Deepwalk/Node2vec/Bot2vec models in both public datasets are trained with 90% of the data and tested with the remaining 10% . Both GCN/GAT/SATAR/BotRGCN/RFGNN and our model use 70% of the data as the training set, 20% of the data as the validation set, and the remaining 10% of the data as the testing set. The training of neural network is stochastic to some extent, so the learned model weights and errors can vary slightly after each iteration even with the fixed hyperparameters and data splits. In order to avoid the randomness in the training process, the models are trained and tested for 5 iterations but with the same partitioned data. The average performance over the repeated experiments is reported as the final result, which smooths out the random fluctuations and provides a more stable assessment of model effectiveness. Accuracy, F1-Score and Precision are used as evaluation metrics and experiments are conducted on three benchmark datasets. The experimental results are shown in Table&#x000a0;<xref rid="Tab5" ref-type="table">5</xref>, where the best results are in bold.<table-wrap id="Tab5"><label>Table 5</label><caption><p>Performance comparison of multiple social bot detection models on three benchmark datasets (%).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2">Model</th><th align="left" colspan="4">Twitbot-20</th><th align="left" colspan="4">TwiBot-22</th></tr><tr><th align="left">Accuracy</th><th align="left">F1-Score</th><th align="left">Precision</th><th align="left">AUC</th><th align="left">Accuracy</th><th align="left">F1-Score</th><th align="left">Precision</th><th align="left">AUC</th></tr></thead><tbody><tr><td align="left">Deepwalk</td><td align="left">56.31 &#x000b1; 1.34</td><td align="left">61.13 &#x000b1; 0.87</td><td align="left">53.27 &#x000b1; 1.26</td><td align="left">57.71 &#x000b1; 0.73</td><td align="left">51.87 &#x000b1; 1.65</td><td align="left">37.94 &#x000b1; 1.41</td><td align="left">49.17 &#x000b1; 0.76</td><td align="left">50.28 &#x000b1; 0.91</td></tr><tr><td align="left">Node2vec</td><td align="left">60.66 &#x000b1; 1.03</td><td align="left">66.05 &#x000b1; 1.17</td><td align="left">59.23 &#x000b1; 0.89</td><td align="left">61.81 &#x000b1; 0.87</td><td align="left">57.11 &#x000b1; 1.25</td><td align="left">39.27 &#x000b1; 1.31</td><td align="left">55.97 &#x000b1; 0.97</td><td align="left">55.78 &#x000b1; 1.07</td></tr><tr><td align="left">Bot2vec</td><td align="left">63.28 &#x000b1; 0.87</td><td align="left">71.47 &#x000b1; 1.04</td><td align="left">63.18 &#x000b1; 0.71</td><td align="left">60.37 &#x000b1; 1.37</td><td align="left">59.14 &#x000b1; 0.83</td><td align="left">41.08 &#x000b1; 1.16</td><td align="left">57.26 &#x000b1; 0.73</td><td align="left">49.81 &#x000b1; 2.37</td></tr><tr><td align="left">GCN</td><td align="left">74.64 &#x000b1; 0.24</td><td align="left">77.03 &#x000b1; 0.37</td><td align="left">73.17 &#x000b1; 0.17</td><td align="left">83.07 &#x000b1; 0.48</td><td align="left">72.39 &#x000b1; 0.51</td><td align="left">44.80 &#x000b1; 0.35</td><td align="left">71.19 &#x000b1; 0.27</td><td align="left">72.78 &#x000b1; 0.42</td></tr><tr><td align="left">GAT</td><td align="left">83.27 &#x000b1; 0.32</td><td align="left">85.25 &#x000b1; 0.44</td><td align="left">81.26 &#x000b1; 0.29</td><td align="left">84.63 &#x000b1; 0.56</td><td align="left">78.36 &#x000b1; 0.41</td><td align="left">55.86 &#x000b1; 0.39</td><td align="left">72.23 &#x000b1; 0.25</td><td align="left">73.47 &#x000b1; 0.33</td></tr><tr><td align="left">SATAR</td><td align="left">84.02 &#x000b1; 0.17</td><td align="left">86.07 &#x000b1; 0.24</td><td align="left">81.50 &#x000b1; 0.18</td><td align="left">90.88 &#x000b1; 0.27</td><td align="left">78.71 &#x000b1; 0.42</td><td align="left">57.10 &#x000b1; 0.26</td><td align="left">74.07 &#x000b1; 0.13</td><td align="left">79.26 &#x000b1; 0.67</td></tr><tr><td align="left">BotRGCN</td><td align="left">84.61 &#x000b1; 0.38</td><td align="left">87.07 &#x000b1; 0.43</td><td align="left">83.79 &#x000b1; 0.24</td><td align="left">91.46 &#x000b1; 0.26</td><td align="left">79.66 &#x000b1; 0.14</td><td align="left">57.50 &#x000b1; 0.12</td><td align="left">74.81 &#x000b1; 0.21</td><td align="left">78.21 &#x000b1; 0.56</td></tr><tr><td align="left">RFGNN</td><td align="left">83.92 &#x000b1; 0.21</td><td align="left">83.37 &#x000b1; 0.27</td><td align="left">82.19 &#x000b1; 0.44</td><td align="left">88.67 &#x000b1; 0.48</td><td align="left">78.61 &#x000b1; 0.32</td><td align="left">55.67 &#x000b1; 0.41</td><td align="left">72.86 &#x000b1; 0.56</td><td align="left">76.87 &#x000b1; 0.51</td></tr><tr><td align="left">RFGNN-R</td><td align="left">85.03 &#x000b1; 0.69</td><td align="left">87.96 &#x000b1; 0.57</td><td align="left">84.11 &#x000b1; 0.51</td><td align="left">91.67 &#x000b1; 0.63</td><td align="left">80.37 &#x000b1; 0.46</td><td align="left">57.97 &#x000b1; 0.58</td><td align="left">75.33 &#x000b1; 0.51</td><td align="left">79.61 &#x000b1; 0.63</td></tr><tr><td align="left">Ours</td><td align="left">87.01 &#x000b1; 0.08</td><td align="left">88.74 &#x000b1; 0.13</td><td align="left">85.83 &#x000b1; 0.06</td><td align="left">93.79 &#x000b1; 0.32</td><td align="left">82.71 &#x000b1; 0.16</td><td align="left">59.31 &#x000b1; 0.12</td><td align="left">77.23 &#x000b1; 0.17</td><td align="left"> 82.31 &#x000b1; 0.49</td></tr></tbody></table></table-wrap></p><p id="Par62">
<fig id="Fig3"><label>Figure 3</label><caption><p>Visualization of human-bot user representations of the TwiBot-20 dataset by various models via t-SNE 2D projections and the corresponding homogeneity score.</p></caption><graphic xlink:href="41598_2024_54809_Fig3_HTML" id="MO4"/></fig>
<fig id="Fig4"><label>Figure 4</label><caption><p>Visualization of human-bot user representations of the TwiBot-22 dataset by various models via t-SNE 2D projections and the corresponding homogeneity score.</p></caption><graphic xlink:href="41598_2024_54809_Fig4_HTML" id="MO5"/></fig>
</p><p id="Par63">As seen in Table&#x000a0;<xref rid="Tab5" ref-type="table">5</xref>, the Accuracy of the social bot detection model (Deepwalk/Node2vec/Bot2vec) using only graph structure features is below 0.65 on the Twibot-20 dataset, which may be ascribed to the following reasons. Only 20 neighbor nodes (10 Following and 10 Followers) were extracted for each account in the Twibot-20 dataset, and the structural features of the accounts were impaired. Such models use only structural features which allow novel bots to evade detection. The social bot detection models that simultaneously utilize account property features, semantic features, and structural features all have an accuracy of over 74% on the Twibot-20 dataset, which improves the detection accuracy by more than 10% than purely utilize graph structural features, indicating the desirability of combining multiple types of features for social bot detection. Compared with the GCN model, GAT and SATAR introduced attention mechanisms, and the effect was improved by more than 8.6%. BotRGCN divides the edge into Following edge and Follower edge, aggregates the surrounding neighbor information according to different relationships, and the accuracy is improved by about 9.9%; Our model uses subgraph encoding to improve accuracy by about 12.4%. These phenomena indicate that changing the node aggregation method affects the performance of the model. Compared with the BotRGCN, our model&#x02019;s detection accuracy improves by about 2.4%, compared with the RFGNN-R, our model&#x02019;s detection accuracy improves by about 2.0%, indicating that the design idea of the subgraph encoding-based graph convolutional network social bot detection model is feasible.</p><p id="Par64">To justify why the proposed model has better performance, we use the t-SNE 2D visualization technique to visualize the embedding vectors and the corresponding homogeneity score obtained by each model on the TwiBot-20 dataset and TwiBot-22, as illustrated in Figs.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref> and <xref rid="Fig4" ref-type="fig">4</xref>. The t-SNE visualization results can reflect the quality of model training to a certain extent<sup><xref ref-type="bibr" rid="CR11">11</xref>,<xref ref-type="bibr" rid="CR12">12</xref>,<xref ref-type="bibr" rid="CR32">32</xref>,<xref ref-type="bibr" rid="CR34">34</xref></sup>. A higher homogeneity score means the samples are better clustered. It can be observed from Figs.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref> and <xref rid="Fig4" ref-type="fig">4</xref> that our model achieves the highest homogeneity score and the embedding vector obtained from our model training is more beneficial for the social bot detection task.<fig id="Fig5"><label>Figure 5</label><caption><p>The ROC-AUC curve on two benchmark datasets.</p></caption><graphic xlink:href="41598_2024_54809_Fig5_HTML" id="MO6"/></fig><fig id="Fig6"><label>Figure 6</label><caption><p>Illustration of accuracy when using various combination of the features for the training of the SEGCN model. The features used are accounts&#x02019; description features (d), tweet feature (t), numerical features (n) and category features (c).</p></caption><graphic xlink:href="41598_2024_54809_Fig6_HTML" id="MO7"/></fig></p><p id="Par65">In addition, we selected five representative models and plotted the ROC-AUC curves of each model on the Twibot-20 and Twibot-22 datasets based on the SVM classifier (Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>). Observing the ROC-AUC curves, the one corresponding the node representation vectors learned by our model has the largest area under the curve, which indicates the proposed model has a stronger expressive power than the compared models.</p><sec id="Sec28"><title>Ablation experiment on features</title><p id="Par66">To investigate the effect of different types of features on the detection performance of our model, we conducted feature ablation experiments on two datasets. After adding account description features (d), tweet semantic features (t), numeric features (n), and category features (c) to SEGCN, the detection accuracy of the model are shown in Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref>. By comparing &#x0201c;d&#x0201d;, &#x0201c;t&#x0201d;, &#x0201c;n&#x0201d; and &#x0201c;c&#x0201d;, we can see that the category features have a greater impact on the model performance, which may be due to the fact that both datasets have more important category features such as whether they are authenticated or not. The accounts that are authenticated are usually human accounts. Most importantly, the best detection performance is achieved by &#x0201c;d+t+n+c&#x0201d;, which validates that all of the four types of features are necessary for social bot detection.</p><p id="Par67">In general, the use of subgraph encoding can capture the differences of structural features in subgraphs and improve the expressive power of GCN, and a large number of experiments showed the good performance of SEGCN. It should be noted that the proposed model is a general social bot detection framework, which is applicable for furthermore meaningful features. It can also adjust the features dynamically according to the development of social bot, which has great potential for industrial applications.</p></sec></sec></sec><sec id="Sec29"><title>Discussion</title><p id="Par68">This section discusses the differences between our research and the existing ones. The investigation in<sup><xref ref-type="bibr" rid="CR10">10</xref></sup> and extensive experimental results in &#x0201c;<xref rid="Sec14" ref-type="sec">Experiments</xref>&#x0201d; shows that the evolution of social bots made social bot detection methods using only a single type of feature less effective in detecting novel bots. The existing social bot detection methods using multiple types of features have yielded promising results in detecting novel bot tasks, but they ignore the fact that the MPNN&#x02019;s expressive power is upper-bounded by the 1-WL isomorphism test<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>. The experimental results in Table&#x000a0;<xref rid="Tab5" ref-type="table">5</xref> shows that compared with classical GCN, the subgraph coding can better capture the structural features of nodes in the social bot detection task, indicating that the subgraph encoding can improve the expression ability of GCN.</p><p id="Par69">The most significant difference between our model and the existing ones is that subgraph coding method is introduced to improve the performance of social bot detection. To explicitly compare with the detection models, we present an overview of the account features used by each model in Table&#x000a0;<xref rid="Tab3" ref-type="table">3</xref>. The Deepwalk<sup><xref ref-type="bibr" rid="CR55">55</xref></sup>, Node2vec<sup><xref ref-type="bibr" rid="CR56">56</xref></sup> and Bot2vec<sup><xref ref-type="bibr" rid="CR34">34</xref></sup> utilize the structure features of the account. GCN<sup><xref ref-type="bibr" rid="CR44">44</xref></sup>, GAT<sup><xref ref-type="bibr" rid="CR57">57</xref></sup>, SATAR<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>, BotRGCN<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>, RFGNN<sup><xref ref-type="bibr" rid="CR48">48</xref></sup> and our model all exploit the semantic features, property features, and structural features of the account. However, our model uses subgraph encoding to improve the expressiveness of the GCN.</p></sec><sec id="Sec30"><title>Conclusion</title><p id="Par70">In this paper, we propose a subgraph encoding based graph convolutional network model for social bot detection, named SEGCN, which uses subgraph encoding to improve the expressive power of graph convolutional networks and uses multiple types of features simultaneously for social bot detection. To the best of our knowledge, this is the first work using subgraph encoding based graph convolutional networks for social bot detection. Experimental results on two benchmark datasets show that the model achieves better performance than the SOTA approach and effectively improves the expressive power of GCN. However, the application of the proposed method in the real world social platform, for instance, Twitter (now called X ), is facing more difficulty, because some of the data that needed to evaluate the social account is not free to access anymore. Nevertheless, our method provides a generalized framework for social bot detection, and social platforms and individuals can refer to this pipeline to detect the social bots. In the future, we will try to investigate the construction of heterogeneous graphs to detect social bots using accounts in social networks with multiple types of activity relationships.</p></sec></body><back><fn-group><fn><p><bold>Publisher's note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><ack><title>Acknowledgements</title><p>This work is supported by the National Natural Science Foundation of China (Grant Nos. 62002387, 61872448, 61772549, U1804263, 62002386), the Science and Technology Research Project of Henan Province (No. 222102210075), China and the Key Research and Development Project of Henan Province (No. 221111321200), China.</p></ack><notes notes-type="author-contribution"><title>Author contributions</title><p>F.L. contributed the central idea, analysed most of the data, and wrote the initial draft of the paper. Z.L. provided detailed guidance on writing the manuscript and made meticulous revisions and polish to the manuscript. The remaining authors contributed to refining the ideas, carrying out additional analyses and finalizing this paper. All authors read and approved the manuscript.</p></notes><notes notes-type="data-availability"><title>Data availibility</title><p>The Twibot-20 dataset and the Twibot-22 dataset are used to support the findings of this study, which are available at &#x0201c;<ext-link ext-link-type="uri" xlink:href="https://github.com/BunsenFeng/TwiBot-20">https://github.com/BunsenFeng/TwiBot-20</ext-link>&#x0201d; and &#x0201c;<ext-link ext-link-type="uri" xlink:href="https://github.com/LuoUndergradXJTU/TwiBot-22">https://github.com/LuoUndergradXJTU/TwiBot-22</ext-link>&#x0201d;, respectively.</p></notes><notes id="FPar1" notes-type="COI-statement"><title>Competing Interests</title><p id="Par71">The authors declare no competing interests.</p></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferrara</surname><given-names>E</given-names></name><name><surname>Varol</surname><given-names>O</given-names></name><name><surname>Davis</surname><given-names>C</given-names></name><name><surname>Menczer</surname><given-names>F</given-names></name><name><surname>Flammini</surname><given-names>A</given-names></name></person-group><article-title>The rise of social bots</article-title><source>Commun. ACM</source><year>2016</year><volume>59</volume><fpage>96</fpage><lpage>104</lpage><pub-id pub-id-type="doi">10.1145/2818717</pub-id></element-citation></ref><ref id="CR2"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Subrahmanian</surname><given-names>VS</given-names></name><etal/></person-group><article-title>The darpa twitter bot challenge</article-title><source>Computer</source><year>2016</year><volume>49</volume><fpage>38</fpage><lpage>46</lpage><pub-id pub-id-type="doi">10.1109/MC.2016.183</pub-id></element-citation></ref><ref id="CR3"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stella</surname><given-names>M</given-names></name><name><surname>Ferrara</surname><given-names>E</given-names></name><name><surname>De Domenico</surname><given-names>M</given-names></name></person-group><article-title>Bots increase exposure to negative and inflammatory content in online social systems</article-title><source>Proc. Natl. Acad. Sci.</source><year>2018</year><volume>115</volume><fpage>12435</fpage><lpage>12440</lpage><pub-id pub-id-type="doi">10.1073/pnas.1803470115</pub-id><?supplied-pmid 30459270?><pub-id pub-id-type="pmid">30459270</pub-id>
</element-citation></ref><ref id="CR4"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cresci</surname><given-names>S</given-names></name><name><surname>Di Pietro</surname><given-names>R</given-names></name><name><surname>Petrocchi</surname><given-names>M</given-names></name><name><surname>Spognardi</surname><given-names>A</given-names></name><name><surname>Tesconi</surname><given-names>M</given-names></name></person-group><article-title>Fame for sale: Efficient detection of fake twitter followers</article-title><source>Decis. Support Syst.</source><year>2015</year><volume>80</volume><fpage>56</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1016/j.dss.2015.09.003</pub-id></element-citation></ref><ref id="CR5"><label>5.</label><mixed-citation publication-type="other">Ratkiewicz, J. <italic>et&#x000a0;al.</italic> Truthy: Mapping the spread of astroturf in microblog streams. In <italic>Proceedings of the 20th International Conference Companion on World Wide Web</italic>, 249&#x02013;252 (2011).</mixed-citation></ref><ref id="CR6"><label>6.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>H-CH</given-names></name><name><surname>Chen</surname><given-names>E</given-names></name><name><surname>Zhang</surname><given-names>M</given-names></name><name><surname>Muric</surname><given-names>G</given-names></name><name><surname>Ferrara</surname><given-names>E</given-names></name></person-group><article-title>Social bots and social media manipulation in 2020: The year in review</article-title><source>Handbook of Computational Social Science</source><year>2021</year><publisher-name>Routledge</publisher-name><fpage>304</fpage><lpage>323</lpage></element-citation></ref><ref id="CR7"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Donovan</surname><given-names>J</given-names></name></person-group><article-title>Stuck: How vaccine rumors start-and why they don&#x02019;t go away</article-title><source>Nature</source><year>2020</year><volume>583</volume><fpage>680</fpage><lpage>681</lpage><pub-id pub-id-type="doi">10.1038/d41586-020-02192-w</pub-id></element-citation></ref><ref id="CR8"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cresci</surname><given-names>S</given-names></name><name><surname>Lillo</surname><given-names>F</given-names></name><name><surname>Regoli</surname><given-names>D</given-names></name><name><surname>Tardelli</surname><given-names>S</given-names></name><name><surname>Tesconi</surname><given-names>M</given-names></name></person-group><article-title>Cashtag piggybacking: Uncovering spam and bot activity in stock microblogs on twitter</article-title><source>ACM Trans. Web</source><year>2019</year><volume>13</volume><fpage>1</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1145/3313184</pub-id></element-citation></ref><ref id="CR9"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noekhah</surname><given-names>S</given-names></name><name><surname>Binti Salim</surname><given-names>N</given-names></name><name><surname>Zakaria</surname><given-names>NH</given-names></name></person-group><article-title>Opinion spam detection: Using multi-iterative graph-based model</article-title><source>Inf. Process. Manage.</source><year>2020</year><volume>57</volume><fpage>102140</fpage><pub-id pub-id-type="doi">10.1016/j.ipm.2019.102140</pub-id></element-citation></ref><ref id="CR10"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cresci</surname><given-names>S</given-names></name></person-group><article-title>A decade of social bot detection</article-title><source>Commun. ACM</source><year>2020</year><volume>63</volume><fpage>72</fpage><lpage>83</lpage><pub-id pub-id-type="doi">10.1145/3409116</pub-id></element-citation></ref><ref id="CR11"><label>11.</label><mixed-citation publication-type="other">Feng, S., Wan, H., Wang, N. &#x00026; Luo, M. Botrgcn: Twitter bot detection with relational graph convolutional networks. In <italic>Proceedings of the 2021 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining</italic>, 236&#x02013;239 (2021).</mixed-citation></ref><ref id="CR12"><label>12.</label><mixed-citation publication-type="other">Feng, S., Wan, H., Wang, N. &#x00026; Luo, M. Botrgcn: Twitter bot detection with relational graph convolutional networks. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2106.13092">arXiv:2106.13092</ext-link> (arXiv preprint) (2021).</mixed-citation></ref><ref id="CR13"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fazil</surname><given-names>M</given-names></name><name><surname>Sah</surname><given-names>AK</given-names></name><name><surname>Abulaish</surname><given-names>M</given-names></name></person-group><article-title>Deepsbd: A deep neural network model with attention mechanism for socialbot detection</article-title><source>IEEE Trans. Inf. Forensics Secur.</source><year>2021</year><volume>16</volume><fpage>4211</fpage><lpage>4223</lpage><pub-id pub-id-type="doi">10.1109/TIFS.2021.3102498</pub-id></element-citation></ref><ref id="CR14"><label>14.</label><mixed-citation publication-type="other">Ali&#x000a0;Alhosseini, S., Bin&#x000a0;Tareaf, R., Najafi, P. &#x00026; Meinel, C. Detect me if you can: Spam bot detection using inductive representation learning. In <italic>Companion Proceedings of The 2019 World Wide Web Conference</italic>, 148&#x02013;153 (2019).</mixed-citation></ref><ref id="CR15"><label>15.</label><mixed-citation publication-type="other">Leskovec, K. X. W. H.&#x000a0;J. &#x00026; Jegelka, S. How powerful are graph neural networks? In <italic>International Conference on Learning Representations</italic>, 1&#x02013;9 (2018).</mixed-citation></ref><ref id="CR16"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>Z</given-names></name><name><surname>Chen</surname><given-names>L</given-names></name><name><surname>Villar</surname><given-names>S</given-names></name><name><surname>Bruna</surname><given-names>J</given-names></name></person-group><article-title>Can graph neural networks count substructures?</article-title><source>Adv. Neural. Inf. Process. Syst.</source><year>2020</year><volume>33</volume><fpage>10383</fpage><lpage>10395</lpage></element-citation></ref><ref id="CR17"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arvind</surname><given-names>V</given-names></name><name><surname>Fuhlbr&#x000fc;ck</surname><given-names>F</given-names></name><name><surname>K&#x000f6;bler</surname><given-names>J</given-names></name><name><surname>Verbitsky</surname><given-names>O</given-names></name></person-group><article-title>On Weisfeiler&#x02013;Leman invariance: Subgraph counts and related graph properties</article-title><source>J. Comput. Syst. Sci.</source><year>2020</year><volume>113</volume><fpage>42</fpage><lpage>59</lpage><pub-id pub-id-type="doi">10.1016/j.jcss.2020.04.003</pub-id></element-citation></ref><ref id="CR18"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>C</given-names></name><name><surname>Harkreader</surname><given-names>R</given-names></name><name><surname>Gu</surname><given-names>G</given-names></name></person-group><article-title>Empirical evaluation and new design for fighting evolving twitter spammers</article-title><source>IEEE Trans. Inf. Forensics Secur.</source><year>2013</year><volume>8</volume><fpage>1280</fpage><lpage>1293</lpage><pub-id pub-id-type="doi">10.1109/TIFS.2013.2267732</pub-id></element-citation></ref><ref id="CR19"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yardi</surname><given-names>S</given-names></name><name><surname>Romero</surname><given-names>D</given-names></name><name><surname>Schoenebeck</surname><given-names>G</given-names></name><etal/></person-group><article-title>Detecting spam in a twitter network</article-title><source>First Monday</source><year>2010</year><volume>20</volume><fpage>20</fpage></element-citation></ref><ref id="CR20"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>K</given-names></name><name><surname>Eoff</surname><given-names>B</given-names></name><name><surname>Caverlee</surname><given-names>J</given-names></name></person-group><article-title>Seven months with the devils: A long-term study of content polluters on twitter</article-title><source>Proc. Int. AAAI Conf. Web Soc. Med.</source><year>2011</year><volume>5</volume><fpage>185</fpage><lpage>192</lpage><pub-id pub-id-type="doi">10.1609/icwsm.v5i1.14106</pub-id></element-citation></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="other">Beskow, D.&#x000a0;M. &#x00026; Carley, K.&#x000a0;M. Bot conversations are different: Leveraging network metrics for bot detection in twitter. In <italic>2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)</italic>, 825&#x02013;832 (IEEE, 2018).</mixed-citation></ref><ref id="CR22"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>K-C</given-names></name><name><surname>Varol</surname><given-names>O</given-names></name><name><surname>Hui</surname><given-names>P-M</given-names></name><name><surname>Menczer</surname><given-names>F</given-names></name></person-group><article-title>Scalable and generalizable social bot detection through data selection</article-title><source>Proc. AAAI Conf. Artif. Intell.</source><year>2020</year><volume>34</volume><fpage>1096</fpage><lpage>1103</lpage></element-citation></ref><ref id="CR23"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chu</surname><given-names>Z</given-names></name><name><surname>Gianvecchio</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>H</given-names></name><name><surname>Jajodia</surname><given-names>S</given-names></name></person-group><article-title>Detecting automation of twitter accounts: Are you a human, bot, or cyborg?</article-title><source>IEEE Trans. Depend. Secure Comput.</source><year>2012</year><volume>9</volume><fpage>811</fpage><lpage>824</lpage><pub-id pub-id-type="doi">10.1109/TDSC.2012.75</pub-id></element-citation></ref><ref id="CR24"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cresci</surname><given-names>S</given-names></name><name><surname>Di Pietro</surname><given-names>R</given-names></name><name><surname>Petrocchi</surname><given-names>M</given-names></name><name><surname>Spognardi</surname><given-names>A</given-names></name><name><surname>Tesconi</surname><given-names>M</given-names></name></person-group><article-title>Social fingerprinting: Detection of spambot groups through dna-inspired behavioral modeling</article-title><source>IEEE Trans. Depend. Secure Comput.</source><year>2017</year><volume>15</volume><fpage>561</fpage><lpage>576</lpage></element-citation></ref><ref id="CR25"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rodr&#x000ed;guez-Ruiz</surname><given-names>J</given-names></name><name><surname>Mata-S&#x000e1;nchez</surname><given-names>JI</given-names></name><name><surname>Monroy</surname><given-names>R</given-names></name><name><surname>Loyola-Gonz&#x000e1;lez</surname><given-names>O</given-names></name><name><surname>L&#x000f3;pez-Cuevas</surname><given-names>A</given-names></name></person-group><article-title>A one-class classification approach for bot detection on twitter</article-title><source>Comput. Secur.</source><year>2020</year><volume>91</volume><fpage>101715</fpage><pub-id pub-id-type="doi">10.1016/j.cose.2020.101715</pub-id></element-citation></ref><ref id="CR26"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Nicola</surname><given-names>R</given-names></name><name><surname>Petrocchi</surname><given-names>M</given-names></name><name><surname>Pratelli</surname><given-names>M</given-names></name></person-group><article-title>On the efficacy of old features for the detection of new bots</article-title><source>Inf. Process. Manage.</source><year>2021</year><volume>58</volume><fpage>102685</fpage><pub-id pub-id-type="doi">10.1016/j.ipm.2021.102685</pub-id></element-citation></ref><ref id="CR27"><label>27.</label><mixed-citation publication-type="other">Sayyadiharikandeh, M., Varol, O., Yang, K.-C., Flammini, A. &#x00026; Menczer, F. Detection of novel social bots by ensembles of specialized classifiers. In <italic>Proceedings of the 29th ACM International Conference on Information and Knowledge Management</italic>, 2725&#x02013;2732 (2020).</mixed-citation></ref><ref id="CR28"><label>28.</label><mixed-citation publication-type="other">Yang, K.-C., Ferrara, E. &#x00026; Menczer, F. Botometer 101: Social bot practicum for computational social scientists. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2201.01608">arXiv:2201.01608</ext-link> (arXiv preprint) (2022).</mixed-citation></ref><ref id="CR29"><label>29.</label><mixed-citation publication-type="other">Davis, C.&#x000a0;A., Varol, O., Ferrara, E., Flammini, A. &#x00026; Menczer, F. Botornot: A system to evaluate social bots. In <italic>Proceedings of the 25th International Conference Companion on World Wide Web</italic>, 273&#x02013;274 (2016).</mixed-citation></ref><ref id="CR30"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>Z</given-names></name><name><surname>Dickinson</surname><given-names>B</given-names></name><name><surname>Deitrick</surname><given-names>W</given-names></name><name><surname>Hu</surname><given-names>W</given-names></name><name><surname>Wang</surname><given-names>AH</given-names></name></person-group><article-title>Twitter spammer detection using data stream clustering</article-title><source>Inf. Sci.</source><year>2014</year><volume>260</volume><fpage>64</fpage><lpage>73</lpage><pub-id pub-id-type="doi">10.1016/j.ins.2013.11.016</pub-id></element-citation></ref><ref id="CR31"><label>31.</label><mixed-citation publication-type="other">Ping, H. &#x00026; Qin, S. A social bots detection model based on deep learning algorithm. In <italic>2018 IEEE 18th International Conference on Communication Technology (ICCT)</italic>, 1435&#x02013;1439 (IEEE, 2018).</mixed-citation></ref><ref id="CR32"><label>32.</label><mixed-citation publication-type="other">Feng, S., Wan, H., Wang, N., Li, J. &#x00026; Luo, M. Satar: A self-supervised approach to twitter account representation learning and its application in bot detection. In <italic>Proceedings of the 30th ACM International Conference on Information &#x00026; Knowledge Management</italic>, 3808&#x02013;3817 (2021).</mixed-citation></ref><ref id="CR33"><label>33.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Karpov</surname><given-names>Ilia</given-names></name><name><surname>Glazkova</surname><given-names>Ekaterina</given-names></name></person-group><person-group person-group-type="editor"><name><surname>van der Aalst</surname><given-names>Wil M. P.</given-names></name><name><surname>Batagelj</surname><given-names>Vladimir</given-names></name><name><surname>Buzmakov</surname><given-names>Alexey</given-names></name><name><surname>Ignatov</surname><given-names>Dmitry I.</given-names></name><name><surname>Kalenkova</surname><given-names>Anna</given-names></name><name><surname>Khachay</surname><given-names>Michael</given-names></name><name><surname>Koltsova</surname><given-names>Olessia</given-names></name><name><surname>Kutuzov</surname><given-names>Andrey</given-names></name><name><surname>Kuznetsov</surname><given-names>Sergei O.</given-names></name><name><surname>Lomazova</surname><given-names>Irina A.</given-names></name><name><surname>Loukachevitch</surname><given-names>Natalia</given-names></name><name><surname>Makarov</surname><given-names>Ilya</given-names></name><name><surname>Napoli</surname><given-names>Amedeo</given-names></name><name><surname>Panchenko</surname><given-names>Alexander</given-names></name><name><surname>Pardalos</surname><given-names>Panos M.</given-names></name><name><surname>Pelillo</surname><given-names>Marcello</given-names></name><name><surname>Savchenko</surname><given-names>Andrey V.</given-names></name><name><surname>Tutubalina</surname><given-names>Elena</given-names></name></person-group><article-title>Detecting automatically managed accounts in online social networks: Graph embeddings approach</article-title><source>Recent Trends in Analysis of Images, Social Networks and Texts: 9th International Conference, AIST 2020, Skolkovo, Moscow, Russia, October 15&#x02013;16, 2020 Revised Supplementary Proceedings</source><year>2021</year><publisher-name>Springer International Publishing</publisher-name><fpage>11</fpage><lpage>21</lpage></element-citation></ref><ref id="CR34"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pham</surname><given-names>P</given-names></name><name><surname>Nguyen</surname><given-names>LT</given-names></name><name><surname>Vo</surname><given-names>B</given-names></name><name><surname>Yun</surname><given-names>U</given-names></name></person-group><article-title>Bot2vec: A general approach of intra-community oriented representation learning for bot detection in different types of social networks</article-title><source>Inf. Syst.</source><year>2022</year><volume>103</volume><fpage>101771</fpage><pub-id pub-id-type="doi">10.1016/j.is.2021.101771</pub-id></element-citation></ref><ref id="CR35"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Wenxian</given-names></name><name><surname>Chen</surname><given-names>Xingshu</given-names></name><name><surname>Jiang</surname><given-names>Shuyu</given-names></name><name><surname>Wang</surname><given-names>Haizhou</given-names></name><name><surname>Yin</surname><given-names>Mingyong</given-names></name><name><surname>Wang</surname><given-names>Peiming</given-names></name></person-group><article-title>Exploring the construction and infiltration strategies of social bots in sina microblog</article-title><source>Sci. Rep.</source><year>2020</year><pub-id pub-id-type="doi">10.1038/s41598-020-76814-8</pub-id><?supplied-pmid 33384438?><pub-id pub-id-type="pmid">33384438</pub-id>
</element-citation></ref><ref id="CR36"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>R</given-names></name><name><surname>Sun</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Zhang</surname><given-names>C</given-names></name></person-group><article-title>Truetop: A sybil-resilient system for user influence measurement on twitter</article-title><source>IEEE/ACM Trans. Network.</source><year>2015</year><volume>24</volume><fpage>2834</fpage><lpage>2846</lpage><pub-id pub-id-type="doi">10.1109/TNET.2015.2494059</pub-id></element-citation></ref><ref id="CR37"><label>37.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>B</given-names></name><name><surname>Jia</surname><given-names>J</given-names></name><name><surname>Zhang</surname><given-names>L</given-names></name><name><surname>Gong</surname><given-names>NZ</given-names></name></person-group><article-title>Structure-based sybil detection in social networks via local rule-based propagation</article-title><source>IEEE Trans. Netw. Sci. Eng.</source><year>2018</year><volume>6</volume><fpage>523</fpage><lpage>537</lpage><pub-id pub-id-type="doi">10.1109/TNSE.2018.2813672</pub-id></element-citation></ref><ref id="CR38"><label>38.</label><mixed-citation publication-type="other">Wang, B., Gong, N.&#x000a0;Z. &#x00026; Fu, H. Gang: Detecting fraudulent users in online social networks via guilt-by-association on directed graphs. In <italic>2017 IEEE International Conference on Data Mining (ICDM)</italic>, 465&#x02013;474 (IEEE, 2017).</mixed-citation></ref><ref id="CR39"><label>39.</label><mixed-citation publication-type="other">Jia, J., Wang, B. &#x00026; Gong, N.&#x000a0;Z. Random walk based fake account detection in online social networks. In <italic>2017 47th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)</italic>, 273&#x02013;284 (IEEE, 2017).</mixed-citation></ref><ref id="CR40"><label>40.</label><mixed-citation publication-type="other">Wang, B., Zhang, L. &#x00026; Gong, N.&#x000a0;Z. Sybilscar: Sybil detection in online social networks via local rule based propagation. In <italic>IEEE INFOCOM 2017-IEEE Conference on Computer Communications</italic>, 1&#x02013;9 (IEEE, 2017).</mixed-citation></ref><ref id="CR41"><label>41.</label><mixed-citation publication-type="other">Gao, P. <italic>et&#x000a0;al.</italic> Sybilfuse: Combining local attributes with global structure to perform robust sybil detection. In <italic>2018 IEEE Conference on Communications and Network Security (CNS)</italic>, 1&#x02013;9 (IEEE, 2018).</mixed-citation></ref><ref id="CR42"><label>42.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>J</given-names></name><etal/></person-group><article-title>Multi-attributed heterogeneous graph convolutional network for bot detection</article-title><source>Inf. Sci.</source><year>2020</year><volume>537</volume><fpage>380</fpage><lpage>393</lpage><pub-id pub-id-type="doi">10.1016/j.ins.2020.03.113</pub-id></element-citation></ref><ref id="CR43"><label>43.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lo</surname><given-names>WW</given-names></name><name><surname>Kulatilleke</surname><given-names>G</given-names></name><name><surname>Sarhan</surname><given-names>M</given-names></name><name><surname>Layeghy</surname><given-names>S</given-names></name><name><surname>Portmann</surname><given-names>M</given-names></name></person-group><article-title>Xg-bot: An explainable deep graph neural network for botnet detection and forensics</article-title><source>Internet Things</source><year>2023</year><volume>22</volume><fpage>100747</fpage><pub-id pub-id-type="doi">10.1016/j.iot.2023.100747</pub-id></element-citation></ref><ref id="CR44"><label>44.</label><mixed-citation publication-type="other">Welling, M. &#x00026; Kipf, T.&#x000a0;N. Semi-supervised classification with graph convolutional networks. In <italic>International Conference on Learning Representations (ICLR)</italic> (2017).</mixed-citation></ref><ref id="CR45"><label>45.</label><mixed-citation publication-type="other">Sun, Y., Yang, Z. &#x00026; Dai, Y. Trustgcn: Enabling graph convolutional network for robust sybil detection in osns. In <italic>2020 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)</italic>, 1&#x02013;7 (IEEE, 2020).</mixed-citation></ref><ref id="CR46"><label>46.</label><mixed-citation publication-type="other">Schlichtkrull, M. <italic>et&#x000a0;al.</italic> Modeling relational data with graph convolutional networks. In <italic>European Semantic Web Conference</italic>, 593&#x02013;607 (Springer, 2018).</mixed-citation></ref><ref id="CR47"><label>47.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>Y</given-names></name><etal/></person-group><article-title>Rosgas: Adaptive social bot detection with reinforced self-supervised gnn architecture search</article-title><source>ACM Trans. Web</source><year>2023</year><volume>17</volume><fpage>1</fpage><lpage>31</lpage><pub-id pub-id-type="doi">10.1145/3572403</pub-id></element-citation></ref><ref id="CR48"><label>48.</label><mixed-citation publication-type="other">Shi, S. <italic>et&#x000a0;al.</italic> Rf-gnn: Random forest boosted graph neural network for social bot detection. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2304.08239">arXiv:2304.08239</ext-link> (arXiv preprint) (2023).</mixed-citation></ref><ref id="CR49"><label>49.</label><mixed-citation publication-type="other">Liu, Y. <italic>et&#x000a0;al.</italic> Roberta: A robustly optimized bert pretraining approach. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1907.11692">arXiv:1907.11692</ext-link> (arXiv preprint) (2019).</mixed-citation></ref><ref id="CR50"><label>50.</label><mixed-citation publication-type="other">Xu, B., Wang, N., Chen, T. &#x00026; Li, M. Empirical evaluation of rectified activations in convolutional network. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1505.00853">arXiv:1505.00853</ext-link> (arXiv preprint) (2015).</mixed-citation></ref><ref id="CR51"><label>51.</label><mixed-citation publication-type="other">Zhao, L., Jin, W., Akoglu, L. &#x00026; Shah, N. From stars to subgraphs: Uplifting any gnn with local structure awareness. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2110.03753">arXiv:2110.03753</ext-link> (arXiv preprint) (2021).</mixed-citation></ref><ref id="CR52"><label>52.</label><mixed-citation publication-type="other">Kleinberg, J. The small-world phenomenon: An algorithmic perspective. In <italic>Proceedings of the Thirty-Second Annual ACM Symposium on Theory of Computing</italic>, 163&#x02013;170 (2000).</mixed-citation></ref><ref id="CR53"><label>53.</label><mixed-citation publication-type="other">Feng, S., Wan, H., Wang, N., Li, J. &#x00026; Luo, M. Twibot-20: A comprehensive twitter bot detection benchmark. In <italic>Proceedings of the 30th ACM International Conference on Information and Knowledge Management</italic>, 4485&#x02013;4494 (2021).</mixed-citation></ref><ref id="CR54"><label>54.</label><mixed-citation publication-type="other">Feng, S. <italic>et&#x000a0;al.</italic> Twibot-22: Towards graph-based twitter bot detection. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2206.04564">arXiv:2206.04564</ext-link> (arXiv preprint) (2022).</mixed-citation></ref><ref id="CR55"><label>55.</label><mixed-citation publication-type="other">Perozzi, B., Al-Rfou, R. &#x00026; Skiena, S. Deepwalk: Online learning of social representations. In <italic>Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</italic>, 701&#x02013;710 (2014).</mixed-citation></ref><ref id="CR56"><label>56.</label><mixed-citation publication-type="other">Grover, A. &#x00026; Leskovec, J. node2vec: Scalable feature learning for networks. In <italic>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</italic>, 855&#x02013;864 (2016).</mixed-citation></ref><ref id="CR57"><label>57.</label><mixed-citation publication-type="other">Veli&#x0010d;kovi&#x00107;, P. <italic>et&#x000a0;al.</italic> Graph attention networks. In <italic>International Conference on Learning Representations (ICLR)</italic> (2018).</mixed-citation></ref></ref-list></back></article>