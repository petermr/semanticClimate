{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/petermr/semanticClimate/blob/main/semanticClimate/Summarization/summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Abstractive Summarization**"
      ],
      "metadata": {
        "id": "uTk_ViCimmCK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Install the github repository and the required libraries."
      ],
      "metadata": {
        "id": "llp-tRtRwt0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch==2.0.0 torchvision\n",
        "!git clone https://github.com/petermr/semanticClimate.git\n",
        "!pip install pandas\n",
        "%pip install transformers\n",
        "print('\\033[1;32m We have successfully finished running this cell.')"
      ],
      "metadata": {
        "id": "MvSIJTn0mr9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Import the libraries onto your colab page and make sure you've gotten the correct version."
      ],
      "metadata": {
        "id": "P00CNUSa4UCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "print(torch.__version__)\n",
        "print('\\033[1;32m We have successfully finished running this cell.')"
      ],
      "metadata": {
        "id": "VCunoWJHpcGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Import the Transformer methods and specify the transformer needed to be used."
      ],
      "metadata": {
        "id": "qfxb012wTve9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"pszemraj/led-large-book-summary\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"pszemraj/led-large-book-summary\")\n",
        "hf_name = 'pszemraj/led-large-book-summary'\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "summarizer = pipeline(\n",
        "    \"summarization\",\n",
        "    hf_name,\n",
        "    device=0 if torch.cuda.is_available() else -1,\n",
        ")\n",
        "def count_words(string):\n",
        "  string1 = string.strip()\n",
        "  count = 1\n",
        "  for i in string1:\n",
        "    if i == \" \":\n",
        "      count += 1\n",
        "  return count\n",
        "print('\\033[1;32m We have successfully finished running this cell.')"
      ],
      "metadata": {
        "id": "o9RvkkiiuSVm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Paste the text that needs to be summarized in quotes, decide the minimum and maximum words, and run the cell."
      ],
      "metadata": {
        "id": "j4qkaGaRXyOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wall_of_text = \"\"\n",
        "\n",
        "result = summarizer(\n",
        "    wall_of_text,\n",
        "    min_length=64,\n",
        "    max_length=512,\n",
        "    no_repeat_ngram_size=3,\n",
        "    encoder_no_repeat_ngram_size=3,\n",
        "    repetition_penalty=3.5,\n",
        "    num_beams=4,\n",
        "    early_stopping=True,\n",
        ")\n",
        "#print(count_words(wall_of_text))\n",
        "output = result[0]['summary_text']\n",
        "print(output)"
      ],
      "metadata": {
        "id": "iM4nkeq2wA2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Append the summaries into a CSV file"
      ],
      "metadata": {
        "id": "hckDZ42HX_9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/semanticClimate/paragraphLinking/parsed_sample_anchor_target_pairs.csv')\n",
        "df[\"anchor_summary\"] = df[\"anchor_text\"].apply(lambda x: summarizer(x,\n",
        "    min_length=64,\n",
        "    max_length=512,\n",
        "    no_repeat_ngram_size=3,\n",
        "    encoder_no_repeat_ngram_size=3,\n",
        "    repetition_penalty=3.5,\n",
        "    num_beams=4,\n",
        "    early_stopping=True,)[0]['summary_text'])\n",
        "df[\"target_summary\"] = df[\"target_text\"].apply(lambda x: summarizer(x,\n",
        "    min_length=64,\n",
        "    max_length=512,\n",
        "    no_repeat_ngram_size=3,\n",
        "    encoder_no_repeat_ngram_size=3,\n",
        "    repetition_penalty=3.5,\n",
        "    num_beams=4,\n",
        "    early_stopping=True,)[0]['summary_text'])\n",
        "df.to_csv('/content/parsed_sample_anchor_target_pairs.csv', index=None)\n",
        "print('\\033[1;32m We have successfully finished running this cell.')"
      ],
      "metadata": {
        "id": "8StiI-1d9Hkn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}